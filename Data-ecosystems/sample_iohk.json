{
    _id: ObjectId('60c6dbf7b4955c8b76aa7739'),
    componentChunkName: 'component---src-templates-blog-posts-js',
    path: '/en/blog/posts/page-1/',
    result: {
        pageContext: {
            posts: [
                {
                    publish_date: '2021-06-10T00:00:00.000Z',
                    author: {
                        title: 'Aggelos Kiayias',
                        display_name: 'Prof Aggelos Kiayias',
                        thumbnail: 'https://ucarecdn.com/e9b32a47-1d44-49ae-9f36-3e008e7533c7/',
                        is_team_member: true,
                        is_active: true,
                        localized: [
                            {
                                job_titles: [
                                    {
                                        name: 'Chief scientist',
                                        primary: null
                                    },
                                    {
                                        name: 'Academic Research',
                                        primary: null
                                    }
                                ],
                                lang: 'en',
                                profile_links: {
                                    email: 'aggelos.kiayias@iohk.io',
                                    youtube: '//www.youtube.com/watch?v=nB6eDbnkAk8',
                                    linkedin: null,
                                    twitter: null,
                                    github: null
                                }
                            }
                        ],
                        job_titles: [
                            {
                                name: 'Chief scientist',
                                primary: null
                            },
                            {
                                name: 'Academic Research',
                                primary: null
                            }
                        ],
                        lang: 'en',
                        profile_links: {
                            email: 'aggelos.kiayias@iohk.io',
                            youtube: '//www.youtube.com/watch?v=nB6eDbnkAk8',
                            linkedin: null,
                            twitter: null,
                            github: null
                        },
                        profile_url: '/blog/authors/aggelos-kiayias/',
                        blog_posts: []
                    },
                    video_id: null,
                    main_image: 'https://ucarecdn.com/7aaaa825-7c80-4bfb-8712-a1e66bc809b8/',
                    custom_meta_img: null,
                    old_url: null,
                    haskell: null,
                    localized: [
                        {
                            lang: 'en',
                            title: 'Stablefees and the Decentralized Reserve System',
                            subtitle: 'Exploring a new mechanism to help make fees fair, stable, and more predictable over time',
                            audio: null,
                            soundcloud: [],
                            body_content: 'Facilitating transactions in cryptocurrency platforms stumbles on the dual utility of the platform’s underlying asset. On the one hand, users can hold and trade it as part of their investment portfolios. On the other hand, it supplies the necessary “fuel” for processing transactions. \n\nThis duality suggests that the system should have a mechanism for adjusting transaction costs, so they remain competitive and reasonable. Also, the bounded throughput of decentralized platforms per unit of time introduces another hurdle: the system should also allow the users to discover the correct price for timely transaction processing, depending on their individual needs. \n\nWhy not drop transaction fees altogether? Three reasons: One, transaction processing incurs costs on the system’s side (in terms of computation and storage). It is reasonable to allow transaction processors (stake pool operators, in the case of Cardano) to offset their costs. Two, even with a theoretically infinite capacity, it is important to prevent transaction issuers from saturating the network with worthless transactions. Three, it is appropriate to incentivize transaction processors to provide quality of service. A surge in demand should influence their payoffs accordingly.\n\nAdding a fee to each transaction can address the above considerations. \n\n### Bitcoin and beyond\n\nBitcoin set out the first mechanism for pricing transactions in distributed ledger platforms. This mechanism resembles a first-price auction: transactions bid for a place in a block naming a specific reward, and block producers select the transactions that they prefer to include. Block producers also get rewarded with the right to mint new coins, i.e., their operation is subsidized by the whole community via inflation of the total coin supply. Inflation drops geometrically over time, and transaction fees become increasingly dominant in the rewards. This mechanism, while enabling Bitcoin to run for well over a decade, has been criticized for its inefficiency. Transaction costs have also risen over time.\n\nIn this blog post, we explore a new mechanism that builds on Cardano\'s approach to ledger rules and system assets, and complements the [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) concept. The objective is making fees fair, stable, and predictable over time. We describe the mechanism in the context of Cardano. However, it can be adapted to any other cryptocurrency with similar characteristics.\n\n### Introducing \'Stablefees\'\n\nThe core idea behind Stablefees is to have a base price for transactions through pegging to a basket of commodities or currencies. Stablefees includes a native "decentralized reserve" contract that issues and manages a stablecoin pegged to the basket. A comparison in the fiat world might be the International Monetary Fund’s[ SDR](https://www.imf.org/en/About/Factsheets/Sheets/2016/08/01/14/51/Special-Drawing-Right-SDR), (established in 1969) and valued based on a basket of five currencies—the U.S. dollar, the euro, the Chinese renminbi, the Japanese yen, and the British pound sterling. The stablecoin --- let’s call it "Basket Equivalent Coin" (BEC) --- is the currency used for paying transaction fees (and all other real world pricing needs of the platform, e.g., SPO costs). \n\nIn this system, ada will play a dual role: Reserve asset of the decentralized reserve, and reward currency for staking. It will also be the fall-back currency in extreme scenarios where the reserve contract is in a liquidity crunch. Before a transaction, the issuer will have to obtain BECs, either via other third parties or directly by sending ada to the decentralized reserve contract. On what basis will the reserve issue BECs? The reserve contract will also issue equity shares -we will call them decentralized equity coins (DECs)-, in exchange of ada. Leveraging the value of DECs, the decentralized reserve will often adjust the value of BEC so it is pegged on the underlying basket of commodities. In other words, DECs will absorb the fluctuations of ada vs. the basket to ensure that the real-world value of BECs remains stable (cf. the [AgeUSD stablecoin design](https://github.com/Emurgo/age-usd) that has been already [deployed and used on Ergo](https://sigmausd.io/#/)). \n\nThis trinity of coinage, issued natively by the system, will attract different cohorts. BECs\' stability and liquidity might be attractive to risk-averse, transaction-intensive holders. DECs will offer the highest rewards if ada goes up, but also take the most significant hit when ada goes down. Long-term holders may find DECs more attractive. Also, since decentralized reserve prices these coins in ada, both BECs and DECs can facilitate participation in staking and governance. Returns can be issued at different rates, reflecting the different nature of each coin. Ultimately, rewards will always be denominated and payable in ada, which will remain the most versatile of all three coins.\n\n### Oracles\n\nThe centerpiece of this mechanism is an on-chain oracle that determines the price of the basket in ada. SPOs can implement this oracle in a decentralized manner. The reserve can offer extra rewards to all oracle contributors from the fees collected during BEC/DEC issuances. This will ensure two things: thousands of geographically-diverse contributors, and ledger rules calculating a synthesized exchange rate in some canonical way (through a weighted median across all price submissions in an epoch, for example). If oracle contributors manipulate their contributions, they can be held accountable by tracking their reputation and performance on-chain.\n\n### The pricing mechanism\n\nHow would one price transactions and reward block producers? Using the current approach in Cardano, each transaction will be deterministically mapped to a precise value denominated in BECs, using a formula determined by the ledger rules. The formula will take into account both transaction size and its computational requirements, and may also incorporate runtime metrics (such as the average system load). The resulting value will be the base fee guaranteeing that the transaction will be processed by the system. Given the base fee, end users will be able to apply a multiplier if they wish (which will be a value at least 1, e.g., 1.5x, 3x, etc.) to increase the fee and accelerate processing. This will become relevant at times of surging demand.  \n\nThis approach has one advantage when compared with the first-price auction model: the pricing mechanism is continuously stabilized to a reasonable default value. Users perform price discovery in one direction only to accelerate processing, if required. Also, transaction issuers can store BECs to secure their future transaction-issuing ability without being affected by ada price volatility.\n\n### Stablefees and Babel fees\n\nThe Stablefees mechanism can be considered a natural extension of [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) ---spot conversion of BECs into ada by the decentralized reserve. Both mechanisms complement (and are compatible with) each other. Babel fees can be deployed together with Stablefees with just one change: Using BECs to cover Babel fee liabilities, instead of ada. This also means that fees will always be payable in ada (via a Babel fee liability convertible in ada on the spot). Hence, the whole mechanism is backwards compatible: it won’t affect occasional users who just hold ada and do not wish to obtain BECs.  \n\nA final point about diversity. While the above narrative identifies a unique and global BEC, the same mechanism can be used to issue regional BECs pegged to different baskets of commodities, which could possibly be weighted differently. Such “regional” BECs will be able to increase system inclusivity, while enabling SPOs to have more fine-grained policies in terms of transaction inclusion.\n\n### Stablefees \'lite\'\n\nThe above mechanism requires a decentralized reserve contract and the issuance of BECs and DECs by the contract to buyers. A “lite” version avoids the reserve contract and directly adjusts the fee formula by pegging it onto the agreed basket of commodities through the price oracle. The resulting system denominates transaction fees nominally in BECs and immediately converts them into ada. The payable amount fluctuates, depending on the value of BEC. The mechanism is otherwise identical, also facilitating unidirectional price discovery through the multiplier. The only disadvantage is that a prospective transaction issuer has no access to a native token that enables transaction processing predictably; transaction issuers must pay fees in ada. Still, the fees will continuously adjust and remain stable via the pegging mechanism with respect to the basket. As a result, a transaction issuer will be able to organize their off-chain asset portfolio to meet their transaction needs effectively.\n\n### The road ahead\n\nOur team is currently researching the granular details of the Stablefees mechanism. Once this research is complete, Stablefees can be integrated into Cardano to offer fair and predictable transaction pricing. Moreover, the price oracle and the global BEC (and regional variants, if included) will undoubtedly find uses beyond paying transaction fees, expanding the capabilities of decentralized applications in the Cardano ecosystem.',
                            uses_mathjax: false,
                            attachments: []
                        }
                    ],
                    lang: 'en',
                    title: 'Stablefees and the Decentralized Reserve System',
                    subtitle: 'Exploring a new mechanism to help make fees fair, stable, and more predictable over time',
                    audio: null,
                    soundcloud: [],
                    body_content: 'Facilitating transactions in cryptocurrency platforms stumbles on the dual utility of the platform’s underlying asset. On the one hand, users can hold and trade it as part of their investment portfolios. On the other hand, it supplies the necessary “fuel” for processing transactions. \n\nThis duality suggests that the system should have a mechanism for adjusting transaction costs, so they remain competitive and reasonable. Also, the bounded throughput of decentralized platforms per unit of time introduces another hurdle: the system should also allow the users to discover the correct price for timely transaction processing, depending on their individual needs. \n\nWhy not drop transaction fees altogether? Three reasons: One, transaction processing incurs costs on the system’s side (in terms of computation and storage). It is reasonable to allow transaction processors (stake pool operators, in the case of Cardano) to offset their costs. Two, even with a theoretically infinite capacity, it is important to prevent transaction issuers from saturating the network with worthless transactions. Three, it is appropriate to incentivize transaction processors to provide quality of service. A surge in demand should influence their payoffs accordingly.\n\nAdding a fee to each transaction can address the above considerations. \n\n### Bitcoin and beyond\n\nBitcoin set out the first mechanism for pricing transactions in distributed ledger platforms. This mechanism resembles a first-price auction: transactions bid for a place in a block naming a specific reward, and block producers select the transactions that they prefer to include. Block producers also get rewarded with the right to mint new coins, i.e., their operation is subsidized by the whole community via inflation of the total coin supply. Inflation drops geometrically over time, and transaction fees become increasingly dominant in the rewards. This mechanism, while enabling Bitcoin to run for well over a decade, has been criticized for its inefficiency. Transaction costs have also risen over time.\n\nIn this blog post, we explore a new mechanism that builds on Cardano\'s approach to ledger rules and system assets, and complements the [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) concept. The objective is making fees fair, stable, and predictable over time. We describe the mechanism in the context of Cardano. However, it can be adapted to any other cryptocurrency with similar characteristics.\n\n### Introducing \'Stablefees\'\n\nThe core idea behind Stablefees is to have a base price for transactions through pegging to a basket of commodities or currencies. Stablefees includes a native "decentralized reserve" contract that issues and manages a stablecoin pegged to the basket. A comparison in the fiat world might be the International Monetary Fund’s[ SDR](https://www.imf.org/en/About/Factsheets/Sheets/2016/08/01/14/51/Special-Drawing-Right-SDR), (established in 1969) and valued based on a basket of five currencies—the U.S. dollar, the euro, the Chinese renminbi, the Japanese yen, and the British pound sterling. The stablecoin --- let’s call it "Basket Equivalent Coin" (BEC) --- is the currency used for paying transaction fees (and all other real world pricing needs of the platform, e.g., SPO costs). \n\nIn this system, ada will play a dual role: Reserve asset of the decentralized reserve, and reward currency for staking. It will also be the fall-back currency in extreme scenarios where the reserve contract is in a liquidity crunch. Before a transaction, the issuer will have to obtain BECs, either via other third parties or directly by sending ada to the decentralized reserve contract. On what basis will the reserve issue BECs? The reserve contract will also issue equity shares -we will call them decentralized equity coins (DECs)-, in exchange of ada. Leveraging the value of DECs, the decentralized reserve will often adjust the value of BEC so it is pegged on the underlying basket of commodities. In other words, DECs will absorb the fluctuations of ada vs. the basket to ensure that the real-world value of BECs remains stable (cf. the [AgeUSD stablecoin design](https://github.com/Emurgo/age-usd) that has been already [deployed and used on Ergo](https://sigmausd.io/#/)). \n\nThis trinity of coinage, issued natively by the system, will attract different cohorts. BECs\' stability and liquidity might be attractive to risk-averse, transaction-intensive holders. DECs will offer the highest rewards if ada goes up, but also take the most significant hit when ada goes down. Long-term holders may find DECs more attractive. Also, since decentralized reserve prices these coins in ada, both BECs and DECs can facilitate participation in staking and governance. Returns can be issued at different rates, reflecting the different nature of each coin. Ultimately, rewards will always be denominated and payable in ada, which will remain the most versatile of all three coins.\n\n### Oracles\n\nThe centerpiece of this mechanism is an on-chain oracle that determines the price of the basket in ada. SPOs can implement this oracle in a decentralized manner. The reserve can offer extra rewards to all oracle contributors from the fees collected during BEC/DEC issuances. This will ensure two things: thousands of geographically-diverse contributors, and ledger rules calculating a synthesized exchange rate in some canonical way (through a weighted median across all price submissions in an epoch, for example). If oracle contributors manipulate their contributions, they can be held accountable by tracking their reputation and performance on-chain.\n\n### The pricing mechanism\n\nHow would one price transactions and reward block producers? Using the current approach in Cardano, each transaction will be deterministically mapped to a precise value denominated in BECs, using a formula determined by the ledger rules. The formula will take into account both transaction size and its computational requirements, and may also incorporate runtime metrics (such as the average system load). The resulting value will be the base fee guaranteeing that the transaction will be processed by the system. Given the base fee, end users will be able to apply a multiplier if they wish (which will be a value at least 1, e.g., 1.5x, 3x, etc.) to increase the fee and accelerate processing. This will become relevant at times of surging demand.  \n\nThis approach has one advantage when compared with the first-price auction model: the pricing mechanism is continuously stabilized to a reasonable default value. Users perform price discovery in one direction only to accelerate processing, if required. Also, transaction issuers can store BECs to secure their future transaction-issuing ability without being affected by ada price volatility.\n\n### Stablefees and Babel fees\n\nThe Stablefees mechanism can be considered a natural extension of [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) ---spot conversion of BECs into ada by the decentralized reserve. Both mechanisms complement (and are compatible with) each other. Babel fees can be deployed together with Stablefees with just one change: Using BECs to cover Babel fee liabilities, instead of ada. This also means that fees will always be payable in ada (via a Babel fee liability convertible in ada on the spot). Hence, the whole mechanism is backwards compatible: it won’t affect occasional users who just hold ada and do not wish to obtain BECs.  \n\nA final point about diversity. While the above narrative identifies a unique and global BEC, the same mechanism can be used to issue regional BECs pegged to different baskets of commodities, which could possibly be weighted differently. Such “regional” BECs will be able to increase system inclusivity, while enabling SPOs to have more fine-grained policies in terms of transaction inclusion.\n\n### Stablefees \'lite\'\n\nThe above mechanism requires a decentralized reserve contract and the issuance of BECs and DECs by the contract to buyers. A “lite” version avoids the reserve contract and directly adjusts the fee formula by pegging it onto the agreed basket of commodities through the price oracle. The resulting system denominates transaction fees nominally in BECs and immediately converts them into ada. The payable amount fluctuates, depending on the value of BEC. The mechanism is otherwise identical, also facilitating unidirectional price discovery through the multiplier. The only disadvantage is that a prospective transaction issuer has no access to a native token that enables transaction processing predictably; transaction issuers must pay fees in ada. Still, the fees will continuously adjust and remain stable via the pegging mechanism with respect to the basket. As a result, a transaction issuer will be able to organize their off-chain asset portfolio to meet their transaction needs effectively.\n\n### The road ahead\n\nOur team is currently researching the granular details of the Stablefees mechanism. Once this research is complete, Stablefees can be integrated into Cardano to offer fair and predictable transaction pricing. Moreover, the price oracle and the global BEC (and regional variants, if included) will undoubtedly find uses beyond paying transaction fees, expanding the capabilities of decentralized applications in the Cardano ecosystem.',
                    uses_mathjax: false,
                    attachments: [],
                    slug: 'stablefees-and-the-decentralized-reserve-system',
                    url: '/blog/posts/2021/06/10/stablefees-and-the-decentralized-reserve-system/',
                    read_time: 7
                },
                {
                    publish_date: '2021-06-08T00:00:00.000Z',
                    author: {
                        title: 'Niamh Ahern',
                        display_name: 'Niamh Ahern',
                        thumbnail: 'https://ucarecdn.com/8ac49795-0145-4168-8d90-d667340a7ac8/',
                        is_team_member: true,
                        is_active: true,
                        localized: [
                            {
                                job_titles: [
                                    {
                                        name: 'Technical Writer',
                                        primary: null
                                    },
                                    {
                                        name: 'Education',
                                        primary: null
                                    }
                                ],
                                lang: 'en',
                                profile_links: {
                                    email: 'niamh.ahern@iohk.io',
                                    youtube: '',
                                    linkedin: 'https://www.linkedin.com/in/niamh-ahern-67849949/',
                                    twitter: 'https://twitter.com/nahern_iohk?lang=en',
                                    github: 'https://github.com/nahern'
                                }
                            }
                        ],
                        job_titles: [
                            {
                                name: 'Technical Writer',
                                primary: null
                            },
                            {
                                name: 'Education',
                                primary: null
                            }
                        ],
                        lang: 'en',
                        profile_links: {
                            email: 'niamh.ahern@iohk.io',
                            youtube: '',
                            linkedin: 'https://www.linkedin.com/in/niamh-ahern-67849949/',
                            twitter: 'https://twitter.com/nahern_iohk?lang=en',
                            github: 'https://github.com/nahern'
                        },
                        profile_url: '/blog/authors/niamh-ahern/',
                        blog_posts: []
                    },
                    video_id: null,
                    main_image: 'https://ucarecdn.com/350386c8-b07f-44f0-9787-0c898a3d0460/',
                    custom_meta_img: null,
                    old_url: null,
                    haskell: null,
                    localized: [
                        {
                            lang: 'en',
                            title: 'A close look at the software running Cardano',
                            subtitle: 'Learn about the ‘stack’ of components that interact to run the blockchain platform',
                            audio: null,
                            soundcloud: [
                                {
                                    trackid: 1066347517
                                }
                            ],
                            body_content: 'Cardano has been designed in modules, with linked components that can be used in various ways. These components form the Cardano ‘platform stack’. They work together under the hood to support the construction and use of the live Cardano blockchain.\n\nWe are currently in the early testnet phase on the way to the Alonzo hard fork, which will bring full smart contract capability to Cardano. This process is highly complex, requiring the steady upgrade of the different elements which make up the Cardano platform, and their careful integration and testing. So, it is a good time to revisit these components, explain some of the terminology, and discover how they interact within the ‘platform stack’.\n\n## Elements of the Cardano platform stack\n\n![](https://ucarecdn.com/913ea221-dd67-4938-84be-3461f79b0baa/)\n\n**Figure 1. Components that communicate with the Cardano node**\n\nThe platform stack for Cardano includes these core components:\n\n* Cardano node (and associated processes)\n* Cardano wallet\n* Wallet command line interface (CLI)\n* DB Sync (synchronizes blockchain data with a relational database)\n* PostgreSQL database (which interacts with GraphQL, REST API, and Smash)\n* Smash server\n* Rosetta API (blockchain communication protocol)\n\nNote that the Daedalus wallet is not part of the core stack, but does communicate with the components (Figure 1). \n\n### The node and the networking layer\n\nFirst, let\'s take a look at the [Cardano node](https://github.com/input-output-hk/cardano-node). This software runs on your computer and underpins the network, enabling everyone to participate in the decentralized blockchain. The node integrates the consensus, ledger, and networking sub-components, providing top-level configuration, API, CLI, logging, memory management, and monitoring capabilities that can be used by other Cardano components or by skilled users. Daedalus is a full-node wallet, so if you are running that on your local machine, you are effectively helping to run the network. \n\n*The networking layer*\n\nNext, we have the networking layer. This links each Cardano node into a distributed system that manages the blockchain and associated services. The network consists of a collection of nodes that communicate with each other to maintain the distributed ledger, support transaction submission, and interact with user wallets and other services. The core of the network is built around the decentralized nodes – the stake pools – that collectively validate blocks, and add new blocks to the chain. They are supported by dedicated relay nodes that manage network connections and establish the structure of the network as a whole. The dedicated consumer nodes that are run by the Daedalus wallet and other services connect to this network to track and submit transactions on-chain.\n\nCardano nodes maintain connections with their peers. A set of mini-protocols enable communication between the nodes. Each mini-protocol implements a basic information exchange requirement, such as informing peers of the latest block, sharing blocks as needed, or sharing new transactions around the Cardano network. For connection purposes, mini-protocols are determined by the version of the network protocol. \n\n### Cardano wallet backend\n\nThe [Cardano wallet](https://github.com/input-output-hk/cardano-wallet) backend component supports the graphical user interface of the Daedalus wallet. It is used to send and receive ada. Behind the scenes, the wallet runs a full Cardano node. Unlike a light client wallet, it loads the entire shared ledger and validates all transactions, thus bolstering the security of the blockchain for everyone.\n\n### Wallet command line interface (CLI)\n\nThe wallet command line interface (CLI) supports interactions with the actual blockchain. More technically advanced users can use the CLI  to work with a collection of tools for generating keys, constructing transactions, creating certificates, and performing other tasks. It is organized in a hierarchy of subcommands, and each level comes with its own built-in documentation of command syntax and options.\n\n### DB Sync\n\n[DB Sync](https://github.com/input-output-hk/cardano-db-sync) is a component that follows the activities on the Cardano chain and stores blocks and transactions in PostgreSQL. As a ‘middleware’ component, it powers [cardano-graphql](https://github.com/input-output-hk/cardano-graphql). DB Sync stores blockchain data fetched from [cardano-node](https://github.com/input-output-hk/cardano-node) in an intermediate database to enable higher-level interfaces for blockchain exploration. It also provides a number of queries to fetch Cardano blockchain data from the PostgreSQL, and supports services such as the [Cardano Explorer](https://explorer.cardano.org/en.html), a graphical user interface that reflects the blockchain data in a straightforward way. Cardano GraphQL is a cross-platform API for the GraphQL data query language. \n\n### Rosetta API\n\nThe Rosetta application programming interface provides a high-level interface that aims to make the integration process easier, faster, and more reliable so that you can build once and integrate your blockchain everywhere. We have created a unique [cardano-rosetta](https://github.com/input-output-hk/cardano-rosetta) implementation to simplify the process of integration with Cardano. This interface is particularly useful for exchanges, since they can interact with the Cardano chain using the same interface that they use with other blockchains.\n\n### Looking forward\n\nWith [smart contracts](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) coming to Cardano soon, this means that [Plutus](https://iohk.io/en/blog/posts/2021/04/13/plutus-what-you-need-to-know/), the native smart contract language, and other smart contract development languages like [Marlowe](https://iohk.io/en/blog/posts/2021/05/26/reimagining-peer-to-peer-finance-with-marlowe/) for finance and [Glow](https://glow-lang.org/) for DApps will be integrated into the Cardano stack. IO Global’s engineers will provide new and extended components to compile Plutus, Marlowe, and Glow scripts, submit them on-chain, and interact with them (Figure 2).\n\n![](https://ucarecdn.com/49d00118-da94-4dde-9be2-1a721c698a39/)\n\n**Figure 2. Plutus, Marlowe, Glow, Solidity, and IELE can all be used to write Cardano smart contracts**\n\nThe [Alonzo protocol upgrade](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) will build on recent token upgrades and is being deployed to the mainnet via several testnets. Our Plutus partners and Plutus Pioneers will help us to test Plutus Core and will be part of the user acceptance phase before mainnet deployment. At this point we will officially add the Plutus and Marlowe components, such as both interpreters, to Cardano’s platform stack. \n\n*To keep up to date with the Alonzo rollout, please check our social channels and blog page.*',
                            uses_mathjax: false,
                            attachments: []
                        },
                        {
                            lang: 'jp',
                            title: 'Cardanoで稼働するソフトウェアに注目',
                            subtitle: 'ブロックチェーンプラットフォームを実行するために相互作用するコンポーネントの「スタック」を知ろう',
                            audio: null,
                            soundcloud: [],
                            body_content: 'Cardanoはモジュール単位で設計されています。ここには、さまざまな方法で使用できるコンポーネントがリンクされています。こうしたコンポーネントはCardano「プラットフォームスタック」を形成しています。これらは内部で共に作動し、稼働するCardanoブロックチェーンの構造と使用を支えています。\n現在は、Cardnaoに完全なスマートコントラクト機能をもたらすAlonzoハードフォークに向けた、初期テストネットの段階にあります。このプロセスは極めて複雑で、Cardanoプラットフォームを構成するさまざまな要素をしっかりとアップグレードし、慎重に統合、テストする必要があります。したがって、今こそこうしたコンポーネントを振り返り、一部の用語を説明し、「プラットフォームスタック」の中でこれらがいかに相互作用するかを考察するいい機会です。\n\n## Cardanoプラットフォームスタックの要素\n\n\n![](https://ucarecdn.com/913ea221-dd67-4938-84be-3461f79b0baa/)\n\n**図1：Cardanoノードと通信するコンポーネント**\n\nCardanoプラットフォームスタックには以下のコアコンポーネントが含まれます。\n\n* Cardanoノード（および関連プロセス）\n* Cardanoウォレット\n* ウォレットコマンドラインインターフェイス（CLI）\n* DB Sync（ブロックチェーンデータを関連するデータベースと同期)\n* PostgreSQLデータベース（GraphQL、REST API、SMASHと相互作用）\n* SMASHサーバー\n* Rosetta API（ブロックチェーン通信プロトコル）\n\n注：Daedalusはコアスタックに含まれませんが、コンポーネントと通信します（図1）。\n\n### ノードとネットワーク層\n\nはじめに、Cardanoノードを見てみましょう。このソフトウェアは個人のコンピューター上で実行されてネットワークを支え、誰もが分散型ブロックチェーンに参加できるようにするものです。ノードは、コンセンサス、台帳、ネットワークのサブコンポーネントを統合し、他のCardanoコンポーネントまたは熟練したユーザーが使用できるトップレベルの設定、API、CLI、ログ、メモリー管理、そして監視機能を提供します。Daedalusはフルノードウォレットで、ローカルマシンで実行することにより、実質的にネットワークの実行に貢献することになります。\n\n*ネットワーク層*\n\n次にネットワーク層です。これは各Cardanoノードを、ブロックチェーンを管理する1つの分散型システムと関連サービスにリンクさせます。ネットワークは、互いに通信しあって分散型台帳を維持し、トランザクションの送信を支え、ユーザーのウォレットや他のサービスとやり取りするノードの集合で構成されます。ネットワークのコアは、集団的にブロックを検証し、チェーンに新たなブロックを追加する分散型ノード（ステークプール）を中心に構築されています。これを支えるのは、ネットワーク接続を管理し、ネットワークの構造を全体として確立する専用のリレーノードです。Daedalusウォレットや他のサービスが実行する専用のコンシューマーノードはこのネットワークに接続し、チェーン上でトランザクションを追跡、送信します。\nCardanoノードはピアとの接続を維持します。一連のミニプロトコルがノード間の通信を可能にします。各ミニプロトコルは基本的な情報交換要件を実装しています。例えば、Cardanoネットワークのあちこちでピアに最新ブロックを伝える、必要に応じてブロックを共有する、新たなトランザクションを共有する、などです。ミニプロトコルは、接続を目的として、ネットワークプロトコルのバージョンによって決定されます。\n\n### Cardanoウォレットバックエンド\n\nCardanoウォレットバックエンドコンポーネントはDaedalusウォレットのグラフィカルユーザーインターフェイスをサポートしています。これは、ADAの送受信に使用されます。ウォレットはバックグラウンドでCardanoフルノードを実行しています。軽量クライアントウォレットとは異なり、これは共有された台帳全体をロードし、すべてのトランザクションを検証するため、全員にとってブロックチェーンのセキュリティが強化されます。\n\n### ウォレットコマンドラインインターフェイス（CLI）\n\nウォレットコマンドラインインターフェイス（CLI）は実際のブロックチェーンとのやり取りをサポートします。高度な技術を持つユーザーは、CLIにより、ツールのコレクションを使用して、鍵の生成やトランザクションの構築、証明書の作成、その他のタスクを実行することができます。これはサブコマンドの階層順に整理され、各レベルには、コマンドシンタックスやオプションのビルトインドキュメンテーションが付されています。\n\n### DB Sync\n\nDB SyncはCardanoチェーンのアクティビティに従い、PostgreSQLにブロックとトランザクションを保存するコンポーネントです。「ミドルウェア」コンポーネントとして、cardano-graphqlを強化します。DB Syncは、ブロックチェーン探索のための高レベルのインターフェイスを有効にするために、cardano-nodeからフェッチしたブロックチェーンを中間データベースに保存します。また、数多くのクエリを提供してPostgreSQLからCardanoブロックチェーンデータをフェッチし、ブロックチェーンデータをシンプルに反映するグラフィカルユーザーインターフェイス、Cardanoエクスプローラーなどのサービスをサポートします。Cardano GraphQLは、GraphQLデータクエリ言語用のクロスプラットフォームAPIです。\n\n### Rosetta API\n\nRosettaアプリケーションプログラミングインターフェイスは、統合プロセスをより簡単に、より速く、より信頼できるものにすることを目的とした高レベルインターフェイスを提供します。これにより、一度構築すると、どこでもブロックチェーンを統合できます。Cardanoとの統合プロセスを簡易化するために、私たちはユニークなcardano-rosettaを作成しました。このインターフェイスは、取引所に特に役立ちます。他のブロックチェーンで使用するものと同じインターフェイスを使って、Cardanoチェーンとやり取りすることができるためです。\n\n### 今後\n\nまもなくCardanoにスマートコントラクトが搭載されますが、これは、スマートコントラクトのネイティブ言語Plutusや、金融仕様のMarlowe、DApp仕様のGlowなど、その他のスマートコントラクト開発言語がCardanoスタックに統合されることを意味します。IO Globalのエンジニアは、Plutus、Marlowe、Glowのスクリプトをコンパイルし、チェーン上に送信し、やり取りするための新コンポーネントや拡張コンポーネントを提供します（図2）。\n\n![](https://ucarecdn.com/49d00118-da94-4dde-9be2-1a721c698a39/)\n\n**図2：Plutus、Marlowe、Glow、Solidity、IELEはすべて、Cardanoスマートコントラクトの作成に使用可能**\n\nAlonzoプロトコルアップグレードは、最近のトークンアップグレードの上に構築され、複数のテストネットを経てメインネットで展開されます。PlutusパートナーやPlutusパイオニアたちはPlutus Coreのテストに協力し、メインネットへの展開前のユーザー受け入れフェーズに参加します。この時点で、インタープリターなどのPlutusとMarloweコンポーネントはCardanoプラットフォームスタックへと公式に追加されます。\nAlonzoロールアウトの最新情報は、ソーシャルチャネルとブログをチェックしてください。\n',
                            uses_mathjax: false,
                            attachments: []
                        }
                    ],
                    lang: 'en',
                    title: 'A close look at the software running Cardano',
                    subtitle: 'Learn about the ‘stack’ of components that interact to run the blockchain platform',
                    audio: null,
                    soundcloud: [
                        {
                            trackid: 1066347517
                        }
                    ],
                    body_content: 'Cardano has been designed in modules, with linked components that can be used in various ways. These components form the Cardano ‘platform stack’. They work together under the hood to support the construction and use of the live Cardano blockchain.\n\nWe are currently in the early testnet phase on the way to the Alonzo hard fork, which will bring full smart contract capability to Cardano. This process is highly complex, requiring the steady upgrade of the different elements which make up the Cardano platform, and their careful integration and testing. So, it is a good time to revisit these components, explain some of the terminology, and discover how they interact within the ‘platform stack’.\n\n## Elements of the Cardano platform stack\n\n![](https://ucarecdn.com/913ea221-dd67-4938-84be-3461f79b0baa/)\n\n**Figure 1. Components that communicate with the Cardano node**\n\nThe platform stack for Cardano includes these core components:\n\n* Cardano node (and associated processes)\n* Cardano wallet\n* Wallet command line interface (CLI)\n* DB Sync (synchronizes blockchain data with a relational database)\n* PostgreSQL database (which interacts with GraphQL, REST API, and Smash)\n* Smash server\n* Rosetta API (blockchain communication protocol)\n\nNote that the Daedalus wallet is not part of the core stack, but does communicate with the components (Figure 1). \n\n### The node and the networking layer\n\nFirst, let\'s take a look at the [Cardano node](https://github.com/input-output-hk/cardano-node). This software runs on your computer and underpins the network, enabling everyone to participate in the decentralized blockchain. The node integrates the consensus, ledger, and networking sub-components, providing top-level configuration, API, CLI, logging, memory management, and monitoring capabilities that can be used by other Cardano components or by skilled users. Daedalus is a full-node wallet, so if you are running that on your local machine, you are effectively helping to run the network. \n\n*The networking layer*\n\nNext, we have the networking layer. This links each Cardano node into a distributed system that manages the blockchain and associated services. The network consists of a collection of nodes that communicate with each other to maintain the distributed ledger, support transaction submission, and interact with user wallets and other services. The core of the network is built around the decentralized nodes – the stake pools – that collectively validate blocks, and add new blocks to the chain. They are supported by dedicated relay nodes that manage network connections and establish the structure of the network as a whole. The dedicated consumer nodes that are run by the Daedalus wallet and other services connect to this network to track and submit transactions on-chain.\n\nCardano nodes maintain connections with their peers. A set of mini-protocols enable communication between the nodes. Each mini-protocol implements a basic information exchange requirement, such as informing peers of the latest block, sharing blocks as needed, or sharing new transactions around the Cardano network. For connection purposes, mini-protocols are determined by the version of the network protocol. \n\n### Cardano wallet backend\n\nThe [Cardano wallet](https://github.com/input-output-hk/cardano-wallet) backend component supports the graphical user interface of the Daedalus wallet. It is used to send and receive ada. Behind the scenes, the wallet runs a full Cardano node. Unlike a light client wallet, it loads the entire shared ledger and validates all transactions, thus bolstering the security of the blockchain for everyone.\n\n### Wallet command line interface (CLI)\n\nThe wallet command line interface (CLI) supports interactions with the actual blockchain. More technically advanced users can use the CLI  to work with a collection of tools for generating keys, constructing transactions, creating certificates, and performing other tasks. It is organized in a hierarchy of subcommands, and each level comes with its own built-in documentation of command syntax and options.\n\n### DB Sync\n\n[DB Sync](https://github.com/input-output-hk/cardano-db-sync) is a component that follows the activities on the Cardano chain and stores blocks and transactions in PostgreSQL. As a ‘middleware’ component, it powers [cardano-graphql](https://github.com/input-output-hk/cardano-graphql). DB Sync stores blockchain data fetched from [cardano-node](https://github.com/input-output-hk/cardano-node) in an intermediate database to enable higher-level interfaces for blockchain exploration. It also provides a number of queries to fetch Cardano blockchain data from the PostgreSQL, and supports services such as the [Cardano Explorer](https://explorer.cardano.org/en.html), a graphical user interface that reflects the blockchain data in a straightforward way. Cardano GraphQL is a cross-platform API for the GraphQL data query language. \n\n### Rosetta API\n\nThe Rosetta application programming interface provides a high-level interface that aims to make the integration process easier, faster, and more reliable so that you can build once and integrate your blockchain everywhere. We have created a unique [cardano-rosetta](https://github.com/input-output-hk/cardano-rosetta) implementation to simplify the process of integration with Cardano. This interface is particularly useful for exchanges, since they can interact with the Cardano chain using the same interface that they use with other blockchains.\n\n### Looking forward\n\nWith [smart contracts](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) coming to Cardano soon, this means that [Plutus](https://iohk.io/en/blog/posts/2021/04/13/plutus-what-you-need-to-know/), the native smart contract language, and other smart contract development languages like [Marlowe](https://iohk.io/en/blog/posts/2021/05/26/reimagining-peer-to-peer-finance-with-marlowe/) for finance and [Glow](https://glow-lang.org/) for DApps will be integrated into the Cardano stack. IO Global’s engineers will provide new and extended components to compile Plutus, Marlowe, and Glow scripts, submit them on-chain, and interact with them (Figure 2).\n\n![](https://ucarecdn.com/49d00118-da94-4dde-9be2-1a721c698a39/)\n\n**Figure 2. Plutus, Marlowe, Glow, Solidity, and IELE can all be used to write Cardano smart contracts**\n\nThe [Alonzo protocol upgrade](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) will build on recent token upgrades and is being deployed to the mainnet via several testnets. Our Plutus partners and Plutus Pioneers will help us to test Plutus Core and will be part of the user acceptance phase before mainnet deployment. At this point we will officially add the Plutus and Marlowe components, such as both interpreters, to Cardano’s platform stack. \n\n*To keep up to date with the Alonzo rollout, please check our social channels and blog page.*',
                    uses_mathjax: false,
                    attachments: [],
                    slug: 'a-close-look-at-the-software-running-cardano',
                    url: '/blog/posts/2021/06/08/a-close-look-at-the-software-running-cardano/',
                    read_time: 5
                },
                {
                    publish_date: '2021-06-02T00:00:00.000Z',
                    author: {
                        title: 'Eric Czuleger',
                        display_name: null,
                        thumbnail: 'https://ucarecdn.com/fd70c3a0-974f-406f-88e2-a9956d82cc86/',
                        is_team_member: true,
                        is_active: true,
                        localized: [
                            {
                                job_titles: [
                                    {
                                        name: 'Senior Content Editor',
                                        primary: null
                                    },
                                    {
                                        name: 'Marketing & Communications',
                                        primary: null
                                    }
                                ],
                                lang: 'en',
                                profile_links: {
                                    email: 'eric.czuleger@iohk.io',
                                    youtube: null,
                                    linkedin: 'https://www.linkedin.com/in/eric-czuleger-6b67a395/',
                                    twitter: 'https://twitter.com/eczuleger',
                                    github: null
                                }
                            }
                        ],
                        job_titles: [
                            {
                                name: 'Senior Content Editor',
                                primary: null
                            },
                            {
                                name: 'Marketing & Communications',
                                primary: null
                            }
                        ],
                        lang: 'en',
                        profile_links: {
                            email: 'eric.czuleger@iohk.io',
                            youtube: null,
                            linkedin: 'https://www.linkedin.com/in/eric-czuleger-6b67a395/',
                            twitter: 'https://twitter.com/eczuleger',
                            github: null
                        },
                        profile_url: '/blog/authors/eric-czuleger/',
                        blog_posts: []
                    },
                    video_id: null,
                    main_image: 'https://ucarecdn.com/a654b860-da1e-415c-8eb9-0b6188229740/',
                    custom_meta_img: null,
                    old_url: null,
                    haskell: null,
                    localized: [
                        {
                            lang: 'en',
                            title: 'Nervos partnership to build the first cross-chain bridge with Cardano',
                            subtitle: ' Our new collab lets Cardano and Nervos token holders transmit their value across both platforms while building interoperability across the crypto space',
                            audio: null,
                            soundcloud: [
                                {
                                    trackid: 1060596082
                                }
                            ],
                            body_content: '<!--StartFragment-->\n\nIOHK and Nervos are teaming up to build a bridge of interoperability between Cardano and the Nervos Network. Once completed, this pioneering cross-chain bridge will enable users to transact assets between the two blockchains. The end goal is to foster greater interoperability while expanding the global reach and utility of both Nervos and Cardano.\n\n\n\nThe Nervos ‘Common Knowledge Base’ ([CKB](https://coinmarketcap.com/currencies/nervos-network/historical-data/)) is a permissionless, layer 1, open-source, proof-of-work blockchain protocol focused on creating the foundations for an interoperable universal public network. It allows any crypto asset to be kept in a secure, immutable, and permissionless environment with the added benefit of smart contracts and layer 2 scaling. \n\n\n\nNervos is developing this robust network through three key components. Together, these make up the Universal Passport, Nervos’ approach to next generation interoperability. \n\n\n\n* **PW Core** – enables developers to build applications on all chains\n* **Nervos’ Polyjuice** – an Ethereum-compatible layer that allows developers to port a smart contract from Ethereum to Nervos\n* **Force Bridge** – a trustless bridge that enables cross-chain transactions between Nervos and a spectrum of blockchains. Nervos will use Force Bridge to connect directly to Cardano, which means that users will be able to transact using their existing Cardano wallets.\n\n\n\n## Bridging blockchains with transportable tokens\n\n\n\nSo what does this mean in practice? Holders of Nervos CKByte (CKB) and ada will be able to transact both currencies interchangeably. Nervos users will also be able to take advantage of Cardano\'s native asset standard to create tokens that can be ported and used across both networks. On top of this, the bridge enables developers on both chains gain access to services and features to expand their DApp ecosystem and user bases. \n\n\n\n[Mousebelt](https://www.mousebelt.com/), a full-service blockchain accelerator, will build the bridge with financial support from Nervos. The Cardano team will contribute expertise and resources to connect Cardano to the bridge. Development work is already underway and it is expected to be completed in the next six weeks. \n\n\n\n\'Using the Force Bridge to link the Nervos Network and Cardano is especially exciting given the relationship we have already built with IOHK,\' said Kevin Wang, co-founder of Nervos. \'We have been growing our research and development partnership, but we will soon have a tangible bridge that will also showcase the power of the Force Bridge and push us further along the road to a functional and interoperable network.\'\n\n\n\nThis bridge is just part of our collaboration with Nervos. \'We share a vision of a world that works on a ‘constellation’ of interoperating blockchains,\' says Romain Pellerin, CTO at Input Output. \'We believe that academic research is also fundamental to advancing the entire crypto space. Together we will also be co-authoring academic papers to pioneer improvements to the UTXO model, explore universal accounting standards, and contribute to the future development of decentralized technology through open-source research.\'\n\n\n\nBlockchain technology will only achieve mainstream acceptance when end users are not locked into one blockchain or standard, but can seamlessly access value and utility, regardless of which blockchain they are using. \'Bridges like this are an absolute necessity in order to ensure that users have a seamless experience,\' continued Pellerin. ‘By connecting our communities and finding innovative new ways to work together, as we have been doing with Nervos, we can ensure that blockchain lives up to its promises of creating a fairer and more efficient global financial operating system.\'\n\n\n\n*Check out the [Nervos website](https://www.nervos.org/) for more information on upcoming partnerships and research initiatives.*\n\n\n\n<!--EndFragment-->',
                            uses_mathjax: false,
                            attachments: []
                        },
                        {
                            lang: 'jp',
                            title: 'NervosとのパートナーシップでCardanoと初のクロスチェーンブリッジを構築',
                            subtitle: '新たなコラボレーションにより、暗号資産界全体に相互運用性を構築。CardanoとNervosのトークン所有者は、両プラットフォーム間で資産取引が可能に',
                            audio: null,
                            soundcloud: [
                                {
                                    trackid: 1060596082
                                }
                            ],
                            body_content: '<!--StartFragment-->\n\nIOHKとNervosは協力してCardanoとNervosネットワーク間に相互運用性を構築します。完成すれば、この先駆的なクロスチェーンのブリッジにより、ユーザーは2つのブロックチェーン間で資産取引が可能になります。最終目標はより優れた相互運用性を促進すること。その間、NervosとCardano両者のグローバルリーチとユーティリティを拡張していきます。\n\n\nNervosの「Common Knowledge Base」（共通知識ベース：CKB）は、パーミッションレス、レイヤー1、オープンソースのプルーフオブワークブロックチェーンプロトコルで、相互運用可能なユニバーサルパブリックネットワークの基礎を築くことに主眼を置いています。これにより、あらゆる暗号資産は、スマートコントラクトとレイヤー2スケーリングのメリットが追加された、安全、不変、そしてパーミッションレスな環境に保管されます。 \n\n\nNervosはこの頑丈なネットワークを3つの主要コンポーネントを軸として開発しています。これらはともに、Nervosの次世代相互運用性へのアプローチであるユニバーサスパスポートを構成するものです。 \n\n\n\n* **PW Core**（PWコア）- 開発者がすべてのチェーンでアプリケーションを構築することを可能にします。\n* **Nervos’ Polyjuice**（Nervosポリジュース）- 開発者がイーサリアムからNervosへスマートコントラクトを移植できるようにするイーサリアム対応レイヤーです。\n\n* **Force Bridge** (フォースブリッジ - Nervosとさまざまなブロックチェーンとのクロスチェーントランザクションを可能にするトラストレスなブリッジです。NervosはForce Bridgeを使用してCardanoと直接接続し、ユーザーは既存のCardanoウォレットを使用してトランザクションを行うことができます。\n\n\n\n## 可搬トークンでブロックチェーンを橋渡しする\n\n\n\nこれは実際何を意味するのでしょうか。NervosのCKByte（CKB）とADA保有者は、両通貨を交換して取引することができます。NervosユーザーはCardanoのネイティブアセット規格を利用してトークンを作成し、両ネットワークを行き来させて、使用することができます。加えて、ブリッジにより開発者は両チェーン上でサービスや機能へアクセスし、自分たちのDAppエコシステムやユーザーベースを拡張することができます。 \n\n\nフルサービスのブロックチェーンアクセラレーター、[Mousebelt](https://www.mousebelt.com/)は、Nervosから財政支援を得てブリッジを構築します。Cardanoチームは、Cardanoとブリッジを接続するために、専門知識とリソースを提供します。開発作業は既に進行中で、今後6週間で完了する見込みです。 \n\n\n\n「Force Bridgeを使用してNervos NetworkとCardanoをリンクすることは、IOHKとの間に既に築き上げられている関係を考えても特にエキサイティングです」と、Nervosの共同創業者Kevin Wang氏は語ります。「私たちは研究開発パートナーシップを育ててきましたが、まもなく実際のブリッジを手にすることができます。これはForce Bridgeのパワーを示すショーケースでもあり、機能的かつ相互運用可能なネットワークへとつながる道にいる私たちをさらに前進させるものです」\n\n\n\nこのブリッジは、Nervosとのコラボレーションの一部に過ぎません。「私たちは、相互運用可能なブロックチェーンの「星座」で機能する世界というビジョンを共有しています」とInput OutputのCTO、Romain Pellerinは述べます。「学術研究も暗号界全体を前進させる基盤となっていると信じています。私たちはまた、UTXOモデルの画期的な改良に関する論文の共同執筆、ユニバーサル会計規格の検討、オープンソースの研究を介した分散型技術の今後の開発への協力を予定しています」\n\n\n\nブロックチェーン技術は、エンドユーザーが1つのブロックチェーンや規格に縛られることなく、どのブロックチェーンを使用していようとも、価値やユーティリティにシームレスにアクセスできて初めて、主流に受け入れられるようになります。「このようなブリッジは、ユーザーにシームレスなエクスペリエンスを提供するうえで絶対に欠かせません」とPellerinは続けます。「私たちとNervosが実行しているように、コミュニティを繋げ、協力するための革新的な方法を見つけることにより、より公正で効率的なグローバル金融オペレーティングシステムを創造するという約束を確実に果たすことができるのです」\n\n\n*予定されているパートナーシップと研究イニシアチブについての詳細は、[Nervos website](https://www.nervos.org/)をご覧ください。*\n\n\n\n\n<!--EndFragment-->',
                            uses_mathjax: false,
                            attachments: []
                        }
                    ],
                    lang: 'en',
                    title: 'Nervos partnership to build the first cross-chain bridge with Cardano',
                    subtitle: ' Our new collab lets Cardano and Nervos token holders transmit their value across both platforms while building interoperability across the crypto space',
                    audio: null,
                    soundcloud: [
                        {
                            trackid: 1060596082
                        }
                    ],
                    body_content: '<!--StartFragment-->\n\nIOHK and Nervos are teaming up to build a bridge of interoperability between Cardano and the Nervos Network. Once completed, this pioneering cross-chain bridge will enable users to transact assets between the two blockchains. The end goal is to foster greater interoperability while expanding the global reach and utility of both Nervos and Cardano.\n\n\n\nThe Nervos ‘Common Knowledge Base’ ([CKB](https://coinmarketcap.com/currencies/nervos-network/historical-data/)) is a permissionless, layer 1, open-source, proof-of-work blockchain protocol focused on creating the foundations for an interoperable universal public network. It allows any crypto asset to be kept in a secure, immutable, and permissionless environment with the added benefit of smart contracts and layer 2 scaling. \n\n\n\nNervos is developing this robust network through three key components. Together, these make up the Universal Passport, Nervos’ approach to next generation interoperability. \n\n\n\n* **PW Core** – enables developers to build applications on all chains\n* **Nervos’ Polyjuice** – an Ethereum-compatible layer that allows developers to port a smart contract from Ethereum to Nervos\n* **Force Bridge** – a trustless bridge that enables cross-chain transactions between Nervos and a spectrum of blockchains. Nervos will use Force Bridge to connect directly to Cardano, which means that users will be able to transact using their existing Cardano wallets.\n\n\n\n## Bridging blockchains with transportable tokens\n\n\n\nSo what does this mean in practice? Holders of Nervos CKByte (CKB) and ada will be able to transact both currencies interchangeably. Nervos users will also be able to take advantage of Cardano\'s native asset standard to create tokens that can be ported and used across both networks. On top of this, the bridge enables developers on both chains gain access to services and features to expand their DApp ecosystem and user bases. \n\n\n\n[Mousebelt](https://www.mousebelt.com/), a full-service blockchain accelerator, will build the bridge with financial support from Nervos. The Cardano team will contribute expertise and resources to connect Cardano to the bridge. Development work is already underway and it is expected to be completed in the next six weeks. \n\n\n\n\'Using the Force Bridge to link the Nervos Network and Cardano is especially exciting given the relationship we have already built with IOHK,\' said Kevin Wang, co-founder of Nervos. \'We have been growing our research and development partnership, but we will soon have a tangible bridge that will also showcase the power of the Force Bridge and push us further along the road to a functional and interoperable network.\'\n\n\n\nThis bridge is just part of our collaboration with Nervos. \'We share a vision of a world that works on a ‘constellation’ of interoperating blockchains,\' says Romain Pellerin, CTO at Input Output. \'We believe that academic research is also fundamental to advancing the entire crypto space. Together we will also be co-authoring academic papers to pioneer improvements to the UTXO model, explore universal accounting standards, and contribute to the future development of decentralized technology through open-source research.\'\n\n\n\nBlockchain technology will only achieve mainstream acceptance when end users are not locked into one blockchain or standard, but can seamlessly access value and utility, regardless of which blockchain they are using. \'Bridges like this are an absolute necessity in order to ensure that users have a seamless experience,\' continued Pellerin. ‘By connecting our communities and finding innovative new ways to work together, as we have been doing with Nervos, we can ensure that blockchain lives up to its promises of creating a fairer and more efficient global financial operating system.\'\n\n\n\n*Check out the [Nervos website](https://www.nervos.org/) for more information on upcoming partnerships and research initiatives.*\n\n\n\n<!--EndFragment-->',
                    uses_mathjax: false,
                    attachments: [],
                    slug: 'nervos-partnership-to-build-the-first-cross-chain-bridge-with-cardano',
                    url: '/blog/posts/2021/06/02/nervos-partnership-to-build-the-first-cross-chain-bridge-with-cardano/',
                    read_time: 3
                },
                {
                    publish_date: '2021-05-26T00:00:00.000Z',
                    author: {
                        title: 'Shruti Appiah',
                        display_name: '',
                        thumbnail: 'https://ucarecdn.com/4df5ffe0-0a4a-4003-89e2-eb9a499b5155/',
                        is_team_member: true,
                        is_active: true,
                        localized: [
                            {
                                job_titles: [
                                    {
                                        name: 'Product Manager',
                                        primary: true
                                    },
                                    {
                                        name: 'Engineering',
                                        primary: null
                                    }
                                ],
                                lang: 'en',
                                profile_links: {
                                    email: '',
                                    youtube: '',
                                    linkedin: 'https://www.linkedin.com/in/shrutiappiah/',
                                    twitter: '',
                                    github: 'https://github.com/ShrutiAppiah'
                                }
                            }
                        ],
                        job_titles: [
                            {
                                name: 'Product Manager',
                                primary: true
                            },
                            {
                                name: 'Engineering',
                                primary: null
                            }
                        ],
                        lang: 'en',
                        profile_links: {
                            email: '',
                            youtube: '',
                            linkedin: 'https://www.linkedin.com/in/shrutiappiah/',
                            twitter: '',
                            github: 'https://github.com/ShrutiAppiah'
                        },
                        profile_url: '/blog/authors/shruti-appiah/',
                        blog_posts: []
                    },
                    video_id: null,
                    main_image: 'https://ucarecdn.com/84e114f9-431a-4539-8ede-c18b883446d7/',
                    custom_meta_img: null,
                    old_url: null,
                    haskell: null,
                    localized: [
                        {
                            lang: 'en',
                            title: 'Reimagining peer to peer finance with Marlowe',
                            subtitle: 'Marlowe decentralizes financial tools allowing anyone to create and execute peer-to-peer financial agreements',
                            audio: null,
                            soundcloud: [],
                            body_content: 'A while ago, I logged in to my stock trading platform to buy some exchange-traded funds (ETFs). Alas, the platform was down! It turned out that the surge in the GameStop stock had forced quite a few trading platforms to shut down temporarily.  We weren’t in the middle of a financial crisis, and I never expected that my bank or brokerage would block me from using my own funds without warning. I had assumed that I would always be able to access my funds, place trades, and reap profits or losses – a service for which I pay a handsome fee. \r\n\r\nIn the following days, several other stock brokers and trading platforms began blocking their users from performing trades that didn’t favour the brokers’ own agenda. Robinhood – which positions itself as the platform that *democratizes* finance – completely censored its users from buying GameStop stock. Are we ever truly in control of our money?\r\n\r\nAlmost all of us have given custody of our funds to some third-party, leaving us at their discretion to decide if and when those funds can be accessed, used, or even viewed. The commonality between these third-party banks and brokers is that there is a central point of control. In the case of Robinhood and GameStop, we have seen how this centralization can lead to failure. The central point of control can be influenced, attacked, or manipulated by an external self-interested actor, making it the antithesis of *democratized* finance.\r\n\r\nThis is the core motivator of decentralized finance, commonly known as DeFi. DeFi offers a similar set of financial tools offered by Wall Street such as lending, escrows, derivatives, swaps, and securities. What makes DeFi platforms stand out is their ability to offer these financial instruments without the need for central market makers, banks, or brokers. Each financial agreement is represented as a smart contract on the blockchain, and is settled algorithmically. Their decentralized nature makes them far more resilient to market manipulation or the failure of a centralized system. \r\n\r\nWe are currently developing a suite of Marlowe products to democratize finance and enable easy access to financial agreements. This includes **Marlowe Run**, a new product that will allow users to seamlessly execute off-the-shelf financial agreements with friends or clients in a secure fashion, and on their own. With added automation features and no need for third-parties, this peer-to-peer solution will be cost-effective, and more importantly, *democratizing*.\r\n\r\n## What is the Marlowe suite?\r\n\r\nWith Marlowe, we aim to democratize finance by facilitating peer-to-peer agreements that run on a blockchain. We seek to empower people to create their own financial instruments and set up agreements with anyone with whom they want to interact. Marlowe will offer a suite of products, each product serving a different function and set of users. Marlowe’s overarching product strategy comprises three streams – *Marlowe for developers*, *Marlowe for end users*, and *Marlowe for enterprise*. \r\n\r\n![](https://lh6.googleusercontent.com/-A46Yrdg7Q5fvq6sZFrNZkA-OwipwfVz13DEkbpe46T2kyTNQyPztJ28ZKQJv1olh0yRoQIgoS5C6nIO9iAHorQRLoC4UxBKM3ABFPdzvvJiWa2O6SR1YjYENcoOVXjUvoRTL4lI)\r\n\r\n## Marlowe for developers\r\n\r\nMarlowe for developers includes **Marlowe Build** and **Marlowe Play** (also called the [Marlowe Playground](https://alpha.marlowe.iohkdev.io/#/)) as well as the input to the **Marlowe Library**. Marlowe Build and Marlowe Play together enable end-to-end financial smart contract development. \r\n\r\nDevelopers can compose smart contract code on *Marlowe Build*. Then, they can perform preliminary iterative design using simulations, and formally verify and test smart contracts on *Marlowe Play*. These capabilities – paired with a purpose-built domain-specific language (DSL) for finance – ensure that the contracts are easy and straightforward to build, as well as being secure, verifiable, and rigorously tested. Once built and tested, developers may contribute them to our open-source smart contract template library, the *Marlowe Library*. \r\n\r\n## Marlowe for end users\r\n\r\nMarlowe for end users will bring an intuitive, straightforward, and seamless interface for users to execute financial agreements with their friends, colleagues, or clients on the blockchain. This includes **Marlowe Run** and gives access to a variety of templates for financial instruments from the Marlowe Library. We’re designing these products with the user in mind. To make financial agreements on the Marlowe Run, the user does not need to know the ins and outs of blockchain, or how to write smart contracts. Every step of the contract is explained in non-technical language, and each action is performed only with the user’s explicit authorization. Our team has built a suite of rigorously tested and verified financial tools including escrows, debt securities, and swaps that can be used on the Marlowe Run. These – and many more verified open-source contracts – are made available through the Marlowe Library. \r\n\r\n## Marlowe for enterprise ##\r\nMarlowe for enterprise aims to expand DeFi beyond individual users, helping enterprises to access the tangible benefits of smart contracts. This will include a bespoke, customizable suite of capabilities and financial agreements that are tailored to a commercial use case, with the provision of smart contract templates that adopt Algorithmic Contract Types Unified Standards [(Actus)](https://www.actusfrf.org/) for financial contracts.\r\n\r\n## Implementing Marlowe on Cardano ##\r\nIn 2020, we rolled out the [Marlowe Playground Alpha](https://alpha.marlowe.iohkdev.io/#/). This provided the ability to write contracts in JavaScript, in addition to Haskell, or directly in Marlowe itself. This also included proof-of-concept oracles, with the ability to access external data such as price, directly from a stock market ‘ticker’ or, in the future, data feeds such as Coinbase. To support the rollout, we published tutorials to guide developers. We have since been building on this work, continuing to improve the user experience, and building, testing, and validating more smart contract templates.\r\n\r\nAs a part of the Goguen rollout, we are now in the process of completing the implementation of Marlowe on Cardano, giving users and organizations the opportunity to execute DeFi contracts they have written themselves or downloaded from a contract repository. Marlowe will run first of all on the Cardano blockchain, but it is blockchain-agnostic so could run on other blockchains to reach an even broader audience in the future.\r\n\r\n## What comes next? ##\r\nMarlowe for end users will come online in stages throughout 2021. First, is the prototype of Marlowe Run, where users can demo and try out their own financial agreements. This will include a suite of financial smart contract templates that users can customize to their needs. This prototype will allow users to explore the experience of making financial agreements in a decentralized fashion, all in a peer-to-peer manner without requiring a value-extracting third party. To use the Marlowe Run prototype, users don’t need to own any real tokens, so they may try the demo before they onboard. This rollout will include a suite of template financial instruments, built by our in-house developers. These templates can be used to execute test agreements on Marlowe Run. We’ll share a demo of Marlowe Run on this month’s Cardano360 show (airs May 27) so join us for that.\r\n\r\nWe are committed to delivering this suite of products for the Marlowe ecosystem that empower people across the globe to build, control, and execute their own financial instruments on their terms. \r\n\r\n*We are planning a series of webinars on decentralized finance with Marlowe (starting June 3rd), you can [register on our website](https://webinar.marlowe-finance.io/) for these webinars now!*',
                            uses_mathjax: false,
                            attachments: []
                        },
                        {
                            lang: 'jp',
                            title: 'MarloweでP2P金融を再解釈',
                            subtitle: 'Marloweで金融ツールを分散化し、誰でもP2P金融契約の作成や実行が可能に',
                            audio: null,
                            soundcloud: [],
                            body_content: 'しばらく前に、私は上場投資信託（ETF）を購入するために株取引プラットフォームにログインしました。ところが、プラットフォームがダウンしていたのです。GameStop株の急騰により、かなりの数の取引プラットフォームが一時的にシャットダウンされたことが判明しました。金融危機の最中だったわけでもなく、銀行や証券会社が警告もなく自分の資金を使えないようにするとは夢にも思いませんでした。私はいつでも自分の資金にアクセスし、取引を行い、利益または損失を得ることができると思っていました。このサービスのために私は高い料金を払っているのです。\n\n\r\n続く数日間、他のいくつかの株式ブローカーや取引プラットフォームは、ユーザーがブローカー自身に都合のよくない取引を実行することを妨げ始めました。金融を民主化するプラットフォームとして自らを位置付けていたRobinhoodは、自己のユーザーによるGameStop株購入に対し完全な検閲を行いました。私たちは本当に自分のお金を管理できているのでしょうか。\r\n\r\n私たちのほとんどすべてが自分の資金をなんらかの第三者に保管しており、それらの資金にアクセス、使用、または閲覧することですら、その可否や時の決定は彼らの裁量に任されています。こうしたサードパーティの銀行やブローカーの共通点は、中央管理ポイントを持つことです。RobinhoodやGameStopのケースでは、この集中化がいかに障害につながるかが示されました。中央管理ポイントは外部の利己的なアクターから影響、攻撃、または操作を受けやすく、金融の民主化とは対照的です。\r\n\r\nこれが、一般にDeFiとして知られる分散型金融の主な動機です。DeFiは、ウォール街が提供する、貸付、エスクロー、デリバティブ、スワップ、証券などと同様の、金融ツール一式を提供します。DeFiプラットフォームの違いは、中央のマーケットメーカー、銀行、ブローカーを必要とせずにこれらの金融商品を提供できることです。各金融契約は、ブロックチェーン上のスマートコントラクトとして表され、アルゴリズムによって解決されます。分散型という性質により、市場操作や集中型システムの障害に対してはるかに高い回復力を持ちます。\r\n\r\n現在、私たちは金融の民主化と金融契約への容易なアクセスを可能にするMarlowe製品スイートを開発しています。これには、ユーザーが友人やクライアントと自分で既成の金融契約を安全かつシームレスに実行できるようにする新製品、**Marlowe Run**が含まれます。自動化機能の追加と第三機関が不要になることで、このP2Pソリューションは費用効果の高さもさることながら、民主化されたものである点が特に重要です。\r\n\r\n##Marloweスイートとは\r\n\r\n私たちはMarloweによってブロックチェーン上で実行されるP2P契約を利用可能にすることで、金融の民主化を目指しています。人々が独自の金融商品を作成し、取引したい相手と契約を結べるようにしたいと考えています。Marloweは一連の製品を提供し、各製品は異なるユーザー集団向けに別個の機能を提供します。Marloweの包括的な製品戦略は、開発者向けMarlowe、エンドユーザー向けMarlowe、エンタープライズ向けMarloweの3つのラインで構成されています。  \r\n\r\n![](https://lh6.googleusercontent.com/-A46Yrdg7Q5fvq6sZFrNZkA-OwipwfVz13DEkbpe46T2kyTNQyPztJ28ZKQJv1olh0yRoQIgoS5C6nIO9iAHorQRLoC4UxBKM3ABFPdzvvJiWa2O6SR1YjYENcoOVXjUvoRTL4lI)\r\n\r\n## 開発者向けMarlowe\r\n\r\n開発者向けMarloweには、**Marlowe Build**、**Marlowe Play**（または[Marlowe Playground](https://alpha.marlowe.iohkdev.io/#/)）、そして**Marlowe Library**へのインプットがあります。Marlowe BuildとMarlowe Playは共に、エンドツーエンドの金融スマートコントラクト開発を可能にします。\r\n\r\n開発者はMarlowe Buildでスマートコントラクトコードを作成できます。次に、Marlowe Play上でシミュレーションを使用して予備的なイテレーション設計を実行し、スマートコントラクトのフォーマル検証およびテストを行うことができます。こうした機能と金融専用に作られたドメイン固有言語（DSL）により、コントラクトが簡単に構築でき、その安全性と検証可能性、および厳密なテストが確保されます。構築およびテストが済むと、開発者はこれをオープンソースのスマートコントラクトテンプレートライブラリーであるMarlowe Libraryに提供できます。 \r\n\r\n## エンドユーザー向けMarlowe\r\n\r\nエンドユーザー向けMarloweは、ユーザーが友人や同僚、またはクライアントと、ブロックチェーン上で金融契約を実行するための直感的で簡単かつシームレスなインターフェイスを提供します。これにはMarlowe Runが含まれ、Marlowe Libraryのさまざな金融商品テンプレートへのアクセスを提供します。これらの製品はユーザー視点に立って設計されています。Marlowe Runで金融契約を作成するにあたり、ユーザーはブロックチェーンの詳細もスマートコントラクトの作成方法も知る必要はありません。コントラクトのステップごとに非技術的な言語による説明があり、各アクションはユーザーの明示的な許可がある場合にのみ実行されます。私たちのチームは、Marlowe Runで使用できるエスクロー、債務証券、スワップなど、厳密にテストおよび検証された一連の金融ツールを構築しました。これら、そしてさらに多くのオープンソースの検証済みコントラクトは、Marlowe Libraryから利用可能です。 \r\n\r\n## エンタープライズ向けMarlowe ##\r\n\r\nエンタープライズ向けMarloweは、DeFiを個々のユーザーを超えて拡張し、企業がスマートコントラクトの具体的なメリットにアクセスできるようにすることを目指しています。これには、金融契約用にアルゴリズム契約タイプ統一標準（[(Actus)](https://www.actusfrf.org/)）を採用したスマートコントラクトテンプレートの提供とともに、商用ユースケースに合わせて調整した特別仕様のカスタマイズ可能な一連の機能と金融契約が含まれます。\r\n\r\n## CardanoへのMarlowe実装 ##\r\n\r\n2020年、[Marlowe Playground Alpha](https://alpha.marlowe.iohkdev.io/#/)が発表されました。これにより、Haskellに加えてJavaScriptを使用した、もしくは直接Marlowe自体を使用したコントラクトの作成が可能になりました。また、これにはプルーフオブコンセプトOracleが含まれており、株式市場の「ティッカー」や将来的にはCoinbaseなどのデータフィードから、価格などの外部データに直接アクセスできます。また、ロールアウトをサポートするために、開発者向けチュートリアルを公開しました。以来、これを基盤として構築を進め、ユーザーエクスペリエンスの改善を続け、さらに多くのスマートコントラクトテンプレートの構築、テスト、検証を行っています。\r\n\r\nMarloweは、Goguen（ゴーグエン）ロールアウトの一環としてCardanoへの実装を終えようとしています。ユーザーや企業はDeFiコントラクトを自分自身で作成、またはコントラクトリポジトリからダウンロードして実行する機会が得られます。MarloweはまずCardanoブロックチェーンで実行されますが、特定のブロックチェーンに囚われるものではないため、将来的には他のブロックチェーンで実行され、より幅広いユーザーを獲得する可能性があります。\r\n\r\n## 今後の予定 ##\r\nエンドユーザー向けMarloweは2021年を通じて段階的にオンラインにもたらされます。最初はMarlowe Runのプロトタイプです。ここではユーザーはデモと、自分の金融契約を試すことができます。これには金融スマートコントラクトのテンプレート一式が含まれ、ユーザーはニーズに合わせてカスタマイズすることができます。プロトタイプでは、ユーザーは中間マージンを要求する第三者機関なしにP2Pによる分散型方式で金融契約の作成を体験できます。Marlowe Runプロトタイプを使用するために、実際のトークンを所有する必要はありません。始める前にデモを試してみることができます。本ロールアウトには、社内の開発者が構築した金融商品のテンプレート一式が含まれます。これらのテンプレートは、Marlowe Runでテスト契約を実行するために使用できます。Marlowe Runのデモは今月のCardano360（5月27日配信）で紹介しますので、ぜひご参加ください。\r\n\r\n私たちは、世界中の人々が独自の金融商品を思うがままに構築、管理、実行できるようにするMarloweエコシステムの製品スイートの提供に取り組んでいます。 \r\n\r\n現在Marloweを使ったDeFiウェビナーシリーズを企画しています（6月3日開始）。現在[ウェブサイトでウェビナーへの登録](https://webinar.marlowe-finance.io/)を受け付けています。 *',
                            uses_mathjax: false,
                            attachments: []
                        }
                    ],
                    lang: 'en',
                    title: 'Reimagining peer to peer finance with Marlowe',
                    subtitle: 'Marlowe decentralizes financial tools allowing anyone to create and execute peer-to-peer financial agreements',
                    audio: null,
                    soundcloud: [],
                    body_content: 'A while ago, I logged in to my stock trading platform to buy some exchange-traded funds (ETFs). Alas, the platform was down! It turned out that the surge in the GameStop stock had forced quite a few trading platforms to shut down temporarily.  We weren’t in the middle of a financial crisis, and I never expected that my bank or brokerage would block me from using my own funds without warning. I had assumed that I would always be able to access my funds, place trades, and reap profits or losses – a service for which I pay a handsome fee. \r\n\r\nIn the following days, several other stock brokers and trading platforms began blocking their users from performing trades that didn’t favour the brokers’ own agenda. Robinhood – which positions itself as the platform that *democratizes* finance – completely censored its users from buying GameStop stock. Are we ever truly in control of our money?\r\n\r\nAlmost all of us have given custody of our funds to some third-party, leaving us at their discretion to decide if and when those funds can be accessed, used, or even viewed. The commonality between these third-party banks and brokers is that there is a central point of control. In the case of Robinhood and GameStop, we have seen how this centralization can lead to failure. The central point of control can be influenced, attacked, or manipulated by an external self-interested actor, making it the antithesis of *democratized* finance.\r\n\r\nThis is the core motivator of decentralized finance, commonly known as DeFi. DeFi offers a similar set of financial tools offered by Wall Street such as lending, escrows, derivatives, swaps, and securities. What makes DeFi platforms stand out is their ability to offer these financial instruments without the need for central market makers, banks, or brokers. Each financial agreement is represented as a smart contract on the blockchain, and is settled algorithmically. Their decentralized nature makes them far more resilient to market manipulation or the failure of a centralized system. \r\n\r\nWe are currently developing a suite of Marlowe products to democratize finance and enable easy access to financial agreements. This includes **Marlowe Run**, a new product that will allow users to seamlessly execute off-the-shelf financial agreements with friends or clients in a secure fashion, and on their own. With added automation features and no need for third-parties, this peer-to-peer solution will be cost-effective, and more importantly, *democratizing*.\r\n\r\n## What is the Marlowe suite?\r\n\r\nWith Marlowe, we aim to democratize finance by facilitating peer-to-peer agreements that run on a blockchain. We seek to empower people to create their own financial instruments and set up agreements with anyone with whom they want to interact. Marlowe will offer a suite of products, each product serving a different function and set of users. Marlowe’s overarching product strategy comprises three streams – *Marlowe for developers*, *Marlowe for end users*, and *Marlowe for enterprise*. \r\n\r\n![](https://lh6.googleusercontent.com/-A46Yrdg7Q5fvq6sZFrNZkA-OwipwfVz13DEkbpe46T2kyTNQyPztJ28ZKQJv1olh0yRoQIgoS5C6nIO9iAHorQRLoC4UxBKM3ABFPdzvvJiWa2O6SR1YjYENcoOVXjUvoRTL4lI)\r\n\r\n## Marlowe for developers\r\n\r\nMarlowe for developers includes **Marlowe Build** and **Marlowe Play** (also called the [Marlowe Playground](https://alpha.marlowe.iohkdev.io/#/)) as well as the input to the **Marlowe Library**. Marlowe Build and Marlowe Play together enable end-to-end financial smart contract development. \r\n\r\nDevelopers can compose smart contract code on *Marlowe Build*. Then, they can perform preliminary iterative design using simulations, and formally verify and test smart contracts on *Marlowe Play*. These capabilities – paired with a purpose-built domain-specific language (DSL) for finance – ensure that the contracts are easy and straightforward to build, as well as being secure, verifiable, and rigorously tested. Once built and tested, developers may contribute them to our open-source smart contract template library, the *Marlowe Library*. \r\n\r\n## Marlowe for end users\r\n\r\nMarlowe for end users will bring an intuitive, straightforward, and seamless interface for users to execute financial agreements with their friends, colleagues, or clients on the blockchain. This includes **Marlowe Run** and gives access to a variety of templates for financial instruments from the Marlowe Library. We’re designing these products with the user in mind. To make financial agreements on the Marlowe Run, the user does not need to know the ins and outs of blockchain, or how to write smart contracts. Every step of the contract is explained in non-technical language, and each action is performed only with the user’s explicit authorization. Our team has built a suite of rigorously tested and verified financial tools including escrows, debt securities, and swaps that can be used on the Marlowe Run. These – and many more verified open-source contracts – are made available through the Marlowe Library. \r\n\r\n## Marlowe for enterprise ##\r\nMarlowe for enterprise aims to expand DeFi beyond individual users, helping enterprises to access the tangible benefits of smart contracts. This will include a bespoke, customizable suite of capabilities and financial agreements that are tailored to a commercial use case, with the provision of smart contract templates that adopt Algorithmic Contract Types Unified Standards [(Actus)](https://www.actusfrf.org/) for financial contracts.\r\n\r\n## Implementing Marlowe on Cardano ##\r\nIn 2020, we rolled out the [Marlowe Playground Alpha](https://alpha.marlowe.iohkdev.io/#/). This provided the ability to write contracts in JavaScript, in addition to Haskell, or directly in Marlowe itself. This also included proof-of-concept oracles, with the ability to access external data such as price, directly from a stock market ‘ticker’ or, in the future, data feeds such as Coinbase. To support the rollout, we published tutorials to guide developers. We have since been building on this work, continuing to improve the user experience, and building, testing, and validating more smart contract templates.\r\n\r\nAs a part of the Goguen rollout, we are now in the process of completing the implementation of Marlowe on Cardano, giving users and organizations the opportunity to execute DeFi contracts they have written themselves or downloaded from a contract repository. Marlowe will run first of all on the Cardano blockchain, but it is blockchain-agnostic so could run on other blockchains to reach an even broader audience in the future.\r\n\r\n## What comes next? ##\r\nMarlowe for end users will come online in stages throughout 2021. First, is the prototype of Marlowe Run, where users can demo and try out their own financial agreements. This will include a suite of financial smart contract templates that users can customize to their needs. This prototype will allow users to explore the experience of making financial agreements in a decentralized fashion, all in a peer-to-peer manner without requiring a value-extracting third party. To use the Marlowe Run prototype, users don’t need to own any real tokens, so they may try the demo before they onboard. This rollout will include a suite of template financial instruments, built by our in-house developers. These templates can be used to execute test agreements on Marlowe Run. We’ll share a demo of Marlowe Run on this month’s Cardano360 show (airs May 27) so join us for that.\r\n\r\nWe are committed to delivering this suite of products for the Marlowe ecosystem that empower people across the globe to build, control, and execute their own financial instruments on their terms. \r\n\r\n*We are planning a series of webinars on decentralized finance with Marlowe (starting June 3rd), you can [register on our website](https://webinar.marlowe-finance.io/) for these webinars now!*',
                    uses_mathjax: false,
                    attachments: [],
                    slug: 'reimagining-peer-to-peer-finance-with-marlowe',
                    url: '/blog/posts/2021/05/26/reimagining-peer-to-peer-finance-with-marlowe/',
                    read_time: 6
                },
                {
                    publish_date: '2021-05-17T00:00:00.000Z',
                    author: {
                        title: 'Francisco Landino',
                        display_name: null,
                        thumbnail: 'https://ucarecdn.com/ecf233e0-54bf-4189-86e3-acaefa2f2762/',
                        is_team_member: true,
                        is_active: true,
                        localized: [
                            {
                                job_titles: [
                                    {
                                        name: 'Project Manager',
                                        primary: null
                                    },
                                    {
                                        name: 'Commercial',
                                        primary: null
                                    }
                                ],
                                lang: 'en',
                                profile_links: {
                                    email: 'francisco.landino@iohk.io',
                                    youtube: '',
                                    linkedin: 'https://www.linkedin.com/in/francisco-landino/',
                                    twitter: null,
                                    github: 'https://github.com/plandino'
                                }
                            }
                        ],
                        job_titles: [
                            {
                                name: 'Project Manager',
                                primary: null
                            },
                            {
                                name: 'Commercial',
                                primary: null
                            }
                        ],
                        lang: 'en',
                        profile_links: {
                            email: 'francisco.landino@iohk.io',
                            youtube: '',
                            linkedin: 'https://www.linkedin.com/in/francisco-landino/',
                            twitter: null,
                            github: 'https://github.com/plandino'
                        },
                        profile_url: '/blog/authors/francisco-landino/',
                        blog_posts: []
                    },
                    video_id: null,
                    main_image: 'https://ucarecdn.com/0e068caf-0cb7-44cc-9ded-858d7b3b2fc2/',
                    custom_meta_img: null,
                    old_url: null,
                    haskell: null,
                    localized: [
                        {
                            lang: 'en',
                            title: 'Bringing ERC20 to Cardano',
                            subtitle: 'Our new ERC20 converter will allow Ethereum tokens like AGI to run on our proof-of-stake blockchain – coming soon to testnet',
                            audio: null,
                            soundcloud: [
                                {
                                    trackid: 1050304474
                                }
                            ],
                            body_content: 'Connecting blockchain protocols and collaborating on applications are essential to achieving the promise of decentralized finance (DeFi) and provide an alternative to the traditional banking system.\n\nAccording to DeFi Pulse, a tracking website, cryptocurrency to a total value of over ‘[$75 billion is now locked up](https://defipulse.com/)’ in DeFi. A year ago, the total was just $700 million. Most of this value is in the form of crypto-assets based on the ERC20 token standard. \n\nBut Ethereum’s proof-of-work infrastructure is challenged with ever-rising costs. We foresaw this issue and providing an alternative was one of the founding principles we set for Cardano. This is about to come into fruition.\n\nTo expand the variety of use cases for application developers and businesses, Cardano will support the ERC20 token migration to its platform. The Alonzo hard fork and Plutus smart contracts are on the way. Once deployed, users of supported Ethereum tokens will be able to bring them over from Ethereum\'s congested network and take advantage of Cardano\'s transaction capacity and lower fees, while enjoying enhanced security, reduced cost, and interoperability. \n\n## Why ERC20?\n\nLet’s take a closer look at the nature of ERC20 to understand why this standard fits the market trends in terms of business needs. First, of course, Ethereum brought the concept of smart contracts and ‘programmable money’ to the blockchain in 2015. Since then, tokenization and the ERC20 token have gained popularity because of utility in everyday business transactions. Applications built on a blockchain can provide tokens that can serve as:\n\n* a payment unit\n* a transaction unit\n* access to digital services\n* a reward or incentive \n* a right to vote \n* an investment mechanism\n\nWell-designed ERC20 tokens address many needs, and the more useful they become, the more demand grows and so their value grows accordingly. That is why these tokens are widely used and are so well supported by wallets and exchanges. \n\n## Ethereum v Cardano\n\nThe ERC20 standard was invented for Ethereum, and as of today, there are [over 400,000 contracts based on this token standard](https://etherscan.io/tokens) with examples including Binance coin (BNB), Tether (USDT), Uniswap (UNI), and Dai (DAI) to name a few. \n\nEthereum is a popular and functional blockchain platform, but it is slowing down and becoming more expensive. As more network participants interact with decentralized applications, the ‘gas’ fees paid for validating transactions are rising sharply (Figure 1).\n\n![Ethereum gas fees ](https://ucarecdn.com/2249a759-2ead-46e5-8c9b-5cd4a33ea8c2/ "Ethereum gas fees are increasing")\n\nFigure 1. Ethereum gas fees are increasing\n\nThe problems being experienced by Ethereum users have also been identified by a Cointelegraph survey cited in ‘[DeFi Adoption 2020](https://s3.cointelegraph.com/storage/uploads/view/48c6c4e03f85bc722d76f88c2676478b.pdf?_ga=2.42938214.270418488.1602500005-1231871226.1593587737)’:\n\n> 45% of platforms built on Ethereum name scalability and high gas costs among the top three problems constraining mass DeFi adoption.\n\nEthereum has not yet resolved these challenges and is unlikely to do so in the short term. So many businesses will want to consider other options. \n\n*By enabling the migration of ERC20 tokens to Cardano, we focus on delivering a value proposition that leverages Cardano’s advantages over Ethereum. In particular, Cardano\'s higher capacity for transaction processing and lower fees when compared with Ethereum\'s high cost and often congested traffic.*\n\n## Enabled by Ouroboros\n\nThe key to addressing the problem of network congestion and high fees is Cardano’s Ouroboros proof-of-stake consensus mechanism. Compared with Ethereum’s proof-of-work protocol, Ouroboros needs far less energy to process network transactions; it runs using amounts of electricity on the scale of a large house, rather than a small country. \nBecause of this, Ouroboros is not only eco-friendly but also needs far lower fees to process transactions. \n\nAdditionally, Cardano does not require smart contract execution costs as the ledger supports native token functionality with its built-in accounting model. This means that the tracking, transfer, and ownership of different types of assets are handled by the ledger instead of smart contracts. Whereas the creation and transfer of ERC20 tokens on Ethereum require the manual modification of the standard contract type, the logic for this is built into Cardano, which also eliminates the risk of errors and vulnerabilities.\n\n## How the ERC20 converter works\n\nCardano currently supports ada and [native tokens](https://iohk.io/en/blog/posts/2021/02/18/building-native-tokens-on-cardano-for-pleasure-and-profit/), which have proven successful with over 160,000 tokens minted. We are now launching an ERC20 converter to ensure better interoperability in the future as well as lay a solid background for extended business opportunities.\n\nOur ERC20 converter is a tool that will allow issuing organizations and their users to handle ERC20 token migration to Cardano. It is designed for token issuers (organizations that wish to enable the migration of their tokens to Cardano), and their users (token holders) to use the tool to move their ERC20 tokens to the Cardano network.\n\nUsers can convert their Ethereum tokens in just a few clicks, and when moved across, these tokens will be ‘translated’ into a special native token on Cardano that has the same value and works just like an ERC20. Additionally, if the user wishes to do so at a later stage, they can move their tokens back to the source network by burning them on Cardano. Two-way convertibility is baked in. \n\nWe’ll soon spin up a version of the ERC20 converter tool on a dedicated testnet. IO Global is currently working with partners for migration to Cardano, and [SingularityNET](https://singularitynet.io/) will be the first of these. The ERC20 converter will introduce a new [SingularityNET AGIX token](https://blog.singularitynet.io/singularitynet-phase-ii-launch-sequence-activated-agi-token-to-be-hard-forked-to-10ede4b6c89), the deployment of which marks the first milestone in the SingularityNET to Cardano migration plan. The initial testnet will allow users to assess the process of migration while working with AGIX tokens both in Cardano and Ethereum Kovan testnets.\n\nIt will be possible to authenticate an account using Metamask (an extension for the Chrome browser) with more options to come later. Users will also need to add their Daedalus testnet address so they can migrate their tokens to Cardano and easily track balances and transactions. \n\nWhen users log into their ERC20 converter account, they will see SingularityNET tokens listed and available for migration, and, by clicking on a token ‒ details such as token balance. They will just need to select the token, indicate the amount they would like to convert, and then migrate them by specifying a Cardano address. When tokens migrate to the address, it will be possible to use them for payments and transactions from the Daedalus wallet. All the activities will be visible both within Etherscan and the Cardano Explorer. \n\n![ERC20 converter dashboard](https://ucarecdn.com/d9abae9f-25e6-4a67-a8c2-d453bc935074/ "ERC20 converter dashboard")\n\nFigure 2. ERC20 converter dashboard\n\nAt later stages, users will see different types of tokens within the dashboard. Tokens available for migration will be listed first, and if not yet eligible – it will be possible to subscribe for updates about any changes.\n\n## A glance ahead\n\nAs the number of ERC20 converter partnerships increases, the range of token types supported will grow. Currently, our partners need to be custodians of their tokens, however, we will achieve greater interoperability while onboarding organizations when Plutus smart contracts operate on mainnet. \n\nOur goal is to support many tokens to create possibilities for business deals. So, further down the road, with a variety of tokens, the ERC20 converter will act as a bridge between blockchains, and this will promote effective cross-chain communication. \n\n*The ERC20 converter testnet is now in the final stages of quality assurance testing before the public launch. This stage will allow us to test the user journey and improve their experience along with fixing any occurring issues. We will also soon provide the dedicated testnet environment with relevant documentation and instructions on how users can test the converter capabilities.* \n\n*We’ll share an update on May’s Cardano360 show. Meanwhile, stay tuned and follow our [Twitter announcements](https://twitter.com/InputOutputHK?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor) to find out more in due course!*',
                            uses_mathjax: false,
                            attachments: []
                        },
                        {
                            lang: 'jp',
                            title: 'CardanoにERC20を搭載',
                            subtitle: 'AGIなどのイーサリアムトークンをCardanoプルーフオブステークブロックチェーンで実行できるようにする新ERC20コンバーターがまもなくテストネットに登場',
                            audio: null,
                            soundcloud: [
                                {
                                    trackid: 1050304474
                                }
                            ],
                            body_content: 'アプリケーションでブロックチェーンプロトコルを繋ぎ、協力することは、従来の金融システムに代わる分散型金融（DeFi）を達成するために欠かせません。\n\n追跡サイトのDeFi Pulseによれば、‘[現在750億ドル相当の暗号通貨がDeFiにロック](https://defipulse.com/)’ されています。1年前の合計額は7億ドルでした。この値のほとんどは、ERC20トークン標準に基づいた暗号資産形式です。 \n\nしかし、イーサリアムのプルーフオブワークインフラストラクチャーは上昇し続けるコストが課題となっています。この問題を予見した私たちが代わりに提供するものは、Cardano設立時に設定された原則の1つです。これがまもなく結実します。\n\nアプリケーション開発者および事業者に向けたさまざまなユースケースを拡張するために、CardanoはERC20トークンをプラットフォームに移行するサポートを行います。Alonzo（アロンゾ）ハードフォークとPlutusスマートコントラクトはまもなく到来します。これによりユーザーは、過密したイーサリアムネットワークに比べてトランザクション処理容量が高く手数料が低いCardanoにサポート対象のイーサリアムトークンを移し、セキュリティ強化、コスト削減、相互運用性を享受することができるようになります。\n\n## ERC20を選ぶ理由\n\nERC20標準がビジネスニーズという点における市場の傾向を満たす理由を理解するために、ERC20の特色を詳しく見てみましょう。もちろん、2015年にブロックチェーンにスマートコントラクトの概念と「プログラム可能なお金」を最初にもたらしたのはイーサリアムです。以来、トークン化とERC20トークンは、日々の商取引への実用性により人気を得てきました。ブロックチェーンに構築されたアプリケーションは、以下に使用可能なトークンを提供できます。\n\n* 支払いユニット\n* トランザクションユニット\n* デジタルサービスへのアクセス\n* 報酬またはインセンティブ\n* 投票権\n* 投資メカニズム\n\n\n優れた設計のERC20は多くのニーズに対応し、役に立てばたつほど需要も増え、それに従い価値も高まります。これが、これらのトークンが幅広く使用され、ウォレットや取引所にしっかりとサポートされている理由です。 \n\n## イーサリアム対Cardano\n\nERC20標準はイーサリアムのために発明され、現時点で [このトークン標準に基づくコントラクトは40万を超えて](https://etherscan.io/tokens) います。この中にはバイナンスコイン（BNB）、Tether（DSDT）、Uniswap（UNI）、Dai（DAI）などが含まれます。\n\nイーサリアムは人気があり機能的なブロックチェーンプラットフォームですが、スローダウン気味でより高額になってきています。分散型アプリケーションでやり取りするネットワーク参加者が増えるほど、トランザクションの検証用に支払われる「ガス」代は急激に上昇します（図1）。\n\n![Ethereum gas fees ](https://ucarecdn.com/2249a759-2ead-46e5-8c9b-5cd4a33ea8c2/ "Ethereum gas fees are increasing")\n\n図1：上昇するイーサリアムガス費用\n\nイーサリアムユーザーが経験した問題は、「[DeFi Adoption 2020](https://s3.cointelegraph.com/storage/uploads/view/48c6c4e03f85bc722d76f88c2676478b.pdf?_ga=2.42938214.270418488.1602500005-1231871226.1593587737)」に引用されたCointelegraphのアンケートでも示されています。\n\n>「イーサリアムに構築されたプラットフォームの45%が、大規模なDeFi適用を妨げる上位3つの問題の中で、スケーラビリティとガスコストの上昇の問題に言及しています」\n\nイーサリアムはこれらの課題をいまだ解決しておらず、短期的に解決できるとも思えません。したがって、多くのビジネスは他のオプションを検討したいと考えています。\n\n*私たちは、ERC20トークンをCardanoへ移行できるようにすることで、Cardanoのイーサリアムに対する優位性を活用した価値提案を提供することに焦点を当てています。特に、イーサリウムの高コストと渋滞しがちなトラフィックに比べて、Cardanoのより大きなトランザクション処理容量と低コストに重点を置いています。*\n\n## Ouroborosの役割\n\nネットワークの過密と高コストの問題に対応するカギとなるのは、CardanoのOuroborosプルーフオブステークコンセンサスメカニズムです。イーサリアムのプルーフオブワークプロトコルと比較して、Ouroborosがネットワークトランザクションを処理するために必要とする電力ははるかに少なく、その違いは小国に対する家1軒分に匹敵します。このため、Ouroborosは環境に優しいだけでなく、トランザクション処理に必要な手数料もはるかに低くなります。 \nさらにCardanoでは、台帳がネイティブトークン機能をビルトイン会計モデルでサポートしているため、スマートコントラクトの実行手数料がかかりません。これは、異なるタイプの資産の追跡、移転、所有が、スマートコントラクトの代わりに台帳で処理されることを意味します。イーサリアム上でERC20トークンを作成、転送するためには、標準コントラクトタイプを手動で変更する必要があるのに対し、このロジックはCardanoに組み込まれ、エラーや脆弱性のリスクを排除します。\n\n## ERC20コンバーターの仕組み\n\nCardanoは現在ADAと [ネイティブトークン](https://iohk.io/en/blog/posts/2021/02/18/building-native-tokens-on-cardano-for-pleasure-and-profit/), をサポートしており、16万を超えるネイティブトークンがミント（作成）されていることにその成功が証明されています。この度のERC20コンバーターの始動により、将来の相互運用性の向上が確実になるだけでなく、ビジネスチャンス拡大に向けた堅固な基盤が築かれることにもなります。\n\nERC20コンバーターは、発行組織やそのユーザーがERC20トークンのCardanoへの移行を処理するために使用できるツールです。トークンの発行者（Cardanoへのトークンの移行を望む組織）、次にそのツールを使って自分のERC20をCardanoネットワークに動かすユーザー（トークン保有者）のために設計されています。\n\nユーザーは自分のイーサリアムトークンをわずか数クリックで変換でき、移動させる際には、これらのトークンはERC20とまったく同じ価値と働きを持つCardanoの特別なネイティブトークンへと「翻訳」されます。さらに、ユーザーが後になって望む場合には、そのトークンをCardano上でバーン（廃棄）することによって元のネットワークに戻すこともでき、双方向変換が可能です。\nまもなく、ERC20コンバーターの1つのバージョンが専用のテストネットで展開されます。IO Globalはパートナーと協力してCardanoへの移行に取り組んでいます。 [SingularityNET](https://singularitynet.io/) は、その最初の例です。ERC20コンバーターは新しい [SingularityNET AGIXトークン](https://blog.singularitynet.io/singularitynet-phase-ii-launch-sequence-activated-agi-token-to-be-hard-forked-to-10ede4b6c89), を導入します。このデプロイは、SingularityNETのCardano移行計画の最初のマイルストンとなります。初期テストネットでは、ユーザーはCardanoとEthereum Kovanの両テストネットでAGIXトークンを操作しながら、移行プロセスを査定できます。\n\nMetaMask（Chrome拡張機能）を使用してアカウント認証することも可能になる他、多くのオプションが追加されます。ユーザーは、Cardanoに自分のトークンを移行して残高およびトランザクションを簡単に追跡するために、Daedalusテストネットアドレスを追加する必要があります。\n\nユーザーがERC20コンバーターアカウントにログインすると、SingularityNETトークンがリストに表示され、移行させることができるほか、トークンをクリックすると、トークン残高などの詳細を表示することができます。トークンを選択し、変換する額を指定し、Cardanoのアドレスを特定して移行します。トークンをアドレスに移動させると、Daedalusウォレットで支払いやトランザクションに使用できるようになります。すべてのアクティビティは、EtherscanおよびCardanoエクスプローラーで見ることができます。\n\n![ERC20 converter dashboard](https://ucarecdn.com/d9abae9f-25e6-4a67-a8c2-d453bc935074/ "ERC20 converter dashboard")\n\n図2：ERC20コンバーターダッシュボード\n\n後の段階では、異なるタイプのトークンがダッシュボードに表示されるようになります。移行可能なトークンが最初に表示され、まだ可能になっていない物は、変更に関する更新情報を受け取ることも可能です。\n\n## 今後の展望\n\nERC20コンバーターの提携先が増えれば、サポートされるトークンタイプの幅も広がります。現在、パートナーはトークンの管理者である必要がありますが、Plutusスマートコントラクトがメインネットで稼働する際には、組織をオンボーディングする間に相互運用性が向上します。\n私たちの目標は、多くのトークンをサポートして、商取引の可能性を創り出すことです。したがって長期的展望としては、多彩なトークンにより、ERC20コンバーターがブロックチェーン間の架け橋となり、その効果的なコミュニケーションを促進します。\nERC20コンバーターテストネットは、現在公開に向けてQAテストの最終段階に入っています。このステージにより、ユーザー経験をテストし、発生した不具合を修正しながら操作性を向上させることができます。まもなく専用テストネット環境と関連ドキュメンテーションおよびユーザーがコンバーターの機能をテストする方法を案内するガイドを提供します。\n5月のCardano360ショーで更新情報をお届けします。その間は、公式Twitterをフォローして最新情報をお受け取り下さい。',
                            uses_mathjax: false,
                            attachments: []
                        }
                    ],
                    lang: 'en',
                    title: 'Bringing ERC20 to Cardano',
                    subtitle: 'Our new ERC20 converter will allow Ethereum tokens like AGI to run on our proof-of-stake blockchain – coming soon to testnet',
                    audio: null,
                    soundcloud: [
                        {
                            trackid: 1050304474
                        }
                    ],
                    body_content: 'Connecting blockchain protocols and collaborating on applications are essential to achieving the promise of decentralized finance (DeFi) and provide an alternative to the traditional banking system.\n\nAccording to DeFi Pulse, a tracking website, cryptocurrency to a total value of over ‘[$75 billion is now locked up](https://defipulse.com/)’ in DeFi. A year ago, the total was just $700 million. Most of this value is in the form of crypto-assets based on the ERC20 token standard. \n\nBut Ethereum’s proof-of-work infrastructure is challenged with ever-rising costs. We foresaw this issue and providing an alternative was one of the founding principles we set for Cardano. This is about to come into fruition.\n\nTo expand the variety of use cases for application developers and businesses, Cardano will support the ERC20 token migration to its platform. The Alonzo hard fork and Plutus smart contracts are on the way. Once deployed, users of supported Ethereum tokens will be able to bring them over from Ethereum\'s congested network and take advantage of Cardano\'s transaction capacity and lower fees, while enjoying enhanced security, reduced cost, and interoperability. \n\n## Why ERC20?\n\nLet’s take a closer look at the nature of ERC20 to understand why this standard fits the market trends in terms of business needs. First, of course, Ethereum brought the concept of smart contracts and ‘programmable money’ to the blockchain in 2015. Since then, tokenization and the ERC20 token have gained popularity because of utility in everyday business transactions. Applications built on a blockchain can provide tokens that can serve as:\n\n* a payment unit\n* a transaction unit\n* access to digital services\n* a reward or incentive \n* a right to vote \n* an investment mechanism\n\nWell-designed ERC20 tokens address many needs, and the more useful they become, the more demand grows and so their value grows accordingly. That is why these tokens are widely used and are so well supported by wallets and exchanges. \n\n## Ethereum v Cardano\n\nThe ERC20 standard was invented for Ethereum, and as of today, there are [over 400,000 contracts based on this token standard](https://etherscan.io/tokens) with examples including Binance coin (BNB), Tether (USDT), Uniswap (UNI), and Dai (DAI) to name a few. \n\nEthereum is a popular and functional blockchain platform, but it is slowing down and becoming more expensive. As more network participants interact with decentralized applications, the ‘gas’ fees paid for validating transactions are rising sharply (Figure 1).\n\n![Ethereum gas fees ](https://ucarecdn.com/2249a759-2ead-46e5-8c9b-5cd4a33ea8c2/ "Ethereum gas fees are increasing")\n\nFigure 1. Ethereum gas fees are increasing\n\nThe problems being experienced by Ethereum users have also been identified by a Cointelegraph survey cited in ‘[DeFi Adoption 2020](https://s3.cointelegraph.com/storage/uploads/view/48c6c4e03f85bc722d76f88c2676478b.pdf?_ga=2.42938214.270418488.1602500005-1231871226.1593587737)’:\n\n> 45% of platforms built on Ethereum name scalability and high gas costs among the top three problems constraining mass DeFi adoption.\n\nEthereum has not yet resolved these challenges and is unlikely to do so in the short term. So many businesses will want to consider other options. \n\n*By enabling the migration of ERC20 tokens to Cardano, we focus on delivering a value proposition that leverages Cardano’s advantages over Ethereum. In particular, Cardano\'s higher capacity for transaction processing and lower fees when compared with Ethereum\'s high cost and often congested traffic.*\n\n## Enabled by Ouroboros\n\nThe key to addressing the problem of network congestion and high fees is Cardano’s Ouroboros proof-of-stake consensus mechanism. Compared with Ethereum’s proof-of-work protocol, Ouroboros needs far less energy to process network transactions; it runs using amounts of electricity on the scale of a large house, rather than a small country. \nBecause of this, Ouroboros is not only eco-friendly but also needs far lower fees to process transactions. \n\nAdditionally, Cardano does not require smart contract execution costs as the ledger supports native token functionality with its built-in accounting model. This means that the tracking, transfer, and ownership of different types of assets are handled by the ledger instead of smart contracts. Whereas the creation and transfer of ERC20 tokens on Ethereum require the manual modification of the standard contract type, the logic for this is built into Cardano, which also eliminates the risk of errors and vulnerabilities.\n\n## How the ERC20 converter works\n\nCardano currently supports ada and [native tokens](https://iohk.io/en/blog/posts/2021/02/18/building-native-tokens-on-cardano-for-pleasure-and-profit/), which have proven successful with over 160,000 tokens minted. We are now launching an ERC20 converter to ensure better interoperability in the future as well as lay a solid background for extended business opportunities.\n\nOur ERC20 converter is a tool that will allow issuing organizations and their users to handle ERC20 token migration to Cardano. It is designed for token issuers (organizations that wish to enable the migration of their tokens to Cardano), and their users (token holders) to use the tool to move their ERC20 tokens to the Cardano network.\n\nUsers can convert their Ethereum tokens in just a few clicks, and when moved across, these tokens will be ‘translated’ into a special native token on Cardano that has the same value and works just like an ERC20. Additionally, if the user wishes to do so at a later stage, they can move their tokens back to the source network by burning them on Cardano. Two-way convertibility is baked in. \n\nWe’ll soon spin up a version of the ERC20 converter tool on a dedicated testnet. IO Global is currently working with partners for migration to Cardano, and [SingularityNET](https://singularitynet.io/) will be the first of these. The ERC20 converter will introduce a new [SingularityNET AGIX token](https://blog.singularitynet.io/singularitynet-phase-ii-launch-sequence-activated-agi-token-to-be-hard-forked-to-10ede4b6c89), the deployment of which marks the first milestone in the SingularityNET to Cardano migration plan. The initial testnet will allow users to assess the process of migration while working with AGIX tokens both in Cardano and Ethereum Kovan testnets.\n\nIt will be possible to authenticate an account using Metamask (an extension for the Chrome browser) with more options to come later. Users will also need to add their Daedalus testnet address so they can migrate their tokens to Cardano and easily track balances and transactions. \n\nWhen users log into their ERC20 converter account, they will see SingularityNET tokens listed and available for migration, and, by clicking on a token ‒ details such as token balance. They will just need to select the token, indicate the amount they would like to convert, and then migrate them by specifying a Cardano address. When tokens migrate to the address, it will be possible to use them for payments and transactions from the Daedalus wallet. All the activities will be visible both within Etherscan and the Cardano Explorer. \n\n![ERC20 converter dashboard](https://ucarecdn.com/d9abae9f-25e6-4a67-a8c2-d453bc935074/ "ERC20 converter dashboard")\n\nFigure 2. ERC20 converter dashboard\n\nAt later stages, users will see different types of tokens within the dashboard. Tokens available for migration will be listed first, and if not yet eligible – it will be possible to subscribe for updates about any changes.\n\n## A glance ahead\n\nAs the number of ERC20 converter partnerships increases, the range of token types supported will grow. Currently, our partners need to be custodians of their tokens, however, we will achieve greater interoperability while onboarding organizations when Plutus smart contracts operate on mainnet. \n\nOur goal is to support many tokens to create possibilities for business deals. So, further down the road, with a variety of tokens, the ERC20 converter will act as a bridge between blockchains, and this will promote effective cross-chain communication. \n\n*The ERC20 converter testnet is now in the final stages of quality assurance testing before the public launch. This stage will allow us to test the user journey and improve their experience along with fixing any occurring issues. We will also soon provide the dedicated testnet environment with relevant documentation and instructions on how users can test the converter capabilities.* \n\n*We’ll share an update on May’s Cardano360 show. Meanwhile, stay tuned and follow our [Twitter announcements](https://twitter.com/InputOutputHK?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor) to find out more in due course!*',
                    uses_mathjax: false,
                    attachments: [],
                    slug: 'bringing-erc20-to-cardano',
                    url: '/blog/posts/2021/05/17/bringing-erc20-to-cardano/',
                    read_time: 7
                }
            ],
            recentPosts: [
                {
                    publish_date: '2021-06-10T00:00:00.000Z',
                    author: {
                        title: 'Aggelos Kiayias',
                        display_name: 'Prof Aggelos Kiayias',
                        thumbnail: 'https://ucarecdn.com/e9b32a47-1d44-49ae-9f36-3e008e7533c7/',
                        is_team_member: true,
                        is_active: true,
                        localized: [
                            {
                                job_titles: [
                                    {
                                        name: 'Chief scientist',
                                        primary: null
                                    },
                                    {
                                        name: 'Academic Research',
                                        primary: null
                                    }
                                ],
                                lang: 'en',
                                profile_links: {
                                    email: 'aggelos.kiayias@iohk.io',
                                    youtube: '//www.youtube.com/watch?v=nB6eDbnkAk8',
                                    linkedin: null,
                                    twitter: null,
                                    github: null
                                }
                            }
                        ],
                        job_titles: [
                            {
                                name: 'Chief scientist',
                                primary: null
                            },
                            {
                                name: 'Academic Research',
                                primary: null
                            }
                        ],
                        lang: 'en',
                        profile_links: {
                            email: 'aggelos.kiayias@iohk.io',
                            youtube: '//www.youtube.com/watch?v=nB6eDbnkAk8',
                            linkedin: null,
                            twitter: null,
                            github: null
                        },
                        profile_url: '/blog/authors/aggelos-kiayias/',
                        blog_posts: [
                            {
                                publish_date: '2021-06-10T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/7aaaa825-7c80-4bfb-8712-a1e66bc809b8/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Stablefees and the Decentralized Reserve System',
                                        subtitle: 'Exploring a new mechanism to help make fees fair, stable, and more predictable over time',
                                        audio: null,
                                        soundcloud: [],
                                        body_content: 'Facilitating transactions in cryptocurrency platforms stumbles on the dual utility of the platform’s underlying asset. On the one hand, users can hold and trade it as part of their investment portfolios. On the other hand, it supplies the necessary “fuel” for processing transactions. \n\nThis duality suggests that the system should have a mechanism for adjusting transaction costs, so they remain competitive and reasonable. Also, the bounded throughput of decentralized platforms per unit of time introduces another hurdle: the system should also allow the users to discover the correct price for timely transaction processing, depending on their individual needs. \n\nWhy not drop transaction fees altogether? Three reasons: One, transaction processing incurs costs on the system’s side (in terms of computation and storage). It is reasonable to allow transaction processors (stake pool operators, in the case of Cardano) to offset their costs. Two, even with a theoretically infinite capacity, it is important to prevent transaction issuers from saturating the network with worthless transactions. Three, it is appropriate to incentivize transaction processors to provide quality of service. A surge in demand should influence their payoffs accordingly.\n\nAdding a fee to each transaction can address the above considerations. \n\n### Bitcoin and beyond\n\nBitcoin set out the first mechanism for pricing transactions in distributed ledger platforms. This mechanism resembles a first-price auction: transactions bid for a place in a block naming a specific reward, and block producers select the transactions that they prefer to include. Block producers also get rewarded with the right to mint new coins, i.e., their operation is subsidized by the whole community via inflation of the total coin supply. Inflation drops geometrically over time, and transaction fees become increasingly dominant in the rewards. This mechanism, while enabling Bitcoin to run for well over a decade, has been criticized for its inefficiency. Transaction costs have also risen over time.\n\nIn this blog post, we explore a new mechanism that builds on Cardano\'s approach to ledger rules and system assets, and complements the [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) concept. The objective is making fees fair, stable, and predictable over time. We describe the mechanism in the context of Cardano. However, it can be adapted to any other cryptocurrency with similar characteristics.\n\n### Introducing \'Stablefees\'\n\nThe core idea behind Stablefees is to have a base price for transactions through pegging to a basket of commodities or currencies. Stablefees includes a native "decentralized reserve" contract that issues and manages a stablecoin pegged to the basket. A comparison in the fiat world might be the International Monetary Fund’s[ SDR](https://www.imf.org/en/About/Factsheets/Sheets/2016/08/01/14/51/Special-Drawing-Right-SDR), (established in 1969) and valued based on a basket of five currencies—the U.S. dollar, the euro, the Chinese renminbi, the Japanese yen, and the British pound sterling. The stablecoin --- let’s call it "Basket Equivalent Coin" (BEC) --- is the currency used for paying transaction fees (and all other real world pricing needs of the platform, e.g., SPO costs). \n\nIn this system, ada will play a dual role: Reserve asset of the decentralized reserve, and reward currency for staking. It will also be the fall-back currency in extreme scenarios where the reserve contract is in a liquidity crunch. Before a transaction, the issuer will have to obtain BECs, either via other third parties or directly by sending ada to the decentralized reserve contract. On what basis will the reserve issue BECs? The reserve contract will also issue equity shares -we will call them decentralized equity coins (DECs)-, in exchange of ada. Leveraging the value of DECs, the decentralized reserve will often adjust the value of BEC so it is pegged on the underlying basket of commodities. In other words, DECs will absorb the fluctuations of ada vs. the basket to ensure that the real-world value of BECs remains stable (cf. the [AgeUSD stablecoin design](https://github.com/Emurgo/age-usd) that has been already [deployed and used on Ergo](https://sigmausd.io/#/)). \n\nThis trinity of coinage, issued natively by the system, will attract different cohorts. BECs\' stability and liquidity might be attractive to risk-averse, transaction-intensive holders. DECs will offer the highest rewards if ada goes up, but also take the most significant hit when ada goes down. Long-term holders may find DECs more attractive. Also, since decentralized reserve prices these coins in ada, both BECs and DECs can facilitate participation in staking and governance. Returns can be issued at different rates, reflecting the different nature of each coin. Ultimately, rewards will always be denominated and payable in ada, which will remain the most versatile of all three coins.\n\n### Oracles\n\nThe centerpiece of this mechanism is an on-chain oracle that determines the price of the basket in ada. SPOs can implement this oracle in a decentralized manner. The reserve can offer extra rewards to all oracle contributors from the fees collected during BEC/DEC issuances. This will ensure two things: thousands of geographically-diverse contributors, and ledger rules calculating a synthesized exchange rate in some canonical way (through a weighted median across all price submissions in an epoch, for example). If oracle contributors manipulate their contributions, they can be held accountable by tracking their reputation and performance on-chain.\n\n### The pricing mechanism\n\nHow would one price transactions and reward block producers? Using the current approach in Cardano, each transaction will be deterministically mapped to a precise value denominated in BECs, using a formula determined by the ledger rules. The formula will take into account both transaction size and its computational requirements, and may also incorporate runtime metrics (such as the average system load). The resulting value will be the base fee guaranteeing that the transaction will be processed by the system. Given the base fee, end users will be able to apply a multiplier if they wish (which will be a value at least 1, e.g., 1.5x, 3x, etc.) to increase the fee and accelerate processing. This will become relevant at times of surging demand.  \n\nThis approach has one advantage when compared with the first-price auction model: the pricing mechanism is continuously stabilized to a reasonable default value. Users perform price discovery in one direction only to accelerate processing, if required. Also, transaction issuers can store BECs to secure their future transaction-issuing ability without being affected by ada price volatility.\n\n### Stablefees and Babel fees\n\nThe Stablefees mechanism can be considered a natural extension of [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) ---spot conversion of BECs into ada by the decentralized reserve. Both mechanisms complement (and are compatible with) each other. Babel fees can be deployed together with Stablefees with just one change: Using BECs to cover Babel fee liabilities, instead of ada. This also means that fees will always be payable in ada (via a Babel fee liability convertible in ada on the spot). Hence, the whole mechanism is backwards compatible: it won’t affect occasional users who just hold ada and do not wish to obtain BECs.  \n\nA final point about diversity. While the above narrative identifies a unique and global BEC, the same mechanism can be used to issue regional BECs pegged to different baskets of commodities, which could possibly be weighted differently. Such “regional” BECs will be able to increase system inclusivity, while enabling SPOs to have more fine-grained policies in terms of transaction inclusion.\n\n### Stablefees \'lite\'\n\nThe above mechanism requires a decentralized reserve contract and the issuance of BECs and DECs by the contract to buyers. A “lite” version avoids the reserve contract and directly adjusts the fee formula by pegging it onto the agreed basket of commodities through the price oracle. The resulting system denominates transaction fees nominally in BECs and immediately converts them into ada. The payable amount fluctuates, depending on the value of BEC. The mechanism is otherwise identical, also facilitating unidirectional price discovery through the multiplier. The only disadvantage is that a prospective transaction issuer has no access to a native token that enables transaction processing predictably; transaction issuers must pay fees in ada. Still, the fees will continuously adjust and remain stable via the pegging mechanism with respect to the basket. As a result, a transaction issuer will be able to organize their off-chain asset portfolio to meet their transaction needs effectively.\n\n### The road ahead\n\nOur team is currently researching the granular details of the Stablefees mechanism. Once this research is complete, Stablefees can be integrated into Cardano to offer fair and predictable transaction pricing. Moreover, the price oracle and the global BEC (and regional variants, if included) will undoubtedly find uses beyond paying transaction fees, expanding the capabilities of decentralized applications in the Cardano ecosystem.',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Stablefees and the Decentralized Reserve System',
                                subtitle: 'Exploring a new mechanism to help make fees fair, stable, and more predictable over time',
                                audio: null,
                                soundcloud: [],
                                body_content: 'Facilitating transactions in cryptocurrency platforms stumbles on the dual utility of the platform’s underlying asset. On the one hand, users can hold and trade it as part of their investment portfolios. On the other hand, it supplies the necessary “fuel” for processing transactions. \n\nThis duality suggests that the system should have a mechanism for adjusting transaction costs, so they remain competitive and reasonable. Also, the bounded throughput of decentralized platforms per unit of time introduces another hurdle: the system should also allow the users to discover the correct price for timely transaction processing, depending on their individual needs. \n\nWhy not drop transaction fees altogether? Three reasons: One, transaction processing incurs costs on the system’s side (in terms of computation and storage). It is reasonable to allow transaction processors (stake pool operators, in the case of Cardano) to offset their costs. Two, even with a theoretically infinite capacity, it is important to prevent transaction issuers from saturating the network with worthless transactions. Three, it is appropriate to incentivize transaction processors to provide quality of service. A surge in demand should influence their payoffs accordingly.\n\nAdding a fee to each transaction can address the above considerations. \n\n### Bitcoin and beyond\n\nBitcoin set out the first mechanism for pricing transactions in distributed ledger platforms. This mechanism resembles a first-price auction: transactions bid for a place in a block naming a specific reward, and block producers select the transactions that they prefer to include. Block producers also get rewarded with the right to mint new coins, i.e., their operation is subsidized by the whole community via inflation of the total coin supply. Inflation drops geometrically over time, and transaction fees become increasingly dominant in the rewards. This mechanism, while enabling Bitcoin to run for well over a decade, has been criticized for its inefficiency. Transaction costs have also risen over time.\n\nIn this blog post, we explore a new mechanism that builds on Cardano\'s approach to ledger rules and system assets, and complements the [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) concept. The objective is making fees fair, stable, and predictable over time. We describe the mechanism in the context of Cardano. However, it can be adapted to any other cryptocurrency with similar characteristics.\n\n### Introducing \'Stablefees\'\n\nThe core idea behind Stablefees is to have a base price for transactions through pegging to a basket of commodities or currencies. Stablefees includes a native "decentralized reserve" contract that issues and manages a stablecoin pegged to the basket. A comparison in the fiat world might be the International Monetary Fund’s[ SDR](https://www.imf.org/en/About/Factsheets/Sheets/2016/08/01/14/51/Special-Drawing-Right-SDR), (established in 1969) and valued based on a basket of five currencies—the U.S. dollar, the euro, the Chinese renminbi, the Japanese yen, and the British pound sterling. The stablecoin --- let’s call it "Basket Equivalent Coin" (BEC) --- is the currency used for paying transaction fees (and all other real world pricing needs of the platform, e.g., SPO costs). \n\nIn this system, ada will play a dual role: Reserve asset of the decentralized reserve, and reward currency for staking. It will also be the fall-back currency in extreme scenarios where the reserve contract is in a liquidity crunch. Before a transaction, the issuer will have to obtain BECs, either via other third parties or directly by sending ada to the decentralized reserve contract. On what basis will the reserve issue BECs? The reserve contract will also issue equity shares -we will call them decentralized equity coins (DECs)-, in exchange of ada. Leveraging the value of DECs, the decentralized reserve will often adjust the value of BEC so it is pegged on the underlying basket of commodities. In other words, DECs will absorb the fluctuations of ada vs. the basket to ensure that the real-world value of BECs remains stable (cf. the [AgeUSD stablecoin design](https://github.com/Emurgo/age-usd) that has been already [deployed and used on Ergo](https://sigmausd.io/#/)). \n\nThis trinity of coinage, issued natively by the system, will attract different cohorts. BECs\' stability and liquidity might be attractive to risk-averse, transaction-intensive holders. DECs will offer the highest rewards if ada goes up, but also take the most significant hit when ada goes down. Long-term holders may find DECs more attractive. Also, since decentralized reserve prices these coins in ada, both BECs and DECs can facilitate participation in staking and governance. Returns can be issued at different rates, reflecting the different nature of each coin. Ultimately, rewards will always be denominated and payable in ada, which will remain the most versatile of all three coins.\n\n### Oracles\n\nThe centerpiece of this mechanism is an on-chain oracle that determines the price of the basket in ada. SPOs can implement this oracle in a decentralized manner. The reserve can offer extra rewards to all oracle contributors from the fees collected during BEC/DEC issuances. This will ensure two things: thousands of geographically-diverse contributors, and ledger rules calculating a synthesized exchange rate in some canonical way (through a weighted median across all price submissions in an epoch, for example). If oracle contributors manipulate their contributions, they can be held accountable by tracking their reputation and performance on-chain.\n\n### The pricing mechanism\n\nHow would one price transactions and reward block producers? Using the current approach in Cardano, each transaction will be deterministically mapped to a precise value denominated in BECs, using a formula determined by the ledger rules. The formula will take into account both transaction size and its computational requirements, and may also incorporate runtime metrics (such as the average system load). The resulting value will be the base fee guaranteeing that the transaction will be processed by the system. Given the base fee, end users will be able to apply a multiplier if they wish (which will be a value at least 1, e.g., 1.5x, 3x, etc.) to increase the fee and accelerate processing. This will become relevant at times of surging demand.  \n\nThis approach has one advantage when compared with the first-price auction model: the pricing mechanism is continuously stabilized to a reasonable default value. Users perform price discovery in one direction only to accelerate processing, if required. Also, transaction issuers can store BECs to secure their future transaction-issuing ability without being affected by ada price volatility.\n\n### Stablefees and Babel fees\n\nThe Stablefees mechanism can be considered a natural extension of [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) ---spot conversion of BECs into ada by the decentralized reserve. Both mechanisms complement (and are compatible with) each other. Babel fees can be deployed together with Stablefees with just one change: Using BECs to cover Babel fee liabilities, instead of ada. This also means that fees will always be payable in ada (via a Babel fee liability convertible in ada on the spot). Hence, the whole mechanism is backwards compatible: it won’t affect occasional users who just hold ada and do not wish to obtain BECs.  \n\nA final point about diversity. While the above narrative identifies a unique and global BEC, the same mechanism can be used to issue regional BECs pegged to different baskets of commodities, which could possibly be weighted differently. Such “regional” BECs will be able to increase system inclusivity, while enabling SPOs to have more fine-grained policies in terms of transaction inclusion.\n\n### Stablefees \'lite\'\n\nThe above mechanism requires a decentralized reserve contract and the issuance of BECs and DECs by the contract to buyers. A “lite” version avoids the reserve contract and directly adjusts the fee formula by pegging it onto the agreed basket of commodities through the price oracle. The resulting system denominates transaction fees nominally in BECs and immediately converts them into ada. The payable amount fluctuates, depending on the value of BEC. The mechanism is otherwise identical, also facilitating unidirectional price discovery through the multiplier. The only disadvantage is that a prospective transaction issuer has no access to a native token that enables transaction processing predictably; transaction issuers must pay fees in ada. Still, the fees will continuously adjust and remain stable via the pegging mechanism with respect to the basket. As a result, a transaction issuer will be able to organize their off-chain asset portfolio to meet their transaction needs effectively.\n\n### The road ahead\n\nOur team is currently researching the granular details of the Stablefees mechanism. Once this research is complete, Stablefees can be integrated into Cardano to offer fair and predictable transaction pricing. Moreover, the price oracle and the global BEC (and regional variants, if included) will undoubtedly find uses beyond paying transaction fees, expanding the capabilities of decentralized applications in the Cardano ecosystem.',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'stablefees-and-the-decentralized-reserve-system',
                                url: '/blog/posts/2021/06/10/stablefees-and-the-decentralized-reserve-system/',
                                read_time: 7
                            },
                            {
                                publish_date: '2021-02-25T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/89c32658-5415-43bc-9dc4-e7acff7735ab/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Babel fees - denominating transaction costs in native tokens',
                                        subtitle: 'Introducing a novel mechanism that allows the payment of transaction fees in user-defined tokens on Cardano',
                                        audio: null,
                                        soundcloud: [
                                            {
                                                trackid: 992849701
                                            }
                                        ],
                                        body_content: 'In Douglas Adams\' classic The Hitchhiker\'s Guide to the Galaxy, a [Babel fish](http://www.bbc.co.uk/cult/hitchhikers/guide/babelfish.shtml) is a creature that allows you to hear any language translated into your own. This fantasy of universal translation ensures meaningful interaction despite the myriad different languages in the galaxy. \n\nIn the cryptocurrency space, smart contract platforms enable the development of a myriad custom tokens. Is it possible to interact with the platform using your preferred token? If only there was a “Babel fees” mechanism to translate the token you use to the one that the platform requires for posting a transaction. \n\nCommon wisdom in blockchain systems suggests that posting a valid transaction must incur a cost to the sender. The argument is that, without such constraint, there is nothing to stop anyone from overloading the system with trivial transactions saturating its capacity and rendering it unusable. Given the above tenet, a frequently made corollary is that in any blockchain system where user-defined tokens are supported, it should be prohibited to pay transaction fees in such tokens. Instead, transactions should carry a fee in the native token of the platform that is accepted by all participants as being valuable.  Arguably such a restriction is undesirable. But how is it possible to circumvent the ensuing – and seemingly inevitable – vulnerability? \n\n## The art of the possible\n\nCryptography and game theory have been known to make possible what seemed impossible. Celebrated examples include key exchange over a public channel, Merkle\'s puzzles, and auctions where being truthful is the rational thing to do, like Vickrey\'s auctions. And so it also turns out in this case. \n\nFirst, let us recall how native assets work in Cardano: Tokens can be created according to a minting policy and they are treated natively in the ledger along with ada. Cardano\'s ledger adopts the Extended UTXO (EUTXO) model, and issuing a valid transaction requires consuming one or more UTXOs. A UTXO in Cardano may carry not just ada but in fact a token bundle that can contain multiple different tokens, both fungible and non-fungible. In this way it is possible to write transactions that transfer multiple different tokens with a single UTXO. \n\nTransaction fees in the ledger are denominated in ada according to a function fixed as a ledger parameter. A powerful feature of Cardano\'s EUTXO model is that the fees required for a valid transaction can be predicted precisely prior to posting it. This is a unique feature that is not enjoyed by other ledger arrangements (such as the account-based model used in Ethereum). Indeed, in this latter case the fees needed for a transaction may change during the time it takes for the transaction to settle, since other transactions may affect the ledger\'s state in between and influence the required cost for processing the transaction. \n\n## A thought experiment\n\nLet\'s consider the following thought experiment to help us move closer towards our objective of Babel fees. Imagine that it is possible to issue a transaction that declares a liability denominated in ada equal to the amount of fees that the transaction issuer is supposed to pay. Such a transaction would not be admissible to the ledger. However it can be perceived as an open offer that asks for the liability to be covered. Why would anyone respond to such an offer? To entice a response, assuming the token bundle concept already present in Cardano,  the transaction can offer some amount of token(s) to whoever covers the liability. This suggests a spot trade between ada and the offered token(s) at a certain exchange rate. Consider now a block producer that sees such a transaction. The block producer can create a matching transaction absorbing the liability covering it with ada as well as claiming the tokens that are on offer. \n\nBy suitably extending the ledger rules, the transaction with the liability as well as its matching transaction become admissible to the ledger as a group. Due to the absorption of the liability, the set of two transactions becomes properly priced in ada as a whole and hence it does not break the ledgers\' bookkeeping rules in terms of ada fees. As a result, the transaction with the liability settles, and we have achieved our objective. Users can submit transactions priced in any token(s) they possess and, providing a block producer is willing to take them up on the spot trade, have them settle in the ledger as regular transactions!\n\n## A concrete example\n\nThe mechanism is of course conditioned on the presence of liquidity providers that possess ada and are willing to issue matching transactions. In fact the mechanism creates a market for such liquidity providers. For instance, a stake pool operator (SPO), can publish exchange rates for specific tokens they consider acceptable. For instance an SPO can declare that they will accept tokenX for an exchange rate 3:1 over ada. It follows that if a transaction costs, say ₳0.16, the transaction can declare a liability of ₳0.16 as well as offer 0.48 of tokenX. In the native asset model of Cardano this can be implemented as a single UTXO carrying a token bundle with the following specification (Ada→ -0.16, tokenX→0.48). Note the negative sign signifying the liability. \n\nSuppose now that the SPO is about to produce a block. She recovers the liability transaction from the mempool and issues a matching transaction consuming the UTXO with the liability. The matching transaction transfers 0.48 of tokenX to a new output which is owned by the SPO. The resulting block contains the two transactions in sequence. The matching transaction provides the missing ₳0.16 in addition to the fees that are needed for itself. In fact multiple transactions can be batched together and have their fees covered by a single matching transaction. \n\n![](https://lh4.googleusercontent.com/9MEHGqNJxiDK510lAb8fvAWJBS19MwRiyPxdpdn6gc-7jloOcmaykYOuh0HNg3fI6wDIw5I6WqwdkCDENETK9zXZ2K16l_t4XGfbT5Ee1jvgkMYq1BcT--iAeA7qojLIhfkRnn5_)\n\n*Figure. Alice sends a quantity of 9 tokens of type X to Bob with the assistance of Stacy, an SPO, who covers Alice\'s transaction liability and receives tokens of type X in exchange. The implied exchange rate between X and Ada is 3:1.* \n\n## New measures of value\n\nThe above process is entirely opt-in for SPOs. Each one can determine their own policy and exchange rate as well as decide to change the exchange rate for the various tokens they accept on the spot. Moreover, there is no need for agreement between SPOs about the value of a specific token. In fact, different SPOs may provide different exchange rates for the same token and a user issuing a liability transaction can offer an amount of tokens corresponding to the minimum, average or even maximum of the posted exchange rates in the network. In this way, a natural trade off arises between settlement time of liability transactions and the market value of tokens they offer. \n\nThis illustrates how native assets, the EUTXO model, and the simple but powerful tweak of introducing liabilities in the form of negative values in token bundles can accommodate Babel fees empowering users to price transactions in any token supported natively by the system. It also shows the unique advantage of being an SPO in such a system. It should be noted that SPOs need not be the only entities in the network offering to cover liabilities. In fact, an SPO can readily partner -if they wish- with an external liquidity provider who will be issuing the matching transactions. In addition, third party providers can also act on the network independently and issue matching transactions. Nevertheless, the benefit will remain with the block producers; SPOs can always front-run matching transactions and substitute them for their own if they wish so. This is a case that front-running transactions is a feature: it makes it feasible for SPOs to be paid in the tokens they prefer for their transaction processing services.\n\nThe mechanism of negative quantities in token bundles can be implemented in the basic ledger rules of Cardano at some point following the introduction of native assets with the Mary Hard Fork. Beyond Babel fees, the mechanism allows a variety of other interesting applications, such as atomic swaps for spot trades, that we will cover in a future blog post. It is yet another illustration of the power of Cardano\'s approach and its ability to support a diverse and entrepreneurial community of users and stake pool operators. \n\n*I am grateful to Manuel Chakravarty, Michael Peyton Jones, Nikos Karagiannidis, Chad Nester and Polina Vinogradova for helpful discussions, suggestions and comments related to the concept of Babel fees and its implementation in the Cardano ledger. We also have a [video whiteboard walkthrough](https://youtu.be/YXaK0cvgoFQ?t=2184) covering this topic.*',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Babel fees - denominating transaction costs in native tokens',
                                subtitle: 'Introducing a novel mechanism that allows the payment of transaction fees in user-defined tokens on Cardano',
                                audio: null,
                                soundcloud: [
                                    {
                                        trackid: 992849701
                                    }
                                ],
                                body_content: 'In Douglas Adams\' classic The Hitchhiker\'s Guide to the Galaxy, a [Babel fish](http://www.bbc.co.uk/cult/hitchhikers/guide/babelfish.shtml) is a creature that allows you to hear any language translated into your own. This fantasy of universal translation ensures meaningful interaction despite the myriad different languages in the galaxy. \n\nIn the cryptocurrency space, smart contract platforms enable the development of a myriad custom tokens. Is it possible to interact with the platform using your preferred token? If only there was a “Babel fees” mechanism to translate the token you use to the one that the platform requires for posting a transaction. \n\nCommon wisdom in blockchain systems suggests that posting a valid transaction must incur a cost to the sender. The argument is that, without such constraint, there is nothing to stop anyone from overloading the system with trivial transactions saturating its capacity and rendering it unusable. Given the above tenet, a frequently made corollary is that in any blockchain system where user-defined tokens are supported, it should be prohibited to pay transaction fees in such tokens. Instead, transactions should carry a fee in the native token of the platform that is accepted by all participants as being valuable.  Arguably such a restriction is undesirable. But how is it possible to circumvent the ensuing – and seemingly inevitable – vulnerability? \n\n## The art of the possible\n\nCryptography and game theory have been known to make possible what seemed impossible. Celebrated examples include key exchange over a public channel, Merkle\'s puzzles, and auctions where being truthful is the rational thing to do, like Vickrey\'s auctions. And so it also turns out in this case. \n\nFirst, let us recall how native assets work in Cardano: Tokens can be created according to a minting policy and they are treated natively in the ledger along with ada. Cardano\'s ledger adopts the Extended UTXO (EUTXO) model, and issuing a valid transaction requires consuming one or more UTXOs. A UTXO in Cardano may carry not just ada but in fact a token bundle that can contain multiple different tokens, both fungible and non-fungible. In this way it is possible to write transactions that transfer multiple different tokens with a single UTXO. \n\nTransaction fees in the ledger are denominated in ada according to a function fixed as a ledger parameter. A powerful feature of Cardano\'s EUTXO model is that the fees required for a valid transaction can be predicted precisely prior to posting it. This is a unique feature that is not enjoyed by other ledger arrangements (such as the account-based model used in Ethereum). Indeed, in this latter case the fees needed for a transaction may change during the time it takes for the transaction to settle, since other transactions may affect the ledger\'s state in between and influence the required cost for processing the transaction. \n\n## A thought experiment\n\nLet\'s consider the following thought experiment to help us move closer towards our objective of Babel fees. Imagine that it is possible to issue a transaction that declares a liability denominated in ada equal to the amount of fees that the transaction issuer is supposed to pay. Such a transaction would not be admissible to the ledger. However it can be perceived as an open offer that asks for the liability to be covered. Why would anyone respond to such an offer? To entice a response, assuming the token bundle concept already present in Cardano,  the transaction can offer some amount of token(s) to whoever covers the liability. This suggests a spot trade between ada and the offered token(s) at a certain exchange rate. Consider now a block producer that sees such a transaction. The block producer can create a matching transaction absorbing the liability covering it with ada as well as claiming the tokens that are on offer. \n\nBy suitably extending the ledger rules, the transaction with the liability as well as its matching transaction become admissible to the ledger as a group. Due to the absorption of the liability, the set of two transactions becomes properly priced in ada as a whole and hence it does not break the ledgers\' bookkeeping rules in terms of ada fees. As a result, the transaction with the liability settles, and we have achieved our objective. Users can submit transactions priced in any token(s) they possess and, providing a block producer is willing to take them up on the spot trade, have them settle in the ledger as regular transactions!\n\n## A concrete example\n\nThe mechanism is of course conditioned on the presence of liquidity providers that possess ada and are willing to issue matching transactions. In fact the mechanism creates a market for such liquidity providers. For instance, a stake pool operator (SPO), can publish exchange rates for specific tokens they consider acceptable. For instance an SPO can declare that they will accept tokenX for an exchange rate 3:1 over ada. It follows that if a transaction costs, say ₳0.16, the transaction can declare a liability of ₳0.16 as well as offer 0.48 of tokenX. In the native asset model of Cardano this can be implemented as a single UTXO carrying a token bundle with the following specification (Ada→ -0.16, tokenX→0.48). Note the negative sign signifying the liability. \n\nSuppose now that the SPO is about to produce a block. She recovers the liability transaction from the mempool and issues a matching transaction consuming the UTXO with the liability. The matching transaction transfers 0.48 of tokenX to a new output which is owned by the SPO. The resulting block contains the two transactions in sequence. The matching transaction provides the missing ₳0.16 in addition to the fees that are needed for itself. In fact multiple transactions can be batched together and have their fees covered by a single matching transaction. \n\n![](https://lh4.googleusercontent.com/9MEHGqNJxiDK510lAb8fvAWJBS19MwRiyPxdpdn6gc-7jloOcmaykYOuh0HNg3fI6wDIw5I6WqwdkCDENETK9zXZ2K16l_t4XGfbT5Ee1jvgkMYq1BcT--iAeA7qojLIhfkRnn5_)\n\n*Figure. Alice sends a quantity of 9 tokens of type X to Bob with the assistance of Stacy, an SPO, who covers Alice\'s transaction liability and receives tokens of type X in exchange. The implied exchange rate between X and Ada is 3:1.* \n\n## New measures of value\n\nThe above process is entirely opt-in for SPOs. Each one can determine their own policy and exchange rate as well as decide to change the exchange rate for the various tokens they accept on the spot. Moreover, there is no need for agreement between SPOs about the value of a specific token. In fact, different SPOs may provide different exchange rates for the same token and a user issuing a liability transaction can offer an amount of tokens corresponding to the minimum, average or even maximum of the posted exchange rates in the network. In this way, a natural trade off arises between settlement time of liability transactions and the market value of tokens they offer. \n\nThis illustrates how native assets, the EUTXO model, and the simple but powerful tweak of introducing liabilities in the form of negative values in token bundles can accommodate Babel fees empowering users to price transactions in any token supported natively by the system. It also shows the unique advantage of being an SPO in such a system. It should be noted that SPOs need not be the only entities in the network offering to cover liabilities. In fact, an SPO can readily partner -if they wish- with an external liquidity provider who will be issuing the matching transactions. In addition, third party providers can also act on the network independently and issue matching transactions. Nevertheless, the benefit will remain with the block producers; SPOs can always front-run matching transactions and substitute them for their own if they wish so. This is a case that front-running transactions is a feature: it makes it feasible for SPOs to be paid in the tokens they prefer for their transaction processing services.\n\nThe mechanism of negative quantities in token bundles can be implemented in the basic ledger rules of Cardano at some point following the introduction of native assets with the Mary Hard Fork. Beyond Babel fees, the mechanism allows a variety of other interesting applications, such as atomic swaps for spot trades, that we will cover in a future blog post. It is yet another illustration of the power of Cardano\'s approach and its ability to support a diverse and entrepreneurial community of users and stake pool operators. \n\n*I am grateful to Manuel Chakravarty, Michael Peyton Jones, Nikos Karagiannidis, Chad Nester and Polina Vinogradova for helpful discussions, suggestions and comments related to the concept of Babel fees and its implementation in the Cardano ledger. We also have a [video whiteboard walkthrough](https://youtu.be/YXaK0cvgoFQ?t=2184) covering this topic.*',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'babel-fees',
                                url: '/blog/posts/2021/02/25/babel-fees/',
                                read_time: 8
                            },
                            {
                                publish_date: '2020-11-30T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/efe10f62-5ed9-40df-ba6b-2db352dad69f/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Blockchain reward sharing - a comparative systematization from first principles',
                                        subtitle: 'Navigating the diverse landscape of reward-sharing schemes and the choices we have made in the design of Cardano’s reward-sharing scheme',
                                        audio: 'https://ucarecdn.com/7ad17830-600c-4313-b55a-751d0149f93a/',
                                        soundcloud: null,
                                        body_content: 'In the previous article, we identified the [objectives of the reward scheme in Cardano](https://iohk.io/en/blog/posts/2020/11/13/the-general-perspective-on-staking-in-cardano/), and we gave general guidelines regarding engaging with the system.\n\nTaking a more high-level view, we will examine from first principles, the general problem of reward sharing in blockchain systems. To recall, the two overarching objectives of any *resource-based* consensus system is to incentivize the following.\n\n**High engagement**. Resource-based consensus protocols are more secure the more resources are engaged with protocol maintenance. The problem, of course, is that the underlying resources are useful for a wide variety of other things too (e.g., electricity and computational power in the case of proof of work, **or stake for engaging in decentralized apps** in the case of proof of stake), so resource holders should be incentivized to commit resources for protocol maintenance.\n\n**Low leverage**: leverage relates to decentralization. Take a group of 10 people; if there is a leader and the group follows the leader’s wishes all the time, the leader’s leverage is 10 while everyone else’s is zero. If, on the other hand, everyone’s opinion matters the same, everyone’s leverage is 1. These are two extremes, but it should be fairly obvious what types of leverage align better with decentralization. From an economic viewpoint, however, a “benevolent dictatorship” is always more efficient; as a result, decentralization will come at a cost (exactly as democracy does), and hence it has to be also properly incentivized.  \n\nGiven the above objectives, let us now examine some approaches that have been considered in consensus systems and systematize them in terms of how they address the above objectives. An important first categorization we will introduce is between unimodal and multimodal reward schemes.\n\n## Unimodal\n\nIn a unimodal scheme, there is only one way to engage in the consensus protocol with your resources. We examine two sub-categories of unimodal schemes. \n\n1. **Linear Unimodal**\n\nThis is the simplest approach and is followed by many systems, notably Bitcoin; the original proof-of-work based Ethereum, as well as Algorand. The idea is simple: if an entity commands x% resources, then the system will attempt to provide x% of the rewards – at least in expectation. This might seem fair—until one observes the serious downsides that come with it. \n\nFirst, consider that someone has x% of resources and that x% of the rewards in expectation are below their individual cost to operate as a node. Then, they will either not engage (lowering the engagement rate of the system), or, more likely, actively seek others to combine resources and create a node. Even if there are two resource holders with x% of resources each and a viable individual cost *c* when running as separate nodes, they will fare better by combining resources into a single node of 2x% resources because the resulting cost will be typically less than *2c*. This can result in a strong trend to centralize, and lead to high leverage since the combined pool of resources will be (typically) run by one entity. \n\nIn practice, a single dictatorially operated node is unlikely to emerge. This is due to various reasons such as friction in coordination between parties, fear of the potential drop in the exchange rate of the system’s underlying token if the centralization trend becomes noticeable, as well as the occasional use of complex protocols to jointly run pools. Even so, it is clear that unimodal linear rewards can hurt decentralization. \n\nOne does not need to go much further than looking at Bitcoin and its current, fairly centralized, mining pool lineup. It is worth noting that if stake (rather than hashing power) is used as a resource, the centralization pressure will be less – since the expenditure to operate a node is smaller. But the same problems apply in principle. \n\nAn additional disadvantage of the above setting is that the ensuing “off-chain” resource pooling that occurs will be completely opaque from the ledger perspective, and hence more difficult for the community to monitor and react to. In summary, the linear unimodal approach has the advantage of being simple, but is precarious, both in terms of increasing engagement and for keeping leverage low. \n\n2. **Quantized Linear Unimodal**\n\nThis approach is the same as the linear rewards approach, but it quantizes the underlying resource. I.e., if your resources are below a certain threshold, you may be completely unable to participate; you can only participate in fixed quanta. Notably, this approach is taken in [ETH2.0, where 32 Ether](https://blog.ethereum.org/2019/11/27/validated-staking-on-eth2-0/) should be pledged in order to acquire a validator identity. It should be clear that this quantized approach shares the same problems with the linear unimodal approach in terms of participation and leverage. Despite this, it has been considered for two primary reasons. First, using the quantized approach enables one to retrofit traditional BFT-style protocol design elements (e.g. that require counting identities) in a resource-based consensus setting. The resulting system is less elegant than true resource-based consensus but this is unavoidable since traditional BFT-style protocols do not work very well when there are more than a few hundred nodes involved. The second reason, specific to the proof-of-stake setting, is seeking to impose penalties on participants as a means of ensuring compliance with the protocol. Imposing quantized collateral pledges makes penalties for protocol infractions more substantial and painful.\n\n## Multimodal\n\nWe next turn to multimodal schemes. This broad category includes Cosmos, Tezos, Polkadot & EOS.  It also includes Cardano. In a multimodal scheme, a resource holder may take different roles in the protocol; being a fully active node in the consensus protocol is just one of the options. The advantage of a multimodal scheme is that offering multiple ways to engage (with correspondingly different rates of return) within the protocol itself can accommodate a higher engagement, as well as limit off-chain resource pooling. For instance, if the potential rewards received by an individual when they engage with all their resources sit below their operational cost of running a node,  they can still choose to engage by a different mode in the protocol. In this way, the tendency to combine resources off-chain is eased and the system – if designed properly – may translate this higher engagement to increased resilience. \n\nWe will distinguish between a number of different multimodal schemes.\n\n* **Representative bimodal without leverage control.** The representative approach is inspired by [representative democracy](https://en.wikipedia.org/wiki/Representative_democracy): the system is run by a number of elected operators. The approach is bimodal as it enables parties to (1) advertise themselves as operators in the ledger and/or (2) “vote” for operators with their resources. The set of representative operators has a fixed size and is updated on a rolling basis typically with fixed terms using some election function that selects representatives based on the votes they received. Rewards are distributed evenly between representatives, possibly taking into account performance data and adjusting accordingly. Allowing rewards to flow to voters using a smart contract can incentivize higher engagement in voting since resource holders get paid for voting for good representatives (note that this is not necessarily followed by all schemes in this category). The disadvantage of this approach is the lack of leverage control, beyond,  possibly, the existence of a very large upper bound, which suggests that the system may end up with a set of very highly leveraged operators. This is the approach that is broadly followed by Cosmos,  EOS, and Polkadot.\n\nA different approach to the representative approach is the *delegative* approach. In general, this approach is closer to direct democracy as it allows resource holders the option to engage directly with the protocol with the resources they have. However, they are free to also delegate their resources to others as in [liquid (or delegative) democracy](https://en.wikipedia.org/wiki/Liquid_democracy) (where the term delegative is derived from). This results in a community-selected operator configuration that does not have a predetermined number of representatives. As in the representative approach, user engagement is bimodal. Resource holders can advertise themselves as operators and/or delegate their resources to existing operators. The rewards provided are proportional to the amount of delegated resources and delegates can be paid via an on-chain smart contract, perhaps at various different rates. Within the delegative approach we will further distinguish two subcategories.\n\n* **Delegative bimodal with pledge-based capped rewards.** What typifies this particular delegative approach is that the resource pool’s rewards have a bound that is determined by the amount of pledge that is committed to the pool by its operator. In this way, the total leverage of an operator can be controlled and fixed to a constant. Unfortunately, this leverage control feature has the negative side effect of implicitly imposing the same bound to all, small and large resource holders. So, on the one hand, in a population of small resource holders, engagement will be constrained by the little pledge that operators are able to commit. On the other hand, a few large whale resource holders may end up influencing the consensus protocol in a very significant manner, possibly even beyond its security threshold bound. In terms of leverage control, it should be clear that one size does not fit all! From existing systems, this is the approach that is (in essence) followed by Tezos. \n\nIt is worth noting that all the specific approaches we have seen so far come with downsides – either in terms of maximizing engagement, controlling leverage, or both. With this in mind, let us now fit into our systematization, the approach of the reward-sharing scheme that we are using in Cardano. \n\n* **Delegative bimodal with capped rewards and incentivized pledging.** In this delegative system (introduced in our [reward-sharing scheme](https://arxiv.org/abs/1807.11218) paper), the rewards that are provided to each pool follow a piecewise function on the pool’s size. The function is initially monotonically increasing and then becomes constant at a certain “cap” level which is a configurable system parameter (in Cardano this is determined by the parameter *k*). This cap limits the incentives to grow individual resource pools. At the same time, pledging resources to a pool is *incentivized* with higher pledged pools receiving more rewards. As a result, lowering one’s leverage becomes incentive-driven: resource pools have bounded size and operators have an incentive to pledge all the resources they can afford into the smallest number of pools possible. In particular, whale resource holders are incentivized to keep their leverage low. The benefit of the approach is that high engagement is reinforced, while leverage is kept in control by incentivizing the community to (i) pledge as much as possible, (ii) use all the remaining unpledged resources as part of a crowdsourced filtering mechanism. This translates stake to voting power and supports exactly those operators that materially contribute to the system’s goals the most.\n\nThe above systematization puts into perspective the choices that we have made in the design of the reward-sharing scheme used in Cardano vis-a-vis other systems. In summary, what the Cardano reward system achieves is to materially promote with incentives and community stake-based voting the best possible outcome: *low leverage and high engagement*. And this is accomplished, while still allowing for a very high degree of heterogeneity in terms of input behavior from the stakeholders.\n\nAs a final point, it is important to stress that while considerable progress has been made since the introduction of the Bitcoin blockchain, research in reward sharing for collaborative projects is still an extremely active and growing domain. Our team continuously evaluates various aspects of reward-sharing schemes and actively explores the whole design space in a first-principles manner. In this way, we can ensure that any research advances will be disseminated widely for the benefit of the whole community.\n\n*I am grateful to Christian Badertscher, Sandro Coretti-Drayton, Matthias Fitzi, and Peter Gaži, for their help in the review of other systems and their placement in the systematization of this article.*',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Blockchain reward sharing - a comparative systematization from first principles',
                                subtitle: 'Navigating the diverse landscape of reward-sharing schemes and the choices we have made in the design of Cardano’s reward-sharing scheme',
                                audio: 'https://ucarecdn.com/7ad17830-600c-4313-b55a-751d0149f93a/',
                                soundcloud: null,
                                body_content: 'In the previous article, we identified the [objectives of the reward scheme in Cardano](https://iohk.io/en/blog/posts/2020/11/13/the-general-perspective-on-staking-in-cardano/), and we gave general guidelines regarding engaging with the system.\n\nTaking a more high-level view, we will examine from first principles, the general problem of reward sharing in blockchain systems. To recall, the two overarching objectives of any *resource-based* consensus system is to incentivize the following.\n\n**High engagement**. Resource-based consensus protocols are more secure the more resources are engaged with protocol maintenance. The problem, of course, is that the underlying resources are useful for a wide variety of other things too (e.g., electricity and computational power in the case of proof of work, **or stake for engaging in decentralized apps** in the case of proof of stake), so resource holders should be incentivized to commit resources for protocol maintenance.\n\n**Low leverage**: leverage relates to decentralization. Take a group of 10 people; if there is a leader and the group follows the leader’s wishes all the time, the leader’s leverage is 10 while everyone else’s is zero. If, on the other hand, everyone’s opinion matters the same, everyone’s leverage is 1. These are two extremes, but it should be fairly obvious what types of leverage align better with decentralization. From an economic viewpoint, however, a “benevolent dictatorship” is always more efficient; as a result, decentralization will come at a cost (exactly as democracy does), and hence it has to be also properly incentivized.  \n\nGiven the above objectives, let us now examine some approaches that have been considered in consensus systems and systematize them in terms of how they address the above objectives. An important first categorization we will introduce is between unimodal and multimodal reward schemes.\n\n## Unimodal\n\nIn a unimodal scheme, there is only one way to engage in the consensus protocol with your resources. We examine two sub-categories of unimodal schemes. \n\n1. **Linear Unimodal**\n\nThis is the simplest approach and is followed by many systems, notably Bitcoin; the original proof-of-work based Ethereum, as well as Algorand. The idea is simple: if an entity commands x% resources, then the system will attempt to provide x% of the rewards – at least in expectation. This might seem fair—until one observes the serious downsides that come with it. \n\nFirst, consider that someone has x% of resources and that x% of the rewards in expectation are below their individual cost to operate as a node. Then, they will either not engage (lowering the engagement rate of the system), or, more likely, actively seek others to combine resources and create a node. Even if there are two resource holders with x% of resources each and a viable individual cost *c* when running as separate nodes, they will fare better by combining resources into a single node of 2x% resources because the resulting cost will be typically less than *2c*. This can result in a strong trend to centralize, and lead to high leverage since the combined pool of resources will be (typically) run by one entity. \n\nIn practice, a single dictatorially operated node is unlikely to emerge. This is due to various reasons such as friction in coordination between parties, fear of the potential drop in the exchange rate of the system’s underlying token if the centralization trend becomes noticeable, as well as the occasional use of complex protocols to jointly run pools. Even so, it is clear that unimodal linear rewards can hurt decentralization. \n\nOne does not need to go much further than looking at Bitcoin and its current, fairly centralized, mining pool lineup. It is worth noting that if stake (rather than hashing power) is used as a resource, the centralization pressure will be less – since the expenditure to operate a node is smaller. But the same problems apply in principle. \n\nAn additional disadvantage of the above setting is that the ensuing “off-chain” resource pooling that occurs will be completely opaque from the ledger perspective, and hence more difficult for the community to monitor and react to. In summary, the linear unimodal approach has the advantage of being simple, but is precarious, both in terms of increasing engagement and for keeping leverage low. \n\n2. **Quantized Linear Unimodal**\n\nThis approach is the same as the linear rewards approach, but it quantizes the underlying resource. I.e., if your resources are below a certain threshold, you may be completely unable to participate; you can only participate in fixed quanta. Notably, this approach is taken in [ETH2.0, where 32 Ether](https://blog.ethereum.org/2019/11/27/validated-staking-on-eth2-0/) should be pledged in order to acquire a validator identity. It should be clear that this quantized approach shares the same problems with the linear unimodal approach in terms of participation and leverage. Despite this, it has been considered for two primary reasons. First, using the quantized approach enables one to retrofit traditional BFT-style protocol design elements (e.g. that require counting identities) in a resource-based consensus setting. The resulting system is less elegant than true resource-based consensus but this is unavoidable since traditional BFT-style protocols do not work very well when there are more than a few hundred nodes involved. The second reason, specific to the proof-of-stake setting, is seeking to impose penalties on participants as a means of ensuring compliance with the protocol. Imposing quantized collateral pledges makes penalties for protocol infractions more substantial and painful.\n\n## Multimodal\n\nWe next turn to multimodal schemes. This broad category includes Cosmos, Tezos, Polkadot & EOS.  It also includes Cardano. In a multimodal scheme, a resource holder may take different roles in the protocol; being a fully active node in the consensus protocol is just one of the options. The advantage of a multimodal scheme is that offering multiple ways to engage (with correspondingly different rates of return) within the protocol itself can accommodate a higher engagement, as well as limit off-chain resource pooling. For instance, if the potential rewards received by an individual when they engage with all their resources sit below their operational cost of running a node,  they can still choose to engage by a different mode in the protocol. In this way, the tendency to combine resources off-chain is eased and the system – if designed properly – may translate this higher engagement to increased resilience. \n\nWe will distinguish between a number of different multimodal schemes.\n\n* **Representative bimodal without leverage control.** The representative approach is inspired by [representative democracy](https://en.wikipedia.org/wiki/Representative_democracy): the system is run by a number of elected operators. The approach is bimodal as it enables parties to (1) advertise themselves as operators in the ledger and/or (2) “vote” for operators with their resources. The set of representative operators has a fixed size and is updated on a rolling basis typically with fixed terms using some election function that selects representatives based on the votes they received. Rewards are distributed evenly between representatives, possibly taking into account performance data and adjusting accordingly. Allowing rewards to flow to voters using a smart contract can incentivize higher engagement in voting since resource holders get paid for voting for good representatives (note that this is not necessarily followed by all schemes in this category). The disadvantage of this approach is the lack of leverage control, beyond,  possibly, the existence of a very large upper bound, which suggests that the system may end up with a set of very highly leveraged operators. This is the approach that is broadly followed by Cosmos,  EOS, and Polkadot.\n\nA different approach to the representative approach is the *delegative* approach. In general, this approach is closer to direct democracy as it allows resource holders the option to engage directly with the protocol with the resources they have. However, they are free to also delegate their resources to others as in [liquid (or delegative) democracy](https://en.wikipedia.org/wiki/Liquid_democracy) (where the term delegative is derived from). This results in a community-selected operator configuration that does not have a predetermined number of representatives. As in the representative approach, user engagement is bimodal. Resource holders can advertise themselves as operators and/or delegate their resources to existing operators. The rewards provided are proportional to the amount of delegated resources and delegates can be paid via an on-chain smart contract, perhaps at various different rates. Within the delegative approach we will further distinguish two subcategories.\n\n* **Delegative bimodal with pledge-based capped rewards.** What typifies this particular delegative approach is that the resource pool’s rewards have a bound that is determined by the amount of pledge that is committed to the pool by its operator. In this way, the total leverage of an operator can be controlled and fixed to a constant. Unfortunately, this leverage control feature has the negative side effect of implicitly imposing the same bound to all, small and large resource holders. So, on the one hand, in a population of small resource holders, engagement will be constrained by the little pledge that operators are able to commit. On the other hand, a few large whale resource holders may end up influencing the consensus protocol in a very significant manner, possibly even beyond its security threshold bound. In terms of leverage control, it should be clear that one size does not fit all! From existing systems, this is the approach that is (in essence) followed by Tezos. \n\nIt is worth noting that all the specific approaches we have seen so far come with downsides – either in terms of maximizing engagement, controlling leverage, or both. With this in mind, let us now fit into our systematization, the approach of the reward-sharing scheme that we are using in Cardano. \n\n* **Delegative bimodal with capped rewards and incentivized pledging.** In this delegative system (introduced in our [reward-sharing scheme](https://arxiv.org/abs/1807.11218) paper), the rewards that are provided to each pool follow a piecewise function on the pool’s size. The function is initially monotonically increasing and then becomes constant at a certain “cap” level which is a configurable system parameter (in Cardano this is determined by the parameter *k*). This cap limits the incentives to grow individual resource pools. At the same time, pledging resources to a pool is *incentivized* with higher pledged pools receiving more rewards. As a result, lowering one’s leverage becomes incentive-driven: resource pools have bounded size and operators have an incentive to pledge all the resources they can afford into the smallest number of pools possible. In particular, whale resource holders are incentivized to keep their leverage low. The benefit of the approach is that high engagement is reinforced, while leverage is kept in control by incentivizing the community to (i) pledge as much as possible, (ii) use all the remaining unpledged resources as part of a crowdsourced filtering mechanism. This translates stake to voting power and supports exactly those operators that materially contribute to the system’s goals the most.\n\nThe above systematization puts into perspective the choices that we have made in the design of the reward-sharing scheme used in Cardano vis-a-vis other systems. In summary, what the Cardano reward system achieves is to materially promote with incentives and community stake-based voting the best possible outcome: *low leverage and high engagement*. And this is accomplished, while still allowing for a very high degree of heterogeneity in terms of input behavior from the stakeholders.\n\nAs a final point, it is important to stress that while considerable progress has been made since the introduction of the Bitcoin blockchain, research in reward sharing for collaborative projects is still an extremely active and growing domain. Our team continuously evaluates various aspects of reward-sharing schemes and actively explores the whole design space in a first-principles manner. In this way, we can ensure that any research advances will be disseminated widely for the benefit of the whole community.\n\n*I am grateful to Christian Badertscher, Sandro Coretti-Drayton, Matthias Fitzi, and Peter Gaži, for their help in the review of other systems and their placement in the systematization of this article.*',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'blockchain-reward-sharing-a-comparative-systematization-from-first-principles',
                                url: '/blog/posts/2020/11/30/blockchain-reward-sharing-a-comparative-systematization-from-first-principles/',
                                read_time: 10
                            },
                            {
                                publish_date: '2020-11-13T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/11b8ba18-b116-4f00-9c34-0c4ea1554f73/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'The general perspective on staking in Cardano',
                                        subtitle: 'Advice for Stakeholders - Delegators and Stake Pool Operators.',
                                        audio: 'https://ucarecdn.com/9fba0645-fb60-4d88-8dc2-148c2d7b0f64/Aggelosblog13Sept.mp3',
                                        soundcloud: null,
                                        body_content: 'As a project, decentralization remains arguably our most important and fundamental goal for Cardano. Protocols and parameters provide the foundations for any blockchain. Last week, we outlined some of the planned [changes around Cardano parameters](https://iohk.io/en/blog/posts/2020/11/05/parameters-and-decentralization-the-way-ahead/) and how these will impact the staking ecosystem and thus accelerate our decentralization mission.\n\nYet the community itself – how it sees itself, how it behaves, and how it sets common standards – is a key factor in the pace of this success. Cardano has been very carefully engineered to provide “by design” all the necessary properties for a blockchain system to operate successfully. However, Cardano is also a *social* construct, and as such, observance, interpretation, and social norms play a crucial role in shaping its resilience and longevity.\n\nSo in anticipation of the *k*-parameter adjustment on December 6th, I would like to give a broader perspective on staking, highlighting some of the innovative features of the [rewards sharing scheme](https://arxiv.org/abs/1807.11218) used in Cardano. \n\n### Principles & practical intent\n\nAs well as outlining some of the key principles, this piece has a clear practical intent; to provide guidance and some recommendations to stakeholders so that they engage meaningfully with the mechanism, and support the project’s longer-term strategic goals through their actions.\n\nConsensus based on a *resource* that is dispersed somehow across a population of users – as opposed to identity-based participation – has been the hallmark of the blockchain space since the launch of the Bitcoin blockchain. In this domain, proof-of-stake systems are distinguished in the sense that they use a virtual resource, *stake*, which is recorded in the blockchain itself. \n\nPooling resources for participation is something that is inevitable; some level of pooling is typically beneficial in the economic sense and hence resource holders will find a way to make it happen. Given this inevitability, the question arises: how does a system prevent a dictatorship or an oligarchy from emerging?\n\n### The objectives of the reward sharing scheme\n\nContrary to other blockchain systems, Cardano uses a reward sharing scheme that (1) facilitates staking with *minimum friction as well* as (2) it incentivizes pooling resources in a way that *system-wide decentralization* emerges naturally from the rational engagement of the resource holders.\n\nThe mechanism has the following two broad objectives:\n\n1. **Engage *all* stakeholders** - This is important since the more stakeholders are engaged in the system, the more *secure* the distributed ledger will be. This also means that the system should have no barriers for participation, nor should impose friction by requiring off-chain coordination between stakeholders to engage with the mechanism. \n2. **Keep the leverage of individual stakeholders low** -. Pooling resources leads to increased leverage for some stakeholders. Pool operators exert an influence in the system proportional to the resources controlled by their pool, *not to their own* resources. Without pooling, all resource holders have leverage of exactly 1; contrast this e.g., to a pool operator, owning, say 100K ada, who controls a pool of total delegated stake of 200M ada; that operator has leverage of 2,000. The higher the leverage of the system, the worse its security (to see this, consider that with leverage above 50, launching a 51% attack requires a mere 1% of the total resources!).\n\nIt should also be stressed that a disproportionately large pool size is not the only reason for increased leverage; stakeholders creating multiple pools, either openly or covertly (what is known as a Sybil attack) can also lead to increased leverage. The lower the leverage of a blockchain system, the higher its degree of decentralization.\n\n### Putting this into practice\n\nSo how does the reward sharing scheme used in Cardano meet the above objectives? Staking via our scheme facilitates two different paths: *pledging* and *delegating*. Pledging applies to stake pool operators; pledged stake is committed to a stake pool and is supposed to stay put for as long as the pool is operating. Think of pledge as a ‘commitment’ to the network – ‘locking up’ a certain amount of stake in order to help safeguard and secure the protocol. Delegating on the other hand, is for those who do not wish to be involved as operators. Instead, they are invited to assess the offerings the stake pool operators provide, and delegate their stake to one or more pools that, in their opinion, best serve their interests and the interest of the community at large. Given that delegation does not require locking up funds, there is no reason to abstain from staking in Cardano; all stakeholders can and are encouraged to engage in staking.\n\nCentral to the mechanism’s behavior are two parameters: *k* and a0. The k-parameter caps the rewards of pools to 1/*k* of the total available. The a0 parameter creates a benefit for pledging more stake into a single pool; adding X amount of pledge to a pool increases its rewards additively by up to a0*X. This is not to the detriment of other pools; any rewards left unclaimed due to insufficient pledging will be returned to the Cardano’s reserves and allocated in the future. \n\nBeyond deciding on an amount to pledge, creating a stake pool requires that  operators declare their profit margin and operational costs. When the pool rewards are allocated at the end of each epoch, the operational costs are withheld first, ensuring that stake pools remain viable. Subsequently, operator profit is calculated, and all pool delegators are rewarded in ada proportional to their stake afterwards. \n\nPaired with the assessment of stake pools performed by the delegates, this mechanism provides the right set of constraints for the system to converge to a configuration of *k* equal size pools with the maximum amount of pledge possible. The equilibrium point has the property that delegator rewards are equalized (so it doesn’t matter what pool they delegate to!), while stake pool operators are rewarded appropriately for their performance, their cost efficiency, and their general contributions to the ecosystem.\n\nFor the above to happen, it is necessary to engage with the mechanism in a meaningful and rational manner. To assist stakeholders in understanding the mechanism, here are some points of advice. \n\n### Guidance for delegators\n\n1. **Know your pool(s)** - Investigate the pools’ available data and information. What is the operators’ web-presence? What kind of information do they provide about their operation? Are they descriptive about their costs? Are the costs reasonably based on geographic location and other aspects of their operation? Do they update their costs regularly to account for the fluctuation of ada? Do they include the costs for their personal time? Remember that maintaining a high-performance pool requires commitment and effort, so those committed operators deserve compensation. \n\n\n2. **Think bigger** - Consider your choice holistically, not based on just a single dimension. Consider the longer term value your choices bring to the network.  Think of your delegation as a ‘vote of confidence’, or a way to show your support to a pool\'s mission or goals. Opt for professionalism and demonstrated long-term commitment to the system’s goals. Recognize community members who have been helping to lay down the foundations for the ecosystem, either with their community presence or by helping to build things. The long-term wellbeing of the ecosystem is crucially affected by your delegation choice. A more decentralized network is a more resilient and long-lived network. \n3. **Be wary of ‘pool splitters’** - Pool operators that run multiple pools *with small pledge* ***hurt delegators and smaller operators***. They hurt their delegators because they could have provided a higher amount of rewards by concentrating their pledge into a single pool; by not doing that, there are rewards that remain unclaimed. They hurt smaller and new operators, because they are forcing them to remain without delegates and hence making their operation unviable – without delegates a pool may be forced to close. So avoid pool operators that run multiple pools with pledge below saturation level. Note there are legitimate reasons for large stakeholders to accept delegators and run a public pool (e.g., they are delegating some of their stake to other pools to support the community); consult any public statements such operators make about their delegation strategy and their leverage. It is ok to delegate to them, assuming they keep their leverage low and they support the community. \n4. **Be wary of highly leveraged operators** - Be mindful of the stake pool operators’ *leverage* (see below for more details on how to calculate leverage). A higher pledge is correlated to less leverage when comparing pools of the same size; a high leverage is indicative of a stake pool operator with very little “skin in the game.” Stake pool operators may prove to have skin in the game in other ways than pledging stake of course; e.g., they can be very professional and contribute to the community in different ways. You should be the judge of this: high leverage in itself is not a reason to avoid delegating to a particular pool, but it is a *strong* indication that you should proceed with caution and carefully evaluate the people behind the operation. \n5. **Shop around** - Do take into account the information provided from your wallet software (or from recognized community resources such as [adapools](https://adapools.org/) or [pooltool](https://pooltool.io/)) in terms of the pool’s ranking and its performance factor.  Remember though, while the ranking is important, it should not be the sole factor behind your delegation choice. Think holistically – you may want to consider pools fulfilling a mission you agree with, or trying to add value to the wider community through podcasts or social activity, even if they do not offer the highest possible returns.\n6. **Be involved** - A pool with no performance data on display may have attractive characteristics; it could be providing better rewards in the best case scenario, but also high risk as a delegation choice since its performance may turn out to be suboptimal. Delegate according to your ‘risk profile’, and the frequency you are willing to re-delegate your stake. Do check the pool’s performance and updates regularly to ensure that your choice and assessment remains the best possible. \n\n### Guidance for pool operators\n\n1. **Be transparent** - Choose your pool’s operational cost as accurately as possible. Do include the personal effort (priced at a reasonable rate) that you and your partners put into the pool operation! You are a pillar of Cardano and so you have every right to be compensated by the community. Be upfront about your costs and include them in your pool’s website. Educate your prospective delegates about where the pool costs are going. Always remember that it is important to charge for the time you invest in maintaining your pool. In the short term, you may be prepared to invest your time and energy ‘for free’ (or after hosting costs, at an effective loss) but remember that this is not a sustainable model for the network over the medium and longer term. \n2. **Don’t split your pool** - With the coming changes in *k* (commencing with the move to k=500 on 6th December), we are already seeing pool operators splitting their pools in order to retain delegators without becoming saturated. Do not engage in pool splitting unless you can saturate a pool completely with your stake. If you are a whale (relative stake > 1/*k*) you can create multiple pools – but you should keep your leverage as close to 1 as possible or less. Pool splitting that increases your leverage hurts the delegators’ rewards, and more importantly, it hurts the decentralization of the Cardano ecosystem, which is detrimental to everyone. If you run and control multiple pools under different tickers, make a public statement about it. Explain the steps you take to control your leverage. Creating multiple pools while trying to conceal the fact that you control them is akin to a Sybil attack against Cardano. This behavior should be condemned by the community. You can calculate and publicize your leverage using the following formula:\n\n   ![](https://ucarecdn.com/dc5b9d2a-1786-44bd-b261-e471e93afeba/)\n\nExchanges are a special kind of whale stakeholder, since they collectively  manage other people’s stake. One strategy for an exchange is to avoid leverage altogether and delegate the stake they control to community pools. If an exchange becomes a pool operator, they can maintain their leverage below 1 by using a mixed pledging and delegation strategy. \n\n3. **Set your profit margin wisely** - Select the margin to make your pool competitive. Remember that if everyone delegates their stake and is rational, you only have to beat the (*k*+1)-th pool in the rankings offered by the Daedalus wallet. If your pool offers other advantages that can attract delegation (e.g., you are contributing to a charitable cause you feel others may wish to support), or you have acquired exceptional equipment that promises notable uptime/performance, make sure you promote this widely. When you offer such benefits, you should consider setting a higher profit margin. \n\n\n4. **Keep your pool data updated** - Regularly update the cost and margin to accommodate fluctuations in ada price. Give assurances to your delegators and update them about the stake pool operational details. In case of mishaps and downtimes, be upfront and inform your delegators via your website and/or other communication channels you maintain with them. \n5. **Pledge as much as you are able to** - Increase the amount of pledge as much as you comfortably can and not more. Beyond using your own stake, you can also partner with other stakeholders to increase the pledge of your pool. A high pledge signals long-term commitment and reduced leverage, and it unlocks additional rewards every epoch as dictated by the a0 term in the rewards sharing scheme calculation. As a result, it does make your pool more desirable to prospective delegators. On the other hand, remember that pledge is not the only factor that makes a pool attractive. Spend time on your web and social media presence and be sure to advertise all the ways that you contribute to the Cardano ecosystem. \n\nIf you are a Cardano stakeholder, we hope that you find the above advice informative and helpful in your efforts to engage in staking. As in many other respects, Cardano brings a novel and heavily researched mechanism to its blockchain design. The rewards scheme is mathematically proven to offer an equilibrium that meets the set of objectives set out in the beginning of this document. Ultimately though, the math is not enough; it is *only the people* that can make it happen. \n\nCardano’s future is in the hands of the community. \n\n*The opinions expressed in the blogpost are for educational purposes only and are not intended to provide any form of financial advice.*',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'The general perspective on staking in Cardano',
                                subtitle: 'Advice for Stakeholders - Delegators and Stake Pool Operators.',
                                audio: 'https://ucarecdn.com/9fba0645-fb60-4d88-8dc2-148c2d7b0f64/Aggelosblog13Sept.mp3',
                                soundcloud: null,
                                body_content: 'As a project, decentralization remains arguably our most important and fundamental goal for Cardano. Protocols and parameters provide the foundations for any blockchain. Last week, we outlined some of the planned [changes around Cardano parameters](https://iohk.io/en/blog/posts/2020/11/05/parameters-and-decentralization-the-way-ahead/) and how these will impact the staking ecosystem and thus accelerate our decentralization mission.\n\nYet the community itself – how it sees itself, how it behaves, and how it sets common standards – is a key factor in the pace of this success. Cardano has been very carefully engineered to provide “by design” all the necessary properties for a blockchain system to operate successfully. However, Cardano is also a *social* construct, and as such, observance, interpretation, and social norms play a crucial role in shaping its resilience and longevity.\n\nSo in anticipation of the *k*-parameter adjustment on December 6th, I would like to give a broader perspective on staking, highlighting some of the innovative features of the [rewards sharing scheme](https://arxiv.org/abs/1807.11218) used in Cardano. \n\n### Principles & practical intent\n\nAs well as outlining some of the key principles, this piece has a clear practical intent; to provide guidance and some recommendations to stakeholders so that they engage meaningfully with the mechanism, and support the project’s longer-term strategic goals through their actions.\n\nConsensus based on a *resource* that is dispersed somehow across a population of users – as opposed to identity-based participation – has been the hallmark of the blockchain space since the launch of the Bitcoin blockchain. In this domain, proof-of-stake systems are distinguished in the sense that they use a virtual resource, *stake*, which is recorded in the blockchain itself. \n\nPooling resources for participation is something that is inevitable; some level of pooling is typically beneficial in the economic sense and hence resource holders will find a way to make it happen. Given this inevitability, the question arises: how does a system prevent a dictatorship or an oligarchy from emerging?\n\n### The objectives of the reward sharing scheme\n\nContrary to other blockchain systems, Cardano uses a reward sharing scheme that (1) facilitates staking with *minimum friction as well* as (2) it incentivizes pooling resources in a way that *system-wide decentralization* emerges naturally from the rational engagement of the resource holders.\n\nThe mechanism has the following two broad objectives:\n\n1. **Engage *all* stakeholders** - This is important since the more stakeholders are engaged in the system, the more *secure* the distributed ledger will be. This also means that the system should have no barriers for participation, nor should impose friction by requiring off-chain coordination between stakeholders to engage with the mechanism. \n2. **Keep the leverage of individual stakeholders low** -. Pooling resources leads to increased leverage for some stakeholders. Pool operators exert an influence in the system proportional to the resources controlled by their pool, *not to their own* resources. Without pooling, all resource holders have leverage of exactly 1; contrast this e.g., to a pool operator, owning, say 100K ada, who controls a pool of total delegated stake of 200M ada; that operator has leverage of 2,000. The higher the leverage of the system, the worse its security (to see this, consider that with leverage above 50, launching a 51% attack requires a mere 1% of the total resources!).\n\nIt should also be stressed that a disproportionately large pool size is not the only reason for increased leverage; stakeholders creating multiple pools, either openly or covertly (what is known as a Sybil attack) can also lead to increased leverage. The lower the leverage of a blockchain system, the higher its degree of decentralization.\n\n### Putting this into practice\n\nSo how does the reward sharing scheme used in Cardano meet the above objectives? Staking via our scheme facilitates two different paths: *pledging* and *delegating*. Pledging applies to stake pool operators; pledged stake is committed to a stake pool and is supposed to stay put for as long as the pool is operating. Think of pledge as a ‘commitment’ to the network – ‘locking up’ a certain amount of stake in order to help safeguard and secure the protocol. Delegating on the other hand, is for those who do not wish to be involved as operators. Instead, they are invited to assess the offerings the stake pool operators provide, and delegate their stake to one or more pools that, in their opinion, best serve their interests and the interest of the community at large. Given that delegation does not require locking up funds, there is no reason to abstain from staking in Cardano; all stakeholders can and are encouraged to engage in staking.\n\nCentral to the mechanism’s behavior are two parameters: *k* and a0. The k-parameter caps the rewards of pools to 1/*k* of the total available. The a0 parameter creates a benefit for pledging more stake into a single pool; adding X amount of pledge to a pool increases its rewards additively by up to a0*X. This is not to the detriment of other pools; any rewards left unclaimed due to insufficient pledging will be returned to the Cardano’s reserves and allocated in the future. \n\nBeyond deciding on an amount to pledge, creating a stake pool requires that  operators declare their profit margin and operational costs. When the pool rewards are allocated at the end of each epoch, the operational costs are withheld first, ensuring that stake pools remain viable. Subsequently, operator profit is calculated, and all pool delegators are rewarded in ada proportional to their stake afterwards. \n\nPaired with the assessment of stake pools performed by the delegates, this mechanism provides the right set of constraints for the system to converge to a configuration of *k* equal size pools with the maximum amount of pledge possible. The equilibrium point has the property that delegator rewards are equalized (so it doesn’t matter what pool they delegate to!), while stake pool operators are rewarded appropriately for their performance, their cost efficiency, and their general contributions to the ecosystem.\n\nFor the above to happen, it is necessary to engage with the mechanism in a meaningful and rational manner. To assist stakeholders in understanding the mechanism, here are some points of advice. \n\n### Guidance for delegators\n\n1. **Know your pool(s)** - Investigate the pools’ available data and information. What is the operators’ web-presence? What kind of information do they provide about their operation? Are they descriptive about their costs? Are the costs reasonably based on geographic location and other aspects of their operation? Do they update their costs regularly to account for the fluctuation of ada? Do they include the costs for their personal time? Remember that maintaining a high-performance pool requires commitment and effort, so those committed operators deserve compensation. \n\n\n2. **Think bigger** - Consider your choice holistically, not based on just a single dimension. Consider the longer term value your choices bring to the network.  Think of your delegation as a ‘vote of confidence’, or a way to show your support to a pool\'s mission or goals. Opt for professionalism and demonstrated long-term commitment to the system’s goals. Recognize community members who have been helping to lay down the foundations for the ecosystem, either with their community presence or by helping to build things. The long-term wellbeing of the ecosystem is crucially affected by your delegation choice. A more decentralized network is a more resilient and long-lived network. \n3. **Be wary of ‘pool splitters’** - Pool operators that run multiple pools *with small pledge* ***hurt delegators and smaller operators***. They hurt their delegators because they could have provided a higher amount of rewards by concentrating their pledge into a single pool; by not doing that, there are rewards that remain unclaimed. They hurt smaller and new operators, because they are forcing them to remain without delegates and hence making their operation unviable – without delegates a pool may be forced to close. So avoid pool operators that run multiple pools with pledge below saturation level. Note there are legitimate reasons for large stakeholders to accept delegators and run a public pool (e.g., they are delegating some of their stake to other pools to support the community); consult any public statements such operators make about their delegation strategy and their leverage. It is ok to delegate to them, assuming they keep their leverage low and they support the community. \n4. **Be wary of highly leveraged operators** - Be mindful of the stake pool operators’ *leverage* (see below for more details on how to calculate leverage). A higher pledge is correlated to less leverage when comparing pools of the same size; a high leverage is indicative of a stake pool operator with very little “skin in the game.” Stake pool operators may prove to have skin in the game in other ways than pledging stake of course; e.g., they can be very professional and contribute to the community in different ways. You should be the judge of this: high leverage in itself is not a reason to avoid delegating to a particular pool, but it is a *strong* indication that you should proceed with caution and carefully evaluate the people behind the operation. \n5. **Shop around** - Do take into account the information provided from your wallet software (or from recognized community resources such as [adapools](https://adapools.org/) or [pooltool](https://pooltool.io/)) in terms of the pool’s ranking and its performance factor.  Remember though, while the ranking is important, it should not be the sole factor behind your delegation choice. Think holistically – you may want to consider pools fulfilling a mission you agree with, or trying to add value to the wider community through podcasts or social activity, even if they do not offer the highest possible returns.\n6. **Be involved** - A pool with no performance data on display may have attractive characteristics; it could be providing better rewards in the best case scenario, but also high risk as a delegation choice since its performance may turn out to be suboptimal. Delegate according to your ‘risk profile’, and the frequency you are willing to re-delegate your stake. Do check the pool’s performance and updates regularly to ensure that your choice and assessment remains the best possible. \n\n### Guidance for pool operators\n\n1. **Be transparent** - Choose your pool’s operational cost as accurately as possible. Do include the personal effort (priced at a reasonable rate) that you and your partners put into the pool operation! You are a pillar of Cardano and so you have every right to be compensated by the community. Be upfront about your costs and include them in your pool’s website. Educate your prospective delegates about where the pool costs are going. Always remember that it is important to charge for the time you invest in maintaining your pool. In the short term, you may be prepared to invest your time and energy ‘for free’ (or after hosting costs, at an effective loss) but remember that this is not a sustainable model for the network over the medium and longer term. \n2. **Don’t split your pool** - With the coming changes in *k* (commencing with the move to k=500 on 6th December), we are already seeing pool operators splitting their pools in order to retain delegators without becoming saturated. Do not engage in pool splitting unless you can saturate a pool completely with your stake. If you are a whale (relative stake > 1/*k*) you can create multiple pools – but you should keep your leverage as close to 1 as possible or less. Pool splitting that increases your leverage hurts the delegators’ rewards, and more importantly, it hurts the decentralization of the Cardano ecosystem, which is detrimental to everyone. If you run and control multiple pools under different tickers, make a public statement about it. Explain the steps you take to control your leverage. Creating multiple pools while trying to conceal the fact that you control them is akin to a Sybil attack against Cardano. This behavior should be condemned by the community. You can calculate and publicize your leverage using the following formula:\n\n   ![](https://ucarecdn.com/dc5b9d2a-1786-44bd-b261-e471e93afeba/)\n\nExchanges are a special kind of whale stakeholder, since they collectively  manage other people’s stake. One strategy for an exchange is to avoid leverage altogether and delegate the stake they control to community pools. If an exchange becomes a pool operator, they can maintain their leverage below 1 by using a mixed pledging and delegation strategy. \n\n3. **Set your profit margin wisely** - Select the margin to make your pool competitive. Remember that if everyone delegates their stake and is rational, you only have to beat the (*k*+1)-th pool in the rankings offered by the Daedalus wallet. If your pool offers other advantages that can attract delegation (e.g., you are contributing to a charitable cause you feel others may wish to support), or you have acquired exceptional equipment that promises notable uptime/performance, make sure you promote this widely. When you offer such benefits, you should consider setting a higher profit margin. \n\n\n4. **Keep your pool data updated** - Regularly update the cost and margin to accommodate fluctuations in ada price. Give assurances to your delegators and update them about the stake pool operational details. In case of mishaps and downtimes, be upfront and inform your delegators via your website and/or other communication channels you maintain with them. \n5. **Pledge as much as you are able to** - Increase the amount of pledge as much as you comfortably can and not more. Beyond using your own stake, you can also partner with other stakeholders to increase the pledge of your pool. A high pledge signals long-term commitment and reduced leverage, and it unlocks additional rewards every epoch as dictated by the a0 term in the rewards sharing scheme calculation. As a result, it does make your pool more desirable to prospective delegators. On the other hand, remember that pledge is not the only factor that makes a pool attractive. Spend time on your web and social media presence and be sure to advertise all the ways that you contribute to the Cardano ecosystem. \n\nIf you are a Cardano stakeholder, we hope that you find the above advice informative and helpful in your efforts to engage in staking. As in many other respects, Cardano brings a novel and heavily researched mechanism to its blockchain design. The rewards scheme is mathematically proven to offer an equilibrium that meets the set of objectives set out in the beginning of this document. Ultimately though, the math is not enough; it is *only the people* that can make it happen. \n\nCardano’s future is in the hands of the community. \n\n*The opinions expressed in the blogpost are for educational purposes only and are not intended to provide any form of financial advice.*',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'the-general-perspective-on-staking-in-cardano',
                                url: '/blog/posts/2020/11/13/the-general-perspective-on-staking-in-cardano/',
                                read_time: 13
                            },
                            {
                                publish_date: '2020-06-23T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/3dd87ee7-829f-4c0d-8941-d9cec23cc27f/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'The Ouroboros path to decentralization',
                                        subtitle: 'The protocol that powers Cardano and its design philosophy',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'Designing and deploying a distributed ledger is a technically challenging task. What is expected of a ledger is the promise of a consistent view to all participants as well as a guarantee of responsiveness to the continuous flow of events that result from their actions. These two properties, sometimes referred to as *persistence* and *liveness*, are the hallmark of distributed ledger systems.\n\nAchieving persistence and liveness in a centralized system is a well-studied and fairly straightforward task; unfortunately, the ledger that emerges is precariously brittle because the server that supports the ledger becomes a single point of failure. As a result, hacking the server can lead to the instant violation of both properties. Even if the server is not hacked, the interests of the server’s operators may not align with the continuous assurance of these properties. For this reason, *decentralization* has been advanced as an essential remedy.\n\nInformally, decentralization refers to a system architecture that calls for many entities to act individually in such a way that the ledger’s properties emerge from the convergence of their actions. In exchange for this increase in complexity, a well-designed system can continue to function even if some parties deviate from proper operation. Moreover, in the case of more significant deviations, even if some disruption is unavoidable, the system should still be capable of returning to normal operation and contain the damage.\n\nHow does one design a robust decentralized system? The world is a complicated place and decentralization is not a characteristic that can be hard-coded or demonstrated via testing – the potential configurations that might arise are infinite. To counter this, one must develop *models* that systematically encompass all the different threats the system may encounter and demonstrate rigorously that the two basic properties of persistence and liveness are upheld.\n\nThe strongest arguments for the reliability of a decentralized system combine formal guarantees against a broad portfolio of different classes of failure and attack models. The first important class is that of powerful Byzantine models. In this setting, it should be guaranteed that even if a subset of participants *arbitrarily* deviate from the rules, the two fundamental properties are retained. The second important class is models of rationality. Here, participants are assumed to be *rational utility maximizers* and the objective is to show that the ledger properties arise from their efforts to pursue their self interest.\n\nOuroboros is a decentralized ledger protocol that is analyzed in the context of both Byzantine and rational behavior. What makes the protocol unique is the combination of the following design elements.\n\n* It uses **stake** as the fundamental resource to identify the participants’ leverage in the system. No physical resource is wasted in the process of ledger maintenance, which is shown to be robust despite ‘costless simulation’ and ‘nothing at stake’ attacks that were previously thought to be fundamental barriers to stake-based ledgers. This makes Ouroboros distinctly more appealing than proof-of-work protocols, which require prodigious energy expenditure to maintain consensus.\n* It is proven to be resilient even if arbitrarily large subsets of participants, in terms of stake, abstain from ledger maintenance. This guarantee of **dynamic availability** ensures liveness even under arbitrary, and unpredictable, levels of engagement. At the same time, of those participants who are active, barely more than half need to follow the protocol – the rest can arbitrarily deviate; in fact, even temporary spikes above the 50% threshold can be tolerated. Thus Ouroboros is distinctly more resilient and adaptable than classical Byzantine fault tolerance protocols (as well as all their modern adaptations), which have to predict with relative certainty the level of expected participation and may stop operating when the prediction is false.\n* The process of joining and participating in the protocol execution is **trustless** in the sense that it does not require the availability of any special shared resource such as a recent checkpoint or a common clock. Engaging in the protocol requires merely the public genesis block of the chain, and access to the network. This makes Ouroboros free of the trust assumptions common in other consensus protocols whose security collapses when trusted shared resources are subverted or unavailable.\n* Ouroboros incorporates a reward-sharing mechanism to incentivize participants to **organize themselves** in operational nodes, known as stake pools, that can offer a good quality of service independently of how stake is distributed among the user population. In this way, all stakeholders contribute to the system’s operation – ensuring robustness and democratic representation – while the cost of ledger maintenance is efficiently distributed across the user population. At the same time, the mechanism comes with countermeasures that de-incentivize centralization. This makes Ouroboros fundamentally more inclusive and decentralized compared with other protocols that either end up with just a handful of actors responsible for ledger maintenance or provide no incentives to stakeholders to participate and offer a good quality of service.\n\nThese design elements of Ouroboros are not supposed to be self-evident appeals to the common sense of the protocol user. Instead, they were delivered with meticulous documentation in papers that have undergone peer review and appeared in top-tier conferences and publications in the area of cybersecurity and cryptography. Indeed, it is fair to say that no other consensus research effort is represented so comprehensively in these circles. Each paper is explicit about the specific type of model that is used to analyze the protocol and the results derived are laid out in concrete terms. The papers are open-access, patent-free, and include all technical details to allow anyone, with the relevant technical expertise, to convince themselves of the veracity of the claims made about performance, security, and functionality.\n\nBuilding an inclusive, fair and resilient infrastructure for financial and social applications on a global scale is the grand challenge of information technology today. Ouroboros contributes, not just as a protocol with unique characteristics, but also in presenting a design methodology that highlights first principles, careful modeling and rigorous analysis. Its modular and adaptable architecture also lends itself to continuous improvement, adaptation and enrichment with additional elements (such as parallelization to improve scalability or zero-knowledge proofs to improve privacy, to name two examples), which is a befitting characteristic to meet the ever-evolving needs and complexities of the real world.\n\n## Further reading\n\nTo delve deeper into the Ouroboros protocol, from its inception to recent new features, follow these links:\n\n1. [Ouroboros (Classic)](http://ia.cr/2016/889): the first provably secure proof-of-stake blockchain protocol.\n2. [Ouroboros Praos](http://ia.cr/2017/573): removes the need for a rigid round structure and improves resilience against ‘adaptive’ attackers.\n3. [Ouroboros Genesis](https://ia.cr/2018/378): how to avoid the need for a recent checkpoint and prove the protocol is secure under dynamic availability for trustless joining and participating.\n4. [Ouroboros Chronos](http://ia.cr/2019/838): removes the need for a common clock.\n5. [Reward sharing schemes](https://arxiv.org/abs/1807.11218) for stake pools.\n6. [Account management](https://ia.cr/2020/525) and maximizing participation in stake pools.\n7. [Optimizing transaction throughput](http://ia.cr/2020/037) with proof-of-stake protocols.\n8. [Fast settlement](http://ia.cr/2020/675) using ledger combiners.\n9. [Ouroboros Crypsinous](http://ia.cr/2018/1132): a privacy-preserving proof-of-stake protocol.\n10. [Kachina](http://ia.cr/2020/543): a unified security model for private smart contracts.\n11. [Hydra](http://ia.cr/2020/299): an off-chain scalability architecture for high transaction throughput with low latency, and minimal storage per node.',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'The Ouroboros path to decentralization',
                                subtitle: 'The protocol that powers Cardano and its design philosophy',
                                audio: null,
                                soundcloud: null,
                                body_content: 'Designing and deploying a distributed ledger is a technically challenging task. What is expected of a ledger is the promise of a consistent view to all participants as well as a guarantee of responsiveness to the continuous flow of events that result from their actions. These two properties, sometimes referred to as *persistence* and *liveness*, are the hallmark of distributed ledger systems.\n\nAchieving persistence and liveness in a centralized system is a well-studied and fairly straightforward task; unfortunately, the ledger that emerges is precariously brittle because the server that supports the ledger becomes a single point of failure. As a result, hacking the server can lead to the instant violation of both properties. Even if the server is not hacked, the interests of the server’s operators may not align with the continuous assurance of these properties. For this reason, *decentralization* has been advanced as an essential remedy.\n\nInformally, decentralization refers to a system architecture that calls for many entities to act individually in such a way that the ledger’s properties emerge from the convergence of their actions. In exchange for this increase in complexity, a well-designed system can continue to function even if some parties deviate from proper operation. Moreover, in the case of more significant deviations, even if some disruption is unavoidable, the system should still be capable of returning to normal operation and contain the damage.\n\nHow does one design a robust decentralized system? The world is a complicated place and decentralization is not a characteristic that can be hard-coded or demonstrated via testing – the potential configurations that might arise are infinite. To counter this, one must develop *models* that systematically encompass all the different threats the system may encounter and demonstrate rigorously that the two basic properties of persistence and liveness are upheld.\n\nThe strongest arguments for the reliability of a decentralized system combine formal guarantees against a broad portfolio of different classes of failure and attack models. The first important class is that of powerful Byzantine models. In this setting, it should be guaranteed that even if a subset of participants *arbitrarily* deviate from the rules, the two fundamental properties are retained. The second important class is models of rationality. Here, participants are assumed to be *rational utility maximizers* and the objective is to show that the ledger properties arise from their efforts to pursue their self interest.\n\nOuroboros is a decentralized ledger protocol that is analyzed in the context of both Byzantine and rational behavior. What makes the protocol unique is the combination of the following design elements.\n\n* It uses **stake** as the fundamental resource to identify the participants’ leverage in the system. No physical resource is wasted in the process of ledger maintenance, which is shown to be robust despite ‘costless simulation’ and ‘nothing at stake’ attacks that were previously thought to be fundamental barriers to stake-based ledgers. This makes Ouroboros distinctly more appealing than proof-of-work protocols, which require prodigious energy expenditure to maintain consensus.\n* It is proven to be resilient even if arbitrarily large subsets of participants, in terms of stake, abstain from ledger maintenance. This guarantee of **dynamic availability** ensures liveness even under arbitrary, and unpredictable, levels of engagement. At the same time, of those participants who are active, barely more than half need to follow the protocol – the rest can arbitrarily deviate; in fact, even temporary spikes above the 50% threshold can be tolerated. Thus Ouroboros is distinctly more resilient and adaptable than classical Byzantine fault tolerance protocols (as well as all their modern adaptations), which have to predict with relative certainty the level of expected participation and may stop operating when the prediction is false.\n* The process of joining and participating in the protocol execution is **trustless** in the sense that it does not require the availability of any special shared resource such as a recent checkpoint or a common clock. Engaging in the protocol requires merely the public genesis block of the chain, and access to the network. This makes Ouroboros free of the trust assumptions common in other consensus protocols whose security collapses when trusted shared resources are subverted or unavailable.\n* Ouroboros incorporates a reward-sharing mechanism to incentivize participants to **organize themselves** in operational nodes, known as stake pools, that can offer a good quality of service independently of how stake is distributed among the user population. In this way, all stakeholders contribute to the system’s operation – ensuring robustness and democratic representation – while the cost of ledger maintenance is efficiently distributed across the user population. At the same time, the mechanism comes with countermeasures that de-incentivize centralization. This makes Ouroboros fundamentally more inclusive and decentralized compared with other protocols that either end up with just a handful of actors responsible for ledger maintenance or provide no incentives to stakeholders to participate and offer a good quality of service.\n\nThese design elements of Ouroboros are not supposed to be self-evident appeals to the common sense of the protocol user. Instead, they were delivered with meticulous documentation in papers that have undergone peer review and appeared in top-tier conferences and publications in the area of cybersecurity and cryptography. Indeed, it is fair to say that no other consensus research effort is represented so comprehensively in these circles. Each paper is explicit about the specific type of model that is used to analyze the protocol and the results derived are laid out in concrete terms. The papers are open-access, patent-free, and include all technical details to allow anyone, with the relevant technical expertise, to convince themselves of the veracity of the claims made about performance, security, and functionality.\n\nBuilding an inclusive, fair and resilient infrastructure for financial and social applications on a global scale is the grand challenge of information technology today. Ouroboros contributes, not just as a protocol with unique characteristics, but also in presenting a design methodology that highlights first principles, careful modeling and rigorous analysis. Its modular and adaptable architecture also lends itself to continuous improvement, adaptation and enrichment with additional elements (such as parallelization to improve scalability or zero-knowledge proofs to improve privacy, to name two examples), which is a befitting characteristic to meet the ever-evolving needs and complexities of the real world.\n\n## Further reading\n\nTo delve deeper into the Ouroboros protocol, from its inception to recent new features, follow these links:\n\n1. [Ouroboros (Classic)](http://ia.cr/2016/889): the first provably secure proof-of-stake blockchain protocol.\n2. [Ouroboros Praos](http://ia.cr/2017/573): removes the need for a rigid round structure and improves resilience against ‘adaptive’ attackers.\n3. [Ouroboros Genesis](https://ia.cr/2018/378): how to avoid the need for a recent checkpoint and prove the protocol is secure under dynamic availability for trustless joining and participating.\n4. [Ouroboros Chronos](http://ia.cr/2019/838): removes the need for a common clock.\n5. [Reward sharing schemes](https://arxiv.org/abs/1807.11218) for stake pools.\n6. [Account management](https://ia.cr/2020/525) and maximizing participation in stake pools.\n7. [Optimizing transaction throughput](http://ia.cr/2020/037) with proof-of-stake protocols.\n8. [Fast settlement](http://ia.cr/2020/675) using ledger combiners.\n9. [Ouroboros Crypsinous](http://ia.cr/2018/1132): a privacy-preserving proof-of-stake protocol.\n10. [Kachina](http://ia.cr/2020/543): a unified security model for private smart contracts.\n11. [Hydra](http://ia.cr/2020/299): an off-chain scalability architecture for high transaction throughput with low latency, and minimal storage per node.',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'the-ouroboros-path-to-decentralization',
                                url: '/blog/posts/2020/06/23/the-ouroboros-path-to-decentralization/',
                                read_time: 6
                            },
                            {
                                publish_date: '2020-03-26',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/16a0b7e2-2620-4333-acd5-57a713c5d2f6/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Enter the Hydra: scaling distributed ledgers, the evidence-based way ',
                                        subtitle: 'Learn about Hydra: the multi-headed ledger protocol ',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'Scalability is the greatest challenge to blockchain adoption. By applying a principled, evidence-based approach, we have arrived at a solution for Cardano and networks similar to it: Hydra. Hydra is the culmination of extensive research, and a decisive step in enabling decentralized networks to securely scale to global requirements. \n\n## What is scalability and how do we measure it?\n\nScaling a distributed ledger system refers to the capability of providing high transaction throughput, low latency, and minimal storage per node. These properties have been repeatedly touted as critical for the successful deployment of blockchain protocols as part of real-world systems. In terms of throughput, the VISA network [reportedly](https://usa.visa.com/run-your-business/small-business-tools/retail.html) handles an average of 1,736 payment transactions per second (TPS) with the capability of handling up to 24,000 TPS and is frequently used as a baseline comparison. Transaction latency is clearly desired to be as low as possible, with the ultimate goal of appearing instantaneous to the end-user. Other applications of distributed ledgers have a wide range of different requirements in terms of these metrics. When designing a general purpose distributed ledger, it is natural to strive to excel on all three counts. \n\nDeploying a system that provides satisfactory scaling for a certain use case requires an appropriate combination of two independent aspects: adopting a proper algorithmic design and deploying it over a suitable underlying hardware and network infrastructure.\n\nWhen evaluating a particular algorithmic design, considering absolute numbers in terms of specific metrics can be misleading. The reason is that such absolute quantities must refer to a particular underlying hardware and network configuration which can blur the advantages and disadvantages of particular algorithms. Indeed, a poorly designed protocol may still perform well enough when deployed over superior hardware and networking.\n\nFor this reason, it is more insightful to evaluate the ability of a protocol to reach the physical limits of the underlying network and hardware. This can be achieved by comparing the protocol with simple strawman protocols, in which all the design elements have been stripped away. For instance, if we want to evaluate the overhead of an encryption algorithm, we can compare the communication performance of two end-points using encryption against their performance when they simply exchange unencrypted messages. In such an experiment, the absolute message-per-second rate is unimportant. The important conclusion is the relative overhead that is added by the encryption algorithm. Moreover, in case the overhead approximates 0 for some configuration of the experimental setup, we can conclude that the algorithm approximates the physical limits of the underlying network’s message-passing ability for that particular configuration, and is hence optimal in this sense. \n\n## Hydra – 30,000-feet view\n\nHydra is an off-chain scalability architecture for distributed ledgers, which addresses all three of the scalability challenges mentioned above: high transaction throughput, low latency, and minimal storage per node. While Hydra is being designed in conjunction with the Ouroboros protocol and the Cardano ledger, it may be employed over other systems as well, provided they share the necessary salient characteristics with Cardano.\n\nDespite being an integrated system aimed at solving one problem – scalability – Hydra consists of several subprotocols. This is necessary as the Cardano ecosystem itself is heterogenous and consists of multiple entities with differing technical capabilities: the system supports block producers with associated stake pools, high-throughput wallets as used by exchanges, but also end-users with a wide variety of computational performance and availability characteristics. It is unrealistic to expect that a one-shoe-fits-all, single-protocol approach is sufficient to provide overall scalability for such a diverse set of network participants.\n\nThe Hydra scalability architecture can be divided into four components: the head protocol, the tail protocol, the cross-head-and-tail communication protocol, as well as a set of supporting protocols for routing, reconfiguration, and virtualization. The centerpiece is the \'head\' protocol, which enables a set of high-performance and high-availability participants (such as stake pools) to very quickly process large numbers of transactions with minimal storage requirements by way of a multiparty state channel – a concept that generalizes two-party payment channels as implemented in the context of the Lightning network. It is complemented by the \'tail\' protocol, which enables those high-performance participants to provide scalability for large numbers of end-users who may use the system from low-power devices, such as mobile phones, and who may be offline for extended periods of time. While heads and tails can already communicate via the Cardano mainchain, the cross-head-and-tail communication protocol provides an efficient off–chain variant of this functionality. All this is tied together by routing and configuration management, while virtualisation facilitates faster communication generalizing head and tail communication. \n\n## The Hydra head protocol\n\nThe Hydra head protocol is the first component of the Hydra architecture to be publicly [released](https://eprint.iacr.org/2020/299). It allows a set of participants to create an off-chain state channel (called a head) wherein they can run smart contracts (or process simpler transactions) among each other without interaction with the underlying blockchain in the optimistic case where all head participants adhere to the protocol. The state channel offers very fast settlement and high transaction throughput; furthermore, it requires very little storage, as the off-chain transaction history can be deleted as soon as its resulting state has been secured via an off–chain \'snapshot\' operation.\n\nEven in the pessimistic case where any number of participants misbehave, full safety is rigorously guaranteed. At any time, any participant can initiate the head\'s \'closure\' with the effect that the head\'s state is transferred back to the (less efficient) blockchain. We emphasize that the execution of any smart contracts can be seamlessly continued on-chain. No funds can be generated off-chain, nor can any single, responsive head participant lose any funds.\n\nThe state channels implemented by Hydra are isomorphic in the sense that they make use of the same transaction format and contract code as the underlying blockchain: contracts can be directly moved back and forth between channels and the blockchain. Thus, state channels effectively yield parallel, off-chain ledger siblings. In other words, the ledger becomes multi-headed.\n\nTransaction confirmation in the head is achieved in full concurrency by an asynchronous off-chain certification process using multi-signatures. This high level of parallelism is enabled by use of the extended UTxO model ([EUTxO](https://github.com/hydra-supplementary-material/eutxo-spec/blob/master/extended-utxo-specification.pdf)). Transaction dependencies in the EUTxO model are explicit, which allows for state updates without unnecessary sequentialization of transactions that are independent of each other.  \n\n## Experimental validation of the Hydra head protocol\n\nAs a first step towards experimentally validating the performance of the Hydra head protocol, we implemented a simulation. The simulation is parameterized by the time required by individual actions (validating transactions, verifying signatures, etc.), and carries out a realistic and timing-correct simulation of a cluster of distributed nodes forming a head. This results in realistic transaction confirmation time and throughput calculations.\n\nWe see that a single Hydra head achieves up to roughly 1,000 TPS, so by running 1,000 heads in parallel (for example, one for each stake pool of the Shelley release), we should achieve a million TPS. That’s impressive and puts us miles ahead of the competition, but why should we stop there? 2,000 heads will give us 2 million TPS – and if someone demands a billion TPS, then we can tell them to just run a million heads. Furthermore, various performance improvements in the implementation can improve the 1,000 TPS single head measurement, further adding to the protocol’s hypothetical performance. \n\nSo, can we just reach any TPS number that we want? In theory the answer is a solid yes, and that points to a problem with the dominant usage of TPS as a metric to compare systems. While it is tempting to reduce the complexity of assessing protocol performance to a single number, in practice this leads to an oversimplification. Without further context, a TPS number is close to meaningless. In order to properly interpret it, and make comparisons, you should at least ask for  the size of the cluster (which influences the communication overhead); its geographic distribution (which determines how much time it takes for information to transit through the system); how the quality of service (transaction confirmation times, providing data to end users) is impacted by a high rate of transactions; how large and complicated the transactions are (which has an impact on transaction validation times, message propagation time, requirements on the local storage system, and composition of the head participants); and what kind of hardware and network connections were used in the experiments. Changing the complexity of transactions alone can change the TPS by a factor of three, as can be seen in the figures in the [paper](https://eprint.iacr.org/2020/299) (refer to Section 7 – Simulations).\n\nClearly, we need a better standard. Is the Hydra head protocol a good protocol design? What we need to ask is whether it reaches the physical limits of the network, not a mere TPS number. Thus, for this first iteration of the evaluation of the Hydra head protocol, we used the following approach to ensure that the data we provide is properly meaningful: \n\n1. We clearly list all the parameters that influence the simulation: transaction size, time to validate a single transaction, time needed for cryptographic operations, allocated bandwidth per node, cluster size and geographical distribution, and limits on the parallelism in which transactions can be issued. Without this controlled environment, it would be impossible to reproduce our numbers.\n2. We compare the protocol’s performance to baselines that provide precise and absolute limits of the underlying network and hardware infrastructure. How well we approach those limits tells us how much room there would be for further improvements. This follows the methodology explained above using the example of an encryption algorithm.\n\nWe use two baselines for Hydra. The first, Full Trust, is universal: it applies to any protocol that distributes transactions amongst nodes and insists that each node validate transactions one after the other – without even ensuring consensus. This yields a limit on TPS by simply adding the message delivery and validation times. How well we approach this limit tells us what price we are paying for consensus, without relying on comparison with other protocols. The second baseline, Hydra Unlimited, yields a TPS limit specifically for the head protocol and also provides the ideal latency and storage for any protocol. We achieve that by assuming that we can send enough transactions in parallel to completely amortize network round-trip times and that all actions can be carried out when needed, without resource contention. The baseline helps us answer the question of what can be achieved under ideal circumstances with the general design of Hydra (for a given set of values of the input parameters) as well as evaluate confirmation latency and storage overhead against any possible protocol. More details and graphs for those interested can be found in our [paper](https://eprint.iacr.org/2020/299) (again, Section 7 – Simulations).  \n\n## What comes next?\n\nSolving the scalability question is the holy grail for the whole blockchain space. The time has come to apply a principled, evidence-based approach in designing and engineering blockchain scalability solutions. Comparing scalability proposals against well-defined baselines can be a significant aide in the design of such protocols. It provides solid evidence for the appropriateness of the design choices and ultimately leads to the engineering of effective and performant distributed ledger protocols that will provide the best possible absolute metrics for use cases of interest. While the Hydra head protocol is implemented and tested, we will, in time, release the rest of the Hydra components following the same principled approach. \n\nAs a last note, Hydra is the joint effort of a number of researchers, whom I\'d like to thank. These include Manuel Chakravarty, Sandro Coretti, Matthias Fitzi, Peter Gaži, Philipp Kant, and Alexander Russel. The research was also supported, in part, by EU Project No.780477, PRIVILEDGE, which we gratefully acknowledge.',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Enter the Hydra: scaling distributed ledgers, the evidence-based way ',
                                subtitle: 'Learn about Hydra: the multi-headed ledger protocol ',
                                audio: null,
                                soundcloud: null,
                                body_content: 'Scalability is the greatest challenge to blockchain adoption. By applying a principled, evidence-based approach, we have arrived at a solution for Cardano and networks similar to it: Hydra. Hydra is the culmination of extensive research, and a decisive step in enabling decentralized networks to securely scale to global requirements. \n\n## What is scalability and how do we measure it?\n\nScaling a distributed ledger system refers to the capability of providing high transaction throughput, low latency, and minimal storage per node. These properties have been repeatedly touted as critical for the successful deployment of blockchain protocols as part of real-world systems. In terms of throughput, the VISA network [reportedly](https://usa.visa.com/run-your-business/small-business-tools/retail.html) handles an average of 1,736 payment transactions per second (TPS) with the capability of handling up to 24,000 TPS and is frequently used as a baseline comparison. Transaction latency is clearly desired to be as low as possible, with the ultimate goal of appearing instantaneous to the end-user. Other applications of distributed ledgers have a wide range of different requirements in terms of these metrics. When designing a general purpose distributed ledger, it is natural to strive to excel on all three counts. \n\nDeploying a system that provides satisfactory scaling for a certain use case requires an appropriate combination of two independent aspects: adopting a proper algorithmic design and deploying it over a suitable underlying hardware and network infrastructure.\n\nWhen evaluating a particular algorithmic design, considering absolute numbers in terms of specific metrics can be misleading. The reason is that such absolute quantities must refer to a particular underlying hardware and network configuration which can blur the advantages and disadvantages of particular algorithms. Indeed, a poorly designed protocol may still perform well enough when deployed over superior hardware and networking.\n\nFor this reason, it is more insightful to evaluate the ability of a protocol to reach the physical limits of the underlying network and hardware. This can be achieved by comparing the protocol with simple strawman protocols, in which all the design elements have been stripped away. For instance, if we want to evaluate the overhead of an encryption algorithm, we can compare the communication performance of two end-points using encryption against their performance when they simply exchange unencrypted messages. In such an experiment, the absolute message-per-second rate is unimportant. The important conclusion is the relative overhead that is added by the encryption algorithm. Moreover, in case the overhead approximates 0 for some configuration of the experimental setup, we can conclude that the algorithm approximates the physical limits of the underlying network’s message-passing ability for that particular configuration, and is hence optimal in this sense. \n\n## Hydra – 30,000-feet view\n\nHydra is an off-chain scalability architecture for distributed ledgers, which addresses all three of the scalability challenges mentioned above: high transaction throughput, low latency, and minimal storage per node. While Hydra is being designed in conjunction with the Ouroboros protocol and the Cardano ledger, it may be employed over other systems as well, provided they share the necessary salient characteristics with Cardano.\n\nDespite being an integrated system aimed at solving one problem – scalability – Hydra consists of several subprotocols. This is necessary as the Cardano ecosystem itself is heterogenous and consists of multiple entities with differing technical capabilities: the system supports block producers with associated stake pools, high-throughput wallets as used by exchanges, but also end-users with a wide variety of computational performance and availability characteristics. It is unrealistic to expect that a one-shoe-fits-all, single-protocol approach is sufficient to provide overall scalability for such a diverse set of network participants.\n\nThe Hydra scalability architecture can be divided into four components: the head protocol, the tail protocol, the cross-head-and-tail communication protocol, as well as a set of supporting protocols for routing, reconfiguration, and virtualization. The centerpiece is the \'head\' protocol, which enables a set of high-performance and high-availability participants (such as stake pools) to very quickly process large numbers of transactions with minimal storage requirements by way of a multiparty state channel – a concept that generalizes two-party payment channels as implemented in the context of the Lightning network. It is complemented by the \'tail\' protocol, which enables those high-performance participants to provide scalability for large numbers of end-users who may use the system from low-power devices, such as mobile phones, and who may be offline for extended periods of time. While heads and tails can already communicate via the Cardano mainchain, the cross-head-and-tail communication protocol provides an efficient off–chain variant of this functionality. All this is tied together by routing and configuration management, while virtualisation facilitates faster communication generalizing head and tail communication. \n\n## The Hydra head protocol\n\nThe Hydra head protocol is the first component of the Hydra architecture to be publicly [released](https://eprint.iacr.org/2020/299). It allows a set of participants to create an off-chain state channel (called a head) wherein they can run smart contracts (or process simpler transactions) among each other without interaction with the underlying blockchain in the optimistic case where all head participants adhere to the protocol. The state channel offers very fast settlement and high transaction throughput; furthermore, it requires very little storage, as the off-chain transaction history can be deleted as soon as its resulting state has been secured via an off–chain \'snapshot\' operation.\n\nEven in the pessimistic case where any number of participants misbehave, full safety is rigorously guaranteed. At any time, any participant can initiate the head\'s \'closure\' with the effect that the head\'s state is transferred back to the (less efficient) blockchain. We emphasize that the execution of any smart contracts can be seamlessly continued on-chain. No funds can be generated off-chain, nor can any single, responsive head participant lose any funds.\n\nThe state channels implemented by Hydra are isomorphic in the sense that they make use of the same transaction format and contract code as the underlying blockchain: contracts can be directly moved back and forth between channels and the blockchain. Thus, state channels effectively yield parallel, off-chain ledger siblings. In other words, the ledger becomes multi-headed.\n\nTransaction confirmation in the head is achieved in full concurrency by an asynchronous off-chain certification process using multi-signatures. This high level of parallelism is enabled by use of the extended UTxO model ([EUTxO](https://github.com/hydra-supplementary-material/eutxo-spec/blob/master/extended-utxo-specification.pdf)). Transaction dependencies in the EUTxO model are explicit, which allows for state updates without unnecessary sequentialization of transactions that are independent of each other.  \n\n## Experimental validation of the Hydra head protocol\n\nAs a first step towards experimentally validating the performance of the Hydra head protocol, we implemented a simulation. The simulation is parameterized by the time required by individual actions (validating transactions, verifying signatures, etc.), and carries out a realistic and timing-correct simulation of a cluster of distributed nodes forming a head. This results in realistic transaction confirmation time and throughput calculations.\n\nWe see that a single Hydra head achieves up to roughly 1,000 TPS, so by running 1,000 heads in parallel (for example, one for each stake pool of the Shelley release), we should achieve a million TPS. That’s impressive and puts us miles ahead of the competition, but why should we stop there? 2,000 heads will give us 2 million TPS – and if someone demands a billion TPS, then we can tell them to just run a million heads. Furthermore, various performance improvements in the implementation can improve the 1,000 TPS single head measurement, further adding to the protocol’s hypothetical performance. \n\nSo, can we just reach any TPS number that we want? In theory the answer is a solid yes, and that points to a problem with the dominant usage of TPS as a metric to compare systems. While it is tempting to reduce the complexity of assessing protocol performance to a single number, in practice this leads to an oversimplification. Without further context, a TPS number is close to meaningless. In order to properly interpret it, and make comparisons, you should at least ask for  the size of the cluster (which influences the communication overhead); its geographic distribution (which determines how much time it takes for information to transit through the system); how the quality of service (transaction confirmation times, providing data to end users) is impacted by a high rate of transactions; how large and complicated the transactions are (which has an impact on transaction validation times, message propagation time, requirements on the local storage system, and composition of the head participants); and what kind of hardware and network connections were used in the experiments. Changing the complexity of transactions alone can change the TPS by a factor of three, as can be seen in the figures in the [paper](https://eprint.iacr.org/2020/299) (refer to Section 7 – Simulations).\n\nClearly, we need a better standard. Is the Hydra head protocol a good protocol design? What we need to ask is whether it reaches the physical limits of the network, not a mere TPS number. Thus, for this first iteration of the evaluation of the Hydra head protocol, we used the following approach to ensure that the data we provide is properly meaningful: \n\n1. We clearly list all the parameters that influence the simulation: transaction size, time to validate a single transaction, time needed for cryptographic operations, allocated bandwidth per node, cluster size and geographical distribution, and limits on the parallelism in which transactions can be issued. Without this controlled environment, it would be impossible to reproduce our numbers.\n2. We compare the protocol’s performance to baselines that provide precise and absolute limits of the underlying network and hardware infrastructure. How well we approach those limits tells us how much room there would be for further improvements. This follows the methodology explained above using the example of an encryption algorithm.\n\nWe use two baselines for Hydra. The first, Full Trust, is universal: it applies to any protocol that distributes transactions amongst nodes and insists that each node validate transactions one after the other – without even ensuring consensus. This yields a limit on TPS by simply adding the message delivery and validation times. How well we approach this limit tells us what price we are paying for consensus, without relying on comparison with other protocols. The second baseline, Hydra Unlimited, yields a TPS limit specifically for the head protocol and also provides the ideal latency and storage for any protocol. We achieve that by assuming that we can send enough transactions in parallel to completely amortize network round-trip times and that all actions can be carried out when needed, without resource contention. The baseline helps us answer the question of what can be achieved under ideal circumstances with the general design of Hydra (for a given set of values of the input parameters) as well as evaluate confirmation latency and storage overhead against any possible protocol. More details and graphs for those interested can be found in our [paper](https://eprint.iacr.org/2020/299) (again, Section 7 – Simulations).  \n\n## What comes next?\n\nSolving the scalability question is the holy grail for the whole blockchain space. The time has come to apply a principled, evidence-based approach in designing and engineering blockchain scalability solutions. Comparing scalability proposals against well-defined baselines can be a significant aide in the design of such protocols. It provides solid evidence for the appropriateness of the design choices and ultimately leads to the engineering of effective and performant distributed ledger protocols that will provide the best possible absolute metrics for use cases of interest. While the Hydra head protocol is implemented and tested, we will, in time, release the rest of the Hydra components following the same principled approach. \n\nAs a last note, Hydra is the joint effort of a number of researchers, whom I\'d like to thank. These include Manuel Chakravarty, Sandro Coretti, Matthias Fitzi, Peter Gaži, Philipp Kant, and Alexander Russel. The research was also supported, in part, by EU Project No.780477, PRIVILEDGE, which we gratefully acknowledge.',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'enter-the-hydra-scaling-distributed-ledgers-the-evidence-based-way',
                                url: '/blog/posts/2020/03/26/enter-the-hydra-scaling-distributed-ledgers-the-evidence-based-way/',
                                read_time: 10
                            },
                            {
                                publish_date: '2018-10-23',
                                author: null,
                                video_id: '',
                                main_image: 'https://ucarecdn.com/15a4e39f-735d-41d4-b928-6f1f50ec2f8c/',
                                custom_meta_img: null,
                                old_url: '/blog/stake-pools-in-cardano/',
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Stake pools in Cardano',
                                        subtitle: 'IOHK’s chief scientist introduces staking',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'In a proof of stake (PoS) blockchain protocol, the ledger is maintained by the stakeholders that hold assets in that ledger. This allows PoS blockchains to use less energy compared with proof of work (PoW) or other types of blockchain protocols. Nevertheless, this requirement imposes a burden on stakeholders. It requires a good number of them to be online and maintain sufficiently good network connectivity that they can collect transactions and have their PoS blocks reach the others without substantial network delays. It follows that any PoS ledger would benefit from reliable server nodes that hold stake and focus on maintenance.\n## The argument for stake pools\n\nWealth is typically distributed according to a power-law such as the [Pareto distribution](https://en.wikipedia.org/wiki/Pareto_distribution "Pareto distribution, wikipedia.org"), so running reliable nodes executing the PoS protocol may be an option only for a small, wealthy, subset of stakeholders, leaving most without the ability to run such services. This is undesirable; it would be better if everyone had the ability to contribute to ledger maintenance. An approach to rectify this problem is by allowing the creation of stake pools. Specifically, this refers to the ability of stakeholders to combine their stake and form a single entity, the stake pool, which can engage in the PoS protocol using the total stake of its members. A pool will have a manager who will be responsible for running the service that processes transactions. At the same time, the pool manager should not be able to spend the stake that their pool represents, while members who are represented by the pool should be free to change their mind and reallocate their stake if they wish to another pool. Finally, and most importantly, any stakeholder should be able to aspire to become a stake pool manager.\n\nParticipating in PoS ledger maintenance incurs costs. Certainly not as high as in the case of a PoW protocol but, nevertheless, still significant. As a result, it is sensible that the community of all stakeholders incentivizes in some way those who support the ledger by setting up servers and processing transactions. This can be achieved by a combination of contributions from those that use the ledger (in the form of transaction fees) and inflation of the circulating supply of coins (by introducing new coins in circulation to be claimed by those engaged in the protocol).\n\nIn the case of Bitcoin, we have both the above mechanisms, incentivization and pools. On the one hand, mining is rewarded by transaction fees as well as a block reward that is fixed and diminishes over time following a geometric series. On the other hand, pools can be facilitated by dividing the work required for producing blocks among many participants and using ‘partial’ PoWs (which are PoWs that are of smaller difficulty than the one indicated by the current state of the ledger) as evidence of pool participation.\n\nIt is straightforward to apply a similar type of incentivization mechanism in the PoS setting. However, one should ask first whether a Bitcoin-like mechanism (or any mechanism for that matter) would converge to a desirable system configuration. Which brings us to the important question: **what are the desirable system configurations?** If the only consideration is to minimize transaction processing costs, in a failure-free environment, the economically optimal configuration is a dictatorial one. One of the parties maintains the ledger as a service while all the others participate in the pool created by this party. This is clearly an undesirable outcome because the single pool leader becomes also a single point of failure in the system, which is exactly the type of outcome that a distributed ledger is supposed to avoid. It follows that the coexistence of many pools, in other words decentralization, should be a desirable characteristic of the ledger incentivization mechanism.\n\n## Reward-sharing schemes for PoS\n\nSo what would a *reward-sharing scheme* look like in a PoS setting? Rewards should be provided at regular intervals and pool maintenance costs should be retained by the pool manager before distributing the remaining rewards among the members. Given that it is possible to keep track of pool membership in the ledger itself using the staking keys of the participants, reward splits within each pool can be encoded in a smart contract and become part of the ledger maintenance service. First things first, pool managers should be rewarded for their entrepreneurship. A pool creation certificate posted on the ledger will declare a profit margin to be shaved off the pool’s rewards after subtracting operational costs, which should also be declared as part of the pool creation certificate. The cost declaration should be updated frequently to absorb any volatility that the native token of the system has with respect to the currency that denominates the actual costs of the pool manager. At the same time, the pool creation certificate, backed up by one or more staking keys provided by stakeholders, can declare a certain amount of stake that “stands behind” the pool and can be used either as an indication that the pool represents the genuine enterprise of one or more stakeholders or as collateral guaranteeing compliance with correct protocol behavior.\n\nGiven the above setup, how do Bitcoin-like mechanisms fare with respect to the decentralization objective? In Bitcoin, assuming everyone follows the protocol, pool rewards are split in proportion to the size of each pool. For example, a mining pool with 20% of the total hashing power is expected to reap 20% of the rewards. This is because rewards are proportional to the number of blocks obtained by the pool and the number of blocks is in turn proportional to the pool’s mining power. Does this lead to a decentralized system? Empirical evidence seems to suggest otherwise: in Bitcoin, mining pools came close (and occasionally [even exceeded](https://en.bitcoinwiki.org/wiki/GHash.IO#51.25_attack_controversy "51% attack controversy, bitcoinwiki.org")) the 50% threshold that is the upper boundary for ensuring the resilience of the ledger. A simple argument can validate this empirical observation in the framework of our reward-sharing schemes: if pools are rewarded proportionally to their size and pool members proportionally to their stake in the pool, the rational thing to do would be to centralize to one pool. To see this consider the following. At first, it is reasonable to expect that all players who are sufficiently wealthy to afford creating a pool will do so by setting up or renting server equipment and promoting it with the objective to attract members so that their share of rewards grows. The other stakeholders that are not pool managers will join the pool that maximizes their payoff, which will be the one with the lowest cost and profit margin. Pool competition for gaining these members will compress profit margins to very small values. But even with zero profit margin, all other pools will lose to the pool with the lowest cost. Assuming that there are no ties, this single pool will attract all stakeholders. Finally, other pool managers will realize that they will be better off joining that pool as opposed to maintaining their own because they will receive more for the stake they possess. Eventually, the system will converge to a dictatorial single pool.\n\nFigure 1 shows a graphical representation of this. It comes from one of the numerous simulations our team has conducted in the process of distilling effective reward sharing schemes. In the experiment, a number of stakeholders follow a reactive process where they attempt to maximize their payoff based on the current system configuration. The experiment leads to a centralized single pool, validating our theoretical observations above for Bitcoin-like schemes. From a decentralization perspective, this is a tragedy of the commons: even though the participants value decentralization as an abstract concept, none of them individually wants to bear the burden of it. \n\n<figure class="">\n<img src="https://ucarecdn.com/1b731f0f-1632-4769-abfa-f3bf4656373c/-/resize/1500/" alt="" class="" width="100%" />\n<figcaption>Figure 1. Centralisation exhibited by a Bitcoin-like reward-sharing scheme in a simulation with 100 stakeholders. Initially, a high number of pools are created by the stakeholders. Taking turns, stakeholders try to maximize their payoff and change strategy, leading to a convergence point where only a single pool exists.</figcaption>\n</figure> \n\n## A better reward sharing scheme\n\nClearly we have to do better than a dictatorship! A first observation is that if we are to achieve decentralization, linearity between rewards and size should taper off after a certain level. This is because, while linearity is attractive when the pool is small and wants to attract stakeholders, after a certain level it should be diminished if we want to give an opportunity for smaller pools to be more competitive. Thus, we will divide the behavior of the reward-sharing scheme depending on the size of the pool to two stages: a growth stage, when linearity is to be respected, and a stabilization stage when the pool is large enough. The point where the transition happens will be called the saturation point and the pool that has passed this point will be saturated. We can fix rewards to be constant after the saturation point, so that if the saturation point is 1%, two pools, with total stakes of 1% and 1.5%, will receive the same rewards. \n\nTo appreciate how the dynamics work from the perspective of a single stakeholder, consider the following example. Suppose there are two pools, A and B managed by Alice and Bob, with operational costs of 25 and 30 coins respectively, each one with a profit margin of 4%. Suppose further that the total rewards to be distributed are 1,000 coins and the saturation point of the reward-sharing mechanism is 20%. At a given point in time, Alice’s pool has 20% of the stake, so it is at the saturation point, while Bob’s pool is at 19%. A prospective pool member, Charlie, holds 1% of the stake and considers which pool to join. Joining Alice’s pool will bring its total stake to 21%, and because it has exceeded the saturation point the reward will be 200 coins (20% of the total rewards). Deducting operational costs will leave 175 coins to be distributed between Alice and the pool members. After removing Alice’s profit margin and considering Charlie’s relative stake in the pool, he will receive 8 coins as a reward. If Charlie joins Bob’s pool, the total rewards will be 200 coins, or 170 coins after removing the operational costs. However, given that Charlie’s stake is 5% (1/20) of the pool, it turns out that he will receive 2% more coins than if he had joined Alice’s pool. So Charlie will join Bob’s pool if he wants to maximize his rewards. \n\nNow, let us see what happens in the case that Charlie is facing the same decision at a hypothetical earlier stage of the whole process when Alice’s pool was already at 20% of the total stake, while Bob’s pool was only at 3%. In this case, Bob has a very small pool and the total rewards available for its members are much less compared with the previous case. As a result, if Charlie did the same calculation for Bob’s pool, his 1% stake would result in a 4% total stake for the pool but, if one does the calculations, he would receive a mere 30% of the rewards that he would have obtained had he joined Alice’s pool. In such a case, the rational decision is to join Alice’s pool despite the fact that his membership will make Alice’s pool exceed the saturation point. Refer to Table 1 below for the exact figures. \n\n<figure class="">\n<img src="https://ucarecdn.com/fcf073c9-fe00-4765-be05-a6303c28a31a/-/resize/1500/" alt="" class="" width="100%" />\n<figcaption>Table 1. Charlie who holds 1% of the total stake, is considering joining pools run by Alice, Bob, Brenda and Ben. His reward is calculated in coins for joining each one. The total reward pool is 1,000 and the saturation point is 20%.</figcaption>\n</figure>\n\n## Being far-sighted matters\n\nThe above appears to be contradictory. To understand what Charlie needs to do we have to appreciate the following fact. The choice of Charlie to join Alice’s pool in the second scenario is only rational in a very near-sighted (aka myopic) sense. In fact, Charlie is better off with Bob’s pool, as is demonstrated by the first scenario, as long as Bob’s pool reaches the saturation point. Thus, if Charlie believes that Bob’s pool will reach the saturation point, the rational choice should be to support it. Other stakeholders will do the same and thus Bob’s pool will rapidly reach the saturation point making everyone that participated in it better off, while also supporting the ideal of decentralization: Alice’s pool instead of constantly growing larger will stop at the saturation point and other pools will be given the ability to grow to the same size. This type of strategic thinking on behalf of the stakeholders is more far-sighted (aka non-myopic) and, as we will see, has the ability to help parties converge to desirable decentralized configurations for the system. \n\nIt is worth noting that it is unavoidable that the system in its evolution will reach pivotal moments where it will be crucial for stakeholders to exercise far-sighted thinking, as in the scenario above where Alice’s pool reaches the saturation point while other pools are still quite small. The reason is that due to the particular circumstances of each stake pool manager, the operational costs will be variable across the stakeholder population. As a result, it is to be expected that starting from a point zero where no stake pools exist, the pool with the lowest operational cost will be also the one that will be the first to grow. This is natural since low operational costs leave a higher level of rewards to be split among the pool members. It is to be expected that the system will reach moments like the second scenario above where the most competitive pool (the one of Alice with operational cost 25) has reached saturation point while the second-most competitive (the one of Bob with operational cost 30) is still at a small membership level. \n\nOne might be tempted to consider long-term thinking in the setting of a Bitcoin-like reward sharing schemes and believe that it can also help to converge to decentralization. Unfortunately, this is not the case. In a Bitcoin-like scheme, contrary to our reward-sharing scheme with a saturation point, there is no point in the development of Alice’s and Bob’s pools when Bob’s pool will become more attractive in Charlie’s view. Indeed, without a saturation point, Alice’s bigger pool will always offer more rewards to Charlie: this stems from the fact that the operational costs of Alice are smaller and hence leave more rewards for all the stakeholders. This will leave Bob’s pool without any members, and eventually, as discussed above, it will be the rational choice for Bob also to dissolve his pool and join Alice’s, making Alice the system’s dictator. \n\nGoing back to our reward-sharing scheme, we have established that non-myopic strategic thinking promotes decentralization; nevertheless, there is an important point still open. At a pivotal moment, when the non-myopic stakeholder Charlie rationally decides to forgo the option to join Alice’s saturated pool, he may have a number of aspiring pools to choose from. For instance, together with Bob’s pool that has operational costs of 30 and profit margin 4%, there could be a pool by Brenda with operational cost of 33 and profit margin 2%, and a pool by Ben with operational cost of 36 and profit margin 1%. The rational choice would be to go with the one that will reach the saturation point; is there a way to tell which one would be the best choice? In our [full analysis paper](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org") we provide an explicit mechanism that orders the pools according to their desirability and, using the information recorded in the ledger about each stake pool, it can assist stakeholders in making the best possible choice at any given moment. In our example, it is Brenda’s pool that Charlie should join if he wants to maximize his rewards (see Table 1). To aid Cardano users, the pool-sorting mechanism will be built into Daedalus (and other Cardano-compatible wallets) and will provide a visual representation of the best choices available to stakeholders using the information in the ledger regarding pool registrations. \n\n## Experimental evaluation\n\nSo how does our reward scheme fare with respect to decentralization? In the [full analysis paper](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org") we prove that there is a class of decentralized system configurations that are “non-myopic Nash equilibria.” An equilibrium strategy here means that stakeholders have a specific way to create pools, set their profit margins and/or delegate to other pools, so that no stakeholder, thinking for the long term, is better off following a different strategy. Moreover, we demonstrate experimentally that reactive play between stakeholders with non-myopic thinking converges to this equilibrium in a small number of iterations, as shown in Figure 2.\n\n<figure class="">\n<img src="https://ucarecdn.com/6ead3506-7d9f-4eac-a56e-5a72542e643a/-/resize/1500/" alt="" class="" width="100%" />\n<figcaption>Figure 2. Decentralization as exhibited by our reward-sharing scheme in a simulation with 100 stakeholders and 10% saturation point. Pools are gradually created by the stakeholders. Taking turns, the stakeholders attempt to maximise their payoff non-myopically leading to a final convergence point where 10 pools exist, each with an equal share of the total stake. At the final point, no rational stakeholder wishes to change the state of the system.</figcaption>\n</figure>\n<br>\n\nA characteristic of our approach is that the number of pools is only part of the description of the reward-sharing scheme and thus is in no way enforced by the system on the stakeholders. This means stakeholders are free to experiment with pool creation and delegation of stake without having to conform to any predetermined system architecture. This is in contrast to other approaches taken in PoS systems such as [EOS](https://eos.io/documents/EOS_An_Introduction.pdf "EOS - An Introduction, eos.io") where the number of participants is a hardcoded parameter of the consensus system (specifically, 21 pools). At the same time, our approach allows the whole stakeholder set to to express its will, by freely joining and leaving pools, receiving guaranteed rewards for their participation while witnessing how their actions have a quantifiable impact on the management of the PoS distributed ledger no matter the size of their stake. This is contrast to other approaches taken in PoS systems such as [Ethereum 2.0](https://github.com/ethereum/eth2.0-specs "eth2.0-specs, github.com") where ledger maintenance is performed by registered validators on the basis of a collateral deposit without a built-in process of vetting by the stakeholder set. \n\nSo what would be a sensible choice for the number of pools that should be favored by the reward scheme for Cardano? Given that decentralization is our main objective, it is sensible to set this parameter to be as high as possible. Our network experiments showed that the system can still operate effectively with as many as 1,000 running pools. Choosing a saturation threshold for our reward-sharing scheme based on this number will make having a stake pool profitable even if the total stake delegated in them is as little as 0.1% of the total circulation of Ada.\n\n## Looking ahead – Sybil attacks\n\nGiven that decentralization can be achieved by a large number of independent stake pools, it is also important to see whether some decentralized system configurations are more preferable than others. As described so far in this post, our reward-sharing scheme will lead rational stakeholders towards promoting the stake pools that will incur the smallest total cost. Even though this maximizes rewards and minimizes costs, it may not be necessarily the most desirable outcome. The reason is that in the equilibrium point one may see a set of stakeholders promoted as stake pool managers who possess collectively a very small stake themselves. This imbalance, in which a small total stake represents the total stake of the system, can be detrimental in many ways: stake pool managers may be prone to corruption or bribery, or, perhaps even worse, a large stake holder may register many stake pools in the hope of controlling the whole ecosystem, performing in this way a [Sybil attack](https://en.wikipedia.org/wiki/Sybil_attack "Sybil attack, wikipedia.org") that would hurt decentralization. For this reason, the reward-sharing scheme as presented in our [full analysis paper](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org") is suitably modified to be sensitive to the stake backing the pool so that this type of behaviour is mitigated. We will delve deeper into this aspect of Cardano reward-sharing in the next blog post.\n\n<small>Artwork, [<img src="https://ucarecdn.com/e711abaa-8d67-4630-bdf5-b9172a104689/-/resize/12/" alt="Creative Commons" />](https://creativecommons.org/licenses/by/4.0/ "Creative Commons") [Mike Beeple](http://www.beeple-crap.com)</small>',
                                        uses_mathjax: null,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Stake pools in Cardano',
                                subtitle: 'IOHK’s chief scientist introduces staking',
                                audio: null,
                                soundcloud: null,
                                body_content: 'In a proof of stake (PoS) blockchain protocol, the ledger is maintained by the stakeholders that hold assets in that ledger. This allows PoS blockchains to use less energy compared with proof of work (PoW) or other types of blockchain protocols. Nevertheless, this requirement imposes a burden on stakeholders. It requires a good number of them to be online and maintain sufficiently good network connectivity that they can collect transactions and have their PoS blocks reach the others without substantial network delays. It follows that any PoS ledger would benefit from reliable server nodes that hold stake and focus on maintenance.\n## The argument for stake pools\n\nWealth is typically distributed according to a power-law such as the [Pareto distribution](https://en.wikipedia.org/wiki/Pareto_distribution "Pareto distribution, wikipedia.org"), so running reliable nodes executing the PoS protocol may be an option only for a small, wealthy, subset of stakeholders, leaving most without the ability to run such services. This is undesirable; it would be better if everyone had the ability to contribute to ledger maintenance. An approach to rectify this problem is by allowing the creation of stake pools. Specifically, this refers to the ability of stakeholders to combine their stake and form a single entity, the stake pool, which can engage in the PoS protocol using the total stake of its members. A pool will have a manager who will be responsible for running the service that processes transactions. At the same time, the pool manager should not be able to spend the stake that their pool represents, while members who are represented by the pool should be free to change their mind and reallocate their stake if they wish to another pool. Finally, and most importantly, any stakeholder should be able to aspire to become a stake pool manager.\n\nParticipating in PoS ledger maintenance incurs costs. Certainly not as high as in the case of a PoW protocol but, nevertheless, still significant. As a result, it is sensible that the community of all stakeholders incentivizes in some way those who support the ledger by setting up servers and processing transactions. This can be achieved by a combination of contributions from those that use the ledger (in the form of transaction fees) and inflation of the circulating supply of coins (by introducing new coins in circulation to be claimed by those engaged in the protocol).\n\nIn the case of Bitcoin, we have both the above mechanisms, incentivization and pools. On the one hand, mining is rewarded by transaction fees as well as a block reward that is fixed and diminishes over time following a geometric series. On the other hand, pools can be facilitated by dividing the work required for producing blocks among many participants and using ‘partial’ PoWs (which are PoWs that are of smaller difficulty than the one indicated by the current state of the ledger) as evidence of pool participation.\n\nIt is straightforward to apply a similar type of incentivization mechanism in the PoS setting. However, one should ask first whether a Bitcoin-like mechanism (or any mechanism for that matter) would converge to a desirable system configuration. Which brings us to the important question: **what are the desirable system configurations?** If the only consideration is to minimize transaction processing costs, in a failure-free environment, the economically optimal configuration is a dictatorial one. One of the parties maintains the ledger as a service while all the others participate in the pool created by this party. This is clearly an undesirable outcome because the single pool leader becomes also a single point of failure in the system, which is exactly the type of outcome that a distributed ledger is supposed to avoid. It follows that the coexistence of many pools, in other words decentralization, should be a desirable characteristic of the ledger incentivization mechanism.\n\n## Reward-sharing schemes for PoS\n\nSo what would a *reward-sharing scheme* look like in a PoS setting? Rewards should be provided at regular intervals and pool maintenance costs should be retained by the pool manager before distributing the remaining rewards among the members. Given that it is possible to keep track of pool membership in the ledger itself using the staking keys of the participants, reward splits within each pool can be encoded in a smart contract and become part of the ledger maintenance service. First things first, pool managers should be rewarded for their entrepreneurship. A pool creation certificate posted on the ledger will declare a profit margin to be shaved off the pool’s rewards after subtracting operational costs, which should also be declared as part of the pool creation certificate. The cost declaration should be updated frequently to absorb any volatility that the native token of the system has with respect to the currency that denominates the actual costs of the pool manager. At the same time, the pool creation certificate, backed up by one or more staking keys provided by stakeholders, can declare a certain amount of stake that “stands behind” the pool and can be used either as an indication that the pool represents the genuine enterprise of one or more stakeholders or as collateral guaranteeing compliance with correct protocol behavior.\n\nGiven the above setup, how do Bitcoin-like mechanisms fare with respect to the decentralization objective? In Bitcoin, assuming everyone follows the protocol, pool rewards are split in proportion to the size of each pool. For example, a mining pool with 20% of the total hashing power is expected to reap 20% of the rewards. This is because rewards are proportional to the number of blocks obtained by the pool and the number of blocks is in turn proportional to the pool’s mining power. Does this lead to a decentralized system? Empirical evidence seems to suggest otherwise: in Bitcoin, mining pools came close (and occasionally [even exceeded](https://en.bitcoinwiki.org/wiki/GHash.IO#51.25_attack_controversy "51% attack controversy, bitcoinwiki.org")) the 50% threshold that is the upper boundary for ensuring the resilience of the ledger. A simple argument can validate this empirical observation in the framework of our reward-sharing schemes: if pools are rewarded proportionally to their size and pool members proportionally to their stake in the pool, the rational thing to do would be to centralize to one pool. To see this consider the following. At first, it is reasonable to expect that all players who are sufficiently wealthy to afford creating a pool will do so by setting up or renting server equipment and promoting it with the objective to attract members so that their share of rewards grows. The other stakeholders that are not pool managers will join the pool that maximizes their payoff, which will be the one with the lowest cost and profit margin. Pool competition for gaining these members will compress profit margins to very small values. But even with zero profit margin, all other pools will lose to the pool with the lowest cost. Assuming that there are no ties, this single pool will attract all stakeholders. Finally, other pool managers will realize that they will be better off joining that pool as opposed to maintaining their own because they will receive more for the stake they possess. Eventually, the system will converge to a dictatorial single pool.\n\nFigure 1 shows a graphical representation of this. It comes from one of the numerous simulations our team has conducted in the process of distilling effective reward sharing schemes. In the experiment, a number of stakeholders follow a reactive process where they attempt to maximize their payoff based on the current system configuration. The experiment leads to a centralized single pool, validating our theoretical observations above for Bitcoin-like schemes. From a decentralization perspective, this is a tragedy of the commons: even though the participants value decentralization as an abstract concept, none of them individually wants to bear the burden of it. \n\n<figure class="">\n<img src="https://ucarecdn.com/1b731f0f-1632-4769-abfa-f3bf4656373c/-/resize/1500/" alt="" class="" width="100%" />\n<figcaption>Figure 1. Centralisation exhibited by a Bitcoin-like reward-sharing scheme in a simulation with 100 stakeholders. Initially, a high number of pools are created by the stakeholders. Taking turns, stakeholders try to maximize their payoff and change strategy, leading to a convergence point where only a single pool exists.</figcaption>\n</figure> \n\n## A better reward sharing scheme\n\nClearly we have to do better than a dictatorship! A first observation is that if we are to achieve decentralization, linearity between rewards and size should taper off after a certain level. This is because, while linearity is attractive when the pool is small and wants to attract stakeholders, after a certain level it should be diminished if we want to give an opportunity for smaller pools to be more competitive. Thus, we will divide the behavior of the reward-sharing scheme depending on the size of the pool to two stages: a growth stage, when linearity is to be respected, and a stabilization stage when the pool is large enough. The point where the transition happens will be called the saturation point and the pool that has passed this point will be saturated. We can fix rewards to be constant after the saturation point, so that if the saturation point is 1%, two pools, with total stakes of 1% and 1.5%, will receive the same rewards. \n\nTo appreciate how the dynamics work from the perspective of a single stakeholder, consider the following example. Suppose there are two pools, A and B managed by Alice and Bob, with operational costs of 25 and 30 coins respectively, each one with a profit margin of 4%. Suppose further that the total rewards to be distributed are 1,000 coins and the saturation point of the reward-sharing mechanism is 20%. At a given point in time, Alice’s pool has 20% of the stake, so it is at the saturation point, while Bob’s pool is at 19%. A prospective pool member, Charlie, holds 1% of the stake and considers which pool to join. Joining Alice’s pool will bring its total stake to 21%, and because it has exceeded the saturation point the reward will be 200 coins (20% of the total rewards). Deducting operational costs will leave 175 coins to be distributed between Alice and the pool members. After removing Alice’s profit margin and considering Charlie’s relative stake in the pool, he will receive 8 coins as a reward. If Charlie joins Bob’s pool, the total rewards will be 200 coins, or 170 coins after removing the operational costs. However, given that Charlie’s stake is 5% (1/20) of the pool, it turns out that he will receive 2% more coins than if he had joined Alice’s pool. So Charlie will join Bob’s pool if he wants to maximize his rewards. \n\nNow, let us see what happens in the case that Charlie is facing the same decision at a hypothetical earlier stage of the whole process when Alice’s pool was already at 20% of the total stake, while Bob’s pool was only at 3%. In this case, Bob has a very small pool and the total rewards available for its members are much less compared with the previous case. As a result, if Charlie did the same calculation for Bob’s pool, his 1% stake would result in a 4% total stake for the pool but, if one does the calculations, he would receive a mere 30% of the rewards that he would have obtained had he joined Alice’s pool. In such a case, the rational decision is to join Alice’s pool despite the fact that his membership will make Alice’s pool exceed the saturation point. Refer to Table 1 below for the exact figures. \n\n<figure class="">\n<img src="https://ucarecdn.com/fcf073c9-fe00-4765-be05-a6303c28a31a/-/resize/1500/" alt="" class="" width="100%" />\n<figcaption>Table 1. Charlie who holds 1% of the total stake, is considering joining pools run by Alice, Bob, Brenda and Ben. His reward is calculated in coins for joining each one. The total reward pool is 1,000 and the saturation point is 20%.</figcaption>\n</figure>\n\n## Being far-sighted matters\n\nThe above appears to be contradictory. To understand what Charlie needs to do we have to appreciate the following fact. The choice of Charlie to join Alice’s pool in the second scenario is only rational in a very near-sighted (aka myopic) sense. In fact, Charlie is better off with Bob’s pool, as is demonstrated by the first scenario, as long as Bob’s pool reaches the saturation point. Thus, if Charlie believes that Bob’s pool will reach the saturation point, the rational choice should be to support it. Other stakeholders will do the same and thus Bob’s pool will rapidly reach the saturation point making everyone that participated in it better off, while also supporting the ideal of decentralization: Alice’s pool instead of constantly growing larger will stop at the saturation point and other pools will be given the ability to grow to the same size. This type of strategic thinking on behalf of the stakeholders is more far-sighted (aka non-myopic) and, as we will see, has the ability to help parties converge to desirable decentralized configurations for the system. \n\nIt is worth noting that it is unavoidable that the system in its evolution will reach pivotal moments where it will be crucial for stakeholders to exercise far-sighted thinking, as in the scenario above where Alice’s pool reaches the saturation point while other pools are still quite small. The reason is that due to the particular circumstances of each stake pool manager, the operational costs will be variable across the stakeholder population. As a result, it is to be expected that starting from a point zero where no stake pools exist, the pool with the lowest operational cost will be also the one that will be the first to grow. This is natural since low operational costs leave a higher level of rewards to be split among the pool members. It is to be expected that the system will reach moments like the second scenario above where the most competitive pool (the one of Alice with operational cost 25) has reached saturation point while the second-most competitive (the one of Bob with operational cost 30) is still at a small membership level. \n\nOne might be tempted to consider long-term thinking in the setting of a Bitcoin-like reward sharing schemes and believe that it can also help to converge to decentralization. Unfortunately, this is not the case. In a Bitcoin-like scheme, contrary to our reward-sharing scheme with a saturation point, there is no point in the development of Alice’s and Bob’s pools when Bob’s pool will become more attractive in Charlie’s view. Indeed, without a saturation point, Alice’s bigger pool will always offer more rewards to Charlie: this stems from the fact that the operational costs of Alice are smaller and hence leave more rewards for all the stakeholders. This will leave Bob’s pool without any members, and eventually, as discussed above, it will be the rational choice for Bob also to dissolve his pool and join Alice’s, making Alice the system’s dictator. \n\nGoing back to our reward-sharing scheme, we have established that non-myopic strategic thinking promotes decentralization; nevertheless, there is an important point still open. At a pivotal moment, when the non-myopic stakeholder Charlie rationally decides to forgo the option to join Alice’s saturated pool, he may have a number of aspiring pools to choose from. For instance, together with Bob’s pool that has operational costs of 30 and profit margin 4%, there could be a pool by Brenda with operational cost of 33 and profit margin 2%, and a pool by Ben with operational cost of 36 and profit margin 1%. The rational choice would be to go with the one that will reach the saturation point; is there a way to tell which one would be the best choice? In our [full analysis paper](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org") we provide an explicit mechanism that orders the pools according to their desirability and, using the information recorded in the ledger about each stake pool, it can assist stakeholders in making the best possible choice at any given moment. In our example, it is Brenda’s pool that Charlie should join if he wants to maximize his rewards (see Table 1). To aid Cardano users, the pool-sorting mechanism will be built into Daedalus (and other Cardano-compatible wallets) and will provide a visual representation of the best choices available to stakeholders using the information in the ledger regarding pool registrations. \n\n## Experimental evaluation\n\nSo how does our reward scheme fare with respect to decentralization? In the [full analysis paper](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org") we prove that there is a class of decentralized system configurations that are “non-myopic Nash equilibria.” An equilibrium strategy here means that stakeholders have a specific way to create pools, set their profit margins and/or delegate to other pools, so that no stakeholder, thinking for the long term, is better off following a different strategy. Moreover, we demonstrate experimentally that reactive play between stakeholders with non-myopic thinking converges to this equilibrium in a small number of iterations, as shown in Figure 2.\n\n<figure class="">\n<img src="https://ucarecdn.com/6ead3506-7d9f-4eac-a56e-5a72542e643a/-/resize/1500/" alt="" class="" width="100%" />\n<figcaption>Figure 2. Decentralization as exhibited by our reward-sharing scheme in a simulation with 100 stakeholders and 10% saturation point. Pools are gradually created by the stakeholders. Taking turns, the stakeholders attempt to maximise their payoff non-myopically leading to a final convergence point where 10 pools exist, each with an equal share of the total stake. At the final point, no rational stakeholder wishes to change the state of the system.</figcaption>\n</figure>\n<br>\n\nA characteristic of our approach is that the number of pools is only part of the description of the reward-sharing scheme and thus is in no way enforced by the system on the stakeholders. This means stakeholders are free to experiment with pool creation and delegation of stake without having to conform to any predetermined system architecture. This is in contrast to other approaches taken in PoS systems such as [EOS](https://eos.io/documents/EOS_An_Introduction.pdf "EOS - An Introduction, eos.io") where the number of participants is a hardcoded parameter of the consensus system (specifically, 21 pools). At the same time, our approach allows the whole stakeholder set to to express its will, by freely joining and leaving pools, receiving guaranteed rewards for their participation while witnessing how their actions have a quantifiable impact on the management of the PoS distributed ledger no matter the size of their stake. This is contrast to other approaches taken in PoS systems such as [Ethereum 2.0](https://github.com/ethereum/eth2.0-specs "eth2.0-specs, github.com") where ledger maintenance is performed by registered validators on the basis of a collateral deposit without a built-in process of vetting by the stakeholder set. \n\nSo what would be a sensible choice for the number of pools that should be favored by the reward scheme for Cardano? Given that decentralization is our main objective, it is sensible to set this parameter to be as high as possible. Our network experiments showed that the system can still operate effectively with as many as 1,000 running pools. Choosing a saturation threshold for our reward-sharing scheme based on this number will make having a stake pool profitable even if the total stake delegated in them is as little as 0.1% of the total circulation of Ada.\n\n## Looking ahead – Sybil attacks\n\nGiven that decentralization can be achieved by a large number of independent stake pools, it is also important to see whether some decentralized system configurations are more preferable than others. As described so far in this post, our reward-sharing scheme will lead rational stakeholders towards promoting the stake pools that will incur the smallest total cost. Even though this maximizes rewards and minimizes costs, it may not be necessarily the most desirable outcome. The reason is that in the equilibrium point one may see a set of stakeholders promoted as stake pool managers who possess collectively a very small stake themselves. This imbalance, in which a small total stake represents the total stake of the system, can be detrimental in many ways: stake pool managers may be prone to corruption or bribery, or, perhaps even worse, a large stake holder may register many stake pools in the hope of controlling the whole ecosystem, performing in this way a [Sybil attack](https://en.wikipedia.org/wiki/Sybil_attack "Sybil attack, wikipedia.org") that would hurt decentralization. For this reason, the reward-sharing scheme as presented in our [full analysis paper](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org") is suitably modified to be sensitive to the stake backing the pool so that this type of behaviour is mitigated. We will delve deeper into this aspect of Cardano reward-sharing in the next blog post.\n\n<small>Artwork, [<img src="https://ucarecdn.com/e711abaa-8d67-4630-bdf5-b9172a104689/-/resize/12/" alt="Creative Commons" />](https://creativecommons.org/licenses/by/4.0/ "Creative Commons") [Mike Beeple](http://www.beeple-crap.com)</small>',
                                uses_mathjax: null,
                                attachments: [],
                                slug: 'stake-pools-in-cardano',
                                url: '/blog/posts/2018/10/23/stake-pools-in-cardano/',
                                read_time: 17
                            },
                            {
                                publish_date: '2018-08-09',
                                author: null,
                                video_id: '',
                                main_image: 'https://ucarecdn.com/8ba04e85-335b-4651-b03f-91b3ed552c01/',
                                custom_meta_img: null,
                                old_url: '/blog/how-does-casper-compare-to-ouroboros/',
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'How does Casper compare to Ouroboros?',
                                        subtitle: 'Differences between the proposed Ethereum protocols and Cardano’s consensus algorithm',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: '**TL;DR**\nIn response to recent discussions in social media, we give a brief comparison of the Ouroboros and Casper proof-of-stake protocols.\n\nOuroboros is a formally specified and analysed protocol with mathematically proven security guarantees based on clearly specified assumptions. The protocol description, models and proofs are all public. Hence, the underlying assumptions, the target protocol properties, and the respective correctness proofs can be publicly scrutinised. Ouroboros offers stake-based finality with the strongest possible guarantees in terms of the amount of stake backing up honest operation. It also provides a solid foundation over which services such as near instant finality of transactions can be offered in optimistic network conditions.\n\nRegarding Casper, we are not aware of any currently published source that sufficiently describes the protocol\'s mode of operation nor any provable guarantees about it. Still, from what has been presented about Casper until now, as compared to Ouroboros, we can safely conclude that Casper provides much weaker guarantees in terms of how much stake the adversary needs to control in order to disrupt the protocol. Below, we compare the two protocols along several dimensions; for lack of proper documentation, many properties of Casper have to be assumed to the best of our knowledge.\n\n<hr>\n\nIn response to a discussion [here](https://www.reddit.com/r/ethereum/comments/92f1u0/eli30_differences_between_casper_and_ouroboros/ "Differences between Casper and Ouroboros, Reddit") and [here](https://www.reddit.com/r/cardano/comments/92r3si/vitalik_allegations_against_ouroboros/ "Vitalik allegations against Ouroboros, Reddit"), we give a brief comparison of the Ouroboros proof-of-stake (PoS) protocol and Casper PoS. For Ouroboros, we refer to the [original version](https://eprint.iacr.org/2016/889 "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, eprint") underlying the Cardano Settlement Layer (published at [Crypto 2017](https://www.iacr.org/conferences/crypto2017/ "Crypto 2017, iacr.org")), however most of our comments apply to later versions [Ouroboros Praos](https://eprint.iacr.org/2017/573 "Ouroboros Praos: An adaptively-secure, semi-synchronous proof-of-stake protocol, eprint") and [Ouroboros Genesis](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint") as well. For Casper, we primarily refer to the Casper Friendly Finality Gadget (FFG) as described in the [white paper](https://arxiv.org/abs/1710.09437 "Casper the Friendly Finality Gadget, arxiv.org"), being the most recent Casper proposal that is sufficiently descriptive to draw a full comparison (other references include [Ethereum Mauve](https://docs.google.com/document/d/1maFT3cpHvwn29gLvtY4WcQiI6kRbN_nbCf3JlgR3m_8/edit "Ethereum 2.0 Mauve Paper"), [Casper+Sharding v2.1, FFG-RPJ](https://notes.ethereum.org/SCIg8AH5SA-O4C1G1LYZHQ?view "Casper+Sharding chain v2.1, ethereum.org"), [Casper TBG/CBC](https://github.com/ethereum/research/blob/master/papers/CasperTFG/CasperTFG.pdf "Casper the Friendly Ghost, github.com")). \n\nAny PoS ledger consensus protocol should satisfy two fundamental properties: persistence and liveness. The first ensures that the ledger is final and immutable. The second ensures that transactions broadcasted by honest parties are eventually included in the (immutable) ledger. Such properties, typically, cannot be proven unconditionally: they will rely on certain conditions, some of them cryptographic, e.g., that digital signatures cannot be forged, while others are related to the behaviour of the participants, e.g., that the players who follow the protocol control a majority of the stake. There are other desirable properties that a PoS protocol should satisfy (such as that executing the protocol as prescribed is the only rational strategy for the participants), but persistence and liveness as defined above constitute the bare minimum pair of fundamental properties necessary for ledger consensus. \n\nLet us now discuss some of the differences between the two protocols and their analyses.\n\n### Execution Model and [Falsifiability](https://en.wikipedia.org/wiki/Falsifiability "Falsifiability, wikipedia.org") of Claims\n\nThe Ouroboros protocol is analyzed in a model that is fully described: it unambiguously defines all the participants’ programs, their execution and interactions, their communication – including network properties – and the potential corruption by an adversarial entity of any set of parties controlling a minority of the stake. Such a model allows the formulation of mathematically precise security guarantees satisfied by any execution, such as the persistence and liveness properties proven for Ouroboros. In particular, the formal modeling of Ouroboros permits precise, quantitative statements about stake bounds and settlement times; see below. **This makes all the claims we make about Ouroboros entirely concrete; there is nothing left up to interpretation or reader perspective.** Without such a model (notably missing in the Casper FFG white paper or in any other available sources related to Casper), it is impossible to prove the correctness of any claims about the protocol. Consensus protocols, in general, are complex objects; designing them without the development of rigorous mathematical arguments that establish the required properties can prove to be precarious as prior practice in secure systems design has shown. Good design intuition and best effort are just not sufficient when a ledger consensus protocol is supposed to carry assets worth billions.\n\n### A comprehensive solution to PoS ledger consensus\n\nGiven the above, it is important to appreciate that the Ouroboros protocol is proven to provide persistence and liveness under clearly defined assumptions such as honest stake majority which is the bare minimum assumption needed in the PoS setting. On the other hand, Casper FFG, as described in the white paper, is an enhancement on top of a pre-existing “block proposal mechanism”, e.g., a PoW blockchain (namely Ethereum); in particular, its security guarantees as a ledger consensus protocol depend on the security of this proposal mechanism. As the authors of Casper FFG observe, “a wholly compromised block proposal mechanism will prevent Casper from finalizing new blocks”, hence the honest-majority-of-hashing power assumption is still necessary for Casper FFG’s liveness. Similarly, other versions of the Casper protocol, such as Casper FFG-RPJ, are incomplete and/or not accompanied by any proofs of security.\n\n### Stake Assumptions \n\nOuroboros is proven to achieve persistence and liveness under the assumption of honest majority of all stake in the system, even in the case that some significant portions of stakeholders are not participating in the protocol (see e.g., Theorem 1 in the [Ouroboros Genesis](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint") paper for the most comprehensive statement on Ouroboros security). In contrast, Casper requires a ⅔-fraction of deposited stake to be controlled by honest parties (see section 2.1 of the [white paper](https://arxiv.org/abs/1710.09437 "Casper the Friendly Finality Gadget, arxiv.org")). Since the deposited stake is blocked and cannot be used for other purposes in the meantime, it is reasonable to assume that the deposited stake will be a small fraction of the total stake in the system. Naturally, larger amounts of stake are more difficult to control so that basing security on the total stake in the system, as in Ouroboros, is a more prudent choice. As a concrete example, in the current sharded version of Ethereum (Ethereum Mauve paper or Casper+Sharding chain v2.1), a minimum of 32 ETH per validator is required with 100-128 validators per shard depending on the reference, without any other restriction. It follows that if the total deposited stake among all prospective validators turns out to be minimal and is not otherwise restricted then just a few thousand ETH would be enough to register a set of [sybil](https://en.wikipedia.org/wiki/Sybil_attack "Sybil Attack, wikipedia.org") validators that could disrupt the ledger consensus security properties.\n\n### Finality\n\nThough the notion is not formally defined in the Casper FFG white paper, it is easy to see that the property of “stake-based finality” is subsumed by persistence, the property that ensures that transactions become permanently part of the public immutable ledger; the stake-based adjective on finality used in Casper FFG refers to the fact that the condition under which finality is to be attained is based on stake as opposed to, e.g., a hashing power assumption. As mentioned above, no protocol can be deemed to solve the ledger consensus problem without providing persistence (and hence finality). In fact, all PoS protocols provide such properties only with a high probability – if for no other reason, cryptography can always fail with (very) small probability (for example, someone may guess your key). We do in fact know that Bitcoin and (pre-Casper) Ethereum provide finality (shown by the works of [GKL15](https://eprint.iacr.org/2014/765 "The Bitcoin Backbone Protocol: Analysis and Applications, eprint"), [GKL17](https://eprint.iacr.org/2016/1048 "The Bitcoin Backbone Protocol with Chains of Variable Difficulty") and [PSS17](https://eprint.iacr.org/2016/454 "Analysis of the Blockchain Protocol in Asynchronous Networks")) assuming honest majority of computational power), and so does Ouroboros, assuming honest majority of stake as shown in [KRDO17](https://eprint.iacr.org/2016/889 "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, eprint"), [DGKR18](https://eprint.iacr.org/2017/573 "Ouroboros Praos: An adaptively-secure, semi-synchronous proof-of-stake protocol, eprint"), [BGKRZ18](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint").\n\n**Put simply, Ouroboros provides stake-based finality** and it does so with the strongest possible guarantee in terms of stake: against a malicious coalition controlling any amount of the total stake existing in the system as long as it is bounded below 50%. In the Casper FFG white paper, where Casper operates over the Ethereum blockchain, stake-based finality is provided every 100 blocks under the assumption that ⅔ of the deposited stake is honest. As a concrete example, in the same window of time, which is a little over half an hour in our current deployment, we can derive from our formal analysis that Ouroboros will offer finality against, say, a 10% stake adversary with probability of error less than 2^(-44). This is less than 1/10000000000000, one over ten trillion. To appreciate such small numbers, consider that it is expected to have one large asteroid hit the earth once every 100 million years ([Scientific American](https://www.scientificamerican.com/article/what-is-the-chance-of-an/ "What is the chance of an asteroid hitting Earth and how do astronomers calculate it?, scientificamerican.com")). Thus, it is 10 thousand times more likely that a big asteroid will hit the earth next month than that Ouroboros will reorganise its chain to drop a particular transaction after it has been included in the ledger for about half an hour.\n\n### Eventual Consensus vs. (near-)Instant finality \nBlockchain protocols like Bitcoin and Ouroboros are called eventual-consensus since they ensure that the irreversibility of a block increases gradually with the number of blocks that are added on top of it. This means that finality is more nuanced than just a true or false value, and is quantified by the probability of reverting a transaction as a function of the strength of the adversary and the length of time that has passed since the block containing that transaction was added. This design enables these protocols to work in the strongest possible adversarial settings and still be very efficient in terms of the number of messages that need to be exchanged; furthermore, they have the feature that the recipient of a transaction can decide for herself how important a transaction is and adjust her own notions of stability per transaction. Their downside is that they do not provide near-instant finality, or in other words, a fast assurance that the transaction will be finalised. This may be a potential advantage of classical BFT protocols that have inspired the design of Casper FFG as well as other protocols in the space including Algorand.\n\nHowever, near-instant finality typically also comes with significant downsides in terms of the security model such as a much higher requirement of honest stake or, perhaps more importantly, a high degree of guaranteed online presence that must be offered by the participants following the protocol. This hurts the dynamic availability of the participants (see below) which is one of the hallmarks of the bitcoin era of consensus protocols. On the other hand, near-instant finality can be built as a service on top of Ouroboros and this is something that we will be releasing in due course. Moreover, we can argue that this is the best possible way forward: use the Ouroboros eventual consensus protocol which is secure under the strongest possible stake-based guarantees as the solid foundation over which services such as near-instant settlement in optimistic network conditions can be safely built.\n\n### Incentives and dynamic availability \n\nCasper FFG is inspired by pre-Bitcoin era standard BFT consensus protocols and as such it cannot handle uncertainty in terms of the number of participating entities once the set of validators becomes fixed. This means that the protocol cannot operate in the “[sleepy setting](https://eprint.iacr.org/2016/918 "The Sleepy Model of Consensus, eprint")” and “[dynamic availability](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint")” setting, where a significant number of parties that are supposed to act in the protocol are unavailable due to network conditions, hardware failure or simply lack of interest. This is a significant concern in a decentralized setting where the execution of the protocol is not meant to be left in the hands of a few centralized-power actors, but is rather distributed proportionally among a great number of smaller players. The Casper-FFG white paper acknowledges this as the “Catastrophic Crash” scenario and observes that in this case “no future checkpoints can be finalized”. The authors propose a mitigation in the form of the so-called “inactivity leak.” This idea is only described informally as draining “the deposit of any validator that does not vote for checkpoints, until eventually its deposit sizes decrease low enough that the validators who are voting are a supermajority.” Unfortunately, this modification would in turn negate any potential advantage Casper can claim in face of network splits, as the authors also recognise: “The inactivity leak introduces the possibility of two conflicting checkpoints being finalized without any validator getting slashed.” This also affects the incentives running the protocol. Ouroboros allows for a natural and incentive-driven aggregation of stake into stake pools that will be performed over a period of time using our [stake pool reward mechanism](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org"), without forcing the behaviour of stakeholders onto a predetermined structure, while Casper has to impose preset numbers of block validators. \n\n### Randomness\n\nWhile the original Ouroboros protocol does not use VRFs to generate protocol randomness (instead it uses a guaranteed-output-delivery coin-tossing protocol based on verifiable secret-sharing), the follow-up versions Praos and Genesis do so for performance gains. The VRFs proposed for use in Ouroboros Praos and Genesis are proven secure under standard cryptographic assumptions (such as the [Computational Diffie Hellman assumption](https://en.wikipedia.org/wiki/Computational_Diffie%E2%80%93Hellman_assumption "Computational Diffie Hellman assumption, wikipedia.org")) while the security analysis we have performed ensures Ouroboros’ resilience to randomness manipulation (see [Ouroboros Praos](https://eprint.iacr.org/2017/573 "Ouroboros Praos: An adaptively-secure, semi-synchronous proof-of-stake protocol, eprint") and [Ouroboros Genesis](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint")). \n\n### Network Assumptions\n\nOuroboros is analysed in the “partially synchronous” setting where messages are delivered to the majority of the parties executing the protocol within a time window upper bounded by a network delay Δ which is unknown to the parties. The order of messages is adversarial and it is not guaranteed that two honest parties will receive messages in the same order. The adversary is allowed to inject arbitrary messages selectively to any of the parties. Casper makes no explicit claims about the network setting it operates in, nevertheless, when describing defenses against long range revisions it alludes to a similar type of model.\n\n### Sharding\n\nThis property refers to the ability of a database or ledger consensus protocol to scale its processing power as more nodes (or processing capacity) enter the system, ideally with a linear speedup in the number of nodes added. Ouroboros Hydra, the scalable version of Ouroboros is in development and will be released in due time following our usual mode of discourse, i.e., the release of a full paper containing complete mathematical formulations of the problem that we solve, a full description of our protocol solution, as well as concrete statements about the protocol’s properties that are accompanied by all necessary proofs. At present, the version of Casper that enables sharding, ([Casper+Sharding v2.1](https://notes.ethereum.org/SCIg8AH5SA-O4C1G1LYZHQ?view "Casper+Sharding chain v2.1, ethereum.org")), is incomplete even in terms of protocol description, and as such, it cannot allow any proof of security. \n\n[Learn more about Ouroboros](https://www.youtube.com/watch?v=Nlmv4fg4NQk&list=PLnPTB0CuBOBw9H7dynFu9U25vqFWRw1UX "Ouroboros: A Provably Secure Proof-of-Stake YouTube").\n\n\n*Team effort is a hallmark of IOHK research and this blog post is no exception. I am grateful to Christian Badertscher, Matthias Fitzi, Peter Gaži, Alexander Russell, Jeremy Wood, and Vassilis Zikas for various suggestions, comments, and corrections to the above text.*\n\n<small>Artwork, <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank"><img src="https://ucarecdn.com/e711abaa-8d67-4630-bdf5-b9172a104689/-/resize/12/" alt="Creative Commons" /> <a href="http://www.beeple-crap.com">Mike Beeple</a>',
                                        uses_mathjax: null,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'How does Casper compare to Ouroboros?',
                                subtitle: 'Differences between the proposed Ethereum protocols and Cardano’s consensus algorithm',
                                audio: null,
                                soundcloud: null,
                                body_content: '**TL;DR**\nIn response to recent discussions in social media, we give a brief comparison of the Ouroboros and Casper proof-of-stake protocols.\n\nOuroboros is a formally specified and analysed protocol with mathematically proven security guarantees based on clearly specified assumptions. The protocol description, models and proofs are all public. Hence, the underlying assumptions, the target protocol properties, and the respective correctness proofs can be publicly scrutinised. Ouroboros offers stake-based finality with the strongest possible guarantees in terms of the amount of stake backing up honest operation. It also provides a solid foundation over which services such as near instant finality of transactions can be offered in optimistic network conditions.\n\nRegarding Casper, we are not aware of any currently published source that sufficiently describes the protocol\'s mode of operation nor any provable guarantees about it. Still, from what has been presented about Casper until now, as compared to Ouroboros, we can safely conclude that Casper provides much weaker guarantees in terms of how much stake the adversary needs to control in order to disrupt the protocol. Below, we compare the two protocols along several dimensions; for lack of proper documentation, many properties of Casper have to be assumed to the best of our knowledge.\n\n<hr>\n\nIn response to a discussion [here](https://www.reddit.com/r/ethereum/comments/92f1u0/eli30_differences_between_casper_and_ouroboros/ "Differences between Casper and Ouroboros, Reddit") and [here](https://www.reddit.com/r/cardano/comments/92r3si/vitalik_allegations_against_ouroboros/ "Vitalik allegations against Ouroboros, Reddit"), we give a brief comparison of the Ouroboros proof-of-stake (PoS) protocol and Casper PoS. For Ouroboros, we refer to the [original version](https://eprint.iacr.org/2016/889 "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, eprint") underlying the Cardano Settlement Layer (published at [Crypto 2017](https://www.iacr.org/conferences/crypto2017/ "Crypto 2017, iacr.org")), however most of our comments apply to later versions [Ouroboros Praos](https://eprint.iacr.org/2017/573 "Ouroboros Praos: An adaptively-secure, semi-synchronous proof-of-stake protocol, eprint") and [Ouroboros Genesis](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint") as well. For Casper, we primarily refer to the Casper Friendly Finality Gadget (FFG) as described in the [white paper](https://arxiv.org/abs/1710.09437 "Casper the Friendly Finality Gadget, arxiv.org"), being the most recent Casper proposal that is sufficiently descriptive to draw a full comparison (other references include [Ethereum Mauve](https://docs.google.com/document/d/1maFT3cpHvwn29gLvtY4WcQiI6kRbN_nbCf3JlgR3m_8/edit "Ethereum 2.0 Mauve Paper"), [Casper+Sharding v2.1, FFG-RPJ](https://notes.ethereum.org/SCIg8AH5SA-O4C1G1LYZHQ?view "Casper+Sharding chain v2.1, ethereum.org"), [Casper TBG/CBC](https://github.com/ethereum/research/blob/master/papers/CasperTFG/CasperTFG.pdf "Casper the Friendly Ghost, github.com")). \n\nAny PoS ledger consensus protocol should satisfy two fundamental properties: persistence and liveness. The first ensures that the ledger is final and immutable. The second ensures that transactions broadcasted by honest parties are eventually included in the (immutable) ledger. Such properties, typically, cannot be proven unconditionally: they will rely on certain conditions, some of them cryptographic, e.g., that digital signatures cannot be forged, while others are related to the behaviour of the participants, e.g., that the players who follow the protocol control a majority of the stake. There are other desirable properties that a PoS protocol should satisfy (such as that executing the protocol as prescribed is the only rational strategy for the participants), but persistence and liveness as defined above constitute the bare minimum pair of fundamental properties necessary for ledger consensus. \n\nLet us now discuss some of the differences between the two protocols and their analyses.\n\n### Execution Model and [Falsifiability](https://en.wikipedia.org/wiki/Falsifiability "Falsifiability, wikipedia.org") of Claims\n\nThe Ouroboros protocol is analyzed in a model that is fully described: it unambiguously defines all the participants’ programs, their execution and interactions, their communication – including network properties – and the potential corruption by an adversarial entity of any set of parties controlling a minority of the stake. Such a model allows the formulation of mathematically precise security guarantees satisfied by any execution, such as the persistence and liveness properties proven for Ouroboros. In particular, the formal modeling of Ouroboros permits precise, quantitative statements about stake bounds and settlement times; see below. **This makes all the claims we make about Ouroboros entirely concrete; there is nothing left up to interpretation or reader perspective.** Without such a model (notably missing in the Casper FFG white paper or in any other available sources related to Casper), it is impossible to prove the correctness of any claims about the protocol. Consensus protocols, in general, are complex objects; designing them without the development of rigorous mathematical arguments that establish the required properties can prove to be precarious as prior practice in secure systems design has shown. Good design intuition and best effort are just not sufficient when a ledger consensus protocol is supposed to carry assets worth billions.\n\n### A comprehensive solution to PoS ledger consensus\n\nGiven the above, it is important to appreciate that the Ouroboros protocol is proven to provide persistence and liveness under clearly defined assumptions such as honest stake majority which is the bare minimum assumption needed in the PoS setting. On the other hand, Casper FFG, as described in the white paper, is an enhancement on top of a pre-existing “block proposal mechanism”, e.g., a PoW blockchain (namely Ethereum); in particular, its security guarantees as a ledger consensus protocol depend on the security of this proposal mechanism. As the authors of Casper FFG observe, “a wholly compromised block proposal mechanism will prevent Casper from finalizing new blocks”, hence the honest-majority-of-hashing power assumption is still necessary for Casper FFG’s liveness. Similarly, other versions of the Casper protocol, such as Casper FFG-RPJ, are incomplete and/or not accompanied by any proofs of security.\n\n### Stake Assumptions \n\nOuroboros is proven to achieve persistence and liveness under the assumption of honest majority of all stake in the system, even in the case that some significant portions of stakeholders are not participating in the protocol (see e.g., Theorem 1 in the [Ouroboros Genesis](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint") paper for the most comprehensive statement on Ouroboros security). In contrast, Casper requires a ⅔-fraction of deposited stake to be controlled by honest parties (see section 2.1 of the [white paper](https://arxiv.org/abs/1710.09437 "Casper the Friendly Finality Gadget, arxiv.org")). Since the deposited stake is blocked and cannot be used for other purposes in the meantime, it is reasonable to assume that the deposited stake will be a small fraction of the total stake in the system. Naturally, larger amounts of stake are more difficult to control so that basing security on the total stake in the system, as in Ouroboros, is a more prudent choice. As a concrete example, in the current sharded version of Ethereum (Ethereum Mauve paper or Casper+Sharding chain v2.1), a minimum of 32 ETH per validator is required with 100-128 validators per shard depending on the reference, without any other restriction. It follows that if the total deposited stake among all prospective validators turns out to be minimal and is not otherwise restricted then just a few thousand ETH would be enough to register a set of [sybil](https://en.wikipedia.org/wiki/Sybil_attack "Sybil Attack, wikipedia.org") validators that could disrupt the ledger consensus security properties.\n\n### Finality\n\nThough the notion is not formally defined in the Casper FFG white paper, it is easy to see that the property of “stake-based finality” is subsumed by persistence, the property that ensures that transactions become permanently part of the public immutable ledger; the stake-based adjective on finality used in Casper FFG refers to the fact that the condition under which finality is to be attained is based on stake as opposed to, e.g., a hashing power assumption. As mentioned above, no protocol can be deemed to solve the ledger consensus problem without providing persistence (and hence finality). In fact, all PoS protocols provide such properties only with a high probability – if for no other reason, cryptography can always fail with (very) small probability (for example, someone may guess your key). We do in fact know that Bitcoin and (pre-Casper) Ethereum provide finality (shown by the works of [GKL15](https://eprint.iacr.org/2014/765 "The Bitcoin Backbone Protocol: Analysis and Applications, eprint"), [GKL17](https://eprint.iacr.org/2016/1048 "The Bitcoin Backbone Protocol with Chains of Variable Difficulty") and [PSS17](https://eprint.iacr.org/2016/454 "Analysis of the Blockchain Protocol in Asynchronous Networks")) assuming honest majority of computational power), and so does Ouroboros, assuming honest majority of stake as shown in [KRDO17](https://eprint.iacr.org/2016/889 "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, eprint"), [DGKR18](https://eprint.iacr.org/2017/573 "Ouroboros Praos: An adaptively-secure, semi-synchronous proof-of-stake protocol, eprint"), [BGKRZ18](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint").\n\n**Put simply, Ouroboros provides stake-based finality** and it does so with the strongest possible guarantee in terms of stake: against a malicious coalition controlling any amount of the total stake existing in the system as long as it is bounded below 50%. In the Casper FFG white paper, where Casper operates over the Ethereum blockchain, stake-based finality is provided every 100 blocks under the assumption that ⅔ of the deposited stake is honest. As a concrete example, in the same window of time, which is a little over half an hour in our current deployment, we can derive from our formal analysis that Ouroboros will offer finality against, say, a 10% stake adversary with probability of error less than 2^(-44). This is less than 1/10000000000000, one over ten trillion. To appreciate such small numbers, consider that it is expected to have one large asteroid hit the earth once every 100 million years ([Scientific American](https://www.scientificamerican.com/article/what-is-the-chance-of-an/ "What is the chance of an asteroid hitting Earth and how do astronomers calculate it?, scientificamerican.com")). Thus, it is 10 thousand times more likely that a big asteroid will hit the earth next month than that Ouroboros will reorganise its chain to drop a particular transaction after it has been included in the ledger for about half an hour.\n\n### Eventual Consensus vs. (near-)Instant finality \nBlockchain protocols like Bitcoin and Ouroboros are called eventual-consensus since they ensure that the irreversibility of a block increases gradually with the number of blocks that are added on top of it. This means that finality is more nuanced than just a true or false value, and is quantified by the probability of reverting a transaction as a function of the strength of the adversary and the length of time that has passed since the block containing that transaction was added. This design enables these protocols to work in the strongest possible adversarial settings and still be very efficient in terms of the number of messages that need to be exchanged; furthermore, they have the feature that the recipient of a transaction can decide for herself how important a transaction is and adjust her own notions of stability per transaction. Their downside is that they do not provide near-instant finality, or in other words, a fast assurance that the transaction will be finalised. This may be a potential advantage of classical BFT protocols that have inspired the design of Casper FFG as well as other protocols in the space including Algorand.\n\nHowever, near-instant finality typically also comes with significant downsides in terms of the security model such as a much higher requirement of honest stake or, perhaps more importantly, a high degree of guaranteed online presence that must be offered by the participants following the protocol. This hurts the dynamic availability of the participants (see below) which is one of the hallmarks of the bitcoin era of consensus protocols. On the other hand, near-instant finality can be built as a service on top of Ouroboros and this is something that we will be releasing in due course. Moreover, we can argue that this is the best possible way forward: use the Ouroboros eventual consensus protocol which is secure under the strongest possible stake-based guarantees as the solid foundation over which services such as near-instant settlement in optimistic network conditions can be safely built.\n\n### Incentives and dynamic availability \n\nCasper FFG is inspired by pre-Bitcoin era standard BFT consensus protocols and as such it cannot handle uncertainty in terms of the number of participating entities once the set of validators becomes fixed. This means that the protocol cannot operate in the “[sleepy setting](https://eprint.iacr.org/2016/918 "The Sleepy Model of Consensus, eprint")” and “[dynamic availability](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint")” setting, where a significant number of parties that are supposed to act in the protocol are unavailable due to network conditions, hardware failure or simply lack of interest. This is a significant concern in a decentralized setting where the execution of the protocol is not meant to be left in the hands of a few centralized-power actors, but is rather distributed proportionally among a great number of smaller players. The Casper-FFG white paper acknowledges this as the “Catastrophic Crash” scenario and observes that in this case “no future checkpoints can be finalized”. The authors propose a mitigation in the form of the so-called “inactivity leak.” This idea is only described informally as draining “the deposit of any validator that does not vote for checkpoints, until eventually its deposit sizes decrease low enough that the validators who are voting are a supermajority.” Unfortunately, this modification would in turn negate any potential advantage Casper can claim in face of network splits, as the authors also recognise: “The inactivity leak introduces the possibility of two conflicting checkpoints being finalized without any validator getting slashed.” This also affects the incentives running the protocol. Ouroboros allows for a natural and incentive-driven aggregation of stake into stake pools that will be performed over a period of time using our [stake pool reward mechanism](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org"), without forcing the behaviour of stakeholders onto a predetermined structure, while Casper has to impose preset numbers of block validators. \n\n### Randomness\n\nWhile the original Ouroboros protocol does not use VRFs to generate protocol randomness (instead it uses a guaranteed-output-delivery coin-tossing protocol based on verifiable secret-sharing), the follow-up versions Praos and Genesis do so for performance gains. The VRFs proposed for use in Ouroboros Praos and Genesis are proven secure under standard cryptographic assumptions (such as the [Computational Diffie Hellman assumption](https://en.wikipedia.org/wiki/Computational_Diffie%E2%80%93Hellman_assumption "Computational Diffie Hellman assumption, wikipedia.org")) while the security analysis we have performed ensures Ouroboros’ resilience to randomness manipulation (see [Ouroboros Praos](https://eprint.iacr.org/2017/573 "Ouroboros Praos: An adaptively-secure, semi-synchronous proof-of-stake protocol, eprint") and [Ouroboros Genesis](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint")). \n\n### Network Assumptions\n\nOuroboros is analysed in the “partially synchronous” setting where messages are delivered to the majority of the parties executing the protocol within a time window upper bounded by a network delay Δ which is unknown to the parties. The order of messages is adversarial and it is not guaranteed that two honest parties will receive messages in the same order. The adversary is allowed to inject arbitrary messages selectively to any of the parties. Casper makes no explicit claims about the network setting it operates in, nevertheless, when describing defenses against long range revisions it alludes to a similar type of model.\n\n### Sharding\n\nThis property refers to the ability of a database or ledger consensus protocol to scale its processing power as more nodes (or processing capacity) enter the system, ideally with a linear speedup in the number of nodes added. Ouroboros Hydra, the scalable version of Ouroboros is in development and will be released in due time following our usual mode of discourse, i.e., the release of a full paper containing complete mathematical formulations of the problem that we solve, a full description of our protocol solution, as well as concrete statements about the protocol’s properties that are accompanied by all necessary proofs. At present, the version of Casper that enables sharding, ([Casper+Sharding v2.1](https://notes.ethereum.org/SCIg8AH5SA-O4C1G1LYZHQ?view "Casper+Sharding chain v2.1, ethereum.org")), is incomplete even in terms of protocol description, and as such, it cannot allow any proof of security. \n\n[Learn more about Ouroboros](https://www.youtube.com/watch?v=Nlmv4fg4NQk&list=PLnPTB0CuBOBw9H7dynFu9U25vqFWRw1UX "Ouroboros: A Provably Secure Proof-of-Stake YouTube").\n\n\n*Team effort is a hallmark of IOHK research and this blog post is no exception. I am grateful to Christian Badertscher, Matthias Fitzi, Peter Gaži, Alexander Russell, Jeremy Wood, and Vassilis Zikas for various suggestions, comments, and corrections to the above text.*\n\n<small>Artwork, <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank"><img src="https://ucarecdn.com/e711abaa-8d67-4630-bdf5-b9172a104689/-/resize/12/" alt="Creative Commons" /> <a href="http://www.beeple-crap.com">Mike Beeple</a>',
                                uses_mathjax: null,
                                attachments: [],
                                slug: 'how-does-casper-compare-to-ouroboros',
                                url: '/blog/posts/2018/08/09/how-does-casper-compare-to-ouroboros/',
                                read_time: 13
                            },
                            {
                                publish_date: '2018-01-11',
                                author: null,
                                video_id: 'JwxVySVF-U4',
                                main_image: '',
                                custom_meta_img: null,
                                old_url: '/blog/on-the-ouroboros-design-how-rigour-and-engineering-are-essential-for-critical-infrastructure/',
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'On the Ouroboros Design: How rigour and engineering are essential for critical infrastructure',
                                        subtitle: '',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'A [blog post](https://steemit.com/cardamon/@dan/peer-review-of-cardano-s-ouroboros "Peer Review of Cardano\'s Ouroboros, steemit.com") on the Steemit website appeared recently making a number of claims regarding [Ouroboros](/research/papers/#9BKRHCSI "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, iohk.io"). The article contains several factual inaccuracies. For instance, it is claimed that “DPOS” in the Ouroboros paper stands for “delegated proof of stake”, while in fact, DPOS means “dynamic proof of stake”, or that the protocol requires a "2/3+" ratio of parties being honest, while in reality it just requires an honest majority, i.e. the stake controlled by parties following the protocol is more than half the total stake.\nFor the benefit of those that are interested in the Ouroboros protocol and who appreciate its general philosophy, we feel it is appropriate to provide here a response to this article making along the way a few broader points. While pointing out inaccuracies in the blog, we take the opportunity to highlight some of the general approaches followed in the design of Ouroboros and in the related research efforts that are currently underway at IOHK.\n \nOuroboros is a proof of stake (PoS) protocol that uses delegation in the spirit of the PoS idea as discussed in the [Bitcoin forum starting from 2011](https://bitcointalk.org/index.php?topic=27787.0 "Proof of stake instead of proof of work, bitcointalk.org"). The references that influenced its design are listed in our paper. PoS is a powerful concept that has inspired a number of other efforts prior, concurrent and post the first Ouroboros paper. Among all other implemented PoS blockchain systems that carry real assets, Ouroboros is unique in that it was designed in tandem with a formal security model and a mathematical proof that it implements a robust transaction ledger. This marks a fundamental shift in the methodology of blockchain system design.\n \nBlockchain systems are in a period of transition from curiosities to critical infrastructure; as such, the all too typical software industry approach of releasing a “minimum viable product” as early as possible and then fixing bugs as they appear, is not appropriate. Failures of critical infrastructure have a significant impact on people’s lives and thus require rigorous engineering discipline to the highest possible standards. Dependability, rather than maximum performance according to some arbitrarily chosen metric, is the primary goal. Performance is important, of course, but the performance required is a function of the ultimate application domain, and from the point of view of dependability it is the worst-case performance that is important, not the ideal-scenario peak rate.\n \nLike all other protocols in the blockchain space, Ouroboros requires some degree of synchronisation. The block production interval has to be consistent with the likely time to complete the required information exchanges. The 20-second slot time in Ouroboros represents a conservative choice for a block of transactions to traverse the diameter of a peer-to-peer network, where the peers may be significantly geographically distributed, the system is operating at peak transaction load and the interconnection is significantly less than perfect. It is improbable for a block of transactions to consistently traverse a global network much faster than that, and as a result any solution that does significantly better (or claims to do significantly better) is either wrong, or provides a weaker level of decentralisation or security, i.e. it solves an easier problem than Ouroboros. There is a tradeoff between achieving a robust, global, participatory service that delivers sustained effective performance even under an adversarial attack, and creating a high performance, limited participation (in geographical scope or network resource requirement) solution that makes overly optimistic assumptions on network stability.\n \nIrreversibility, the property that transactions persist and are immutable in a blockchain protocol, has to be presented as a function of the level of the adversarial strength. This is true in Nakamoto’s Bitcoin paper and also in the [Ouroboros paper](/research/papers/#9BKRHCSI "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, iohk.io"), see Section 10.1 for the actual time needed for confirmation of transactions. Thus, one should be very wary of statements about irreversibility that do not quantify the level of adversarial power. For instance, Ouroboros will confirm a transaction with 99.9% assurance in just five minutes against an adversary holding 10% of the total stake, which in today’s market cap in the Cardano blockchain would amount to more than two billion dollars. Byzantine agreement protocols can provide a more “black and white” irreversibility, in other words the protocol can be guaranteed to be irreversible within a certain time window provided an honest majority or supermajority exists depending on the protocol. Nevertheless, the performance and decentralisation penalty suffered is very high if the level of adversity is allowed to come close to the 1/2 barrier, which is the level of adversity that Ouroboros can withstand.\n \nThe issue of possible dominance of the consensus process by a small group of stakeholders holding a large proportion of the stake is important but is not applicable to the current release of the Cardano system (the Byron release). What we have proved for Ouroboros is that it can facilitate a “fair” transaction ledger (where fairness here means that the ledger can fairly record all significant actions that are performed by the protocol participants despite the presence of an adversary). This enabled us to neutralise a number of rational protocol deviations (e.g. the equivalent of selfish mining attacks in the PoS setting) and provide a Nash equilibrium argument showing how the protocol can support many different types of mechanisms for incentivising participant behaviour. Currently, IOHK Research is actively working to finalise the incentive structure that will be incorporated in the Shelley release of Cardano, where stake pools will be supported and delegation behaviour will be properly incentivised so that it offers effective decentralisation of power. The crux of our methodology is the engineering of a novel reward mechanism for rational participants that provides appropriate incentives to partition their delegation rights. The objectives are first, to avoid concentration of power to a small group of participants – as it could happen by a naïve reward mechanism in a Pareto distributed stakeholder population – and second, to provide appropriate incentives to ensure a desired number of delegates. We are very excited about this work; it will be the first of its kind in the area and, as before, we will be disseminating it widely including full technical details, as well as submitting it for peer review.\n \nThis brings us to the final distinguishing advantage of the philosophy of Cardano. Scientific peer review has been refined over centuries. The way it is implemented by the [International Cryptology Conference](https://www.iacr.org/conferences/crypto2017/ "Crypto 2017, iacr.org") (also called Crypto), where Ouroboros was presented, and the other top conferences in the area, strives to remove conflicts of interest and produce the highest level of objectivity. The method of reviewing is known as "double blind”, i.e. papers are submitted anonymously and reviewers are experts that also remain anonymous to the authors. The committee of experts that reviews submitted papers each year is formed by two program co-chairs that are appointed by the [International Association of Cryptologic Research](https://www.iacr.org/ "iacr.org"), the pre-eminent organisation of cryptology research that was founded in 1982.\n\nBeing invited to serve in the committee as an expert is an important recognition of an individual’s long-term commitment to the area of cryptography (and even a precise count of how many times one has served is [maintained](https://www.iacr.org/cryptodb/data/stats.php "Publishing Statistics, iacr.org")). Blockchain protocols fit perfectly within the cryptography scientific literature and thus scientific peer review is to be done by this community. Of course, we welcome reviews from anyone. That is why we make public very detailed whitepapers with precise and specific claims that leave no uncertainty about what is being claimed, and we appreciate any factual discussion about any of these claims. We strongly encourage other projects to submit their work for scientific peer review as well. They will enjoy the benefits of thorough, well-founded and objective critique and they will have the opportunity to showcase any advantages and novelty that their approach possesses.\n',
                                        uses_mathjax: null,
                                        attachments: [
                                            {
                                                type: 'pdf',
                                                url: 'https://ucarecdn.com/67b9e51b-1022-40d8-b7f2-fa143c8fea18/-/inline/yes/',
                                                name: 'On the Ouroboros Design- How rigour and'
                                            }
                                        ]
                                    }
                                ],
                                lang: 'en',
                                title: 'On the Ouroboros Design: How rigour and engineering are essential for critical infrastructure',
                                subtitle: '',
                                audio: null,
                                soundcloud: null,
                                body_content: 'A [blog post](https://steemit.com/cardamon/@dan/peer-review-of-cardano-s-ouroboros "Peer Review of Cardano\'s Ouroboros, steemit.com") on the Steemit website appeared recently making a number of claims regarding [Ouroboros](/research/papers/#9BKRHCSI "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, iohk.io"). The article contains several factual inaccuracies. For instance, it is claimed that “DPOS” in the Ouroboros paper stands for “delegated proof of stake”, while in fact, DPOS means “dynamic proof of stake”, or that the protocol requires a "2/3+" ratio of parties being honest, while in reality it just requires an honest majority, i.e. the stake controlled by parties following the protocol is more than half the total stake.\nFor the benefit of those that are interested in the Ouroboros protocol and who appreciate its general philosophy, we feel it is appropriate to provide here a response to this article making along the way a few broader points. While pointing out inaccuracies in the blog, we take the opportunity to highlight some of the general approaches followed in the design of Ouroboros and in the related research efforts that are currently underway at IOHK.\n \nOuroboros is a proof of stake (PoS) protocol that uses delegation in the spirit of the PoS idea as discussed in the [Bitcoin forum starting from 2011](https://bitcointalk.org/index.php?topic=27787.0 "Proof of stake instead of proof of work, bitcointalk.org"). The references that influenced its design are listed in our paper. PoS is a powerful concept that has inspired a number of other efforts prior, concurrent and post the first Ouroboros paper. Among all other implemented PoS blockchain systems that carry real assets, Ouroboros is unique in that it was designed in tandem with a formal security model and a mathematical proof that it implements a robust transaction ledger. This marks a fundamental shift in the methodology of blockchain system design.\n \nBlockchain systems are in a period of transition from curiosities to critical infrastructure; as such, the all too typical software industry approach of releasing a “minimum viable product” as early as possible and then fixing bugs as they appear, is not appropriate. Failures of critical infrastructure have a significant impact on people’s lives and thus require rigorous engineering discipline to the highest possible standards. Dependability, rather than maximum performance according to some arbitrarily chosen metric, is the primary goal. Performance is important, of course, but the performance required is a function of the ultimate application domain, and from the point of view of dependability it is the worst-case performance that is important, not the ideal-scenario peak rate.\n \nLike all other protocols in the blockchain space, Ouroboros requires some degree of synchronisation. The block production interval has to be consistent with the likely time to complete the required information exchanges. The 20-second slot time in Ouroboros represents a conservative choice for a block of transactions to traverse the diameter of a peer-to-peer network, where the peers may be significantly geographically distributed, the system is operating at peak transaction load and the interconnection is significantly less than perfect. It is improbable for a block of transactions to consistently traverse a global network much faster than that, and as a result any solution that does significantly better (or claims to do significantly better) is either wrong, or provides a weaker level of decentralisation or security, i.e. it solves an easier problem than Ouroboros. There is a tradeoff between achieving a robust, global, participatory service that delivers sustained effective performance even under an adversarial attack, and creating a high performance, limited participation (in geographical scope or network resource requirement) solution that makes overly optimistic assumptions on network stability.\n \nIrreversibility, the property that transactions persist and are immutable in a blockchain protocol, has to be presented as a function of the level of the adversarial strength. This is true in Nakamoto’s Bitcoin paper and also in the [Ouroboros paper](/research/papers/#9BKRHCSI "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, iohk.io"), see Section 10.1 for the actual time needed for confirmation of transactions. Thus, one should be very wary of statements about irreversibility that do not quantify the level of adversarial power. For instance, Ouroboros will confirm a transaction with 99.9% assurance in just five minutes against an adversary holding 10% of the total stake, which in today’s market cap in the Cardano blockchain would amount to more than two billion dollars. Byzantine agreement protocols can provide a more “black and white” irreversibility, in other words the protocol can be guaranteed to be irreversible within a certain time window provided an honest majority or supermajority exists depending on the protocol. Nevertheless, the performance and decentralisation penalty suffered is very high if the level of adversity is allowed to come close to the 1/2 barrier, which is the level of adversity that Ouroboros can withstand.\n \nThe issue of possible dominance of the consensus process by a small group of stakeholders holding a large proportion of the stake is important but is not applicable to the current release of the Cardano system (the Byron release). What we have proved for Ouroboros is that it can facilitate a “fair” transaction ledger (where fairness here means that the ledger can fairly record all significant actions that are performed by the protocol participants despite the presence of an adversary). This enabled us to neutralise a number of rational protocol deviations (e.g. the equivalent of selfish mining attacks in the PoS setting) and provide a Nash equilibrium argument showing how the protocol can support many different types of mechanisms for incentivising participant behaviour. Currently, IOHK Research is actively working to finalise the incentive structure that will be incorporated in the Shelley release of Cardano, where stake pools will be supported and delegation behaviour will be properly incentivised so that it offers effective decentralisation of power. The crux of our methodology is the engineering of a novel reward mechanism for rational participants that provides appropriate incentives to partition their delegation rights. The objectives are first, to avoid concentration of power to a small group of participants – as it could happen by a naïve reward mechanism in a Pareto distributed stakeholder population – and second, to provide appropriate incentives to ensure a desired number of delegates. We are very excited about this work; it will be the first of its kind in the area and, as before, we will be disseminating it widely including full technical details, as well as submitting it for peer review.\n \nThis brings us to the final distinguishing advantage of the philosophy of Cardano. Scientific peer review has been refined over centuries. The way it is implemented by the [International Cryptology Conference](https://www.iacr.org/conferences/crypto2017/ "Crypto 2017, iacr.org") (also called Crypto), where Ouroboros was presented, and the other top conferences in the area, strives to remove conflicts of interest and produce the highest level of objectivity. The method of reviewing is known as "double blind”, i.e. papers are submitted anonymously and reviewers are experts that also remain anonymous to the authors. The committee of experts that reviews submitted papers each year is formed by two program co-chairs that are appointed by the [International Association of Cryptologic Research](https://www.iacr.org/ "iacr.org"), the pre-eminent organisation of cryptology research that was founded in 1982.\n\nBeing invited to serve in the committee as an expert is an important recognition of an individual’s long-term commitment to the area of cryptography (and even a precise count of how many times one has served is [maintained](https://www.iacr.org/cryptodb/data/stats.php "Publishing Statistics, iacr.org")). Blockchain protocols fit perfectly within the cryptography scientific literature and thus scientific peer review is to be done by this community. Of course, we welcome reviews from anyone. That is why we make public very detailed whitepapers with precise and specific claims that leave no uncertainty about what is being claimed, and we appreciate any factual discussion about any of these claims. We strongly encourage other projects to submit their work for scientific peer review as well. They will enjoy the benefits of thorough, well-founded and objective critique and they will have the opportunity to showcase any advantages and novelty that their approach possesses.\n',
                                uses_mathjax: null,
                                attachments: [
                                    {
                                        type: 'pdf',
                                        url: 'https://ucarecdn.com/67b9e51b-1022-40d8-b7f2-fa143c8fea18/-/inline/yes/',
                                        name: 'On the Ouroboros Design- How rigour and'
                                    }
                                ],
                                slug: 'on-the-ouroboros-design-how-rigour-and-engineering-are-essential-for-critical-infrastructure',
                                url: '/blog/posts/2018/01/11/on-the-ouroboros-design-how-rigour-and-engineering-are-essential-for-critical-infrastructure/',
                                read_time: 7
                            },
                            {
                                publish_date: '2021-06-10T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/7aaaa825-7c80-4bfb-8712-a1e66bc809b8/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Stablefees and the Decentralized Reserve System',
                                        subtitle: 'Exploring a new mechanism to help make fees fair, stable, and more predictable over time',
                                        audio: null,
                                        soundcloud: [],
                                        body_content: 'Facilitating transactions in cryptocurrency platforms stumbles on the dual utility of the platform’s underlying asset. On the one hand, users can hold and trade it as part of their investment portfolios. On the other hand, it supplies the necessary “fuel” for processing transactions. \n\nThis duality suggests that the system should have a mechanism for adjusting transaction costs, so they remain competitive and reasonable. Also, the bounded throughput of decentralized platforms per unit of time introduces another hurdle: the system should also allow the users to discover the correct price for timely transaction processing, depending on their individual needs. \n\nWhy not drop transaction fees altogether? Three reasons: One, transaction processing incurs costs on the system’s side (in terms of computation and storage). It is reasonable to allow transaction processors (stake pool operators, in the case of Cardano) to offset their costs. Two, even with a theoretically infinite capacity, it is important to prevent transaction issuers from saturating the network with worthless transactions. Three, it is appropriate to incentivize transaction processors to provide quality of service. A surge in demand should influence their payoffs accordingly.\n\nAdding a fee to each transaction can address the above considerations. \n\n### Bitcoin and beyond\n\nBitcoin set out the first mechanism for pricing transactions in distributed ledger platforms. This mechanism resembles a first-price auction: transactions bid for a place in a block naming a specific reward, and block producers select the transactions that they prefer to include. Block producers also get rewarded with the right to mint new coins, i.e., their operation is subsidized by the whole community via inflation of the total coin supply. Inflation drops geometrically over time, and transaction fees become increasingly dominant in the rewards. This mechanism, while enabling Bitcoin to run for well over a decade, has been criticized for its inefficiency. Transaction costs have also risen over time.\n\nIn this blog post, we explore a new mechanism that builds on Cardano\'s approach to ledger rules and system assets, and complements the [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) concept. The objective is making fees fair, stable, and predictable over time. We describe the mechanism in the context of Cardano. However, it can be adapted to any other cryptocurrency with similar characteristics.\n\n### Introducing \'Stablefees\'\n\nThe core idea behind Stablefees is to have a base price for transactions through pegging to a basket of commodities or currencies. Stablefees includes a native "decentralized reserve" contract that issues and manages a stablecoin pegged to the basket. A comparison in the fiat world might be the International Monetary Fund’s[ SDR](https://www.imf.org/en/About/Factsheets/Sheets/2016/08/01/14/51/Special-Drawing-Right-SDR), (established in 1969) and valued based on a basket of five currencies—the U.S. dollar, the euro, the Chinese renminbi, the Japanese yen, and the British pound sterling. The stablecoin --- let’s call it "Basket Equivalent Coin" (BEC) --- is the currency used for paying transaction fees (and all other real world pricing needs of the platform, e.g., SPO costs). \n\nIn this system, ada will play a dual role: Reserve asset of the decentralized reserve, and reward currency for staking. It will also be the fall-back currency in extreme scenarios where the reserve contract is in a liquidity crunch. Before a transaction, the issuer will have to obtain BECs, either via other third parties or directly by sending ada to the decentralized reserve contract. On what basis will the reserve issue BECs? The reserve contract will also issue equity shares -we will call them decentralized equity coins (DECs)-, in exchange of ada. Leveraging the value of DECs, the decentralized reserve will often adjust the value of BEC so it is pegged on the underlying basket of commodities. In other words, DECs will absorb the fluctuations of ada vs. the basket to ensure that the real-world value of BECs remains stable (cf. the [AgeUSD stablecoin design](https://github.com/Emurgo/age-usd) that has been already [deployed and used on Ergo](https://sigmausd.io/#/)). \n\nThis trinity of coinage, issued natively by the system, will attract different cohorts. BECs\' stability and liquidity might be attractive to risk-averse, transaction-intensive holders. DECs will offer the highest rewards if ada goes up, but also take the most significant hit when ada goes down. Long-term holders may find DECs more attractive. Also, since decentralized reserve prices these coins in ada, both BECs and DECs can facilitate participation in staking and governance. Returns can be issued at different rates, reflecting the different nature of each coin. Ultimately, rewards will always be denominated and payable in ada, which will remain the most versatile of all three coins.\n\n### Oracles\n\nThe centerpiece of this mechanism is an on-chain oracle that determines the price of the basket in ada. SPOs can implement this oracle in a decentralized manner. The reserve can offer extra rewards to all oracle contributors from the fees collected during BEC/DEC issuances. This will ensure two things: thousands of geographically-diverse contributors, and ledger rules calculating a synthesized exchange rate in some canonical way (through a weighted median across all price submissions in an epoch, for example). If oracle contributors manipulate their contributions, they can be held accountable by tracking their reputation and performance on-chain.\n\n### The pricing mechanism\n\nHow would one price transactions and reward block producers? Using the current approach in Cardano, each transaction will be deterministically mapped to a precise value denominated in BECs, using a formula determined by the ledger rules. The formula will take into account both transaction size and its computational requirements, and may also incorporate runtime metrics (such as the average system load). The resulting value will be the base fee guaranteeing that the transaction will be processed by the system. Given the base fee, end users will be able to apply a multiplier if they wish (which will be a value at least 1, e.g., 1.5x, 3x, etc.) to increase the fee and accelerate processing. This will become relevant at times of surging demand.  \n\nThis approach has one advantage when compared with the first-price auction model: the pricing mechanism is continuously stabilized to a reasonable default value. Users perform price discovery in one direction only to accelerate processing, if required. Also, transaction issuers can store BECs to secure their future transaction-issuing ability without being affected by ada price volatility.\n\n### Stablefees and Babel fees\n\nThe Stablefees mechanism can be considered a natural extension of [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) ---spot conversion of BECs into ada by the decentralized reserve. Both mechanisms complement (and are compatible with) each other. Babel fees can be deployed together with Stablefees with just one change: Using BECs to cover Babel fee liabilities, instead of ada. This also means that fees will always be payable in ada (via a Babel fee liability convertible in ada on the spot). Hence, the whole mechanism is backwards compatible: it won’t affect occasional users who just hold ada and do not wish to obtain BECs.  \n\nA final point about diversity. While the above narrative identifies a unique and global BEC, the same mechanism can be used to issue regional BECs pegged to different baskets of commodities, which could possibly be weighted differently. Such “regional” BECs will be able to increase system inclusivity, while enabling SPOs to have more fine-grained policies in terms of transaction inclusion.\n\n### Stablefees \'lite\'\n\nThe above mechanism requires a decentralized reserve contract and the issuance of BECs and DECs by the contract to buyers. A “lite” version avoids the reserve contract and directly adjusts the fee formula by pegging it onto the agreed basket of commodities through the price oracle. The resulting system denominates transaction fees nominally in BECs and immediately converts them into ada. The payable amount fluctuates, depending on the value of BEC. The mechanism is otherwise identical, also facilitating unidirectional price discovery through the multiplier. The only disadvantage is that a prospective transaction issuer has no access to a native token that enables transaction processing predictably; transaction issuers must pay fees in ada. Still, the fees will continuously adjust and remain stable via the pegging mechanism with respect to the basket. As a result, a transaction issuer will be able to organize their off-chain asset portfolio to meet their transaction needs effectively.\n\n### The road ahead\n\nOur team is currently researching the granular details of the Stablefees mechanism. Once this research is complete, Stablefees can be integrated into Cardano to offer fair and predictable transaction pricing. Moreover, the price oracle and the global BEC (and regional variants, if included) will undoubtedly find uses beyond paying transaction fees, expanding the capabilities of decentralized applications in the Cardano ecosystem.',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Stablefees and the Decentralized Reserve System',
                                subtitle: 'Exploring a new mechanism to help make fees fair, stable, and more predictable over time',
                                audio: null,
                                soundcloud: [],
                                body_content: 'Facilitating transactions in cryptocurrency platforms stumbles on the dual utility of the platform’s underlying asset. On the one hand, users can hold and trade it as part of their investment portfolios. On the other hand, it supplies the necessary “fuel” for processing transactions. \n\nThis duality suggests that the system should have a mechanism for adjusting transaction costs, so they remain competitive and reasonable. Also, the bounded throughput of decentralized platforms per unit of time introduces another hurdle: the system should also allow the users to discover the correct price for timely transaction processing, depending on their individual needs. \n\nWhy not drop transaction fees altogether? Three reasons: One, transaction processing incurs costs on the system’s side (in terms of computation and storage). It is reasonable to allow transaction processors (stake pool operators, in the case of Cardano) to offset their costs. Two, even with a theoretically infinite capacity, it is important to prevent transaction issuers from saturating the network with worthless transactions. Three, it is appropriate to incentivize transaction processors to provide quality of service. A surge in demand should influence their payoffs accordingly.\n\nAdding a fee to each transaction can address the above considerations. \n\n### Bitcoin and beyond\n\nBitcoin set out the first mechanism for pricing transactions in distributed ledger platforms. This mechanism resembles a first-price auction: transactions bid for a place in a block naming a specific reward, and block producers select the transactions that they prefer to include. Block producers also get rewarded with the right to mint new coins, i.e., their operation is subsidized by the whole community via inflation of the total coin supply. Inflation drops geometrically over time, and transaction fees become increasingly dominant in the rewards. This mechanism, while enabling Bitcoin to run for well over a decade, has been criticized for its inefficiency. Transaction costs have also risen over time.\n\nIn this blog post, we explore a new mechanism that builds on Cardano\'s approach to ledger rules and system assets, and complements the [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) concept. The objective is making fees fair, stable, and predictable over time. We describe the mechanism in the context of Cardano. However, it can be adapted to any other cryptocurrency with similar characteristics.\n\n### Introducing \'Stablefees\'\n\nThe core idea behind Stablefees is to have a base price for transactions through pegging to a basket of commodities or currencies. Stablefees includes a native "decentralized reserve" contract that issues and manages a stablecoin pegged to the basket. A comparison in the fiat world might be the International Monetary Fund’s[ SDR](https://www.imf.org/en/About/Factsheets/Sheets/2016/08/01/14/51/Special-Drawing-Right-SDR), (established in 1969) and valued based on a basket of five currencies—the U.S. dollar, the euro, the Chinese renminbi, the Japanese yen, and the British pound sterling. The stablecoin --- let’s call it "Basket Equivalent Coin" (BEC) --- is the currency used for paying transaction fees (and all other real world pricing needs of the platform, e.g., SPO costs). \n\nIn this system, ada will play a dual role: Reserve asset of the decentralized reserve, and reward currency for staking. It will also be the fall-back currency in extreme scenarios where the reserve contract is in a liquidity crunch. Before a transaction, the issuer will have to obtain BECs, either via other third parties or directly by sending ada to the decentralized reserve contract. On what basis will the reserve issue BECs? The reserve contract will also issue equity shares -we will call them decentralized equity coins (DECs)-, in exchange of ada. Leveraging the value of DECs, the decentralized reserve will often adjust the value of BEC so it is pegged on the underlying basket of commodities. In other words, DECs will absorb the fluctuations of ada vs. the basket to ensure that the real-world value of BECs remains stable (cf. the [AgeUSD stablecoin design](https://github.com/Emurgo/age-usd) that has been already [deployed and used on Ergo](https://sigmausd.io/#/)). \n\nThis trinity of coinage, issued natively by the system, will attract different cohorts. BECs\' stability and liquidity might be attractive to risk-averse, transaction-intensive holders. DECs will offer the highest rewards if ada goes up, but also take the most significant hit when ada goes down. Long-term holders may find DECs more attractive. Also, since decentralized reserve prices these coins in ada, both BECs and DECs can facilitate participation in staking and governance. Returns can be issued at different rates, reflecting the different nature of each coin. Ultimately, rewards will always be denominated and payable in ada, which will remain the most versatile of all three coins.\n\n### Oracles\n\nThe centerpiece of this mechanism is an on-chain oracle that determines the price of the basket in ada. SPOs can implement this oracle in a decentralized manner. The reserve can offer extra rewards to all oracle contributors from the fees collected during BEC/DEC issuances. This will ensure two things: thousands of geographically-diverse contributors, and ledger rules calculating a synthesized exchange rate in some canonical way (through a weighted median across all price submissions in an epoch, for example). If oracle contributors manipulate their contributions, they can be held accountable by tracking their reputation and performance on-chain.\n\n### The pricing mechanism\n\nHow would one price transactions and reward block producers? Using the current approach in Cardano, each transaction will be deterministically mapped to a precise value denominated in BECs, using a formula determined by the ledger rules. The formula will take into account both transaction size and its computational requirements, and may also incorporate runtime metrics (such as the average system load). The resulting value will be the base fee guaranteeing that the transaction will be processed by the system. Given the base fee, end users will be able to apply a multiplier if they wish (which will be a value at least 1, e.g., 1.5x, 3x, etc.) to increase the fee and accelerate processing. This will become relevant at times of surging demand.  \n\nThis approach has one advantage when compared with the first-price auction model: the pricing mechanism is continuously stabilized to a reasonable default value. Users perform price discovery in one direction only to accelerate processing, if required. Also, transaction issuers can store BECs to secure their future transaction-issuing ability without being affected by ada price volatility.\n\n### Stablefees and Babel fees\n\nThe Stablefees mechanism can be considered a natural extension of [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) ---spot conversion of BECs into ada by the decentralized reserve. Both mechanisms complement (and are compatible with) each other. Babel fees can be deployed together with Stablefees with just one change: Using BECs to cover Babel fee liabilities, instead of ada. This also means that fees will always be payable in ada (via a Babel fee liability convertible in ada on the spot). Hence, the whole mechanism is backwards compatible: it won’t affect occasional users who just hold ada and do not wish to obtain BECs.  \n\nA final point about diversity. While the above narrative identifies a unique and global BEC, the same mechanism can be used to issue regional BECs pegged to different baskets of commodities, which could possibly be weighted differently. Such “regional” BECs will be able to increase system inclusivity, while enabling SPOs to have more fine-grained policies in terms of transaction inclusion.\n\n### Stablefees \'lite\'\n\nThe above mechanism requires a decentralized reserve contract and the issuance of BECs and DECs by the contract to buyers. A “lite” version avoids the reserve contract and directly adjusts the fee formula by pegging it onto the agreed basket of commodities through the price oracle. The resulting system denominates transaction fees nominally in BECs and immediately converts them into ada. The payable amount fluctuates, depending on the value of BEC. The mechanism is otherwise identical, also facilitating unidirectional price discovery through the multiplier. The only disadvantage is that a prospective transaction issuer has no access to a native token that enables transaction processing predictably; transaction issuers must pay fees in ada. Still, the fees will continuously adjust and remain stable via the pegging mechanism with respect to the basket. As a result, a transaction issuer will be able to organize their off-chain asset portfolio to meet their transaction needs effectively.\n\n### The road ahead\n\nOur team is currently researching the granular details of the Stablefees mechanism. Once this research is complete, Stablefees can be integrated into Cardano to offer fair and predictable transaction pricing. Moreover, the price oracle and the global BEC (and regional variants, if included) will undoubtedly find uses beyond paying transaction fees, expanding the capabilities of decentralized applications in the Cardano ecosystem.',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'stablefees-and-the-decentralized-reserve-system',
                                url: '/blog/posts/2021/06/10/stablefees-and-the-decentralized-reserve-system/',
                                read_time: 7
                            },
                            {
                                publish_date: '2021-02-25T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/89c32658-5415-43bc-9dc4-e7acff7735ab/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Babel fees - denominating transaction costs in native tokens',
                                        subtitle: 'Introducing a novel mechanism that allows the payment of transaction fees in user-defined tokens on Cardano',
                                        audio: null,
                                        soundcloud: [
                                            {
                                                trackid: 992849701
                                            }
                                        ],
                                        body_content: 'In Douglas Adams\' classic The Hitchhiker\'s Guide to the Galaxy, a [Babel fish](http://www.bbc.co.uk/cult/hitchhikers/guide/babelfish.shtml) is a creature that allows you to hear any language translated into your own. This fantasy of universal translation ensures meaningful interaction despite the myriad different languages in the galaxy. \n\nIn the cryptocurrency space, smart contract platforms enable the development of a myriad custom tokens. Is it possible to interact with the platform using your preferred token? If only there was a “Babel fees” mechanism to translate the token you use to the one that the platform requires for posting a transaction. \n\nCommon wisdom in blockchain systems suggests that posting a valid transaction must incur a cost to the sender. The argument is that, without such constraint, there is nothing to stop anyone from overloading the system with trivial transactions saturating its capacity and rendering it unusable. Given the above tenet, a frequently made corollary is that in any blockchain system where user-defined tokens are supported, it should be prohibited to pay transaction fees in such tokens. Instead, transactions should carry a fee in the native token of the platform that is accepted by all participants as being valuable.  Arguably such a restriction is undesirable. But how is it possible to circumvent the ensuing – and seemingly inevitable – vulnerability? \n\n## The art of the possible\n\nCryptography and game theory have been known to make possible what seemed impossible. Celebrated examples include key exchange over a public channel, Merkle\'s puzzles, and auctions where being truthful is the rational thing to do, like Vickrey\'s auctions. And so it also turns out in this case. \n\nFirst, let us recall how native assets work in Cardano: Tokens can be created according to a minting policy and they are treated natively in the ledger along with ada. Cardano\'s ledger adopts the Extended UTXO (EUTXO) model, and issuing a valid transaction requires consuming one or more UTXOs. A UTXO in Cardano may carry not just ada but in fact a token bundle that can contain multiple different tokens, both fungible and non-fungible. In this way it is possible to write transactions that transfer multiple different tokens with a single UTXO. \n\nTransaction fees in the ledger are denominated in ada according to a function fixed as a ledger parameter. A powerful feature of Cardano\'s EUTXO model is that the fees required for a valid transaction can be predicted precisely prior to posting it. This is a unique feature that is not enjoyed by other ledger arrangements (such as the account-based model used in Ethereum). Indeed, in this latter case the fees needed for a transaction may change during the time it takes for the transaction to settle, since other transactions may affect the ledger\'s state in between and influence the required cost for processing the transaction. \n\n## A thought experiment\n\nLet\'s consider the following thought experiment to help us move closer towards our objective of Babel fees. Imagine that it is possible to issue a transaction that declares a liability denominated in ada equal to the amount of fees that the transaction issuer is supposed to pay. Such a transaction would not be admissible to the ledger. However it can be perceived as an open offer that asks for the liability to be covered. Why would anyone respond to such an offer? To entice a response, assuming the token bundle concept already present in Cardano,  the transaction can offer some amount of token(s) to whoever covers the liability. This suggests a spot trade between ada and the offered token(s) at a certain exchange rate. Consider now a block producer that sees such a transaction. The block producer can create a matching transaction absorbing the liability covering it with ada as well as claiming the tokens that are on offer. \n\nBy suitably extending the ledger rules, the transaction with the liability as well as its matching transaction become admissible to the ledger as a group. Due to the absorption of the liability, the set of two transactions becomes properly priced in ada as a whole and hence it does not break the ledgers\' bookkeeping rules in terms of ada fees. As a result, the transaction with the liability settles, and we have achieved our objective. Users can submit transactions priced in any token(s) they possess and, providing a block producer is willing to take them up on the spot trade, have them settle in the ledger as regular transactions!\n\n## A concrete example\n\nThe mechanism is of course conditioned on the presence of liquidity providers that possess ada and are willing to issue matching transactions. In fact the mechanism creates a market for such liquidity providers. For instance, a stake pool operator (SPO), can publish exchange rates for specific tokens they consider acceptable. For instance an SPO can declare that they will accept tokenX for an exchange rate 3:1 over ada. It follows that if a transaction costs, say ₳0.16, the transaction can declare a liability of ₳0.16 as well as offer 0.48 of tokenX. In the native asset model of Cardano this can be implemented as a single UTXO carrying a token bundle with the following specification (Ada→ -0.16, tokenX→0.48). Note the negative sign signifying the liability. \n\nSuppose now that the SPO is about to produce a block. She recovers the liability transaction from the mempool and issues a matching transaction consuming the UTXO with the liability. The matching transaction transfers 0.48 of tokenX to a new output which is owned by the SPO. The resulting block contains the two transactions in sequence. The matching transaction provides the missing ₳0.16 in addition to the fees that are needed for itself. In fact multiple transactions can be batched together and have their fees covered by a single matching transaction. \n\n![](https://lh4.googleusercontent.com/9MEHGqNJxiDK510lAb8fvAWJBS19MwRiyPxdpdn6gc-7jloOcmaykYOuh0HNg3fI6wDIw5I6WqwdkCDENETK9zXZ2K16l_t4XGfbT5Ee1jvgkMYq1BcT--iAeA7qojLIhfkRnn5_)\n\n*Figure. Alice sends a quantity of 9 tokens of type X to Bob with the assistance of Stacy, an SPO, who covers Alice\'s transaction liability and receives tokens of type X in exchange. The implied exchange rate between X and Ada is 3:1.* \n\n## New measures of value\n\nThe above process is entirely opt-in for SPOs. Each one can determine their own policy and exchange rate as well as decide to change the exchange rate for the various tokens they accept on the spot. Moreover, there is no need for agreement between SPOs about the value of a specific token. In fact, different SPOs may provide different exchange rates for the same token and a user issuing a liability transaction can offer an amount of tokens corresponding to the minimum, average or even maximum of the posted exchange rates in the network. In this way, a natural trade off arises between settlement time of liability transactions and the market value of tokens they offer. \n\nThis illustrates how native assets, the EUTXO model, and the simple but powerful tweak of introducing liabilities in the form of negative values in token bundles can accommodate Babel fees empowering users to price transactions in any token supported natively by the system. It also shows the unique advantage of being an SPO in such a system. It should be noted that SPOs need not be the only entities in the network offering to cover liabilities. In fact, an SPO can readily partner -if they wish- with an external liquidity provider who will be issuing the matching transactions. In addition, third party providers can also act on the network independently and issue matching transactions. Nevertheless, the benefit will remain with the block producers; SPOs can always front-run matching transactions and substitute them for their own if they wish so. This is a case that front-running transactions is a feature: it makes it feasible for SPOs to be paid in the tokens they prefer for their transaction processing services.\n\nThe mechanism of negative quantities in token bundles can be implemented in the basic ledger rules of Cardano at some point following the introduction of native assets with the Mary Hard Fork. Beyond Babel fees, the mechanism allows a variety of other interesting applications, such as atomic swaps for spot trades, that we will cover in a future blog post. It is yet another illustration of the power of Cardano\'s approach and its ability to support a diverse and entrepreneurial community of users and stake pool operators. \n\n*I am grateful to Manuel Chakravarty, Michael Peyton Jones, Nikos Karagiannidis, Chad Nester and Polina Vinogradova for helpful discussions, suggestions and comments related to the concept of Babel fees and its implementation in the Cardano ledger. We also have a [video whiteboard walkthrough](https://youtu.be/YXaK0cvgoFQ?t=2184) covering this topic.*',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Babel fees - denominating transaction costs in native tokens',
                                subtitle: 'Introducing a novel mechanism that allows the payment of transaction fees in user-defined tokens on Cardano',
                                audio: null,
                                soundcloud: [
                                    {
                                        trackid: 992849701
                                    }
                                ],
                                body_content: 'In Douglas Adams\' classic The Hitchhiker\'s Guide to the Galaxy, a [Babel fish](http://www.bbc.co.uk/cult/hitchhikers/guide/babelfish.shtml) is a creature that allows you to hear any language translated into your own. This fantasy of universal translation ensures meaningful interaction despite the myriad different languages in the galaxy. \n\nIn the cryptocurrency space, smart contract platforms enable the development of a myriad custom tokens. Is it possible to interact with the platform using your preferred token? If only there was a “Babel fees” mechanism to translate the token you use to the one that the platform requires for posting a transaction. \n\nCommon wisdom in blockchain systems suggests that posting a valid transaction must incur a cost to the sender. The argument is that, without such constraint, there is nothing to stop anyone from overloading the system with trivial transactions saturating its capacity and rendering it unusable. Given the above tenet, a frequently made corollary is that in any blockchain system where user-defined tokens are supported, it should be prohibited to pay transaction fees in such tokens. Instead, transactions should carry a fee in the native token of the platform that is accepted by all participants as being valuable.  Arguably such a restriction is undesirable. But how is it possible to circumvent the ensuing – and seemingly inevitable – vulnerability? \n\n## The art of the possible\n\nCryptography and game theory have been known to make possible what seemed impossible. Celebrated examples include key exchange over a public channel, Merkle\'s puzzles, and auctions where being truthful is the rational thing to do, like Vickrey\'s auctions. And so it also turns out in this case. \n\nFirst, let us recall how native assets work in Cardano: Tokens can be created according to a minting policy and they are treated natively in the ledger along with ada. Cardano\'s ledger adopts the Extended UTXO (EUTXO) model, and issuing a valid transaction requires consuming one or more UTXOs. A UTXO in Cardano may carry not just ada but in fact a token bundle that can contain multiple different tokens, both fungible and non-fungible. In this way it is possible to write transactions that transfer multiple different tokens with a single UTXO. \n\nTransaction fees in the ledger are denominated in ada according to a function fixed as a ledger parameter. A powerful feature of Cardano\'s EUTXO model is that the fees required for a valid transaction can be predicted precisely prior to posting it. This is a unique feature that is not enjoyed by other ledger arrangements (such as the account-based model used in Ethereum). Indeed, in this latter case the fees needed for a transaction may change during the time it takes for the transaction to settle, since other transactions may affect the ledger\'s state in between and influence the required cost for processing the transaction. \n\n## A thought experiment\n\nLet\'s consider the following thought experiment to help us move closer towards our objective of Babel fees. Imagine that it is possible to issue a transaction that declares a liability denominated in ada equal to the amount of fees that the transaction issuer is supposed to pay. Such a transaction would not be admissible to the ledger. However it can be perceived as an open offer that asks for the liability to be covered. Why would anyone respond to such an offer? To entice a response, assuming the token bundle concept already present in Cardano,  the transaction can offer some amount of token(s) to whoever covers the liability. This suggests a spot trade between ada and the offered token(s) at a certain exchange rate. Consider now a block producer that sees such a transaction. The block producer can create a matching transaction absorbing the liability covering it with ada as well as claiming the tokens that are on offer. \n\nBy suitably extending the ledger rules, the transaction with the liability as well as its matching transaction become admissible to the ledger as a group. Due to the absorption of the liability, the set of two transactions becomes properly priced in ada as a whole and hence it does not break the ledgers\' bookkeeping rules in terms of ada fees. As a result, the transaction with the liability settles, and we have achieved our objective. Users can submit transactions priced in any token(s) they possess and, providing a block producer is willing to take them up on the spot trade, have them settle in the ledger as regular transactions!\n\n## A concrete example\n\nThe mechanism is of course conditioned on the presence of liquidity providers that possess ada and are willing to issue matching transactions. In fact the mechanism creates a market for such liquidity providers. For instance, a stake pool operator (SPO), can publish exchange rates for specific tokens they consider acceptable. For instance an SPO can declare that they will accept tokenX for an exchange rate 3:1 over ada. It follows that if a transaction costs, say ₳0.16, the transaction can declare a liability of ₳0.16 as well as offer 0.48 of tokenX. In the native asset model of Cardano this can be implemented as a single UTXO carrying a token bundle with the following specification (Ada→ -0.16, tokenX→0.48). Note the negative sign signifying the liability. \n\nSuppose now that the SPO is about to produce a block. She recovers the liability transaction from the mempool and issues a matching transaction consuming the UTXO with the liability. The matching transaction transfers 0.48 of tokenX to a new output which is owned by the SPO. The resulting block contains the two transactions in sequence. The matching transaction provides the missing ₳0.16 in addition to the fees that are needed for itself. In fact multiple transactions can be batched together and have their fees covered by a single matching transaction. \n\n![](https://lh4.googleusercontent.com/9MEHGqNJxiDK510lAb8fvAWJBS19MwRiyPxdpdn6gc-7jloOcmaykYOuh0HNg3fI6wDIw5I6WqwdkCDENETK9zXZ2K16l_t4XGfbT5Ee1jvgkMYq1BcT--iAeA7qojLIhfkRnn5_)\n\n*Figure. Alice sends a quantity of 9 tokens of type X to Bob with the assistance of Stacy, an SPO, who covers Alice\'s transaction liability and receives tokens of type X in exchange. The implied exchange rate between X and Ada is 3:1.* \n\n## New measures of value\n\nThe above process is entirely opt-in for SPOs. Each one can determine their own policy and exchange rate as well as decide to change the exchange rate for the various tokens they accept on the spot. Moreover, there is no need for agreement between SPOs about the value of a specific token. In fact, different SPOs may provide different exchange rates for the same token and a user issuing a liability transaction can offer an amount of tokens corresponding to the minimum, average or even maximum of the posted exchange rates in the network. In this way, a natural trade off arises between settlement time of liability transactions and the market value of tokens they offer. \n\nThis illustrates how native assets, the EUTXO model, and the simple but powerful tweak of introducing liabilities in the form of negative values in token bundles can accommodate Babel fees empowering users to price transactions in any token supported natively by the system. It also shows the unique advantage of being an SPO in such a system. It should be noted that SPOs need not be the only entities in the network offering to cover liabilities. In fact, an SPO can readily partner -if they wish- with an external liquidity provider who will be issuing the matching transactions. In addition, third party providers can also act on the network independently and issue matching transactions. Nevertheless, the benefit will remain with the block producers; SPOs can always front-run matching transactions and substitute them for their own if they wish so. This is a case that front-running transactions is a feature: it makes it feasible for SPOs to be paid in the tokens they prefer for their transaction processing services.\n\nThe mechanism of negative quantities in token bundles can be implemented in the basic ledger rules of Cardano at some point following the introduction of native assets with the Mary Hard Fork. Beyond Babel fees, the mechanism allows a variety of other interesting applications, such as atomic swaps for spot trades, that we will cover in a future blog post. It is yet another illustration of the power of Cardano\'s approach and its ability to support a diverse and entrepreneurial community of users and stake pool operators. \n\n*I am grateful to Manuel Chakravarty, Michael Peyton Jones, Nikos Karagiannidis, Chad Nester and Polina Vinogradova for helpful discussions, suggestions and comments related to the concept of Babel fees and its implementation in the Cardano ledger. We also have a [video whiteboard walkthrough](https://youtu.be/YXaK0cvgoFQ?t=2184) covering this topic.*',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'babel-fees',
                                url: '/blog/posts/2021/02/25/babel-fees/',
                                read_time: 8
                            },
                            {
                                publish_date: '2020-11-30T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/efe10f62-5ed9-40df-ba6b-2db352dad69f/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Blockchain reward sharing - a comparative systematization from first principles',
                                        subtitle: 'Navigating the diverse landscape of reward-sharing schemes and the choices we have made in the design of Cardano’s reward-sharing scheme',
                                        audio: 'https://ucarecdn.com/7ad17830-600c-4313-b55a-751d0149f93a/',
                                        soundcloud: null,
                                        body_content: 'In the previous article, we identified the [objectives of the reward scheme in Cardano](https://iohk.io/en/blog/posts/2020/11/13/the-general-perspective-on-staking-in-cardano/), and we gave general guidelines regarding engaging with the system.\n\nTaking a more high-level view, we will examine from first principles, the general problem of reward sharing in blockchain systems. To recall, the two overarching objectives of any *resource-based* consensus system is to incentivize the following.\n\n**High engagement**. Resource-based consensus protocols are more secure the more resources are engaged with protocol maintenance. The problem, of course, is that the underlying resources are useful for a wide variety of other things too (e.g., electricity and computational power in the case of proof of work, **or stake for engaging in decentralized apps** in the case of proof of stake), so resource holders should be incentivized to commit resources for protocol maintenance.\n\n**Low leverage**: leverage relates to decentralization. Take a group of 10 people; if there is a leader and the group follows the leader’s wishes all the time, the leader’s leverage is 10 while everyone else’s is zero. If, on the other hand, everyone’s opinion matters the same, everyone’s leverage is 1. These are two extremes, but it should be fairly obvious what types of leverage align better with decentralization. From an economic viewpoint, however, a “benevolent dictatorship” is always more efficient; as a result, decentralization will come at a cost (exactly as democracy does), and hence it has to be also properly incentivized.  \n\nGiven the above objectives, let us now examine some approaches that have been considered in consensus systems and systematize them in terms of how they address the above objectives. An important first categorization we will introduce is between unimodal and multimodal reward schemes.\n\n## Unimodal\n\nIn a unimodal scheme, there is only one way to engage in the consensus protocol with your resources. We examine two sub-categories of unimodal schemes. \n\n1. **Linear Unimodal**\n\nThis is the simplest approach and is followed by many systems, notably Bitcoin; the original proof-of-work based Ethereum, as well as Algorand. The idea is simple: if an entity commands x% resources, then the system will attempt to provide x% of the rewards – at least in expectation. This might seem fair—until one observes the serious downsides that come with it. \n\nFirst, consider that someone has x% of resources and that x% of the rewards in expectation are below their individual cost to operate as a node. Then, they will either not engage (lowering the engagement rate of the system), or, more likely, actively seek others to combine resources and create a node. Even if there are two resource holders with x% of resources each and a viable individual cost *c* when running as separate nodes, they will fare better by combining resources into a single node of 2x% resources because the resulting cost will be typically less than *2c*. This can result in a strong trend to centralize, and lead to high leverage since the combined pool of resources will be (typically) run by one entity. \n\nIn practice, a single dictatorially operated node is unlikely to emerge. This is due to various reasons such as friction in coordination between parties, fear of the potential drop in the exchange rate of the system’s underlying token if the centralization trend becomes noticeable, as well as the occasional use of complex protocols to jointly run pools. Even so, it is clear that unimodal linear rewards can hurt decentralization. \n\nOne does not need to go much further than looking at Bitcoin and its current, fairly centralized, mining pool lineup. It is worth noting that if stake (rather than hashing power) is used as a resource, the centralization pressure will be less – since the expenditure to operate a node is smaller. But the same problems apply in principle. \n\nAn additional disadvantage of the above setting is that the ensuing “off-chain” resource pooling that occurs will be completely opaque from the ledger perspective, and hence more difficult for the community to monitor and react to. In summary, the linear unimodal approach has the advantage of being simple, but is precarious, both in terms of increasing engagement and for keeping leverage low. \n\n2. **Quantized Linear Unimodal**\n\nThis approach is the same as the linear rewards approach, but it quantizes the underlying resource. I.e., if your resources are below a certain threshold, you may be completely unable to participate; you can only participate in fixed quanta. Notably, this approach is taken in [ETH2.0, where 32 Ether](https://blog.ethereum.org/2019/11/27/validated-staking-on-eth2-0/) should be pledged in order to acquire a validator identity. It should be clear that this quantized approach shares the same problems with the linear unimodal approach in terms of participation and leverage. Despite this, it has been considered for two primary reasons. First, using the quantized approach enables one to retrofit traditional BFT-style protocol design elements (e.g. that require counting identities) in a resource-based consensus setting. The resulting system is less elegant than true resource-based consensus but this is unavoidable since traditional BFT-style protocols do not work very well when there are more than a few hundred nodes involved. The second reason, specific to the proof-of-stake setting, is seeking to impose penalties on participants as a means of ensuring compliance with the protocol. Imposing quantized collateral pledges makes penalties for protocol infractions more substantial and painful.\n\n## Multimodal\n\nWe next turn to multimodal schemes. This broad category includes Cosmos, Tezos, Polkadot & EOS.  It also includes Cardano. In a multimodal scheme, a resource holder may take different roles in the protocol; being a fully active node in the consensus protocol is just one of the options. The advantage of a multimodal scheme is that offering multiple ways to engage (with correspondingly different rates of return) within the protocol itself can accommodate a higher engagement, as well as limit off-chain resource pooling. For instance, if the potential rewards received by an individual when they engage with all their resources sit below their operational cost of running a node,  they can still choose to engage by a different mode in the protocol. In this way, the tendency to combine resources off-chain is eased and the system – if designed properly – may translate this higher engagement to increased resilience. \n\nWe will distinguish between a number of different multimodal schemes.\n\n* **Representative bimodal without leverage control.** The representative approach is inspired by [representative democracy](https://en.wikipedia.org/wiki/Representative_democracy): the system is run by a number of elected operators. The approach is bimodal as it enables parties to (1) advertise themselves as operators in the ledger and/or (2) “vote” for operators with their resources. The set of representative operators has a fixed size and is updated on a rolling basis typically with fixed terms using some election function that selects representatives based on the votes they received. Rewards are distributed evenly between representatives, possibly taking into account performance data and adjusting accordingly. Allowing rewards to flow to voters using a smart contract can incentivize higher engagement in voting since resource holders get paid for voting for good representatives (note that this is not necessarily followed by all schemes in this category). The disadvantage of this approach is the lack of leverage control, beyond,  possibly, the existence of a very large upper bound, which suggests that the system may end up with a set of very highly leveraged operators. This is the approach that is broadly followed by Cosmos,  EOS, and Polkadot.\n\nA different approach to the representative approach is the *delegative* approach. In general, this approach is closer to direct democracy as it allows resource holders the option to engage directly with the protocol with the resources they have. However, they are free to also delegate their resources to others as in [liquid (or delegative) democracy](https://en.wikipedia.org/wiki/Liquid_democracy) (where the term delegative is derived from). This results in a community-selected operator configuration that does not have a predetermined number of representatives. As in the representative approach, user engagement is bimodal. Resource holders can advertise themselves as operators and/or delegate their resources to existing operators. The rewards provided are proportional to the amount of delegated resources and delegates can be paid via an on-chain smart contract, perhaps at various different rates. Within the delegative approach we will further distinguish two subcategories.\n\n* **Delegative bimodal with pledge-based capped rewards.** What typifies this particular delegative approach is that the resource pool’s rewards have a bound that is determined by the amount of pledge that is committed to the pool by its operator. In this way, the total leverage of an operator can be controlled and fixed to a constant. Unfortunately, this leverage control feature has the negative side effect of implicitly imposing the same bound to all, small and large resource holders. So, on the one hand, in a population of small resource holders, engagement will be constrained by the little pledge that operators are able to commit. On the other hand, a few large whale resource holders may end up influencing the consensus protocol in a very significant manner, possibly even beyond its security threshold bound. In terms of leverage control, it should be clear that one size does not fit all! From existing systems, this is the approach that is (in essence) followed by Tezos. \n\nIt is worth noting that all the specific approaches we have seen so far come with downsides – either in terms of maximizing engagement, controlling leverage, or both. With this in mind, let us now fit into our systematization, the approach of the reward-sharing scheme that we are using in Cardano. \n\n* **Delegative bimodal with capped rewards and incentivized pledging.** In this delegative system (introduced in our [reward-sharing scheme](https://arxiv.org/abs/1807.11218) paper), the rewards that are provided to each pool follow a piecewise function on the pool’s size. The function is initially monotonically increasing and then becomes constant at a certain “cap” level which is a configurable system parameter (in Cardano this is determined by the parameter *k*). This cap limits the incentives to grow individual resource pools. At the same time, pledging resources to a pool is *incentivized* with higher pledged pools receiving more rewards. As a result, lowering one’s leverage becomes incentive-driven: resource pools have bounded size and operators have an incentive to pledge all the resources they can afford into the smallest number of pools possible. In particular, whale resource holders are incentivized to keep their leverage low. The benefit of the approach is that high engagement is reinforced, while leverage is kept in control by incentivizing the community to (i) pledge as much as possible, (ii) use all the remaining unpledged resources as part of a crowdsourced filtering mechanism. This translates stake to voting power and supports exactly those operators that materially contribute to the system’s goals the most.\n\nThe above systematization puts into perspective the choices that we have made in the design of the reward-sharing scheme used in Cardano vis-a-vis other systems. In summary, what the Cardano reward system achieves is to materially promote with incentives and community stake-based voting the best possible outcome: *low leverage and high engagement*. And this is accomplished, while still allowing for a very high degree of heterogeneity in terms of input behavior from the stakeholders.\n\nAs a final point, it is important to stress that while considerable progress has been made since the introduction of the Bitcoin blockchain, research in reward sharing for collaborative projects is still an extremely active and growing domain. Our team continuously evaluates various aspects of reward-sharing schemes and actively explores the whole design space in a first-principles manner. In this way, we can ensure that any research advances will be disseminated widely for the benefit of the whole community.\n\n*I am grateful to Christian Badertscher, Sandro Coretti-Drayton, Matthias Fitzi, and Peter Gaži, for their help in the review of other systems and their placement in the systematization of this article.*',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Blockchain reward sharing - a comparative systematization from first principles',
                                subtitle: 'Navigating the diverse landscape of reward-sharing schemes and the choices we have made in the design of Cardano’s reward-sharing scheme',
                                audio: 'https://ucarecdn.com/7ad17830-600c-4313-b55a-751d0149f93a/',
                                soundcloud: null,
                                body_content: 'In the previous article, we identified the [objectives of the reward scheme in Cardano](https://iohk.io/en/blog/posts/2020/11/13/the-general-perspective-on-staking-in-cardano/), and we gave general guidelines regarding engaging with the system.\n\nTaking a more high-level view, we will examine from first principles, the general problem of reward sharing in blockchain systems. To recall, the two overarching objectives of any *resource-based* consensus system is to incentivize the following.\n\n**High engagement**. Resource-based consensus protocols are more secure the more resources are engaged with protocol maintenance. The problem, of course, is that the underlying resources are useful for a wide variety of other things too (e.g., electricity and computational power in the case of proof of work, **or stake for engaging in decentralized apps** in the case of proof of stake), so resource holders should be incentivized to commit resources for protocol maintenance.\n\n**Low leverage**: leverage relates to decentralization. Take a group of 10 people; if there is a leader and the group follows the leader’s wishes all the time, the leader’s leverage is 10 while everyone else’s is zero. If, on the other hand, everyone’s opinion matters the same, everyone’s leverage is 1. These are two extremes, but it should be fairly obvious what types of leverage align better with decentralization. From an economic viewpoint, however, a “benevolent dictatorship” is always more efficient; as a result, decentralization will come at a cost (exactly as democracy does), and hence it has to be also properly incentivized.  \n\nGiven the above objectives, let us now examine some approaches that have been considered in consensus systems and systematize them in terms of how they address the above objectives. An important first categorization we will introduce is between unimodal and multimodal reward schemes.\n\n## Unimodal\n\nIn a unimodal scheme, there is only one way to engage in the consensus protocol with your resources. We examine two sub-categories of unimodal schemes. \n\n1. **Linear Unimodal**\n\nThis is the simplest approach and is followed by many systems, notably Bitcoin; the original proof-of-work based Ethereum, as well as Algorand. The idea is simple: if an entity commands x% resources, then the system will attempt to provide x% of the rewards – at least in expectation. This might seem fair—until one observes the serious downsides that come with it. \n\nFirst, consider that someone has x% of resources and that x% of the rewards in expectation are below their individual cost to operate as a node. Then, they will either not engage (lowering the engagement rate of the system), or, more likely, actively seek others to combine resources and create a node. Even if there are two resource holders with x% of resources each and a viable individual cost *c* when running as separate nodes, they will fare better by combining resources into a single node of 2x% resources because the resulting cost will be typically less than *2c*. This can result in a strong trend to centralize, and lead to high leverage since the combined pool of resources will be (typically) run by one entity. \n\nIn practice, a single dictatorially operated node is unlikely to emerge. This is due to various reasons such as friction in coordination between parties, fear of the potential drop in the exchange rate of the system’s underlying token if the centralization trend becomes noticeable, as well as the occasional use of complex protocols to jointly run pools. Even so, it is clear that unimodal linear rewards can hurt decentralization. \n\nOne does not need to go much further than looking at Bitcoin and its current, fairly centralized, mining pool lineup. It is worth noting that if stake (rather than hashing power) is used as a resource, the centralization pressure will be less – since the expenditure to operate a node is smaller. But the same problems apply in principle. \n\nAn additional disadvantage of the above setting is that the ensuing “off-chain” resource pooling that occurs will be completely opaque from the ledger perspective, and hence more difficult for the community to monitor and react to. In summary, the linear unimodal approach has the advantage of being simple, but is precarious, both in terms of increasing engagement and for keeping leverage low. \n\n2. **Quantized Linear Unimodal**\n\nThis approach is the same as the linear rewards approach, but it quantizes the underlying resource. I.e., if your resources are below a certain threshold, you may be completely unable to participate; you can only participate in fixed quanta. Notably, this approach is taken in [ETH2.0, where 32 Ether](https://blog.ethereum.org/2019/11/27/validated-staking-on-eth2-0/) should be pledged in order to acquire a validator identity. It should be clear that this quantized approach shares the same problems with the linear unimodal approach in terms of participation and leverage. Despite this, it has been considered for two primary reasons. First, using the quantized approach enables one to retrofit traditional BFT-style protocol design elements (e.g. that require counting identities) in a resource-based consensus setting. The resulting system is less elegant than true resource-based consensus but this is unavoidable since traditional BFT-style protocols do not work very well when there are more than a few hundred nodes involved. The second reason, specific to the proof-of-stake setting, is seeking to impose penalties on participants as a means of ensuring compliance with the protocol. Imposing quantized collateral pledges makes penalties for protocol infractions more substantial and painful.\n\n## Multimodal\n\nWe next turn to multimodal schemes. This broad category includes Cosmos, Tezos, Polkadot & EOS.  It also includes Cardano. In a multimodal scheme, a resource holder may take different roles in the protocol; being a fully active node in the consensus protocol is just one of the options. The advantage of a multimodal scheme is that offering multiple ways to engage (with correspondingly different rates of return) within the protocol itself can accommodate a higher engagement, as well as limit off-chain resource pooling. For instance, if the potential rewards received by an individual when they engage with all their resources sit below their operational cost of running a node,  they can still choose to engage by a different mode in the protocol. In this way, the tendency to combine resources off-chain is eased and the system – if designed properly – may translate this higher engagement to increased resilience. \n\nWe will distinguish between a number of different multimodal schemes.\n\n* **Representative bimodal without leverage control.** The representative approach is inspired by [representative democracy](https://en.wikipedia.org/wiki/Representative_democracy): the system is run by a number of elected operators. The approach is bimodal as it enables parties to (1) advertise themselves as operators in the ledger and/or (2) “vote” for operators with their resources. The set of representative operators has a fixed size and is updated on a rolling basis typically with fixed terms using some election function that selects representatives based on the votes they received. Rewards are distributed evenly between representatives, possibly taking into account performance data and adjusting accordingly. Allowing rewards to flow to voters using a smart contract can incentivize higher engagement in voting since resource holders get paid for voting for good representatives (note that this is not necessarily followed by all schemes in this category). The disadvantage of this approach is the lack of leverage control, beyond,  possibly, the existence of a very large upper bound, which suggests that the system may end up with a set of very highly leveraged operators. This is the approach that is broadly followed by Cosmos,  EOS, and Polkadot.\n\nA different approach to the representative approach is the *delegative* approach. In general, this approach is closer to direct democracy as it allows resource holders the option to engage directly with the protocol with the resources they have. However, they are free to also delegate their resources to others as in [liquid (or delegative) democracy](https://en.wikipedia.org/wiki/Liquid_democracy) (where the term delegative is derived from). This results in a community-selected operator configuration that does not have a predetermined number of representatives. As in the representative approach, user engagement is bimodal. Resource holders can advertise themselves as operators and/or delegate their resources to existing operators. The rewards provided are proportional to the amount of delegated resources and delegates can be paid via an on-chain smart contract, perhaps at various different rates. Within the delegative approach we will further distinguish two subcategories.\n\n* **Delegative bimodal with pledge-based capped rewards.** What typifies this particular delegative approach is that the resource pool’s rewards have a bound that is determined by the amount of pledge that is committed to the pool by its operator. In this way, the total leverage of an operator can be controlled and fixed to a constant. Unfortunately, this leverage control feature has the negative side effect of implicitly imposing the same bound to all, small and large resource holders. So, on the one hand, in a population of small resource holders, engagement will be constrained by the little pledge that operators are able to commit. On the other hand, a few large whale resource holders may end up influencing the consensus protocol in a very significant manner, possibly even beyond its security threshold bound. In terms of leverage control, it should be clear that one size does not fit all! From existing systems, this is the approach that is (in essence) followed by Tezos. \n\nIt is worth noting that all the specific approaches we have seen so far come with downsides – either in terms of maximizing engagement, controlling leverage, or both. With this in mind, let us now fit into our systematization, the approach of the reward-sharing scheme that we are using in Cardano. \n\n* **Delegative bimodal with capped rewards and incentivized pledging.** In this delegative system (introduced in our [reward-sharing scheme](https://arxiv.org/abs/1807.11218) paper), the rewards that are provided to each pool follow a piecewise function on the pool’s size. The function is initially monotonically increasing and then becomes constant at a certain “cap” level which is a configurable system parameter (in Cardano this is determined by the parameter *k*). This cap limits the incentives to grow individual resource pools. At the same time, pledging resources to a pool is *incentivized* with higher pledged pools receiving more rewards. As a result, lowering one’s leverage becomes incentive-driven: resource pools have bounded size and operators have an incentive to pledge all the resources they can afford into the smallest number of pools possible. In particular, whale resource holders are incentivized to keep their leverage low. The benefit of the approach is that high engagement is reinforced, while leverage is kept in control by incentivizing the community to (i) pledge as much as possible, (ii) use all the remaining unpledged resources as part of a crowdsourced filtering mechanism. This translates stake to voting power and supports exactly those operators that materially contribute to the system’s goals the most.\n\nThe above systematization puts into perspective the choices that we have made in the design of the reward-sharing scheme used in Cardano vis-a-vis other systems. In summary, what the Cardano reward system achieves is to materially promote with incentives and community stake-based voting the best possible outcome: *low leverage and high engagement*. And this is accomplished, while still allowing for a very high degree of heterogeneity in terms of input behavior from the stakeholders.\n\nAs a final point, it is important to stress that while considerable progress has been made since the introduction of the Bitcoin blockchain, research in reward sharing for collaborative projects is still an extremely active and growing domain. Our team continuously evaluates various aspects of reward-sharing schemes and actively explores the whole design space in a first-principles manner. In this way, we can ensure that any research advances will be disseminated widely for the benefit of the whole community.\n\n*I am grateful to Christian Badertscher, Sandro Coretti-Drayton, Matthias Fitzi, and Peter Gaži, for their help in the review of other systems and their placement in the systematization of this article.*',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'blockchain-reward-sharing-a-comparative-systematization-from-first-principles',
                                url: '/blog/posts/2020/11/30/blockchain-reward-sharing-a-comparative-systematization-from-first-principles/',
                                read_time: 10
                            },
                            {
                                publish_date: '2020-11-13T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/11b8ba18-b116-4f00-9c34-0c4ea1554f73/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'The general perspective on staking in Cardano',
                                        subtitle: 'Advice for Stakeholders - Delegators and Stake Pool Operators.',
                                        audio: 'https://ucarecdn.com/9fba0645-fb60-4d88-8dc2-148c2d7b0f64/Aggelosblog13Sept.mp3',
                                        soundcloud: null,
                                        body_content: 'As a project, decentralization remains arguably our most important and fundamental goal for Cardano. Protocols and parameters provide the foundations for any blockchain. Last week, we outlined some of the planned [changes around Cardano parameters](https://iohk.io/en/blog/posts/2020/11/05/parameters-and-decentralization-the-way-ahead/) and how these will impact the staking ecosystem and thus accelerate our decentralization mission.\n\nYet the community itself – how it sees itself, how it behaves, and how it sets common standards – is a key factor in the pace of this success. Cardano has been very carefully engineered to provide “by design” all the necessary properties for a blockchain system to operate successfully. However, Cardano is also a *social* construct, and as such, observance, interpretation, and social norms play a crucial role in shaping its resilience and longevity.\n\nSo in anticipation of the *k*-parameter adjustment on December 6th, I would like to give a broader perspective on staking, highlighting some of the innovative features of the [rewards sharing scheme](https://arxiv.org/abs/1807.11218) used in Cardano. \n\n### Principles & practical intent\n\nAs well as outlining some of the key principles, this piece has a clear practical intent; to provide guidance and some recommendations to stakeholders so that they engage meaningfully with the mechanism, and support the project’s longer-term strategic goals through their actions.\n\nConsensus based on a *resource* that is dispersed somehow across a population of users – as opposed to identity-based participation – has been the hallmark of the blockchain space since the launch of the Bitcoin blockchain. In this domain, proof-of-stake systems are distinguished in the sense that they use a virtual resource, *stake*, which is recorded in the blockchain itself. \n\nPooling resources for participation is something that is inevitable; some level of pooling is typically beneficial in the economic sense and hence resource holders will find a way to make it happen. Given this inevitability, the question arises: how does a system prevent a dictatorship or an oligarchy from emerging?\n\n### The objectives of the reward sharing scheme\n\nContrary to other blockchain systems, Cardano uses a reward sharing scheme that (1) facilitates staking with *minimum friction as well* as (2) it incentivizes pooling resources in a way that *system-wide decentralization* emerges naturally from the rational engagement of the resource holders.\n\nThe mechanism has the following two broad objectives:\n\n1. **Engage *all* stakeholders** - This is important since the more stakeholders are engaged in the system, the more *secure* the distributed ledger will be. This also means that the system should have no barriers for participation, nor should impose friction by requiring off-chain coordination between stakeholders to engage with the mechanism. \n2. **Keep the leverage of individual stakeholders low** -. Pooling resources leads to increased leverage for some stakeholders. Pool operators exert an influence in the system proportional to the resources controlled by their pool, *not to their own* resources. Without pooling, all resource holders have leverage of exactly 1; contrast this e.g., to a pool operator, owning, say 100K ada, who controls a pool of total delegated stake of 200M ada; that operator has leverage of 2,000. The higher the leverage of the system, the worse its security (to see this, consider that with leverage above 50, launching a 51% attack requires a mere 1% of the total resources!).\n\nIt should also be stressed that a disproportionately large pool size is not the only reason for increased leverage; stakeholders creating multiple pools, either openly or covertly (what is known as a Sybil attack) can also lead to increased leverage. The lower the leverage of a blockchain system, the higher its degree of decentralization.\n\n### Putting this into practice\n\nSo how does the reward sharing scheme used in Cardano meet the above objectives? Staking via our scheme facilitates two different paths: *pledging* and *delegating*. Pledging applies to stake pool operators; pledged stake is committed to a stake pool and is supposed to stay put for as long as the pool is operating. Think of pledge as a ‘commitment’ to the network – ‘locking up’ a certain amount of stake in order to help safeguard and secure the protocol. Delegating on the other hand, is for those who do not wish to be involved as operators. Instead, they are invited to assess the offerings the stake pool operators provide, and delegate their stake to one or more pools that, in their opinion, best serve their interests and the interest of the community at large. Given that delegation does not require locking up funds, there is no reason to abstain from staking in Cardano; all stakeholders can and are encouraged to engage in staking.\n\nCentral to the mechanism’s behavior are two parameters: *k* and a0. The k-parameter caps the rewards of pools to 1/*k* of the total available. The a0 parameter creates a benefit for pledging more stake into a single pool; adding X amount of pledge to a pool increases its rewards additively by up to a0*X. This is not to the detriment of other pools; any rewards left unclaimed due to insufficient pledging will be returned to the Cardano’s reserves and allocated in the future. \n\nBeyond deciding on an amount to pledge, creating a stake pool requires that  operators declare their profit margin and operational costs. When the pool rewards are allocated at the end of each epoch, the operational costs are withheld first, ensuring that stake pools remain viable. Subsequently, operator profit is calculated, and all pool delegators are rewarded in ada proportional to their stake afterwards. \n\nPaired with the assessment of stake pools performed by the delegates, this mechanism provides the right set of constraints for the system to converge to a configuration of *k* equal size pools with the maximum amount of pledge possible. The equilibrium point has the property that delegator rewards are equalized (so it doesn’t matter what pool they delegate to!), while stake pool operators are rewarded appropriately for their performance, their cost efficiency, and their general contributions to the ecosystem.\n\nFor the above to happen, it is necessary to engage with the mechanism in a meaningful and rational manner. To assist stakeholders in understanding the mechanism, here are some points of advice. \n\n### Guidance for delegators\n\n1. **Know your pool(s)** - Investigate the pools’ available data and information. What is the operators’ web-presence? What kind of information do they provide about their operation? Are they descriptive about their costs? Are the costs reasonably based on geographic location and other aspects of their operation? Do they update their costs regularly to account for the fluctuation of ada? Do they include the costs for their personal time? Remember that maintaining a high-performance pool requires commitment and effort, so those committed operators deserve compensation. \n\n\n2. **Think bigger** - Consider your choice holistically, not based on just a single dimension. Consider the longer term value your choices bring to the network.  Think of your delegation as a ‘vote of confidence’, or a way to show your support to a pool\'s mission or goals. Opt for professionalism and demonstrated long-term commitment to the system’s goals. Recognize community members who have been helping to lay down the foundations for the ecosystem, either with their community presence or by helping to build things. The long-term wellbeing of the ecosystem is crucially affected by your delegation choice. A more decentralized network is a more resilient and long-lived network. \n3. **Be wary of ‘pool splitters’** - Pool operators that run multiple pools *with small pledge* ***hurt delegators and smaller operators***. They hurt their delegators because they could have provided a higher amount of rewards by concentrating their pledge into a single pool; by not doing that, there are rewards that remain unclaimed. They hurt smaller and new operators, because they are forcing them to remain without delegates and hence making their operation unviable – without delegates a pool may be forced to close. So avoid pool operators that run multiple pools with pledge below saturation level. Note there are legitimate reasons for large stakeholders to accept delegators and run a public pool (e.g., they are delegating some of their stake to other pools to support the community); consult any public statements such operators make about their delegation strategy and their leverage. It is ok to delegate to them, assuming they keep their leverage low and they support the community. \n4. **Be wary of highly leveraged operators** - Be mindful of the stake pool operators’ *leverage* (see below for more details on how to calculate leverage). A higher pledge is correlated to less leverage when comparing pools of the same size; a high leverage is indicative of a stake pool operator with very little “skin in the game.” Stake pool operators may prove to have skin in the game in other ways than pledging stake of course; e.g., they can be very professional and contribute to the community in different ways. You should be the judge of this: high leverage in itself is not a reason to avoid delegating to a particular pool, but it is a *strong* indication that you should proceed with caution and carefully evaluate the people behind the operation. \n5. **Shop around** - Do take into account the information provided from your wallet software (or from recognized community resources such as [adapools](https://adapools.org/) or [pooltool](https://pooltool.io/)) in terms of the pool’s ranking and its performance factor.  Remember though, while the ranking is important, it should not be the sole factor behind your delegation choice. Think holistically – you may want to consider pools fulfilling a mission you agree with, or trying to add value to the wider community through podcasts or social activity, even if they do not offer the highest possible returns.\n6. **Be involved** - A pool with no performance data on display may have attractive characteristics; it could be providing better rewards in the best case scenario, but also high risk as a delegation choice since its performance may turn out to be suboptimal. Delegate according to your ‘risk profile’, and the frequency you are willing to re-delegate your stake. Do check the pool’s performance and updates regularly to ensure that your choice and assessment remains the best possible. \n\n### Guidance for pool operators\n\n1. **Be transparent** - Choose your pool’s operational cost as accurately as possible. Do include the personal effort (priced at a reasonable rate) that you and your partners put into the pool operation! You are a pillar of Cardano and so you have every right to be compensated by the community. Be upfront about your costs and include them in your pool’s website. Educate your prospective delegates about where the pool costs are going. Always remember that it is important to charge for the time you invest in maintaining your pool. In the short term, you may be prepared to invest your time and energy ‘for free’ (or after hosting costs, at an effective loss) but remember that this is not a sustainable model for the network over the medium and longer term. \n2. **Don’t split your pool** - With the coming changes in *k* (commencing with the move to k=500 on 6th December), we are already seeing pool operators splitting their pools in order to retain delegators without becoming saturated. Do not engage in pool splitting unless you can saturate a pool completely with your stake. If you are a whale (relative stake > 1/*k*) you can create multiple pools – but you should keep your leverage as close to 1 as possible or less. Pool splitting that increases your leverage hurts the delegators’ rewards, and more importantly, it hurts the decentralization of the Cardano ecosystem, which is detrimental to everyone. If you run and control multiple pools under different tickers, make a public statement about it. Explain the steps you take to control your leverage. Creating multiple pools while trying to conceal the fact that you control them is akin to a Sybil attack against Cardano. This behavior should be condemned by the community. You can calculate and publicize your leverage using the following formula:\n\n   ![](https://ucarecdn.com/dc5b9d2a-1786-44bd-b261-e471e93afeba/)\n\nExchanges are a special kind of whale stakeholder, since they collectively  manage other people’s stake. One strategy for an exchange is to avoid leverage altogether and delegate the stake they control to community pools. If an exchange becomes a pool operator, they can maintain their leverage below 1 by using a mixed pledging and delegation strategy. \n\n3. **Set your profit margin wisely** - Select the margin to make your pool competitive. Remember that if everyone delegates their stake and is rational, you only have to beat the (*k*+1)-th pool in the rankings offered by the Daedalus wallet. If your pool offers other advantages that can attract delegation (e.g., you are contributing to a charitable cause you feel others may wish to support), or you have acquired exceptional equipment that promises notable uptime/performance, make sure you promote this widely. When you offer such benefits, you should consider setting a higher profit margin. \n\n\n4. **Keep your pool data updated** - Regularly update the cost and margin to accommodate fluctuations in ada price. Give assurances to your delegators and update them about the stake pool operational details. In case of mishaps and downtimes, be upfront and inform your delegators via your website and/or other communication channels you maintain with them. \n5. **Pledge as much as you are able to** - Increase the amount of pledge as much as you comfortably can and not more. Beyond using your own stake, you can also partner with other stakeholders to increase the pledge of your pool. A high pledge signals long-term commitment and reduced leverage, and it unlocks additional rewards every epoch as dictated by the a0 term in the rewards sharing scheme calculation. As a result, it does make your pool more desirable to prospective delegators. On the other hand, remember that pledge is not the only factor that makes a pool attractive. Spend time on your web and social media presence and be sure to advertise all the ways that you contribute to the Cardano ecosystem. \n\nIf you are a Cardano stakeholder, we hope that you find the above advice informative and helpful in your efforts to engage in staking. As in many other respects, Cardano brings a novel and heavily researched mechanism to its blockchain design. The rewards scheme is mathematically proven to offer an equilibrium that meets the set of objectives set out in the beginning of this document. Ultimately though, the math is not enough; it is *only the people* that can make it happen. \n\nCardano’s future is in the hands of the community. \n\n*The opinions expressed in the blogpost are for educational purposes only and are not intended to provide any form of financial advice.*',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'The general perspective on staking in Cardano',
                                subtitle: 'Advice for Stakeholders - Delegators and Stake Pool Operators.',
                                audio: 'https://ucarecdn.com/9fba0645-fb60-4d88-8dc2-148c2d7b0f64/Aggelosblog13Sept.mp3',
                                soundcloud: null,
                                body_content: 'As a project, decentralization remains arguably our most important and fundamental goal for Cardano. Protocols and parameters provide the foundations for any blockchain. Last week, we outlined some of the planned [changes around Cardano parameters](https://iohk.io/en/blog/posts/2020/11/05/parameters-and-decentralization-the-way-ahead/) and how these will impact the staking ecosystem and thus accelerate our decentralization mission.\n\nYet the community itself – how it sees itself, how it behaves, and how it sets common standards – is a key factor in the pace of this success. Cardano has been very carefully engineered to provide “by design” all the necessary properties for a blockchain system to operate successfully. However, Cardano is also a *social* construct, and as such, observance, interpretation, and social norms play a crucial role in shaping its resilience and longevity.\n\nSo in anticipation of the *k*-parameter adjustment on December 6th, I would like to give a broader perspective on staking, highlighting some of the innovative features of the [rewards sharing scheme](https://arxiv.org/abs/1807.11218) used in Cardano. \n\n### Principles & practical intent\n\nAs well as outlining some of the key principles, this piece has a clear practical intent; to provide guidance and some recommendations to stakeholders so that they engage meaningfully with the mechanism, and support the project’s longer-term strategic goals through their actions.\n\nConsensus based on a *resource* that is dispersed somehow across a population of users – as opposed to identity-based participation – has been the hallmark of the blockchain space since the launch of the Bitcoin blockchain. In this domain, proof-of-stake systems are distinguished in the sense that they use a virtual resource, *stake*, which is recorded in the blockchain itself. \n\nPooling resources for participation is something that is inevitable; some level of pooling is typically beneficial in the economic sense and hence resource holders will find a way to make it happen. Given this inevitability, the question arises: how does a system prevent a dictatorship or an oligarchy from emerging?\n\n### The objectives of the reward sharing scheme\n\nContrary to other blockchain systems, Cardano uses a reward sharing scheme that (1) facilitates staking with *minimum friction as well* as (2) it incentivizes pooling resources in a way that *system-wide decentralization* emerges naturally from the rational engagement of the resource holders.\n\nThe mechanism has the following two broad objectives:\n\n1. **Engage *all* stakeholders** - This is important since the more stakeholders are engaged in the system, the more *secure* the distributed ledger will be. This also means that the system should have no barriers for participation, nor should impose friction by requiring off-chain coordination between stakeholders to engage with the mechanism. \n2. **Keep the leverage of individual stakeholders low** -. Pooling resources leads to increased leverage for some stakeholders. Pool operators exert an influence in the system proportional to the resources controlled by their pool, *not to their own* resources. Without pooling, all resource holders have leverage of exactly 1; contrast this e.g., to a pool operator, owning, say 100K ada, who controls a pool of total delegated stake of 200M ada; that operator has leverage of 2,000. The higher the leverage of the system, the worse its security (to see this, consider that with leverage above 50, launching a 51% attack requires a mere 1% of the total resources!).\n\nIt should also be stressed that a disproportionately large pool size is not the only reason for increased leverage; stakeholders creating multiple pools, either openly or covertly (what is known as a Sybil attack) can also lead to increased leverage. The lower the leverage of a blockchain system, the higher its degree of decentralization.\n\n### Putting this into practice\n\nSo how does the reward sharing scheme used in Cardano meet the above objectives? Staking via our scheme facilitates two different paths: *pledging* and *delegating*. Pledging applies to stake pool operators; pledged stake is committed to a stake pool and is supposed to stay put for as long as the pool is operating. Think of pledge as a ‘commitment’ to the network – ‘locking up’ a certain amount of stake in order to help safeguard and secure the protocol. Delegating on the other hand, is for those who do not wish to be involved as operators. Instead, they are invited to assess the offerings the stake pool operators provide, and delegate their stake to one or more pools that, in their opinion, best serve their interests and the interest of the community at large. Given that delegation does not require locking up funds, there is no reason to abstain from staking in Cardano; all stakeholders can and are encouraged to engage in staking.\n\nCentral to the mechanism’s behavior are two parameters: *k* and a0. The k-parameter caps the rewards of pools to 1/*k* of the total available. The a0 parameter creates a benefit for pledging more stake into a single pool; adding X amount of pledge to a pool increases its rewards additively by up to a0*X. This is not to the detriment of other pools; any rewards left unclaimed due to insufficient pledging will be returned to the Cardano’s reserves and allocated in the future. \n\nBeyond deciding on an amount to pledge, creating a stake pool requires that  operators declare their profit margin and operational costs. When the pool rewards are allocated at the end of each epoch, the operational costs are withheld first, ensuring that stake pools remain viable. Subsequently, operator profit is calculated, and all pool delegators are rewarded in ada proportional to their stake afterwards. \n\nPaired with the assessment of stake pools performed by the delegates, this mechanism provides the right set of constraints for the system to converge to a configuration of *k* equal size pools with the maximum amount of pledge possible. The equilibrium point has the property that delegator rewards are equalized (so it doesn’t matter what pool they delegate to!), while stake pool operators are rewarded appropriately for their performance, their cost efficiency, and their general contributions to the ecosystem.\n\nFor the above to happen, it is necessary to engage with the mechanism in a meaningful and rational manner. To assist stakeholders in understanding the mechanism, here are some points of advice. \n\n### Guidance for delegators\n\n1. **Know your pool(s)** - Investigate the pools’ available data and information. What is the operators’ web-presence? What kind of information do they provide about their operation? Are they descriptive about their costs? Are the costs reasonably based on geographic location and other aspects of their operation? Do they update their costs regularly to account for the fluctuation of ada? Do they include the costs for their personal time? Remember that maintaining a high-performance pool requires commitment and effort, so those committed operators deserve compensation. \n\n\n2. **Think bigger** - Consider your choice holistically, not based on just a single dimension. Consider the longer term value your choices bring to the network.  Think of your delegation as a ‘vote of confidence’, or a way to show your support to a pool\'s mission or goals. Opt for professionalism and demonstrated long-term commitment to the system’s goals. Recognize community members who have been helping to lay down the foundations for the ecosystem, either with their community presence or by helping to build things. The long-term wellbeing of the ecosystem is crucially affected by your delegation choice. A more decentralized network is a more resilient and long-lived network. \n3. **Be wary of ‘pool splitters’** - Pool operators that run multiple pools *with small pledge* ***hurt delegators and smaller operators***. They hurt their delegators because they could have provided a higher amount of rewards by concentrating their pledge into a single pool; by not doing that, there are rewards that remain unclaimed. They hurt smaller and new operators, because they are forcing them to remain without delegates and hence making their operation unviable – without delegates a pool may be forced to close. So avoid pool operators that run multiple pools with pledge below saturation level. Note there are legitimate reasons for large stakeholders to accept delegators and run a public pool (e.g., they are delegating some of their stake to other pools to support the community); consult any public statements such operators make about their delegation strategy and their leverage. It is ok to delegate to them, assuming they keep their leverage low and they support the community. \n4. **Be wary of highly leveraged operators** - Be mindful of the stake pool operators’ *leverage* (see below for more details on how to calculate leverage). A higher pledge is correlated to less leverage when comparing pools of the same size; a high leverage is indicative of a stake pool operator with very little “skin in the game.” Stake pool operators may prove to have skin in the game in other ways than pledging stake of course; e.g., they can be very professional and contribute to the community in different ways. You should be the judge of this: high leverage in itself is not a reason to avoid delegating to a particular pool, but it is a *strong* indication that you should proceed with caution and carefully evaluate the people behind the operation. \n5. **Shop around** - Do take into account the information provided from your wallet software (or from recognized community resources such as [adapools](https://adapools.org/) or [pooltool](https://pooltool.io/)) in terms of the pool’s ranking and its performance factor.  Remember though, while the ranking is important, it should not be the sole factor behind your delegation choice. Think holistically – you may want to consider pools fulfilling a mission you agree with, or trying to add value to the wider community through podcasts or social activity, even if they do not offer the highest possible returns.\n6. **Be involved** - A pool with no performance data on display may have attractive characteristics; it could be providing better rewards in the best case scenario, but also high risk as a delegation choice since its performance may turn out to be suboptimal. Delegate according to your ‘risk profile’, and the frequency you are willing to re-delegate your stake. Do check the pool’s performance and updates regularly to ensure that your choice and assessment remains the best possible. \n\n### Guidance for pool operators\n\n1. **Be transparent** - Choose your pool’s operational cost as accurately as possible. Do include the personal effort (priced at a reasonable rate) that you and your partners put into the pool operation! You are a pillar of Cardano and so you have every right to be compensated by the community. Be upfront about your costs and include them in your pool’s website. Educate your prospective delegates about where the pool costs are going. Always remember that it is important to charge for the time you invest in maintaining your pool. In the short term, you may be prepared to invest your time and energy ‘for free’ (or after hosting costs, at an effective loss) but remember that this is not a sustainable model for the network over the medium and longer term. \n2. **Don’t split your pool** - With the coming changes in *k* (commencing with the move to k=500 on 6th December), we are already seeing pool operators splitting their pools in order to retain delegators without becoming saturated. Do not engage in pool splitting unless you can saturate a pool completely with your stake. If you are a whale (relative stake > 1/*k*) you can create multiple pools – but you should keep your leverage as close to 1 as possible or less. Pool splitting that increases your leverage hurts the delegators’ rewards, and more importantly, it hurts the decentralization of the Cardano ecosystem, which is detrimental to everyone. If you run and control multiple pools under different tickers, make a public statement about it. Explain the steps you take to control your leverage. Creating multiple pools while trying to conceal the fact that you control them is akin to a Sybil attack against Cardano. This behavior should be condemned by the community. You can calculate and publicize your leverage using the following formula:\n\n   ![](https://ucarecdn.com/dc5b9d2a-1786-44bd-b261-e471e93afeba/)\n\nExchanges are a special kind of whale stakeholder, since they collectively  manage other people’s stake. One strategy for an exchange is to avoid leverage altogether and delegate the stake they control to community pools. If an exchange becomes a pool operator, they can maintain their leverage below 1 by using a mixed pledging and delegation strategy. \n\n3. **Set your profit margin wisely** - Select the margin to make your pool competitive. Remember that if everyone delegates their stake and is rational, you only have to beat the (*k*+1)-th pool in the rankings offered by the Daedalus wallet. If your pool offers other advantages that can attract delegation (e.g., you are contributing to a charitable cause you feel others may wish to support), or you have acquired exceptional equipment that promises notable uptime/performance, make sure you promote this widely. When you offer such benefits, you should consider setting a higher profit margin. \n\n\n4. **Keep your pool data updated** - Regularly update the cost and margin to accommodate fluctuations in ada price. Give assurances to your delegators and update them about the stake pool operational details. In case of mishaps and downtimes, be upfront and inform your delegators via your website and/or other communication channels you maintain with them. \n5. **Pledge as much as you are able to** - Increase the amount of pledge as much as you comfortably can and not more. Beyond using your own stake, you can also partner with other stakeholders to increase the pledge of your pool. A high pledge signals long-term commitment and reduced leverage, and it unlocks additional rewards every epoch as dictated by the a0 term in the rewards sharing scheme calculation. As a result, it does make your pool more desirable to prospective delegators. On the other hand, remember that pledge is not the only factor that makes a pool attractive. Spend time on your web and social media presence and be sure to advertise all the ways that you contribute to the Cardano ecosystem. \n\nIf you are a Cardano stakeholder, we hope that you find the above advice informative and helpful in your efforts to engage in staking. As in many other respects, Cardano brings a novel and heavily researched mechanism to its blockchain design. The rewards scheme is mathematically proven to offer an equilibrium that meets the set of objectives set out in the beginning of this document. Ultimately though, the math is not enough; it is *only the people* that can make it happen. \n\nCardano’s future is in the hands of the community. \n\n*The opinions expressed in the blogpost are for educational purposes only and are not intended to provide any form of financial advice.*',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'the-general-perspective-on-staking-in-cardano',
                                url: '/blog/posts/2020/11/13/the-general-perspective-on-staking-in-cardano/',
                                read_time: 13
                            },
                            {
                                publish_date: '2020-06-23T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/3dd87ee7-829f-4c0d-8941-d9cec23cc27f/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'The Ouroboros path to decentralization',
                                        subtitle: 'The protocol that powers Cardano and its design philosophy',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'Designing and deploying a distributed ledger is a technically challenging task. What is expected of a ledger is the promise of a consistent view to all participants as well as a guarantee of responsiveness to the continuous flow of events that result from their actions. These two properties, sometimes referred to as *persistence* and *liveness*, are the hallmark of distributed ledger systems.\n\nAchieving persistence and liveness in a centralized system is a well-studied and fairly straightforward task; unfortunately, the ledger that emerges is precariously brittle because the server that supports the ledger becomes a single point of failure. As a result, hacking the server can lead to the instant violation of both properties. Even if the server is not hacked, the interests of the server’s operators may not align with the continuous assurance of these properties. For this reason, *decentralization* has been advanced as an essential remedy.\n\nInformally, decentralization refers to a system architecture that calls for many entities to act individually in such a way that the ledger’s properties emerge from the convergence of their actions. In exchange for this increase in complexity, a well-designed system can continue to function even if some parties deviate from proper operation. Moreover, in the case of more significant deviations, even if some disruption is unavoidable, the system should still be capable of returning to normal operation and contain the damage.\n\nHow does one design a robust decentralized system? The world is a complicated place and decentralization is not a characteristic that can be hard-coded or demonstrated via testing – the potential configurations that might arise are infinite. To counter this, one must develop *models* that systematically encompass all the different threats the system may encounter and demonstrate rigorously that the two basic properties of persistence and liveness are upheld.\n\nThe strongest arguments for the reliability of a decentralized system combine formal guarantees against a broad portfolio of different classes of failure and attack models. The first important class is that of powerful Byzantine models. In this setting, it should be guaranteed that even if a subset of participants *arbitrarily* deviate from the rules, the two fundamental properties are retained. The second important class is models of rationality. Here, participants are assumed to be *rational utility maximizers* and the objective is to show that the ledger properties arise from their efforts to pursue their self interest.\n\nOuroboros is a decentralized ledger protocol that is analyzed in the context of both Byzantine and rational behavior. What makes the protocol unique is the combination of the following design elements.\n\n* It uses **stake** as the fundamental resource to identify the participants’ leverage in the system. No physical resource is wasted in the process of ledger maintenance, which is shown to be robust despite ‘costless simulation’ and ‘nothing at stake’ attacks that were previously thought to be fundamental barriers to stake-based ledgers. This makes Ouroboros distinctly more appealing than proof-of-work protocols, which require prodigious energy expenditure to maintain consensus.\n* It is proven to be resilient even if arbitrarily large subsets of participants, in terms of stake, abstain from ledger maintenance. This guarantee of **dynamic availability** ensures liveness even under arbitrary, and unpredictable, levels of engagement. At the same time, of those participants who are active, barely more than half need to follow the protocol – the rest can arbitrarily deviate; in fact, even temporary spikes above the 50% threshold can be tolerated. Thus Ouroboros is distinctly more resilient and adaptable than classical Byzantine fault tolerance protocols (as well as all their modern adaptations), which have to predict with relative certainty the level of expected participation and may stop operating when the prediction is false.\n* The process of joining and participating in the protocol execution is **trustless** in the sense that it does not require the availability of any special shared resource such as a recent checkpoint or a common clock. Engaging in the protocol requires merely the public genesis block of the chain, and access to the network. This makes Ouroboros free of the trust assumptions common in other consensus protocols whose security collapses when trusted shared resources are subverted or unavailable.\n* Ouroboros incorporates a reward-sharing mechanism to incentivize participants to **organize themselves** in operational nodes, known as stake pools, that can offer a good quality of service independently of how stake is distributed among the user population. In this way, all stakeholders contribute to the system’s operation – ensuring robustness and democratic representation – while the cost of ledger maintenance is efficiently distributed across the user population. At the same time, the mechanism comes with countermeasures that de-incentivize centralization. This makes Ouroboros fundamentally more inclusive and decentralized compared with other protocols that either end up with just a handful of actors responsible for ledger maintenance or provide no incentives to stakeholders to participate and offer a good quality of service.\n\nThese design elements of Ouroboros are not supposed to be self-evident appeals to the common sense of the protocol user. Instead, they were delivered with meticulous documentation in papers that have undergone peer review and appeared in top-tier conferences and publications in the area of cybersecurity and cryptography. Indeed, it is fair to say that no other consensus research effort is represented so comprehensively in these circles. Each paper is explicit about the specific type of model that is used to analyze the protocol and the results derived are laid out in concrete terms. The papers are open-access, patent-free, and include all technical details to allow anyone, with the relevant technical expertise, to convince themselves of the veracity of the claims made about performance, security, and functionality.\n\nBuilding an inclusive, fair and resilient infrastructure for financial and social applications on a global scale is the grand challenge of information technology today. Ouroboros contributes, not just as a protocol with unique characteristics, but also in presenting a design methodology that highlights first principles, careful modeling and rigorous analysis. Its modular and adaptable architecture also lends itself to continuous improvement, adaptation and enrichment with additional elements (such as parallelization to improve scalability or zero-knowledge proofs to improve privacy, to name two examples), which is a befitting characteristic to meet the ever-evolving needs and complexities of the real world.\n\n## Further reading\n\nTo delve deeper into the Ouroboros protocol, from its inception to recent new features, follow these links:\n\n1. [Ouroboros (Classic)](http://ia.cr/2016/889): the first provably secure proof-of-stake blockchain protocol.\n2. [Ouroboros Praos](http://ia.cr/2017/573): removes the need for a rigid round structure and improves resilience against ‘adaptive’ attackers.\n3. [Ouroboros Genesis](https://ia.cr/2018/378): how to avoid the need for a recent checkpoint and prove the protocol is secure under dynamic availability for trustless joining and participating.\n4. [Ouroboros Chronos](http://ia.cr/2019/838): removes the need for a common clock.\n5. [Reward sharing schemes](https://arxiv.org/abs/1807.11218) for stake pools.\n6. [Account management](https://ia.cr/2020/525) and maximizing participation in stake pools.\n7. [Optimizing transaction throughput](http://ia.cr/2020/037) with proof-of-stake protocols.\n8. [Fast settlement](http://ia.cr/2020/675) using ledger combiners.\n9. [Ouroboros Crypsinous](http://ia.cr/2018/1132): a privacy-preserving proof-of-stake protocol.\n10. [Kachina](http://ia.cr/2020/543): a unified security model for private smart contracts.\n11. [Hydra](http://ia.cr/2020/299): an off-chain scalability architecture for high transaction throughput with low latency, and minimal storage per node.',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'The Ouroboros path to decentralization',
                                subtitle: 'The protocol that powers Cardano and its design philosophy',
                                audio: null,
                                soundcloud: null,
                                body_content: 'Designing and deploying a distributed ledger is a technically challenging task. What is expected of a ledger is the promise of a consistent view to all participants as well as a guarantee of responsiveness to the continuous flow of events that result from their actions. These two properties, sometimes referred to as *persistence* and *liveness*, are the hallmark of distributed ledger systems.\n\nAchieving persistence and liveness in a centralized system is a well-studied and fairly straightforward task; unfortunately, the ledger that emerges is precariously brittle because the server that supports the ledger becomes a single point of failure. As a result, hacking the server can lead to the instant violation of both properties. Even if the server is not hacked, the interests of the server’s operators may not align with the continuous assurance of these properties. For this reason, *decentralization* has been advanced as an essential remedy.\n\nInformally, decentralization refers to a system architecture that calls for many entities to act individually in such a way that the ledger’s properties emerge from the convergence of their actions. In exchange for this increase in complexity, a well-designed system can continue to function even if some parties deviate from proper operation. Moreover, in the case of more significant deviations, even if some disruption is unavoidable, the system should still be capable of returning to normal operation and contain the damage.\n\nHow does one design a robust decentralized system? The world is a complicated place and decentralization is not a characteristic that can be hard-coded or demonstrated via testing – the potential configurations that might arise are infinite. To counter this, one must develop *models* that systematically encompass all the different threats the system may encounter and demonstrate rigorously that the two basic properties of persistence and liveness are upheld.\n\nThe strongest arguments for the reliability of a decentralized system combine formal guarantees against a broad portfolio of different classes of failure and attack models. The first important class is that of powerful Byzantine models. In this setting, it should be guaranteed that even if a subset of participants *arbitrarily* deviate from the rules, the two fundamental properties are retained. The second important class is models of rationality. Here, participants are assumed to be *rational utility maximizers* and the objective is to show that the ledger properties arise from their efforts to pursue their self interest.\n\nOuroboros is a decentralized ledger protocol that is analyzed in the context of both Byzantine and rational behavior. What makes the protocol unique is the combination of the following design elements.\n\n* It uses **stake** as the fundamental resource to identify the participants’ leverage in the system. No physical resource is wasted in the process of ledger maintenance, which is shown to be robust despite ‘costless simulation’ and ‘nothing at stake’ attacks that were previously thought to be fundamental barriers to stake-based ledgers. This makes Ouroboros distinctly more appealing than proof-of-work protocols, which require prodigious energy expenditure to maintain consensus.\n* It is proven to be resilient even if arbitrarily large subsets of participants, in terms of stake, abstain from ledger maintenance. This guarantee of **dynamic availability** ensures liveness even under arbitrary, and unpredictable, levels of engagement. At the same time, of those participants who are active, barely more than half need to follow the protocol – the rest can arbitrarily deviate; in fact, even temporary spikes above the 50% threshold can be tolerated. Thus Ouroboros is distinctly more resilient and adaptable than classical Byzantine fault tolerance protocols (as well as all their modern adaptations), which have to predict with relative certainty the level of expected participation and may stop operating when the prediction is false.\n* The process of joining and participating in the protocol execution is **trustless** in the sense that it does not require the availability of any special shared resource such as a recent checkpoint or a common clock. Engaging in the protocol requires merely the public genesis block of the chain, and access to the network. This makes Ouroboros free of the trust assumptions common in other consensus protocols whose security collapses when trusted shared resources are subverted or unavailable.\n* Ouroboros incorporates a reward-sharing mechanism to incentivize participants to **organize themselves** in operational nodes, known as stake pools, that can offer a good quality of service independently of how stake is distributed among the user population. In this way, all stakeholders contribute to the system’s operation – ensuring robustness and democratic representation – while the cost of ledger maintenance is efficiently distributed across the user population. At the same time, the mechanism comes with countermeasures that de-incentivize centralization. This makes Ouroboros fundamentally more inclusive and decentralized compared with other protocols that either end up with just a handful of actors responsible for ledger maintenance or provide no incentives to stakeholders to participate and offer a good quality of service.\n\nThese design elements of Ouroboros are not supposed to be self-evident appeals to the common sense of the protocol user. Instead, they were delivered with meticulous documentation in papers that have undergone peer review and appeared in top-tier conferences and publications in the area of cybersecurity and cryptography. Indeed, it is fair to say that no other consensus research effort is represented so comprehensively in these circles. Each paper is explicit about the specific type of model that is used to analyze the protocol and the results derived are laid out in concrete terms. The papers are open-access, patent-free, and include all technical details to allow anyone, with the relevant technical expertise, to convince themselves of the veracity of the claims made about performance, security, and functionality.\n\nBuilding an inclusive, fair and resilient infrastructure for financial and social applications on a global scale is the grand challenge of information technology today. Ouroboros contributes, not just as a protocol with unique characteristics, but also in presenting a design methodology that highlights first principles, careful modeling and rigorous analysis. Its modular and adaptable architecture also lends itself to continuous improvement, adaptation and enrichment with additional elements (such as parallelization to improve scalability or zero-knowledge proofs to improve privacy, to name two examples), which is a befitting characteristic to meet the ever-evolving needs and complexities of the real world.\n\n## Further reading\n\nTo delve deeper into the Ouroboros protocol, from its inception to recent new features, follow these links:\n\n1. [Ouroboros (Classic)](http://ia.cr/2016/889): the first provably secure proof-of-stake blockchain protocol.\n2. [Ouroboros Praos](http://ia.cr/2017/573): removes the need for a rigid round structure and improves resilience against ‘adaptive’ attackers.\n3. [Ouroboros Genesis](https://ia.cr/2018/378): how to avoid the need for a recent checkpoint and prove the protocol is secure under dynamic availability for trustless joining and participating.\n4. [Ouroboros Chronos](http://ia.cr/2019/838): removes the need for a common clock.\n5. [Reward sharing schemes](https://arxiv.org/abs/1807.11218) for stake pools.\n6. [Account management](https://ia.cr/2020/525) and maximizing participation in stake pools.\n7. [Optimizing transaction throughput](http://ia.cr/2020/037) with proof-of-stake protocols.\n8. [Fast settlement](http://ia.cr/2020/675) using ledger combiners.\n9. [Ouroboros Crypsinous](http://ia.cr/2018/1132): a privacy-preserving proof-of-stake protocol.\n10. [Kachina](http://ia.cr/2020/543): a unified security model for private smart contracts.\n11. [Hydra](http://ia.cr/2020/299): an off-chain scalability architecture for high transaction throughput with low latency, and minimal storage per node.',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'the-ouroboros-path-to-decentralization',
                                url: '/blog/posts/2020/06/23/the-ouroboros-path-to-decentralization/',
                                read_time: 6
                            },
                            {
                                publish_date: '2020-03-26',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/16a0b7e2-2620-4333-acd5-57a713c5d2f6/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Enter the Hydra: scaling distributed ledgers, the evidence-based way ',
                                        subtitle: 'Learn about Hydra: the multi-headed ledger protocol ',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'Scalability is the greatest challenge to blockchain adoption. By applying a principled, evidence-based approach, we have arrived at a solution for Cardano and networks similar to it: Hydra. Hydra is the culmination of extensive research, and a decisive step in enabling decentralized networks to securely scale to global requirements. \n\n## What is scalability and how do we measure it?\n\nScaling a distributed ledger system refers to the capability of providing high transaction throughput, low latency, and minimal storage per node. These properties have been repeatedly touted as critical for the successful deployment of blockchain protocols as part of real-world systems. In terms of throughput, the VISA network [reportedly](https://usa.visa.com/run-your-business/small-business-tools/retail.html) handles an average of 1,736 payment transactions per second (TPS) with the capability of handling up to 24,000 TPS and is frequently used as a baseline comparison. Transaction latency is clearly desired to be as low as possible, with the ultimate goal of appearing instantaneous to the end-user. Other applications of distributed ledgers have a wide range of different requirements in terms of these metrics. When designing a general purpose distributed ledger, it is natural to strive to excel on all three counts. \n\nDeploying a system that provides satisfactory scaling for a certain use case requires an appropriate combination of two independent aspects: adopting a proper algorithmic design and deploying it over a suitable underlying hardware and network infrastructure.\n\nWhen evaluating a particular algorithmic design, considering absolute numbers in terms of specific metrics can be misleading. The reason is that such absolute quantities must refer to a particular underlying hardware and network configuration which can blur the advantages and disadvantages of particular algorithms. Indeed, a poorly designed protocol may still perform well enough when deployed over superior hardware and networking.\n\nFor this reason, it is more insightful to evaluate the ability of a protocol to reach the physical limits of the underlying network and hardware. This can be achieved by comparing the protocol with simple strawman protocols, in which all the design elements have been stripped away. For instance, if we want to evaluate the overhead of an encryption algorithm, we can compare the communication performance of two end-points using encryption against their performance when they simply exchange unencrypted messages. In such an experiment, the absolute message-per-second rate is unimportant. The important conclusion is the relative overhead that is added by the encryption algorithm. Moreover, in case the overhead approximates 0 for some configuration of the experimental setup, we can conclude that the algorithm approximates the physical limits of the underlying network’s message-passing ability for that particular configuration, and is hence optimal in this sense. \n\n## Hydra – 30,000-feet view\n\nHydra is an off-chain scalability architecture for distributed ledgers, which addresses all three of the scalability challenges mentioned above: high transaction throughput, low latency, and minimal storage per node. While Hydra is being designed in conjunction with the Ouroboros protocol and the Cardano ledger, it may be employed over other systems as well, provided they share the necessary salient characteristics with Cardano.\n\nDespite being an integrated system aimed at solving one problem – scalability – Hydra consists of several subprotocols. This is necessary as the Cardano ecosystem itself is heterogenous and consists of multiple entities with differing technical capabilities: the system supports block producers with associated stake pools, high-throughput wallets as used by exchanges, but also end-users with a wide variety of computational performance and availability characteristics. It is unrealistic to expect that a one-shoe-fits-all, single-protocol approach is sufficient to provide overall scalability for such a diverse set of network participants.\n\nThe Hydra scalability architecture can be divided into four components: the head protocol, the tail protocol, the cross-head-and-tail communication protocol, as well as a set of supporting protocols for routing, reconfiguration, and virtualization. The centerpiece is the \'head\' protocol, which enables a set of high-performance and high-availability participants (such as stake pools) to very quickly process large numbers of transactions with minimal storage requirements by way of a multiparty state channel – a concept that generalizes two-party payment channels as implemented in the context of the Lightning network. It is complemented by the \'tail\' protocol, which enables those high-performance participants to provide scalability for large numbers of end-users who may use the system from low-power devices, such as mobile phones, and who may be offline for extended periods of time. While heads and tails can already communicate via the Cardano mainchain, the cross-head-and-tail communication protocol provides an efficient off–chain variant of this functionality. All this is tied together by routing and configuration management, while virtualisation facilitates faster communication generalizing head and tail communication. \n\n## The Hydra head protocol\n\nThe Hydra head protocol is the first component of the Hydra architecture to be publicly [released](https://eprint.iacr.org/2020/299). It allows a set of participants to create an off-chain state channel (called a head) wherein they can run smart contracts (or process simpler transactions) among each other without interaction with the underlying blockchain in the optimistic case where all head participants adhere to the protocol. The state channel offers very fast settlement and high transaction throughput; furthermore, it requires very little storage, as the off-chain transaction history can be deleted as soon as its resulting state has been secured via an off–chain \'snapshot\' operation.\n\nEven in the pessimistic case where any number of participants misbehave, full safety is rigorously guaranteed. At any time, any participant can initiate the head\'s \'closure\' with the effect that the head\'s state is transferred back to the (less efficient) blockchain. We emphasize that the execution of any smart contracts can be seamlessly continued on-chain. No funds can be generated off-chain, nor can any single, responsive head participant lose any funds.\n\nThe state channels implemented by Hydra are isomorphic in the sense that they make use of the same transaction format and contract code as the underlying blockchain: contracts can be directly moved back and forth between channels and the blockchain. Thus, state channels effectively yield parallel, off-chain ledger siblings. In other words, the ledger becomes multi-headed.\n\nTransaction confirmation in the head is achieved in full concurrency by an asynchronous off-chain certification process using multi-signatures. This high level of parallelism is enabled by use of the extended UTxO model ([EUTxO](https://github.com/hydra-supplementary-material/eutxo-spec/blob/master/extended-utxo-specification.pdf)). Transaction dependencies in the EUTxO model are explicit, which allows for state updates without unnecessary sequentialization of transactions that are independent of each other.  \n\n## Experimental validation of the Hydra head protocol\n\nAs a first step towards experimentally validating the performance of the Hydra head protocol, we implemented a simulation. The simulation is parameterized by the time required by individual actions (validating transactions, verifying signatures, etc.), and carries out a realistic and timing-correct simulation of a cluster of distributed nodes forming a head. This results in realistic transaction confirmation time and throughput calculations.\n\nWe see that a single Hydra head achieves up to roughly 1,000 TPS, so by running 1,000 heads in parallel (for example, one for each stake pool of the Shelley release), we should achieve a million TPS. That’s impressive and puts us miles ahead of the competition, but why should we stop there? 2,000 heads will give us 2 million TPS – and if someone demands a billion TPS, then we can tell them to just run a million heads. Furthermore, various performance improvements in the implementation can improve the 1,000 TPS single head measurement, further adding to the protocol’s hypothetical performance. \n\nSo, can we just reach any TPS number that we want? In theory the answer is a solid yes, and that points to a problem with the dominant usage of TPS as a metric to compare systems. While it is tempting to reduce the complexity of assessing protocol performance to a single number, in practice this leads to an oversimplification. Without further context, a TPS number is close to meaningless. In order to properly interpret it, and make comparisons, you should at least ask for  the size of the cluster (which influences the communication overhead); its geographic distribution (which determines how much time it takes for information to transit through the system); how the quality of service (transaction confirmation times, providing data to end users) is impacted by a high rate of transactions; how large and complicated the transactions are (which has an impact on transaction validation times, message propagation time, requirements on the local storage system, and composition of the head participants); and what kind of hardware and network connections were used in the experiments. Changing the complexity of transactions alone can change the TPS by a factor of three, as can be seen in the figures in the [paper](https://eprint.iacr.org/2020/299) (refer to Section 7 – Simulations).\n\nClearly, we need a better standard. Is the Hydra head protocol a good protocol design? What we need to ask is whether it reaches the physical limits of the network, not a mere TPS number. Thus, for this first iteration of the evaluation of the Hydra head protocol, we used the following approach to ensure that the data we provide is properly meaningful: \n\n1. We clearly list all the parameters that influence the simulation: transaction size, time to validate a single transaction, time needed for cryptographic operations, allocated bandwidth per node, cluster size and geographical distribution, and limits on the parallelism in which transactions can be issued. Without this controlled environment, it would be impossible to reproduce our numbers.\n2. We compare the protocol’s performance to baselines that provide precise and absolute limits of the underlying network and hardware infrastructure. How well we approach those limits tells us how much room there would be for further improvements. This follows the methodology explained above using the example of an encryption algorithm.\n\nWe use two baselines for Hydra. The first, Full Trust, is universal: it applies to any protocol that distributes transactions amongst nodes and insists that each node validate transactions one after the other – without even ensuring consensus. This yields a limit on TPS by simply adding the message delivery and validation times. How well we approach this limit tells us what price we are paying for consensus, without relying on comparison with other protocols. The second baseline, Hydra Unlimited, yields a TPS limit specifically for the head protocol and also provides the ideal latency and storage for any protocol. We achieve that by assuming that we can send enough transactions in parallel to completely amortize network round-trip times and that all actions can be carried out when needed, without resource contention. The baseline helps us answer the question of what can be achieved under ideal circumstances with the general design of Hydra (for a given set of values of the input parameters) as well as evaluate confirmation latency and storage overhead against any possible protocol. More details and graphs for those interested can be found in our [paper](https://eprint.iacr.org/2020/299) (again, Section 7 – Simulations).  \n\n## What comes next?\n\nSolving the scalability question is the holy grail for the whole blockchain space. The time has come to apply a principled, evidence-based approach in designing and engineering blockchain scalability solutions. Comparing scalability proposals against well-defined baselines can be a significant aide in the design of such protocols. It provides solid evidence for the appropriateness of the design choices and ultimately leads to the engineering of effective and performant distributed ledger protocols that will provide the best possible absolute metrics for use cases of interest. While the Hydra head protocol is implemented and tested, we will, in time, release the rest of the Hydra components following the same principled approach. \n\nAs a last note, Hydra is the joint effort of a number of researchers, whom I\'d like to thank. These include Manuel Chakravarty, Sandro Coretti, Matthias Fitzi, Peter Gaži, Philipp Kant, and Alexander Russel. The research was also supported, in part, by EU Project No.780477, PRIVILEDGE, which we gratefully acknowledge.',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Enter the Hydra: scaling distributed ledgers, the evidence-based way ',
                                subtitle: 'Learn about Hydra: the multi-headed ledger protocol ',
                                audio: null,
                                soundcloud: null,
                                body_content: 'Scalability is the greatest challenge to blockchain adoption. By applying a principled, evidence-based approach, we have arrived at a solution for Cardano and networks similar to it: Hydra. Hydra is the culmination of extensive research, and a decisive step in enabling decentralized networks to securely scale to global requirements. \n\n## What is scalability and how do we measure it?\n\nScaling a distributed ledger system refers to the capability of providing high transaction throughput, low latency, and minimal storage per node. These properties have been repeatedly touted as critical for the successful deployment of blockchain protocols as part of real-world systems. In terms of throughput, the VISA network [reportedly](https://usa.visa.com/run-your-business/small-business-tools/retail.html) handles an average of 1,736 payment transactions per second (TPS) with the capability of handling up to 24,000 TPS and is frequently used as a baseline comparison. Transaction latency is clearly desired to be as low as possible, with the ultimate goal of appearing instantaneous to the end-user. Other applications of distributed ledgers have a wide range of different requirements in terms of these metrics. When designing a general purpose distributed ledger, it is natural to strive to excel on all three counts. \n\nDeploying a system that provides satisfactory scaling for a certain use case requires an appropriate combination of two independent aspects: adopting a proper algorithmic design and deploying it over a suitable underlying hardware and network infrastructure.\n\nWhen evaluating a particular algorithmic design, considering absolute numbers in terms of specific metrics can be misleading. The reason is that such absolute quantities must refer to a particular underlying hardware and network configuration which can blur the advantages and disadvantages of particular algorithms. Indeed, a poorly designed protocol may still perform well enough when deployed over superior hardware and networking.\n\nFor this reason, it is more insightful to evaluate the ability of a protocol to reach the physical limits of the underlying network and hardware. This can be achieved by comparing the protocol with simple strawman protocols, in which all the design elements have been stripped away. For instance, if we want to evaluate the overhead of an encryption algorithm, we can compare the communication performance of two end-points using encryption against their performance when they simply exchange unencrypted messages. In such an experiment, the absolute message-per-second rate is unimportant. The important conclusion is the relative overhead that is added by the encryption algorithm. Moreover, in case the overhead approximates 0 for some configuration of the experimental setup, we can conclude that the algorithm approximates the physical limits of the underlying network’s message-passing ability for that particular configuration, and is hence optimal in this sense. \n\n## Hydra – 30,000-feet view\n\nHydra is an off-chain scalability architecture for distributed ledgers, which addresses all three of the scalability challenges mentioned above: high transaction throughput, low latency, and minimal storage per node. While Hydra is being designed in conjunction with the Ouroboros protocol and the Cardano ledger, it may be employed over other systems as well, provided they share the necessary salient characteristics with Cardano.\n\nDespite being an integrated system aimed at solving one problem – scalability – Hydra consists of several subprotocols. This is necessary as the Cardano ecosystem itself is heterogenous and consists of multiple entities with differing technical capabilities: the system supports block producers with associated stake pools, high-throughput wallets as used by exchanges, but also end-users with a wide variety of computational performance and availability characteristics. It is unrealistic to expect that a one-shoe-fits-all, single-protocol approach is sufficient to provide overall scalability for such a diverse set of network participants.\n\nThe Hydra scalability architecture can be divided into four components: the head protocol, the tail protocol, the cross-head-and-tail communication protocol, as well as a set of supporting protocols for routing, reconfiguration, and virtualization. The centerpiece is the \'head\' protocol, which enables a set of high-performance and high-availability participants (such as stake pools) to very quickly process large numbers of transactions with minimal storage requirements by way of a multiparty state channel – a concept that generalizes two-party payment channels as implemented in the context of the Lightning network. It is complemented by the \'tail\' protocol, which enables those high-performance participants to provide scalability for large numbers of end-users who may use the system from low-power devices, such as mobile phones, and who may be offline for extended periods of time. While heads and tails can already communicate via the Cardano mainchain, the cross-head-and-tail communication protocol provides an efficient off–chain variant of this functionality. All this is tied together by routing and configuration management, while virtualisation facilitates faster communication generalizing head and tail communication. \n\n## The Hydra head protocol\n\nThe Hydra head protocol is the first component of the Hydra architecture to be publicly [released](https://eprint.iacr.org/2020/299). It allows a set of participants to create an off-chain state channel (called a head) wherein they can run smart contracts (or process simpler transactions) among each other without interaction with the underlying blockchain in the optimistic case where all head participants adhere to the protocol. The state channel offers very fast settlement and high transaction throughput; furthermore, it requires very little storage, as the off-chain transaction history can be deleted as soon as its resulting state has been secured via an off–chain \'snapshot\' operation.\n\nEven in the pessimistic case where any number of participants misbehave, full safety is rigorously guaranteed. At any time, any participant can initiate the head\'s \'closure\' with the effect that the head\'s state is transferred back to the (less efficient) blockchain. We emphasize that the execution of any smart contracts can be seamlessly continued on-chain. No funds can be generated off-chain, nor can any single, responsive head participant lose any funds.\n\nThe state channels implemented by Hydra are isomorphic in the sense that they make use of the same transaction format and contract code as the underlying blockchain: contracts can be directly moved back and forth between channels and the blockchain. Thus, state channels effectively yield parallel, off-chain ledger siblings. In other words, the ledger becomes multi-headed.\n\nTransaction confirmation in the head is achieved in full concurrency by an asynchronous off-chain certification process using multi-signatures. This high level of parallelism is enabled by use of the extended UTxO model ([EUTxO](https://github.com/hydra-supplementary-material/eutxo-spec/blob/master/extended-utxo-specification.pdf)). Transaction dependencies in the EUTxO model are explicit, which allows for state updates without unnecessary sequentialization of transactions that are independent of each other.  \n\n## Experimental validation of the Hydra head protocol\n\nAs a first step towards experimentally validating the performance of the Hydra head protocol, we implemented a simulation. The simulation is parameterized by the time required by individual actions (validating transactions, verifying signatures, etc.), and carries out a realistic and timing-correct simulation of a cluster of distributed nodes forming a head. This results in realistic transaction confirmation time and throughput calculations.\n\nWe see that a single Hydra head achieves up to roughly 1,000 TPS, so by running 1,000 heads in parallel (for example, one for each stake pool of the Shelley release), we should achieve a million TPS. That’s impressive and puts us miles ahead of the competition, but why should we stop there? 2,000 heads will give us 2 million TPS – and if someone demands a billion TPS, then we can tell them to just run a million heads. Furthermore, various performance improvements in the implementation can improve the 1,000 TPS single head measurement, further adding to the protocol’s hypothetical performance. \n\nSo, can we just reach any TPS number that we want? In theory the answer is a solid yes, and that points to a problem with the dominant usage of TPS as a metric to compare systems. While it is tempting to reduce the complexity of assessing protocol performance to a single number, in practice this leads to an oversimplification. Without further context, a TPS number is close to meaningless. In order to properly interpret it, and make comparisons, you should at least ask for  the size of the cluster (which influences the communication overhead); its geographic distribution (which determines how much time it takes for information to transit through the system); how the quality of service (transaction confirmation times, providing data to end users) is impacted by a high rate of transactions; how large and complicated the transactions are (which has an impact on transaction validation times, message propagation time, requirements on the local storage system, and composition of the head participants); and what kind of hardware and network connections were used in the experiments. Changing the complexity of transactions alone can change the TPS by a factor of three, as can be seen in the figures in the [paper](https://eprint.iacr.org/2020/299) (refer to Section 7 – Simulations).\n\nClearly, we need a better standard. Is the Hydra head protocol a good protocol design? What we need to ask is whether it reaches the physical limits of the network, not a mere TPS number. Thus, for this first iteration of the evaluation of the Hydra head protocol, we used the following approach to ensure that the data we provide is properly meaningful: \n\n1. We clearly list all the parameters that influence the simulation: transaction size, time to validate a single transaction, time needed for cryptographic operations, allocated bandwidth per node, cluster size and geographical distribution, and limits on the parallelism in which transactions can be issued. Without this controlled environment, it would be impossible to reproduce our numbers.\n2. We compare the protocol’s performance to baselines that provide precise and absolute limits of the underlying network and hardware infrastructure. How well we approach those limits tells us how much room there would be for further improvements. This follows the methodology explained above using the example of an encryption algorithm.\n\nWe use two baselines for Hydra. The first, Full Trust, is universal: it applies to any protocol that distributes transactions amongst nodes and insists that each node validate transactions one after the other – without even ensuring consensus. This yields a limit on TPS by simply adding the message delivery and validation times. How well we approach this limit tells us what price we are paying for consensus, without relying on comparison with other protocols. The second baseline, Hydra Unlimited, yields a TPS limit specifically for the head protocol and also provides the ideal latency and storage for any protocol. We achieve that by assuming that we can send enough transactions in parallel to completely amortize network round-trip times and that all actions can be carried out when needed, without resource contention. The baseline helps us answer the question of what can be achieved under ideal circumstances with the general design of Hydra (for a given set of values of the input parameters) as well as evaluate confirmation latency and storage overhead against any possible protocol. More details and graphs for those interested can be found in our [paper](https://eprint.iacr.org/2020/299) (again, Section 7 – Simulations).  \n\n## What comes next?\n\nSolving the scalability question is the holy grail for the whole blockchain space. The time has come to apply a principled, evidence-based approach in designing and engineering blockchain scalability solutions. Comparing scalability proposals against well-defined baselines can be a significant aide in the design of such protocols. It provides solid evidence for the appropriateness of the design choices and ultimately leads to the engineering of effective and performant distributed ledger protocols that will provide the best possible absolute metrics for use cases of interest. While the Hydra head protocol is implemented and tested, we will, in time, release the rest of the Hydra components following the same principled approach. \n\nAs a last note, Hydra is the joint effort of a number of researchers, whom I\'d like to thank. These include Manuel Chakravarty, Sandro Coretti, Matthias Fitzi, Peter Gaži, Philipp Kant, and Alexander Russel. The research was also supported, in part, by EU Project No.780477, PRIVILEDGE, which we gratefully acknowledge.',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'enter-the-hydra-scaling-distributed-ledgers-the-evidence-based-way',
                                url: '/blog/posts/2020/03/26/enter-the-hydra-scaling-distributed-ledgers-the-evidence-based-way/',
                                read_time: 10
                            },
                            {
                                publish_date: '2018-10-23',
                                author: null,
                                video_id: '',
                                main_image: 'https://ucarecdn.com/15a4e39f-735d-41d4-b928-6f1f50ec2f8c/',
                                custom_meta_img: null,
                                old_url: '/blog/stake-pools-in-cardano/',
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Stake pools in Cardano',
                                        subtitle: 'IOHK’s chief scientist introduces staking',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'In a proof of stake (PoS) blockchain protocol, the ledger is maintained by the stakeholders that hold assets in that ledger. This allows PoS blockchains to use less energy compared with proof of work (PoW) or other types of blockchain protocols. Nevertheless, this requirement imposes a burden on stakeholders. It requires a good number of them to be online and maintain sufficiently good network connectivity that they can collect transactions and have their PoS blocks reach the others without substantial network delays. It follows that any PoS ledger would benefit from reliable server nodes that hold stake and focus on maintenance.\n## The argument for stake pools\n\nWealth is typically distributed according to a power-law such as the [Pareto distribution](https://en.wikipedia.org/wiki/Pareto_distribution "Pareto distribution, wikipedia.org"), so running reliable nodes executing the PoS protocol may be an option only for a small, wealthy, subset of stakeholders, leaving most without the ability to run such services. This is undesirable; it would be better if everyone had the ability to contribute to ledger maintenance. An approach to rectify this problem is by allowing the creation of stake pools. Specifically, this refers to the ability of stakeholders to combine their stake and form a single entity, the stake pool, which can engage in the PoS protocol using the total stake of its members. A pool will have a manager who will be responsible for running the service that processes transactions. At the same time, the pool manager should not be able to spend the stake that their pool represents, while members who are represented by the pool should be free to change their mind and reallocate their stake if they wish to another pool. Finally, and most importantly, any stakeholder should be able to aspire to become a stake pool manager.\n\nParticipating in PoS ledger maintenance incurs costs. Certainly not as high as in the case of a PoW protocol but, nevertheless, still significant. As a result, it is sensible that the community of all stakeholders incentivizes in some way those who support the ledger by setting up servers and processing transactions. This can be achieved by a combination of contributions from those that use the ledger (in the form of transaction fees) and inflation of the circulating supply of coins (by introducing new coins in circulation to be claimed by those engaged in the protocol).\n\nIn the case of Bitcoin, we have both the above mechanisms, incentivization and pools. On the one hand, mining is rewarded by transaction fees as well as a block reward that is fixed and diminishes over time following a geometric series. On the other hand, pools can be facilitated by dividing the work required for producing blocks among many participants and using ‘partial’ PoWs (which are PoWs that are of smaller difficulty than the one indicated by the current state of the ledger) as evidence of pool participation.\n\nIt is straightforward to apply a similar type of incentivization mechanism in the PoS setting. However, one should ask first whether a Bitcoin-like mechanism (or any mechanism for that matter) would converge to a desirable system configuration. Which brings us to the important question: **what are the desirable system configurations?** If the only consideration is to minimize transaction processing costs, in a failure-free environment, the economically optimal configuration is a dictatorial one. One of the parties maintains the ledger as a service while all the others participate in the pool created by this party. This is clearly an undesirable outcome because the single pool leader becomes also a single point of failure in the system, which is exactly the type of outcome that a distributed ledger is supposed to avoid. It follows that the coexistence of many pools, in other words decentralization, should be a desirable characteristic of the ledger incentivization mechanism.\n\n## Reward-sharing schemes for PoS\n\nSo what would a *reward-sharing scheme* look like in a PoS setting? Rewards should be provided at regular intervals and pool maintenance costs should be retained by the pool manager before distributing the remaining rewards among the members. Given that it is possible to keep track of pool membership in the ledger itself using the staking keys of the participants, reward splits within each pool can be encoded in a smart contract and become part of the ledger maintenance service. First things first, pool managers should be rewarded for their entrepreneurship. A pool creation certificate posted on the ledger will declare a profit margin to be shaved off the pool’s rewards after subtracting operational costs, which should also be declared as part of the pool creation certificate. The cost declaration should be updated frequently to absorb any volatility that the native token of the system has with respect to the currency that denominates the actual costs of the pool manager. At the same time, the pool creation certificate, backed up by one or more staking keys provided by stakeholders, can declare a certain amount of stake that “stands behind” the pool and can be used either as an indication that the pool represents the genuine enterprise of one or more stakeholders or as collateral guaranteeing compliance with correct protocol behavior.\n\nGiven the above setup, how do Bitcoin-like mechanisms fare with respect to the decentralization objective? In Bitcoin, assuming everyone follows the protocol, pool rewards are split in proportion to the size of each pool. For example, a mining pool with 20% of the total hashing power is expected to reap 20% of the rewards. This is because rewards are proportional to the number of blocks obtained by the pool and the number of blocks is in turn proportional to the pool’s mining power. Does this lead to a decentralized system? Empirical evidence seems to suggest otherwise: in Bitcoin, mining pools came close (and occasionally [even exceeded](https://en.bitcoinwiki.org/wiki/GHash.IO#51.25_attack_controversy "51% attack controversy, bitcoinwiki.org")) the 50% threshold that is the upper boundary for ensuring the resilience of the ledger. A simple argument can validate this empirical observation in the framework of our reward-sharing schemes: if pools are rewarded proportionally to their size and pool members proportionally to their stake in the pool, the rational thing to do would be to centralize to one pool. To see this consider the following. At first, it is reasonable to expect that all players who are sufficiently wealthy to afford creating a pool will do so by setting up or renting server equipment and promoting it with the objective to attract members so that their share of rewards grows. The other stakeholders that are not pool managers will join the pool that maximizes their payoff, which will be the one with the lowest cost and profit margin. Pool competition for gaining these members will compress profit margins to very small values. But even with zero profit margin, all other pools will lose to the pool with the lowest cost. Assuming that there are no ties, this single pool will attract all stakeholders. Finally, other pool managers will realize that they will be better off joining that pool as opposed to maintaining their own because they will receive more for the stake they possess. Eventually, the system will converge to a dictatorial single pool.\n\nFigure 1 shows a graphical representation of this. It comes from one of the numerous simulations our team has conducted in the process of distilling effective reward sharing schemes. In the experiment, a number of stakeholders follow a reactive process where they attempt to maximize their payoff based on the current system configuration. The experiment leads to a centralized single pool, validating our theoretical observations above for Bitcoin-like schemes. From a decentralization perspective, this is a tragedy of the commons: even though the participants value decentralization as an abstract concept, none of them individually wants to bear the burden of it. \n\n<figure class="">\n<img src="https://ucarecdn.com/1b731f0f-1632-4769-abfa-f3bf4656373c/-/resize/1500/" alt="" class="" width="100%" />\n<figcaption>Figure 1. Centralisation exhibited by a Bitcoin-like reward-sharing scheme in a simulation with 100 stakeholders. Initially, a high number of pools are created by the stakeholders. Taking turns, stakeholders try to maximize their payoff and change strategy, leading to a convergence point where only a single pool exists.</figcaption>\n</figure> \n\n## A better reward sharing scheme\n\nClearly we have to do better than a dictatorship! A first observation is that if we are to achieve decentralization, linearity between rewards and size should taper off after a certain level. This is because, while linearity is attractive when the pool is small and wants to attract stakeholders, after a certain level it should be diminished if we want to give an opportunity for smaller pools to be more competitive. Thus, we will divide the behavior of the reward-sharing scheme depending on the size of the pool to two stages: a growth stage, when linearity is to be respected, and a stabilization stage when the pool is large enough. The point where the transition happens will be called the saturation point and the pool that has passed this point will be saturated. We can fix rewards to be constant after the saturation point, so that if the saturation point is 1%, two pools, with total stakes of 1% and 1.5%, will receive the same rewards. \n\nTo appreciate how the dynamics work from the perspective of a single stakeholder, consider the following example. Suppose there are two pools, A and B managed by Alice and Bob, with operational costs of 25 and 30 coins respectively, each one with a profit margin of 4%. Suppose further that the total rewards to be distributed are 1,000 coins and the saturation point of the reward-sharing mechanism is 20%. At a given point in time, Alice’s pool has 20% of the stake, so it is at the saturation point, while Bob’s pool is at 19%. A prospective pool member, Charlie, holds 1% of the stake and considers which pool to join. Joining Alice’s pool will bring its total stake to 21%, and because it has exceeded the saturation point the reward will be 200 coins (20% of the total rewards). Deducting operational costs will leave 175 coins to be distributed between Alice and the pool members. After removing Alice’s profit margin and considering Charlie’s relative stake in the pool, he will receive 8 coins as a reward. If Charlie joins Bob’s pool, the total rewards will be 200 coins, or 170 coins after removing the operational costs. However, given that Charlie’s stake is 5% (1/20) of the pool, it turns out that he will receive 2% more coins than if he had joined Alice’s pool. So Charlie will join Bob’s pool if he wants to maximize his rewards. \n\nNow, let us see what happens in the case that Charlie is facing the same decision at a hypothetical earlier stage of the whole process when Alice’s pool was already at 20% of the total stake, while Bob’s pool was only at 3%. In this case, Bob has a very small pool and the total rewards available for its members are much less compared with the previous case. As a result, if Charlie did the same calculation for Bob’s pool, his 1% stake would result in a 4% total stake for the pool but, if one does the calculations, he would receive a mere 30% of the rewards that he would have obtained had he joined Alice’s pool. In such a case, the rational decision is to join Alice’s pool despite the fact that his membership will make Alice’s pool exceed the saturation point. Refer to Table 1 below for the exact figures. \n\n<figure class="">\n<img src="https://ucarecdn.com/fcf073c9-fe00-4765-be05-a6303c28a31a/-/resize/1500/" alt="" class="" width="100%" />\n<figcaption>Table 1. Charlie who holds 1% of the total stake, is considering joining pools run by Alice, Bob, Brenda and Ben. His reward is calculated in coins for joining each one. The total reward pool is 1,000 and the saturation point is 20%.</figcaption>\n</figure>\n\n## Being far-sighted matters\n\nThe above appears to be contradictory. To understand what Charlie needs to do we have to appreciate the following fact. The choice of Charlie to join Alice’s pool in the second scenario is only rational in a very near-sighted (aka myopic) sense. In fact, Charlie is better off with Bob’s pool, as is demonstrated by the first scenario, as long as Bob’s pool reaches the saturation point. Thus, if Charlie believes that Bob’s pool will reach the saturation point, the rational choice should be to support it. Other stakeholders will do the same and thus Bob’s pool will rapidly reach the saturation point making everyone that participated in it better off, while also supporting the ideal of decentralization: Alice’s pool instead of constantly growing larger will stop at the saturation point and other pools will be given the ability to grow to the same size. This type of strategic thinking on behalf of the stakeholders is more far-sighted (aka non-myopic) and, as we will see, has the ability to help parties converge to desirable decentralized configurations for the system. \n\nIt is worth noting that it is unavoidable that the system in its evolution will reach pivotal moments where it will be crucial for stakeholders to exercise far-sighted thinking, as in the scenario above where Alice’s pool reaches the saturation point while other pools are still quite small. The reason is that due to the particular circumstances of each stake pool manager, the operational costs will be variable across the stakeholder population. As a result, it is to be expected that starting from a point zero where no stake pools exist, the pool with the lowest operational cost will be also the one that will be the first to grow. This is natural since low operational costs leave a higher level of rewards to be split among the pool members. It is to be expected that the system will reach moments like the second scenario above where the most competitive pool (the one of Alice with operational cost 25) has reached saturation point while the second-most competitive (the one of Bob with operational cost 30) is still at a small membership level. \n\nOne might be tempted to consider long-term thinking in the setting of a Bitcoin-like reward sharing schemes and believe that it can also help to converge to decentralization. Unfortunately, this is not the case. In a Bitcoin-like scheme, contrary to our reward-sharing scheme with a saturation point, there is no point in the development of Alice’s and Bob’s pools when Bob’s pool will become more attractive in Charlie’s view. Indeed, without a saturation point, Alice’s bigger pool will always offer more rewards to Charlie: this stems from the fact that the operational costs of Alice are smaller and hence leave more rewards for all the stakeholders. This will leave Bob’s pool without any members, and eventually, as discussed above, it will be the rational choice for Bob also to dissolve his pool and join Alice’s, making Alice the system’s dictator. \n\nGoing back to our reward-sharing scheme, we have established that non-myopic strategic thinking promotes decentralization; nevertheless, there is an important point still open. At a pivotal moment, when the non-myopic stakeholder Charlie rationally decides to forgo the option to join Alice’s saturated pool, he may have a number of aspiring pools to choose from. For instance, together with Bob’s pool that has operational costs of 30 and profit margin 4%, there could be a pool by Brenda with operational cost of 33 and profit margin 2%, and a pool by Ben with operational cost of 36 and profit margin 1%. The rational choice would be to go with the one that will reach the saturation point; is there a way to tell which one would be the best choice? In our [full analysis paper](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org") we provide an explicit mechanism that orders the pools according to their desirability and, using the information recorded in the ledger about each stake pool, it can assist stakeholders in making the best possible choice at any given moment. In our example, it is Brenda’s pool that Charlie should join if he wants to maximize his rewards (see Table 1). To aid Cardano users, the pool-sorting mechanism will be built into Daedalus (and other Cardano-compatible wallets) and will provide a visual representation of the best choices available to stakeholders using the information in the ledger regarding pool registrations. \n\n## Experimental evaluation\n\nSo how does our reward scheme fare with respect to decentralization? In the [full analysis paper](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org") we prove that there is a class of decentralized system configurations that are “non-myopic Nash equilibria.” An equilibrium strategy here means that stakeholders have a specific way to create pools, set their profit margins and/or delegate to other pools, so that no stakeholder, thinking for the long term, is better off following a different strategy. Moreover, we demonstrate experimentally that reactive play between stakeholders with non-myopic thinking converges to this equilibrium in a small number of iterations, as shown in Figure 2.\n\n<figure class="">\n<img src="https://ucarecdn.com/6ead3506-7d9f-4eac-a56e-5a72542e643a/-/resize/1500/" alt="" class="" width="100%" />\n<figcaption>Figure 2. Decentralization as exhibited by our reward-sharing scheme in a simulation with 100 stakeholders and 10% saturation point. Pools are gradually created by the stakeholders. Taking turns, the stakeholders attempt to maximise their payoff non-myopically leading to a final convergence point where 10 pools exist, each with an equal share of the total stake. At the final point, no rational stakeholder wishes to change the state of the system.</figcaption>\n</figure>\n<br>\n\nA characteristic of our approach is that the number of pools is only part of the description of the reward-sharing scheme and thus is in no way enforced by the system on the stakeholders. This means stakeholders are free to experiment with pool creation and delegation of stake without having to conform to any predetermined system architecture. This is in contrast to other approaches taken in PoS systems such as [EOS](https://eos.io/documents/EOS_An_Introduction.pdf "EOS - An Introduction, eos.io") where the number of participants is a hardcoded parameter of the consensus system (specifically, 21 pools). At the same time, our approach allows the whole stakeholder set to to express its will, by freely joining and leaving pools, receiving guaranteed rewards for their participation while witnessing how their actions have a quantifiable impact on the management of the PoS distributed ledger no matter the size of their stake. This is contrast to other approaches taken in PoS systems such as [Ethereum 2.0](https://github.com/ethereum/eth2.0-specs "eth2.0-specs, github.com") where ledger maintenance is performed by registered validators on the basis of a collateral deposit without a built-in process of vetting by the stakeholder set. \n\nSo what would be a sensible choice for the number of pools that should be favored by the reward scheme for Cardano? Given that decentralization is our main objective, it is sensible to set this parameter to be as high as possible. Our network experiments showed that the system can still operate effectively with as many as 1,000 running pools. Choosing a saturation threshold for our reward-sharing scheme based on this number will make having a stake pool profitable even if the total stake delegated in them is as little as 0.1% of the total circulation of Ada.\n\n## Looking ahead – Sybil attacks\n\nGiven that decentralization can be achieved by a large number of independent stake pools, it is also important to see whether some decentralized system configurations are more preferable than others. As described so far in this post, our reward-sharing scheme will lead rational stakeholders towards promoting the stake pools that will incur the smallest total cost. Even though this maximizes rewards and minimizes costs, it may not be necessarily the most desirable outcome. The reason is that in the equilibrium point one may see a set of stakeholders promoted as stake pool managers who possess collectively a very small stake themselves. This imbalance, in which a small total stake represents the total stake of the system, can be detrimental in many ways: stake pool managers may be prone to corruption or bribery, or, perhaps even worse, a large stake holder may register many stake pools in the hope of controlling the whole ecosystem, performing in this way a [Sybil attack](https://en.wikipedia.org/wiki/Sybil_attack "Sybil attack, wikipedia.org") that would hurt decentralization. For this reason, the reward-sharing scheme as presented in our [full analysis paper](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org") is suitably modified to be sensitive to the stake backing the pool so that this type of behaviour is mitigated. We will delve deeper into this aspect of Cardano reward-sharing in the next blog post.\n\n<small>Artwork, [<img src="https://ucarecdn.com/e711abaa-8d67-4630-bdf5-b9172a104689/-/resize/12/" alt="Creative Commons" />](https://creativecommons.org/licenses/by/4.0/ "Creative Commons") [Mike Beeple](http://www.beeple-crap.com)</small>',
                                        uses_mathjax: null,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Stake pools in Cardano',
                                subtitle: 'IOHK’s chief scientist introduces staking',
                                audio: null,
                                soundcloud: null,
                                body_content: 'In a proof of stake (PoS) blockchain protocol, the ledger is maintained by the stakeholders that hold assets in that ledger. This allows PoS blockchains to use less energy compared with proof of work (PoW) or other types of blockchain protocols. Nevertheless, this requirement imposes a burden on stakeholders. It requires a good number of them to be online and maintain sufficiently good network connectivity that they can collect transactions and have their PoS blocks reach the others without substantial network delays. It follows that any PoS ledger would benefit from reliable server nodes that hold stake and focus on maintenance.\n## The argument for stake pools\n\nWealth is typically distributed according to a power-law such as the [Pareto distribution](https://en.wikipedia.org/wiki/Pareto_distribution "Pareto distribution, wikipedia.org"), so running reliable nodes executing the PoS protocol may be an option only for a small, wealthy, subset of stakeholders, leaving most without the ability to run such services. This is undesirable; it would be better if everyone had the ability to contribute to ledger maintenance. An approach to rectify this problem is by allowing the creation of stake pools. Specifically, this refers to the ability of stakeholders to combine their stake and form a single entity, the stake pool, which can engage in the PoS protocol using the total stake of its members. A pool will have a manager who will be responsible for running the service that processes transactions. At the same time, the pool manager should not be able to spend the stake that their pool represents, while members who are represented by the pool should be free to change their mind and reallocate their stake if they wish to another pool. Finally, and most importantly, any stakeholder should be able to aspire to become a stake pool manager.\n\nParticipating in PoS ledger maintenance incurs costs. Certainly not as high as in the case of a PoW protocol but, nevertheless, still significant. As a result, it is sensible that the community of all stakeholders incentivizes in some way those who support the ledger by setting up servers and processing transactions. This can be achieved by a combination of contributions from those that use the ledger (in the form of transaction fees) and inflation of the circulating supply of coins (by introducing new coins in circulation to be claimed by those engaged in the protocol).\n\nIn the case of Bitcoin, we have both the above mechanisms, incentivization and pools. On the one hand, mining is rewarded by transaction fees as well as a block reward that is fixed and diminishes over time following a geometric series. On the other hand, pools can be facilitated by dividing the work required for producing blocks among many participants and using ‘partial’ PoWs (which are PoWs that are of smaller difficulty than the one indicated by the current state of the ledger) as evidence of pool participation.\n\nIt is straightforward to apply a similar type of incentivization mechanism in the PoS setting. However, one should ask first whether a Bitcoin-like mechanism (or any mechanism for that matter) would converge to a desirable system configuration. Which brings us to the important question: **what are the desirable system configurations?** If the only consideration is to minimize transaction processing costs, in a failure-free environment, the economically optimal configuration is a dictatorial one. One of the parties maintains the ledger as a service while all the others participate in the pool created by this party. This is clearly an undesirable outcome because the single pool leader becomes also a single point of failure in the system, which is exactly the type of outcome that a distributed ledger is supposed to avoid. It follows that the coexistence of many pools, in other words decentralization, should be a desirable characteristic of the ledger incentivization mechanism.\n\n## Reward-sharing schemes for PoS\n\nSo what would a *reward-sharing scheme* look like in a PoS setting? Rewards should be provided at regular intervals and pool maintenance costs should be retained by the pool manager before distributing the remaining rewards among the members. Given that it is possible to keep track of pool membership in the ledger itself using the staking keys of the participants, reward splits within each pool can be encoded in a smart contract and become part of the ledger maintenance service. First things first, pool managers should be rewarded for their entrepreneurship. A pool creation certificate posted on the ledger will declare a profit margin to be shaved off the pool’s rewards after subtracting operational costs, which should also be declared as part of the pool creation certificate. The cost declaration should be updated frequently to absorb any volatility that the native token of the system has with respect to the currency that denominates the actual costs of the pool manager. At the same time, the pool creation certificate, backed up by one or more staking keys provided by stakeholders, can declare a certain amount of stake that “stands behind” the pool and can be used either as an indication that the pool represents the genuine enterprise of one or more stakeholders or as collateral guaranteeing compliance with correct protocol behavior.\n\nGiven the above setup, how do Bitcoin-like mechanisms fare with respect to the decentralization objective? In Bitcoin, assuming everyone follows the protocol, pool rewards are split in proportion to the size of each pool. For example, a mining pool with 20% of the total hashing power is expected to reap 20% of the rewards. This is because rewards are proportional to the number of blocks obtained by the pool and the number of blocks is in turn proportional to the pool’s mining power. Does this lead to a decentralized system? Empirical evidence seems to suggest otherwise: in Bitcoin, mining pools came close (and occasionally [even exceeded](https://en.bitcoinwiki.org/wiki/GHash.IO#51.25_attack_controversy "51% attack controversy, bitcoinwiki.org")) the 50% threshold that is the upper boundary for ensuring the resilience of the ledger. A simple argument can validate this empirical observation in the framework of our reward-sharing schemes: if pools are rewarded proportionally to their size and pool members proportionally to their stake in the pool, the rational thing to do would be to centralize to one pool. To see this consider the following. At first, it is reasonable to expect that all players who are sufficiently wealthy to afford creating a pool will do so by setting up or renting server equipment and promoting it with the objective to attract members so that their share of rewards grows. The other stakeholders that are not pool managers will join the pool that maximizes their payoff, which will be the one with the lowest cost and profit margin. Pool competition for gaining these members will compress profit margins to very small values. But even with zero profit margin, all other pools will lose to the pool with the lowest cost. Assuming that there are no ties, this single pool will attract all stakeholders. Finally, other pool managers will realize that they will be better off joining that pool as opposed to maintaining their own because they will receive more for the stake they possess. Eventually, the system will converge to a dictatorial single pool.\n\nFigure 1 shows a graphical representation of this. It comes from one of the numerous simulations our team has conducted in the process of distilling effective reward sharing schemes. In the experiment, a number of stakeholders follow a reactive process where they attempt to maximize their payoff based on the current system configuration. The experiment leads to a centralized single pool, validating our theoretical observations above for Bitcoin-like schemes. From a decentralization perspective, this is a tragedy of the commons: even though the participants value decentralization as an abstract concept, none of them individually wants to bear the burden of it. \n\n<figure class="">\n<img src="https://ucarecdn.com/1b731f0f-1632-4769-abfa-f3bf4656373c/-/resize/1500/" alt="" class="" width="100%" />\n<figcaption>Figure 1. Centralisation exhibited by a Bitcoin-like reward-sharing scheme in a simulation with 100 stakeholders. Initially, a high number of pools are created by the stakeholders. Taking turns, stakeholders try to maximize their payoff and change strategy, leading to a convergence point where only a single pool exists.</figcaption>\n</figure> \n\n## A better reward sharing scheme\n\nClearly we have to do better than a dictatorship! A first observation is that if we are to achieve decentralization, linearity between rewards and size should taper off after a certain level. This is because, while linearity is attractive when the pool is small and wants to attract stakeholders, after a certain level it should be diminished if we want to give an opportunity for smaller pools to be more competitive. Thus, we will divide the behavior of the reward-sharing scheme depending on the size of the pool to two stages: a growth stage, when linearity is to be respected, and a stabilization stage when the pool is large enough. The point where the transition happens will be called the saturation point and the pool that has passed this point will be saturated. We can fix rewards to be constant after the saturation point, so that if the saturation point is 1%, two pools, with total stakes of 1% and 1.5%, will receive the same rewards. \n\nTo appreciate how the dynamics work from the perspective of a single stakeholder, consider the following example. Suppose there are two pools, A and B managed by Alice and Bob, with operational costs of 25 and 30 coins respectively, each one with a profit margin of 4%. Suppose further that the total rewards to be distributed are 1,000 coins and the saturation point of the reward-sharing mechanism is 20%. At a given point in time, Alice’s pool has 20% of the stake, so it is at the saturation point, while Bob’s pool is at 19%. A prospective pool member, Charlie, holds 1% of the stake and considers which pool to join. Joining Alice’s pool will bring its total stake to 21%, and because it has exceeded the saturation point the reward will be 200 coins (20% of the total rewards). Deducting operational costs will leave 175 coins to be distributed between Alice and the pool members. After removing Alice’s profit margin and considering Charlie’s relative stake in the pool, he will receive 8 coins as a reward. If Charlie joins Bob’s pool, the total rewards will be 200 coins, or 170 coins after removing the operational costs. However, given that Charlie’s stake is 5% (1/20) of the pool, it turns out that he will receive 2% more coins than if he had joined Alice’s pool. So Charlie will join Bob’s pool if he wants to maximize his rewards. \n\nNow, let us see what happens in the case that Charlie is facing the same decision at a hypothetical earlier stage of the whole process when Alice’s pool was already at 20% of the total stake, while Bob’s pool was only at 3%. In this case, Bob has a very small pool and the total rewards available for its members are much less compared with the previous case. As a result, if Charlie did the same calculation for Bob’s pool, his 1% stake would result in a 4% total stake for the pool but, if one does the calculations, he would receive a mere 30% of the rewards that he would have obtained had he joined Alice’s pool. In such a case, the rational decision is to join Alice’s pool despite the fact that his membership will make Alice’s pool exceed the saturation point. Refer to Table 1 below for the exact figures. \n\n<figure class="">\n<img src="https://ucarecdn.com/fcf073c9-fe00-4765-be05-a6303c28a31a/-/resize/1500/" alt="" class="" width="100%" />\n<figcaption>Table 1. Charlie who holds 1% of the total stake, is considering joining pools run by Alice, Bob, Brenda and Ben. His reward is calculated in coins for joining each one. The total reward pool is 1,000 and the saturation point is 20%.</figcaption>\n</figure>\n\n## Being far-sighted matters\n\nThe above appears to be contradictory. To understand what Charlie needs to do we have to appreciate the following fact. The choice of Charlie to join Alice’s pool in the second scenario is only rational in a very near-sighted (aka myopic) sense. In fact, Charlie is better off with Bob’s pool, as is demonstrated by the first scenario, as long as Bob’s pool reaches the saturation point. Thus, if Charlie believes that Bob’s pool will reach the saturation point, the rational choice should be to support it. Other stakeholders will do the same and thus Bob’s pool will rapidly reach the saturation point making everyone that participated in it better off, while also supporting the ideal of decentralization: Alice’s pool instead of constantly growing larger will stop at the saturation point and other pools will be given the ability to grow to the same size. This type of strategic thinking on behalf of the stakeholders is more far-sighted (aka non-myopic) and, as we will see, has the ability to help parties converge to desirable decentralized configurations for the system. \n\nIt is worth noting that it is unavoidable that the system in its evolution will reach pivotal moments where it will be crucial for stakeholders to exercise far-sighted thinking, as in the scenario above where Alice’s pool reaches the saturation point while other pools are still quite small. The reason is that due to the particular circumstances of each stake pool manager, the operational costs will be variable across the stakeholder population. As a result, it is to be expected that starting from a point zero where no stake pools exist, the pool with the lowest operational cost will be also the one that will be the first to grow. This is natural since low operational costs leave a higher level of rewards to be split among the pool members. It is to be expected that the system will reach moments like the second scenario above where the most competitive pool (the one of Alice with operational cost 25) has reached saturation point while the second-most competitive (the one of Bob with operational cost 30) is still at a small membership level. \n\nOne might be tempted to consider long-term thinking in the setting of a Bitcoin-like reward sharing schemes and believe that it can also help to converge to decentralization. Unfortunately, this is not the case. In a Bitcoin-like scheme, contrary to our reward-sharing scheme with a saturation point, there is no point in the development of Alice’s and Bob’s pools when Bob’s pool will become more attractive in Charlie’s view. Indeed, without a saturation point, Alice’s bigger pool will always offer more rewards to Charlie: this stems from the fact that the operational costs of Alice are smaller and hence leave more rewards for all the stakeholders. This will leave Bob’s pool without any members, and eventually, as discussed above, it will be the rational choice for Bob also to dissolve his pool and join Alice’s, making Alice the system’s dictator. \n\nGoing back to our reward-sharing scheme, we have established that non-myopic strategic thinking promotes decentralization; nevertheless, there is an important point still open. At a pivotal moment, when the non-myopic stakeholder Charlie rationally decides to forgo the option to join Alice’s saturated pool, he may have a number of aspiring pools to choose from. For instance, together with Bob’s pool that has operational costs of 30 and profit margin 4%, there could be a pool by Brenda with operational cost of 33 and profit margin 2%, and a pool by Ben with operational cost of 36 and profit margin 1%. The rational choice would be to go with the one that will reach the saturation point; is there a way to tell which one would be the best choice? In our [full analysis paper](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org") we provide an explicit mechanism that orders the pools according to their desirability and, using the information recorded in the ledger about each stake pool, it can assist stakeholders in making the best possible choice at any given moment. In our example, it is Brenda’s pool that Charlie should join if he wants to maximize his rewards (see Table 1). To aid Cardano users, the pool-sorting mechanism will be built into Daedalus (and other Cardano-compatible wallets) and will provide a visual representation of the best choices available to stakeholders using the information in the ledger regarding pool registrations. \n\n## Experimental evaluation\n\nSo how does our reward scheme fare with respect to decentralization? In the [full analysis paper](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org") we prove that there is a class of decentralized system configurations that are “non-myopic Nash equilibria.” An equilibrium strategy here means that stakeholders have a specific way to create pools, set their profit margins and/or delegate to other pools, so that no stakeholder, thinking for the long term, is better off following a different strategy. Moreover, we demonstrate experimentally that reactive play between stakeholders with non-myopic thinking converges to this equilibrium in a small number of iterations, as shown in Figure 2.\n\n<figure class="">\n<img src="https://ucarecdn.com/6ead3506-7d9f-4eac-a56e-5a72542e643a/-/resize/1500/" alt="" class="" width="100%" />\n<figcaption>Figure 2. Decentralization as exhibited by our reward-sharing scheme in a simulation with 100 stakeholders and 10% saturation point. Pools are gradually created by the stakeholders. Taking turns, the stakeholders attempt to maximise their payoff non-myopically leading to a final convergence point where 10 pools exist, each with an equal share of the total stake. At the final point, no rational stakeholder wishes to change the state of the system.</figcaption>\n</figure>\n<br>\n\nA characteristic of our approach is that the number of pools is only part of the description of the reward-sharing scheme and thus is in no way enforced by the system on the stakeholders. This means stakeholders are free to experiment with pool creation and delegation of stake without having to conform to any predetermined system architecture. This is in contrast to other approaches taken in PoS systems such as [EOS](https://eos.io/documents/EOS_An_Introduction.pdf "EOS - An Introduction, eos.io") where the number of participants is a hardcoded parameter of the consensus system (specifically, 21 pools). At the same time, our approach allows the whole stakeholder set to to express its will, by freely joining and leaving pools, receiving guaranteed rewards for their participation while witnessing how their actions have a quantifiable impact on the management of the PoS distributed ledger no matter the size of their stake. This is contrast to other approaches taken in PoS systems such as [Ethereum 2.0](https://github.com/ethereum/eth2.0-specs "eth2.0-specs, github.com") where ledger maintenance is performed by registered validators on the basis of a collateral deposit without a built-in process of vetting by the stakeholder set. \n\nSo what would be a sensible choice for the number of pools that should be favored by the reward scheme for Cardano? Given that decentralization is our main objective, it is sensible to set this parameter to be as high as possible. Our network experiments showed that the system can still operate effectively with as many as 1,000 running pools. Choosing a saturation threshold for our reward-sharing scheme based on this number will make having a stake pool profitable even if the total stake delegated in them is as little as 0.1% of the total circulation of Ada.\n\n## Looking ahead – Sybil attacks\n\nGiven that decentralization can be achieved by a large number of independent stake pools, it is also important to see whether some decentralized system configurations are more preferable than others. As described so far in this post, our reward-sharing scheme will lead rational stakeholders towards promoting the stake pools that will incur the smallest total cost. Even though this maximizes rewards and minimizes costs, it may not be necessarily the most desirable outcome. The reason is that in the equilibrium point one may see a set of stakeholders promoted as stake pool managers who possess collectively a very small stake themselves. This imbalance, in which a small total stake represents the total stake of the system, can be detrimental in many ways: stake pool managers may be prone to corruption or bribery, or, perhaps even worse, a large stake holder may register many stake pools in the hope of controlling the whole ecosystem, performing in this way a [Sybil attack](https://en.wikipedia.org/wiki/Sybil_attack "Sybil attack, wikipedia.org") that would hurt decentralization. For this reason, the reward-sharing scheme as presented in our [full analysis paper](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org") is suitably modified to be sensitive to the stake backing the pool so that this type of behaviour is mitigated. We will delve deeper into this aspect of Cardano reward-sharing in the next blog post.\n\n<small>Artwork, [<img src="https://ucarecdn.com/e711abaa-8d67-4630-bdf5-b9172a104689/-/resize/12/" alt="Creative Commons" />](https://creativecommons.org/licenses/by/4.0/ "Creative Commons") [Mike Beeple](http://www.beeple-crap.com)</small>',
                                uses_mathjax: null,
                                attachments: [],
                                slug: 'stake-pools-in-cardano',
                                url: '/blog/posts/2018/10/23/stake-pools-in-cardano/',
                                read_time: 17
                            },
                            {
                                publish_date: '2018-08-09',
                                author: null,
                                video_id: '',
                                main_image: 'https://ucarecdn.com/8ba04e85-335b-4651-b03f-91b3ed552c01/',
                                custom_meta_img: null,
                                old_url: '/blog/how-does-casper-compare-to-ouroboros/',
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'How does Casper compare to Ouroboros?',
                                        subtitle: 'Differences between the proposed Ethereum protocols and Cardano’s consensus algorithm',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: '**TL;DR**\nIn response to recent discussions in social media, we give a brief comparison of the Ouroboros and Casper proof-of-stake protocols.\n\nOuroboros is a formally specified and analysed protocol with mathematically proven security guarantees based on clearly specified assumptions. The protocol description, models and proofs are all public. Hence, the underlying assumptions, the target protocol properties, and the respective correctness proofs can be publicly scrutinised. Ouroboros offers stake-based finality with the strongest possible guarantees in terms of the amount of stake backing up honest operation. It also provides a solid foundation over which services such as near instant finality of transactions can be offered in optimistic network conditions.\n\nRegarding Casper, we are not aware of any currently published source that sufficiently describes the protocol\'s mode of operation nor any provable guarantees about it. Still, from what has been presented about Casper until now, as compared to Ouroboros, we can safely conclude that Casper provides much weaker guarantees in terms of how much stake the adversary needs to control in order to disrupt the protocol. Below, we compare the two protocols along several dimensions; for lack of proper documentation, many properties of Casper have to be assumed to the best of our knowledge.\n\n<hr>\n\nIn response to a discussion [here](https://www.reddit.com/r/ethereum/comments/92f1u0/eli30_differences_between_casper_and_ouroboros/ "Differences between Casper and Ouroboros, Reddit") and [here](https://www.reddit.com/r/cardano/comments/92r3si/vitalik_allegations_against_ouroboros/ "Vitalik allegations against Ouroboros, Reddit"), we give a brief comparison of the Ouroboros proof-of-stake (PoS) protocol and Casper PoS. For Ouroboros, we refer to the [original version](https://eprint.iacr.org/2016/889 "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, eprint") underlying the Cardano Settlement Layer (published at [Crypto 2017](https://www.iacr.org/conferences/crypto2017/ "Crypto 2017, iacr.org")), however most of our comments apply to later versions [Ouroboros Praos](https://eprint.iacr.org/2017/573 "Ouroboros Praos: An adaptively-secure, semi-synchronous proof-of-stake protocol, eprint") and [Ouroboros Genesis](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint") as well. For Casper, we primarily refer to the Casper Friendly Finality Gadget (FFG) as described in the [white paper](https://arxiv.org/abs/1710.09437 "Casper the Friendly Finality Gadget, arxiv.org"), being the most recent Casper proposal that is sufficiently descriptive to draw a full comparison (other references include [Ethereum Mauve](https://docs.google.com/document/d/1maFT3cpHvwn29gLvtY4WcQiI6kRbN_nbCf3JlgR3m_8/edit "Ethereum 2.0 Mauve Paper"), [Casper+Sharding v2.1, FFG-RPJ](https://notes.ethereum.org/SCIg8AH5SA-O4C1G1LYZHQ?view "Casper+Sharding chain v2.1, ethereum.org"), [Casper TBG/CBC](https://github.com/ethereum/research/blob/master/papers/CasperTFG/CasperTFG.pdf "Casper the Friendly Ghost, github.com")). \n\nAny PoS ledger consensus protocol should satisfy two fundamental properties: persistence and liveness. The first ensures that the ledger is final and immutable. The second ensures that transactions broadcasted by honest parties are eventually included in the (immutable) ledger. Such properties, typically, cannot be proven unconditionally: they will rely on certain conditions, some of them cryptographic, e.g., that digital signatures cannot be forged, while others are related to the behaviour of the participants, e.g., that the players who follow the protocol control a majority of the stake. There are other desirable properties that a PoS protocol should satisfy (such as that executing the protocol as prescribed is the only rational strategy for the participants), but persistence and liveness as defined above constitute the bare minimum pair of fundamental properties necessary for ledger consensus. \n\nLet us now discuss some of the differences between the two protocols and their analyses.\n\n### Execution Model and [Falsifiability](https://en.wikipedia.org/wiki/Falsifiability "Falsifiability, wikipedia.org") of Claims\n\nThe Ouroboros protocol is analyzed in a model that is fully described: it unambiguously defines all the participants’ programs, their execution and interactions, their communication – including network properties – and the potential corruption by an adversarial entity of any set of parties controlling a minority of the stake. Such a model allows the formulation of mathematically precise security guarantees satisfied by any execution, such as the persistence and liveness properties proven for Ouroboros. In particular, the formal modeling of Ouroboros permits precise, quantitative statements about stake bounds and settlement times; see below. **This makes all the claims we make about Ouroboros entirely concrete; there is nothing left up to interpretation or reader perspective.** Without such a model (notably missing in the Casper FFG white paper or in any other available sources related to Casper), it is impossible to prove the correctness of any claims about the protocol. Consensus protocols, in general, are complex objects; designing them without the development of rigorous mathematical arguments that establish the required properties can prove to be precarious as prior practice in secure systems design has shown. Good design intuition and best effort are just not sufficient when a ledger consensus protocol is supposed to carry assets worth billions.\n\n### A comprehensive solution to PoS ledger consensus\n\nGiven the above, it is important to appreciate that the Ouroboros protocol is proven to provide persistence and liveness under clearly defined assumptions such as honest stake majority which is the bare minimum assumption needed in the PoS setting. On the other hand, Casper FFG, as described in the white paper, is an enhancement on top of a pre-existing “block proposal mechanism”, e.g., a PoW blockchain (namely Ethereum); in particular, its security guarantees as a ledger consensus protocol depend on the security of this proposal mechanism. As the authors of Casper FFG observe, “a wholly compromised block proposal mechanism will prevent Casper from finalizing new blocks”, hence the honest-majority-of-hashing power assumption is still necessary for Casper FFG’s liveness. Similarly, other versions of the Casper protocol, such as Casper FFG-RPJ, are incomplete and/or not accompanied by any proofs of security.\n\n### Stake Assumptions \n\nOuroboros is proven to achieve persistence and liveness under the assumption of honest majority of all stake in the system, even in the case that some significant portions of stakeholders are not participating in the protocol (see e.g., Theorem 1 in the [Ouroboros Genesis](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint") paper for the most comprehensive statement on Ouroboros security). In contrast, Casper requires a ⅔-fraction of deposited stake to be controlled by honest parties (see section 2.1 of the [white paper](https://arxiv.org/abs/1710.09437 "Casper the Friendly Finality Gadget, arxiv.org")). Since the deposited stake is blocked and cannot be used for other purposes in the meantime, it is reasonable to assume that the deposited stake will be a small fraction of the total stake in the system. Naturally, larger amounts of stake are more difficult to control so that basing security on the total stake in the system, as in Ouroboros, is a more prudent choice. As a concrete example, in the current sharded version of Ethereum (Ethereum Mauve paper or Casper+Sharding chain v2.1), a minimum of 32 ETH per validator is required with 100-128 validators per shard depending on the reference, without any other restriction. It follows that if the total deposited stake among all prospective validators turns out to be minimal and is not otherwise restricted then just a few thousand ETH would be enough to register a set of [sybil](https://en.wikipedia.org/wiki/Sybil_attack "Sybil Attack, wikipedia.org") validators that could disrupt the ledger consensus security properties.\n\n### Finality\n\nThough the notion is not formally defined in the Casper FFG white paper, it is easy to see that the property of “stake-based finality” is subsumed by persistence, the property that ensures that transactions become permanently part of the public immutable ledger; the stake-based adjective on finality used in Casper FFG refers to the fact that the condition under which finality is to be attained is based on stake as opposed to, e.g., a hashing power assumption. As mentioned above, no protocol can be deemed to solve the ledger consensus problem without providing persistence (and hence finality). In fact, all PoS protocols provide such properties only with a high probability – if for no other reason, cryptography can always fail with (very) small probability (for example, someone may guess your key). We do in fact know that Bitcoin and (pre-Casper) Ethereum provide finality (shown by the works of [GKL15](https://eprint.iacr.org/2014/765 "The Bitcoin Backbone Protocol: Analysis and Applications, eprint"), [GKL17](https://eprint.iacr.org/2016/1048 "The Bitcoin Backbone Protocol with Chains of Variable Difficulty") and [PSS17](https://eprint.iacr.org/2016/454 "Analysis of the Blockchain Protocol in Asynchronous Networks")) assuming honest majority of computational power), and so does Ouroboros, assuming honest majority of stake as shown in [KRDO17](https://eprint.iacr.org/2016/889 "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, eprint"), [DGKR18](https://eprint.iacr.org/2017/573 "Ouroboros Praos: An adaptively-secure, semi-synchronous proof-of-stake protocol, eprint"), [BGKRZ18](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint").\n\n**Put simply, Ouroboros provides stake-based finality** and it does so with the strongest possible guarantee in terms of stake: against a malicious coalition controlling any amount of the total stake existing in the system as long as it is bounded below 50%. In the Casper FFG white paper, where Casper operates over the Ethereum blockchain, stake-based finality is provided every 100 blocks under the assumption that ⅔ of the deposited stake is honest. As a concrete example, in the same window of time, which is a little over half an hour in our current deployment, we can derive from our formal analysis that Ouroboros will offer finality against, say, a 10% stake adversary with probability of error less than 2^(-44). This is less than 1/10000000000000, one over ten trillion. To appreciate such small numbers, consider that it is expected to have one large asteroid hit the earth once every 100 million years ([Scientific American](https://www.scientificamerican.com/article/what-is-the-chance-of-an/ "What is the chance of an asteroid hitting Earth and how do astronomers calculate it?, scientificamerican.com")). Thus, it is 10 thousand times more likely that a big asteroid will hit the earth next month than that Ouroboros will reorganise its chain to drop a particular transaction after it has been included in the ledger for about half an hour.\n\n### Eventual Consensus vs. (near-)Instant finality \nBlockchain protocols like Bitcoin and Ouroboros are called eventual-consensus since they ensure that the irreversibility of a block increases gradually with the number of blocks that are added on top of it. This means that finality is more nuanced than just a true or false value, and is quantified by the probability of reverting a transaction as a function of the strength of the adversary and the length of time that has passed since the block containing that transaction was added. This design enables these protocols to work in the strongest possible adversarial settings and still be very efficient in terms of the number of messages that need to be exchanged; furthermore, they have the feature that the recipient of a transaction can decide for herself how important a transaction is and adjust her own notions of stability per transaction. Their downside is that they do not provide near-instant finality, or in other words, a fast assurance that the transaction will be finalised. This may be a potential advantage of classical BFT protocols that have inspired the design of Casper FFG as well as other protocols in the space including Algorand.\n\nHowever, near-instant finality typically also comes with significant downsides in terms of the security model such as a much higher requirement of honest stake or, perhaps more importantly, a high degree of guaranteed online presence that must be offered by the participants following the protocol. This hurts the dynamic availability of the participants (see below) which is one of the hallmarks of the bitcoin era of consensus protocols. On the other hand, near-instant finality can be built as a service on top of Ouroboros and this is something that we will be releasing in due course. Moreover, we can argue that this is the best possible way forward: use the Ouroboros eventual consensus protocol which is secure under the strongest possible stake-based guarantees as the solid foundation over which services such as near-instant settlement in optimistic network conditions can be safely built.\n\n### Incentives and dynamic availability \n\nCasper FFG is inspired by pre-Bitcoin era standard BFT consensus protocols and as such it cannot handle uncertainty in terms of the number of participating entities once the set of validators becomes fixed. This means that the protocol cannot operate in the “[sleepy setting](https://eprint.iacr.org/2016/918 "The Sleepy Model of Consensus, eprint")” and “[dynamic availability](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint")” setting, where a significant number of parties that are supposed to act in the protocol are unavailable due to network conditions, hardware failure or simply lack of interest. This is a significant concern in a decentralized setting where the execution of the protocol is not meant to be left in the hands of a few centralized-power actors, but is rather distributed proportionally among a great number of smaller players. The Casper-FFG white paper acknowledges this as the “Catastrophic Crash” scenario and observes that in this case “no future checkpoints can be finalized”. The authors propose a mitigation in the form of the so-called “inactivity leak.” This idea is only described informally as draining “the deposit of any validator that does not vote for checkpoints, until eventually its deposit sizes decrease low enough that the validators who are voting are a supermajority.” Unfortunately, this modification would in turn negate any potential advantage Casper can claim in face of network splits, as the authors also recognise: “The inactivity leak introduces the possibility of two conflicting checkpoints being finalized without any validator getting slashed.” This also affects the incentives running the protocol. Ouroboros allows for a natural and incentive-driven aggregation of stake into stake pools that will be performed over a period of time using our [stake pool reward mechanism](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org"), without forcing the behaviour of stakeholders onto a predetermined structure, while Casper has to impose preset numbers of block validators. \n\n### Randomness\n\nWhile the original Ouroboros protocol does not use VRFs to generate protocol randomness (instead it uses a guaranteed-output-delivery coin-tossing protocol based on verifiable secret-sharing), the follow-up versions Praos and Genesis do so for performance gains. The VRFs proposed for use in Ouroboros Praos and Genesis are proven secure under standard cryptographic assumptions (such as the [Computational Diffie Hellman assumption](https://en.wikipedia.org/wiki/Computational_Diffie%E2%80%93Hellman_assumption "Computational Diffie Hellman assumption, wikipedia.org")) while the security analysis we have performed ensures Ouroboros’ resilience to randomness manipulation (see [Ouroboros Praos](https://eprint.iacr.org/2017/573 "Ouroboros Praos: An adaptively-secure, semi-synchronous proof-of-stake protocol, eprint") and [Ouroboros Genesis](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint")). \n\n### Network Assumptions\n\nOuroboros is analysed in the “partially synchronous” setting where messages are delivered to the majority of the parties executing the protocol within a time window upper bounded by a network delay Δ which is unknown to the parties. The order of messages is adversarial and it is not guaranteed that two honest parties will receive messages in the same order. The adversary is allowed to inject arbitrary messages selectively to any of the parties. Casper makes no explicit claims about the network setting it operates in, nevertheless, when describing defenses against long range revisions it alludes to a similar type of model.\n\n### Sharding\n\nThis property refers to the ability of a database or ledger consensus protocol to scale its processing power as more nodes (or processing capacity) enter the system, ideally with a linear speedup in the number of nodes added. Ouroboros Hydra, the scalable version of Ouroboros is in development and will be released in due time following our usual mode of discourse, i.e., the release of a full paper containing complete mathematical formulations of the problem that we solve, a full description of our protocol solution, as well as concrete statements about the protocol’s properties that are accompanied by all necessary proofs. At present, the version of Casper that enables sharding, ([Casper+Sharding v2.1](https://notes.ethereum.org/SCIg8AH5SA-O4C1G1LYZHQ?view "Casper+Sharding chain v2.1, ethereum.org")), is incomplete even in terms of protocol description, and as such, it cannot allow any proof of security. \n\n[Learn more about Ouroboros](https://www.youtube.com/watch?v=Nlmv4fg4NQk&list=PLnPTB0CuBOBw9H7dynFu9U25vqFWRw1UX "Ouroboros: A Provably Secure Proof-of-Stake YouTube").\n\n\n*Team effort is a hallmark of IOHK research and this blog post is no exception. I am grateful to Christian Badertscher, Matthias Fitzi, Peter Gaži, Alexander Russell, Jeremy Wood, and Vassilis Zikas for various suggestions, comments, and corrections to the above text.*\n\n<small>Artwork, <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank"><img src="https://ucarecdn.com/e711abaa-8d67-4630-bdf5-b9172a104689/-/resize/12/" alt="Creative Commons" /> <a href="http://www.beeple-crap.com">Mike Beeple</a>',
                                        uses_mathjax: null,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'How does Casper compare to Ouroboros?',
                                subtitle: 'Differences between the proposed Ethereum protocols and Cardano’s consensus algorithm',
                                audio: null,
                                soundcloud: null,
                                body_content: '**TL;DR**\nIn response to recent discussions in social media, we give a brief comparison of the Ouroboros and Casper proof-of-stake protocols.\n\nOuroboros is a formally specified and analysed protocol with mathematically proven security guarantees based on clearly specified assumptions. The protocol description, models and proofs are all public. Hence, the underlying assumptions, the target protocol properties, and the respective correctness proofs can be publicly scrutinised. Ouroboros offers stake-based finality with the strongest possible guarantees in terms of the amount of stake backing up honest operation. It also provides a solid foundation over which services such as near instant finality of transactions can be offered in optimistic network conditions.\n\nRegarding Casper, we are not aware of any currently published source that sufficiently describes the protocol\'s mode of operation nor any provable guarantees about it. Still, from what has been presented about Casper until now, as compared to Ouroboros, we can safely conclude that Casper provides much weaker guarantees in terms of how much stake the adversary needs to control in order to disrupt the protocol. Below, we compare the two protocols along several dimensions; for lack of proper documentation, many properties of Casper have to be assumed to the best of our knowledge.\n\n<hr>\n\nIn response to a discussion [here](https://www.reddit.com/r/ethereum/comments/92f1u0/eli30_differences_between_casper_and_ouroboros/ "Differences between Casper and Ouroboros, Reddit") and [here](https://www.reddit.com/r/cardano/comments/92r3si/vitalik_allegations_against_ouroboros/ "Vitalik allegations against Ouroboros, Reddit"), we give a brief comparison of the Ouroboros proof-of-stake (PoS) protocol and Casper PoS. For Ouroboros, we refer to the [original version](https://eprint.iacr.org/2016/889 "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, eprint") underlying the Cardano Settlement Layer (published at [Crypto 2017](https://www.iacr.org/conferences/crypto2017/ "Crypto 2017, iacr.org")), however most of our comments apply to later versions [Ouroboros Praos](https://eprint.iacr.org/2017/573 "Ouroboros Praos: An adaptively-secure, semi-synchronous proof-of-stake protocol, eprint") and [Ouroboros Genesis](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint") as well. For Casper, we primarily refer to the Casper Friendly Finality Gadget (FFG) as described in the [white paper](https://arxiv.org/abs/1710.09437 "Casper the Friendly Finality Gadget, arxiv.org"), being the most recent Casper proposal that is sufficiently descriptive to draw a full comparison (other references include [Ethereum Mauve](https://docs.google.com/document/d/1maFT3cpHvwn29gLvtY4WcQiI6kRbN_nbCf3JlgR3m_8/edit "Ethereum 2.0 Mauve Paper"), [Casper+Sharding v2.1, FFG-RPJ](https://notes.ethereum.org/SCIg8AH5SA-O4C1G1LYZHQ?view "Casper+Sharding chain v2.1, ethereum.org"), [Casper TBG/CBC](https://github.com/ethereum/research/blob/master/papers/CasperTFG/CasperTFG.pdf "Casper the Friendly Ghost, github.com")). \n\nAny PoS ledger consensus protocol should satisfy two fundamental properties: persistence and liveness. The first ensures that the ledger is final and immutable. The second ensures that transactions broadcasted by honest parties are eventually included in the (immutable) ledger. Such properties, typically, cannot be proven unconditionally: they will rely on certain conditions, some of them cryptographic, e.g., that digital signatures cannot be forged, while others are related to the behaviour of the participants, e.g., that the players who follow the protocol control a majority of the stake. There are other desirable properties that a PoS protocol should satisfy (such as that executing the protocol as prescribed is the only rational strategy for the participants), but persistence and liveness as defined above constitute the bare minimum pair of fundamental properties necessary for ledger consensus. \n\nLet us now discuss some of the differences between the two protocols and their analyses.\n\n### Execution Model and [Falsifiability](https://en.wikipedia.org/wiki/Falsifiability "Falsifiability, wikipedia.org") of Claims\n\nThe Ouroboros protocol is analyzed in a model that is fully described: it unambiguously defines all the participants’ programs, their execution and interactions, their communication – including network properties – and the potential corruption by an adversarial entity of any set of parties controlling a minority of the stake. Such a model allows the formulation of mathematically precise security guarantees satisfied by any execution, such as the persistence and liveness properties proven for Ouroboros. In particular, the formal modeling of Ouroboros permits precise, quantitative statements about stake bounds and settlement times; see below. **This makes all the claims we make about Ouroboros entirely concrete; there is nothing left up to interpretation or reader perspective.** Without such a model (notably missing in the Casper FFG white paper or in any other available sources related to Casper), it is impossible to prove the correctness of any claims about the protocol. Consensus protocols, in general, are complex objects; designing them without the development of rigorous mathematical arguments that establish the required properties can prove to be precarious as prior practice in secure systems design has shown. Good design intuition and best effort are just not sufficient when a ledger consensus protocol is supposed to carry assets worth billions.\n\n### A comprehensive solution to PoS ledger consensus\n\nGiven the above, it is important to appreciate that the Ouroboros protocol is proven to provide persistence and liveness under clearly defined assumptions such as honest stake majority which is the bare minimum assumption needed in the PoS setting. On the other hand, Casper FFG, as described in the white paper, is an enhancement on top of a pre-existing “block proposal mechanism”, e.g., a PoW blockchain (namely Ethereum); in particular, its security guarantees as a ledger consensus protocol depend on the security of this proposal mechanism. As the authors of Casper FFG observe, “a wholly compromised block proposal mechanism will prevent Casper from finalizing new blocks”, hence the honest-majority-of-hashing power assumption is still necessary for Casper FFG’s liveness. Similarly, other versions of the Casper protocol, such as Casper FFG-RPJ, are incomplete and/or not accompanied by any proofs of security.\n\n### Stake Assumptions \n\nOuroboros is proven to achieve persistence and liveness under the assumption of honest majority of all stake in the system, even in the case that some significant portions of stakeholders are not participating in the protocol (see e.g., Theorem 1 in the [Ouroboros Genesis](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint") paper for the most comprehensive statement on Ouroboros security). In contrast, Casper requires a ⅔-fraction of deposited stake to be controlled by honest parties (see section 2.1 of the [white paper](https://arxiv.org/abs/1710.09437 "Casper the Friendly Finality Gadget, arxiv.org")). Since the deposited stake is blocked and cannot be used for other purposes in the meantime, it is reasonable to assume that the deposited stake will be a small fraction of the total stake in the system. Naturally, larger amounts of stake are more difficult to control so that basing security on the total stake in the system, as in Ouroboros, is a more prudent choice. As a concrete example, in the current sharded version of Ethereum (Ethereum Mauve paper or Casper+Sharding chain v2.1), a minimum of 32 ETH per validator is required with 100-128 validators per shard depending on the reference, without any other restriction. It follows that if the total deposited stake among all prospective validators turns out to be minimal and is not otherwise restricted then just a few thousand ETH would be enough to register a set of [sybil](https://en.wikipedia.org/wiki/Sybil_attack "Sybil Attack, wikipedia.org") validators that could disrupt the ledger consensus security properties.\n\n### Finality\n\nThough the notion is not formally defined in the Casper FFG white paper, it is easy to see that the property of “stake-based finality” is subsumed by persistence, the property that ensures that transactions become permanently part of the public immutable ledger; the stake-based adjective on finality used in Casper FFG refers to the fact that the condition under which finality is to be attained is based on stake as opposed to, e.g., a hashing power assumption. As mentioned above, no protocol can be deemed to solve the ledger consensus problem without providing persistence (and hence finality). In fact, all PoS protocols provide such properties only with a high probability – if for no other reason, cryptography can always fail with (very) small probability (for example, someone may guess your key). We do in fact know that Bitcoin and (pre-Casper) Ethereum provide finality (shown by the works of [GKL15](https://eprint.iacr.org/2014/765 "The Bitcoin Backbone Protocol: Analysis and Applications, eprint"), [GKL17](https://eprint.iacr.org/2016/1048 "The Bitcoin Backbone Protocol with Chains of Variable Difficulty") and [PSS17](https://eprint.iacr.org/2016/454 "Analysis of the Blockchain Protocol in Asynchronous Networks")) assuming honest majority of computational power), and so does Ouroboros, assuming honest majority of stake as shown in [KRDO17](https://eprint.iacr.org/2016/889 "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, eprint"), [DGKR18](https://eprint.iacr.org/2017/573 "Ouroboros Praos: An adaptively-secure, semi-synchronous proof-of-stake protocol, eprint"), [BGKRZ18](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint").\n\n**Put simply, Ouroboros provides stake-based finality** and it does so with the strongest possible guarantee in terms of stake: against a malicious coalition controlling any amount of the total stake existing in the system as long as it is bounded below 50%. In the Casper FFG white paper, where Casper operates over the Ethereum blockchain, stake-based finality is provided every 100 blocks under the assumption that ⅔ of the deposited stake is honest. As a concrete example, in the same window of time, which is a little over half an hour in our current deployment, we can derive from our formal analysis that Ouroboros will offer finality against, say, a 10% stake adversary with probability of error less than 2^(-44). This is less than 1/10000000000000, one over ten trillion. To appreciate such small numbers, consider that it is expected to have one large asteroid hit the earth once every 100 million years ([Scientific American](https://www.scientificamerican.com/article/what-is-the-chance-of-an/ "What is the chance of an asteroid hitting Earth and how do astronomers calculate it?, scientificamerican.com")). Thus, it is 10 thousand times more likely that a big asteroid will hit the earth next month than that Ouroboros will reorganise its chain to drop a particular transaction after it has been included in the ledger for about half an hour.\n\n### Eventual Consensus vs. (near-)Instant finality \nBlockchain protocols like Bitcoin and Ouroboros are called eventual-consensus since they ensure that the irreversibility of a block increases gradually with the number of blocks that are added on top of it. This means that finality is more nuanced than just a true or false value, and is quantified by the probability of reverting a transaction as a function of the strength of the adversary and the length of time that has passed since the block containing that transaction was added. This design enables these protocols to work in the strongest possible adversarial settings and still be very efficient in terms of the number of messages that need to be exchanged; furthermore, they have the feature that the recipient of a transaction can decide for herself how important a transaction is and adjust her own notions of stability per transaction. Their downside is that they do not provide near-instant finality, or in other words, a fast assurance that the transaction will be finalised. This may be a potential advantage of classical BFT protocols that have inspired the design of Casper FFG as well as other protocols in the space including Algorand.\n\nHowever, near-instant finality typically also comes with significant downsides in terms of the security model such as a much higher requirement of honest stake or, perhaps more importantly, a high degree of guaranteed online presence that must be offered by the participants following the protocol. This hurts the dynamic availability of the participants (see below) which is one of the hallmarks of the bitcoin era of consensus protocols. On the other hand, near-instant finality can be built as a service on top of Ouroboros and this is something that we will be releasing in due course. Moreover, we can argue that this is the best possible way forward: use the Ouroboros eventual consensus protocol which is secure under the strongest possible stake-based guarantees as the solid foundation over which services such as near-instant settlement in optimistic network conditions can be safely built.\n\n### Incentives and dynamic availability \n\nCasper FFG is inspired by pre-Bitcoin era standard BFT consensus protocols and as such it cannot handle uncertainty in terms of the number of participating entities once the set of validators becomes fixed. This means that the protocol cannot operate in the “[sleepy setting](https://eprint.iacr.org/2016/918 "The Sleepy Model of Consensus, eprint")” and “[dynamic availability](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint")” setting, where a significant number of parties that are supposed to act in the protocol are unavailable due to network conditions, hardware failure or simply lack of interest. This is a significant concern in a decentralized setting where the execution of the protocol is not meant to be left in the hands of a few centralized-power actors, but is rather distributed proportionally among a great number of smaller players. The Casper-FFG white paper acknowledges this as the “Catastrophic Crash” scenario and observes that in this case “no future checkpoints can be finalized”. The authors propose a mitigation in the form of the so-called “inactivity leak.” This idea is only described informally as draining “the deposit of any validator that does not vote for checkpoints, until eventually its deposit sizes decrease low enough that the validators who are voting are a supermajority.” Unfortunately, this modification would in turn negate any potential advantage Casper can claim in face of network splits, as the authors also recognise: “The inactivity leak introduces the possibility of two conflicting checkpoints being finalized without any validator getting slashed.” This also affects the incentives running the protocol. Ouroboros allows for a natural and incentive-driven aggregation of stake into stake pools that will be performed over a period of time using our [stake pool reward mechanism](https://arxiv.org/abs/1807.11218 "Reward Sharing Schemes for Stake Pools, arxiv.org"), without forcing the behaviour of stakeholders onto a predetermined structure, while Casper has to impose preset numbers of block validators. \n\n### Randomness\n\nWhile the original Ouroboros protocol does not use VRFs to generate protocol randomness (instead it uses a guaranteed-output-delivery coin-tossing protocol based on verifiable secret-sharing), the follow-up versions Praos and Genesis do so for performance gains. The VRFs proposed for use in Ouroboros Praos and Genesis are proven secure under standard cryptographic assumptions (such as the [Computational Diffie Hellman assumption](https://en.wikipedia.org/wiki/Computational_Diffie%E2%80%93Hellman_assumption "Computational Diffie Hellman assumption, wikipedia.org")) while the security analysis we have performed ensures Ouroboros’ resilience to randomness manipulation (see [Ouroboros Praos](https://eprint.iacr.org/2017/573 "Ouroboros Praos: An adaptively-secure, semi-synchronous proof-of-stake protocol, eprint") and [Ouroboros Genesis](https://eprint.iacr.org/2018/378 "Ouroboros Genesis: Composable Proof-of-Stake Blockchains with Dynamic Availability, eprint")). \n\n### Network Assumptions\n\nOuroboros is analysed in the “partially synchronous” setting where messages are delivered to the majority of the parties executing the protocol within a time window upper bounded by a network delay Δ which is unknown to the parties. The order of messages is adversarial and it is not guaranteed that two honest parties will receive messages in the same order. The adversary is allowed to inject arbitrary messages selectively to any of the parties. Casper makes no explicit claims about the network setting it operates in, nevertheless, when describing defenses against long range revisions it alludes to a similar type of model.\n\n### Sharding\n\nThis property refers to the ability of a database or ledger consensus protocol to scale its processing power as more nodes (or processing capacity) enter the system, ideally with a linear speedup in the number of nodes added. Ouroboros Hydra, the scalable version of Ouroboros is in development and will be released in due time following our usual mode of discourse, i.e., the release of a full paper containing complete mathematical formulations of the problem that we solve, a full description of our protocol solution, as well as concrete statements about the protocol’s properties that are accompanied by all necessary proofs. At present, the version of Casper that enables sharding, ([Casper+Sharding v2.1](https://notes.ethereum.org/SCIg8AH5SA-O4C1G1LYZHQ?view "Casper+Sharding chain v2.1, ethereum.org")), is incomplete even in terms of protocol description, and as such, it cannot allow any proof of security. \n\n[Learn more about Ouroboros](https://www.youtube.com/watch?v=Nlmv4fg4NQk&list=PLnPTB0CuBOBw9H7dynFu9U25vqFWRw1UX "Ouroboros: A Provably Secure Proof-of-Stake YouTube").\n\n\n*Team effort is a hallmark of IOHK research and this blog post is no exception. I am grateful to Christian Badertscher, Matthias Fitzi, Peter Gaži, Alexander Russell, Jeremy Wood, and Vassilis Zikas for various suggestions, comments, and corrections to the above text.*\n\n<small>Artwork, <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank"><img src="https://ucarecdn.com/e711abaa-8d67-4630-bdf5-b9172a104689/-/resize/12/" alt="Creative Commons" /> <a href="http://www.beeple-crap.com">Mike Beeple</a>',
                                uses_mathjax: null,
                                attachments: [],
                                slug: 'how-does-casper-compare-to-ouroboros',
                                url: '/blog/posts/2018/08/09/how-does-casper-compare-to-ouroboros/',
                                read_time: 13
                            },
                            {
                                publish_date: '2018-01-11',
                                author: null,
                                video_id: 'JwxVySVF-U4',
                                main_image: '',
                                custom_meta_img: null,
                                old_url: '/blog/on-the-ouroboros-design-how-rigour-and-engineering-are-essential-for-critical-infrastructure/',
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'On the Ouroboros Design: How rigour and engineering are essential for critical infrastructure',
                                        subtitle: '',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'A [blog post](https://steemit.com/cardamon/@dan/peer-review-of-cardano-s-ouroboros "Peer Review of Cardano\'s Ouroboros, steemit.com") on the Steemit website appeared recently making a number of claims regarding [Ouroboros](/research/papers/#9BKRHCSI "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, iohk.io"). The article contains several factual inaccuracies. For instance, it is claimed that “DPOS” in the Ouroboros paper stands for “delegated proof of stake”, while in fact, DPOS means “dynamic proof of stake”, or that the protocol requires a "2/3+" ratio of parties being honest, while in reality it just requires an honest majority, i.e. the stake controlled by parties following the protocol is more than half the total stake.\nFor the benefit of those that are interested in the Ouroboros protocol and who appreciate its general philosophy, we feel it is appropriate to provide here a response to this article making along the way a few broader points. While pointing out inaccuracies in the blog, we take the opportunity to highlight some of the general approaches followed in the design of Ouroboros and in the related research efforts that are currently underway at IOHK.\n \nOuroboros is a proof of stake (PoS) protocol that uses delegation in the spirit of the PoS idea as discussed in the [Bitcoin forum starting from 2011](https://bitcointalk.org/index.php?topic=27787.0 "Proof of stake instead of proof of work, bitcointalk.org"). The references that influenced its design are listed in our paper. PoS is a powerful concept that has inspired a number of other efforts prior, concurrent and post the first Ouroboros paper. Among all other implemented PoS blockchain systems that carry real assets, Ouroboros is unique in that it was designed in tandem with a formal security model and a mathematical proof that it implements a robust transaction ledger. This marks a fundamental shift in the methodology of blockchain system design.\n \nBlockchain systems are in a period of transition from curiosities to critical infrastructure; as such, the all too typical software industry approach of releasing a “minimum viable product” as early as possible and then fixing bugs as they appear, is not appropriate. Failures of critical infrastructure have a significant impact on people’s lives and thus require rigorous engineering discipline to the highest possible standards. Dependability, rather than maximum performance according to some arbitrarily chosen metric, is the primary goal. Performance is important, of course, but the performance required is a function of the ultimate application domain, and from the point of view of dependability it is the worst-case performance that is important, not the ideal-scenario peak rate.\n \nLike all other protocols in the blockchain space, Ouroboros requires some degree of synchronisation. The block production interval has to be consistent with the likely time to complete the required information exchanges. The 20-second slot time in Ouroboros represents a conservative choice for a block of transactions to traverse the diameter of a peer-to-peer network, where the peers may be significantly geographically distributed, the system is operating at peak transaction load and the interconnection is significantly less than perfect. It is improbable for a block of transactions to consistently traverse a global network much faster than that, and as a result any solution that does significantly better (or claims to do significantly better) is either wrong, or provides a weaker level of decentralisation or security, i.e. it solves an easier problem than Ouroboros. There is a tradeoff between achieving a robust, global, participatory service that delivers sustained effective performance even under an adversarial attack, and creating a high performance, limited participation (in geographical scope or network resource requirement) solution that makes overly optimistic assumptions on network stability.\n \nIrreversibility, the property that transactions persist and are immutable in a blockchain protocol, has to be presented as a function of the level of the adversarial strength. This is true in Nakamoto’s Bitcoin paper and also in the [Ouroboros paper](/research/papers/#9BKRHCSI "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, iohk.io"), see Section 10.1 for the actual time needed for confirmation of transactions. Thus, one should be very wary of statements about irreversibility that do not quantify the level of adversarial power. For instance, Ouroboros will confirm a transaction with 99.9% assurance in just five minutes against an adversary holding 10% of the total stake, which in today’s market cap in the Cardano blockchain would amount to more than two billion dollars. Byzantine agreement protocols can provide a more “black and white” irreversibility, in other words the protocol can be guaranteed to be irreversible within a certain time window provided an honest majority or supermajority exists depending on the protocol. Nevertheless, the performance and decentralisation penalty suffered is very high if the level of adversity is allowed to come close to the 1/2 barrier, which is the level of adversity that Ouroboros can withstand.\n \nThe issue of possible dominance of the consensus process by a small group of stakeholders holding a large proportion of the stake is important but is not applicable to the current release of the Cardano system (the Byron release). What we have proved for Ouroboros is that it can facilitate a “fair” transaction ledger (where fairness here means that the ledger can fairly record all significant actions that are performed by the protocol participants despite the presence of an adversary). This enabled us to neutralise a number of rational protocol deviations (e.g. the equivalent of selfish mining attacks in the PoS setting) and provide a Nash equilibrium argument showing how the protocol can support many different types of mechanisms for incentivising participant behaviour. Currently, IOHK Research is actively working to finalise the incentive structure that will be incorporated in the Shelley release of Cardano, where stake pools will be supported and delegation behaviour will be properly incentivised so that it offers effective decentralisation of power. The crux of our methodology is the engineering of a novel reward mechanism for rational participants that provides appropriate incentives to partition their delegation rights. The objectives are first, to avoid concentration of power to a small group of participants – as it could happen by a naïve reward mechanism in a Pareto distributed stakeholder population – and second, to provide appropriate incentives to ensure a desired number of delegates. We are very excited about this work; it will be the first of its kind in the area and, as before, we will be disseminating it widely including full technical details, as well as submitting it for peer review.\n \nThis brings us to the final distinguishing advantage of the philosophy of Cardano. Scientific peer review has been refined over centuries. The way it is implemented by the [International Cryptology Conference](https://www.iacr.org/conferences/crypto2017/ "Crypto 2017, iacr.org") (also called Crypto), where Ouroboros was presented, and the other top conferences in the area, strives to remove conflicts of interest and produce the highest level of objectivity. The method of reviewing is known as "double blind”, i.e. papers are submitted anonymously and reviewers are experts that also remain anonymous to the authors. The committee of experts that reviews submitted papers each year is formed by two program co-chairs that are appointed by the [International Association of Cryptologic Research](https://www.iacr.org/ "iacr.org"), the pre-eminent organisation of cryptology research that was founded in 1982.\n\nBeing invited to serve in the committee as an expert is an important recognition of an individual’s long-term commitment to the area of cryptography (and even a precise count of how many times one has served is [maintained](https://www.iacr.org/cryptodb/data/stats.php "Publishing Statistics, iacr.org")). Blockchain protocols fit perfectly within the cryptography scientific literature and thus scientific peer review is to be done by this community. Of course, we welcome reviews from anyone. That is why we make public very detailed whitepapers with precise and specific claims that leave no uncertainty about what is being claimed, and we appreciate any factual discussion about any of these claims. We strongly encourage other projects to submit their work for scientific peer review as well. They will enjoy the benefits of thorough, well-founded and objective critique and they will have the opportunity to showcase any advantages and novelty that their approach possesses.\n',
                                        uses_mathjax: null,
                                        attachments: [
                                            {
                                                type: 'pdf',
                                                url: 'https://ucarecdn.com/67b9e51b-1022-40d8-b7f2-fa143c8fea18/-/inline/yes/',
                                                name: 'On the Ouroboros Design- How rigour and'
                                            }
                                        ]
                                    }
                                ],
                                lang: 'en',
                                title: 'On the Ouroboros Design: How rigour and engineering are essential for critical infrastructure',
                                subtitle: '',
                                audio: null,
                                soundcloud: null,
                                body_content: 'A [blog post](https://steemit.com/cardamon/@dan/peer-review-of-cardano-s-ouroboros "Peer Review of Cardano\'s Ouroboros, steemit.com") on the Steemit website appeared recently making a number of claims regarding [Ouroboros](/research/papers/#9BKRHCSI "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, iohk.io"). The article contains several factual inaccuracies. For instance, it is claimed that “DPOS” in the Ouroboros paper stands for “delegated proof of stake”, while in fact, DPOS means “dynamic proof of stake”, or that the protocol requires a "2/3+" ratio of parties being honest, while in reality it just requires an honest majority, i.e. the stake controlled by parties following the protocol is more than half the total stake.\nFor the benefit of those that are interested in the Ouroboros protocol and who appreciate its general philosophy, we feel it is appropriate to provide here a response to this article making along the way a few broader points. While pointing out inaccuracies in the blog, we take the opportunity to highlight some of the general approaches followed in the design of Ouroboros and in the related research efforts that are currently underway at IOHK.\n \nOuroboros is a proof of stake (PoS) protocol that uses delegation in the spirit of the PoS idea as discussed in the [Bitcoin forum starting from 2011](https://bitcointalk.org/index.php?topic=27787.0 "Proof of stake instead of proof of work, bitcointalk.org"). The references that influenced its design are listed in our paper. PoS is a powerful concept that has inspired a number of other efforts prior, concurrent and post the first Ouroboros paper. Among all other implemented PoS blockchain systems that carry real assets, Ouroboros is unique in that it was designed in tandem with a formal security model and a mathematical proof that it implements a robust transaction ledger. This marks a fundamental shift in the methodology of blockchain system design.\n \nBlockchain systems are in a period of transition from curiosities to critical infrastructure; as such, the all too typical software industry approach of releasing a “minimum viable product” as early as possible and then fixing bugs as they appear, is not appropriate. Failures of critical infrastructure have a significant impact on people’s lives and thus require rigorous engineering discipline to the highest possible standards. Dependability, rather than maximum performance according to some arbitrarily chosen metric, is the primary goal. Performance is important, of course, but the performance required is a function of the ultimate application domain, and from the point of view of dependability it is the worst-case performance that is important, not the ideal-scenario peak rate.\n \nLike all other protocols in the blockchain space, Ouroboros requires some degree of synchronisation. The block production interval has to be consistent with the likely time to complete the required information exchanges. The 20-second slot time in Ouroboros represents a conservative choice for a block of transactions to traverse the diameter of a peer-to-peer network, where the peers may be significantly geographically distributed, the system is operating at peak transaction load and the interconnection is significantly less than perfect. It is improbable for a block of transactions to consistently traverse a global network much faster than that, and as a result any solution that does significantly better (or claims to do significantly better) is either wrong, or provides a weaker level of decentralisation or security, i.e. it solves an easier problem than Ouroboros. There is a tradeoff between achieving a robust, global, participatory service that delivers sustained effective performance even under an adversarial attack, and creating a high performance, limited participation (in geographical scope or network resource requirement) solution that makes overly optimistic assumptions on network stability.\n \nIrreversibility, the property that transactions persist and are immutable in a blockchain protocol, has to be presented as a function of the level of the adversarial strength. This is true in Nakamoto’s Bitcoin paper and also in the [Ouroboros paper](/research/papers/#9BKRHCSI "Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol, iohk.io"), see Section 10.1 for the actual time needed for confirmation of transactions. Thus, one should be very wary of statements about irreversibility that do not quantify the level of adversarial power. For instance, Ouroboros will confirm a transaction with 99.9% assurance in just five minutes against an adversary holding 10% of the total stake, which in today’s market cap in the Cardano blockchain would amount to more than two billion dollars. Byzantine agreement protocols can provide a more “black and white” irreversibility, in other words the protocol can be guaranteed to be irreversible within a certain time window provided an honest majority or supermajority exists depending on the protocol. Nevertheless, the performance and decentralisation penalty suffered is very high if the level of adversity is allowed to come close to the 1/2 barrier, which is the level of adversity that Ouroboros can withstand.\n \nThe issue of possible dominance of the consensus process by a small group of stakeholders holding a large proportion of the stake is important but is not applicable to the current release of the Cardano system (the Byron release). What we have proved for Ouroboros is that it can facilitate a “fair” transaction ledger (where fairness here means that the ledger can fairly record all significant actions that are performed by the protocol participants despite the presence of an adversary). This enabled us to neutralise a number of rational protocol deviations (e.g. the equivalent of selfish mining attacks in the PoS setting) and provide a Nash equilibrium argument showing how the protocol can support many different types of mechanisms for incentivising participant behaviour. Currently, IOHK Research is actively working to finalise the incentive structure that will be incorporated in the Shelley release of Cardano, where stake pools will be supported and delegation behaviour will be properly incentivised so that it offers effective decentralisation of power. The crux of our methodology is the engineering of a novel reward mechanism for rational participants that provides appropriate incentives to partition their delegation rights. The objectives are first, to avoid concentration of power to a small group of participants – as it could happen by a naïve reward mechanism in a Pareto distributed stakeholder population – and second, to provide appropriate incentives to ensure a desired number of delegates. We are very excited about this work; it will be the first of its kind in the area and, as before, we will be disseminating it widely including full technical details, as well as submitting it for peer review.\n \nThis brings us to the final distinguishing advantage of the philosophy of Cardano. Scientific peer review has been refined over centuries. The way it is implemented by the [International Cryptology Conference](https://www.iacr.org/conferences/crypto2017/ "Crypto 2017, iacr.org") (also called Crypto), where Ouroboros was presented, and the other top conferences in the area, strives to remove conflicts of interest and produce the highest level of objectivity. The method of reviewing is known as "double blind”, i.e. papers are submitted anonymously and reviewers are experts that also remain anonymous to the authors. The committee of experts that reviews submitted papers each year is formed by two program co-chairs that are appointed by the [International Association of Cryptologic Research](https://www.iacr.org/ "iacr.org"), the pre-eminent organisation of cryptology research that was founded in 1982.\n\nBeing invited to serve in the committee as an expert is an important recognition of an individual’s long-term commitment to the area of cryptography (and even a precise count of how many times one has served is [maintained](https://www.iacr.org/cryptodb/data/stats.php "Publishing Statistics, iacr.org")). Blockchain protocols fit perfectly within the cryptography scientific literature and thus scientific peer review is to be done by this community. Of course, we welcome reviews from anyone. That is why we make public very detailed whitepapers with precise and specific claims that leave no uncertainty about what is being claimed, and we appreciate any factual discussion about any of these claims. We strongly encourage other projects to submit their work for scientific peer review as well. They will enjoy the benefits of thorough, well-founded and objective critique and they will have the opportunity to showcase any advantages and novelty that their approach possesses.\n',
                                uses_mathjax: null,
                                attachments: [
                                    {
                                        type: 'pdf',
                                        url: 'https://ucarecdn.com/67b9e51b-1022-40d8-b7f2-fa143c8fea18/-/inline/yes/',
                                        name: 'On the Ouroboros Design- How rigour and'
                                    }
                                ],
                                slug: 'on-the-ouroboros-design-how-rigour-and-engineering-are-essential-for-critical-infrastructure',
                                url: '/blog/posts/2018/01/11/on-the-ouroboros-design-how-rigour-and-engineering-are-essential-for-critical-infrastructure/',
                                read_time: 7
                            }
                        ]
                    },
                    video_id: null,
                    main_image: 'https://ucarecdn.com/7aaaa825-7c80-4bfb-8712-a1e66bc809b8/',
                    custom_meta_img: null,
                    old_url: null,
                    haskell: null,
                    localized: [
                        {
                            lang: 'en',
                            title: 'Stablefees and the Decentralized Reserve System',
                            subtitle: 'Exploring a new mechanism to help make fees fair, stable, and more predictable over time',
                            audio: null,
                            soundcloud: [],
                            body_content: 'Facilitating transactions in cryptocurrency platforms stumbles on the dual utility of the platform’s underlying asset. On the one hand, users can hold and trade it as part of their investment portfolios. On the other hand, it supplies the necessary “fuel” for processing transactions. \n\nThis duality suggests that the system should have a mechanism for adjusting transaction costs, so they remain competitive and reasonable. Also, the bounded throughput of decentralized platforms per unit of time introduces another hurdle: the system should also allow the users to discover the correct price for timely transaction processing, depending on their individual needs. \n\nWhy not drop transaction fees altogether? Three reasons: One, transaction processing incurs costs on the system’s side (in terms of computation and storage). It is reasonable to allow transaction processors (stake pool operators, in the case of Cardano) to offset their costs. Two, even with a theoretically infinite capacity, it is important to prevent transaction issuers from saturating the network with worthless transactions. Three, it is appropriate to incentivize transaction processors to provide quality of service. A surge in demand should influence their payoffs accordingly.\n\nAdding a fee to each transaction can address the above considerations. \n\n### Bitcoin and beyond\n\nBitcoin set out the first mechanism for pricing transactions in distributed ledger platforms. This mechanism resembles a first-price auction: transactions bid for a place in a block naming a specific reward, and block producers select the transactions that they prefer to include. Block producers also get rewarded with the right to mint new coins, i.e., their operation is subsidized by the whole community via inflation of the total coin supply. Inflation drops geometrically over time, and transaction fees become increasingly dominant in the rewards. This mechanism, while enabling Bitcoin to run for well over a decade, has been criticized for its inefficiency. Transaction costs have also risen over time.\n\nIn this blog post, we explore a new mechanism that builds on Cardano\'s approach to ledger rules and system assets, and complements the [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) concept. The objective is making fees fair, stable, and predictable over time. We describe the mechanism in the context of Cardano. However, it can be adapted to any other cryptocurrency with similar characteristics.\n\n### Introducing \'Stablefees\'\n\nThe core idea behind Stablefees is to have a base price for transactions through pegging to a basket of commodities or currencies. Stablefees includes a native "decentralized reserve" contract that issues and manages a stablecoin pegged to the basket. A comparison in the fiat world might be the International Monetary Fund’s[ SDR](https://www.imf.org/en/About/Factsheets/Sheets/2016/08/01/14/51/Special-Drawing-Right-SDR), (established in 1969) and valued based on a basket of five currencies—the U.S. dollar, the euro, the Chinese renminbi, the Japanese yen, and the British pound sterling. The stablecoin --- let’s call it "Basket Equivalent Coin" (BEC) --- is the currency used for paying transaction fees (and all other real world pricing needs of the platform, e.g., SPO costs). \n\nIn this system, ada will play a dual role: Reserve asset of the decentralized reserve, and reward currency for staking. It will also be the fall-back currency in extreme scenarios where the reserve contract is in a liquidity crunch. Before a transaction, the issuer will have to obtain BECs, either via other third parties or directly by sending ada to the decentralized reserve contract. On what basis will the reserve issue BECs? The reserve contract will also issue equity shares -we will call them decentralized equity coins (DECs)-, in exchange of ada. Leveraging the value of DECs, the decentralized reserve will often adjust the value of BEC so it is pegged on the underlying basket of commodities. In other words, DECs will absorb the fluctuations of ada vs. the basket to ensure that the real-world value of BECs remains stable (cf. the [AgeUSD stablecoin design](https://github.com/Emurgo/age-usd) that has been already [deployed and used on Ergo](https://sigmausd.io/#/)). \n\nThis trinity of coinage, issued natively by the system, will attract different cohorts. BECs\' stability and liquidity might be attractive to risk-averse, transaction-intensive holders. DECs will offer the highest rewards if ada goes up, but also take the most significant hit when ada goes down. Long-term holders may find DECs more attractive. Also, since decentralized reserve prices these coins in ada, both BECs and DECs can facilitate participation in staking and governance. Returns can be issued at different rates, reflecting the different nature of each coin. Ultimately, rewards will always be denominated and payable in ada, which will remain the most versatile of all three coins.\n\n### Oracles\n\nThe centerpiece of this mechanism is an on-chain oracle that determines the price of the basket in ada. SPOs can implement this oracle in a decentralized manner. The reserve can offer extra rewards to all oracle contributors from the fees collected during BEC/DEC issuances. This will ensure two things: thousands of geographically-diverse contributors, and ledger rules calculating a synthesized exchange rate in some canonical way (through a weighted median across all price submissions in an epoch, for example). If oracle contributors manipulate their contributions, they can be held accountable by tracking their reputation and performance on-chain.\n\n### The pricing mechanism\n\nHow would one price transactions and reward block producers? Using the current approach in Cardano, each transaction will be deterministically mapped to a precise value denominated in BECs, using a formula determined by the ledger rules. The formula will take into account both transaction size and its computational requirements, and may also incorporate runtime metrics (such as the average system load). The resulting value will be the base fee guaranteeing that the transaction will be processed by the system. Given the base fee, end users will be able to apply a multiplier if they wish (which will be a value at least 1, e.g., 1.5x, 3x, etc.) to increase the fee and accelerate processing. This will become relevant at times of surging demand.  \n\nThis approach has one advantage when compared with the first-price auction model: the pricing mechanism is continuously stabilized to a reasonable default value. Users perform price discovery in one direction only to accelerate processing, if required. Also, transaction issuers can store BECs to secure their future transaction-issuing ability without being affected by ada price volatility.\n\n### Stablefees and Babel fees\n\nThe Stablefees mechanism can be considered a natural extension of [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) ---spot conversion of BECs into ada by the decentralized reserve. Both mechanisms complement (and are compatible with) each other. Babel fees can be deployed together with Stablefees with just one change: Using BECs to cover Babel fee liabilities, instead of ada. This also means that fees will always be payable in ada (via a Babel fee liability convertible in ada on the spot). Hence, the whole mechanism is backwards compatible: it won’t affect occasional users who just hold ada and do not wish to obtain BECs.  \n\nA final point about diversity. While the above narrative identifies a unique and global BEC, the same mechanism can be used to issue regional BECs pegged to different baskets of commodities, which could possibly be weighted differently. Such “regional” BECs will be able to increase system inclusivity, while enabling SPOs to have more fine-grained policies in terms of transaction inclusion.\n\n### Stablefees \'lite\'\n\nThe above mechanism requires a decentralized reserve contract and the issuance of BECs and DECs by the contract to buyers. A “lite” version avoids the reserve contract and directly adjusts the fee formula by pegging it onto the agreed basket of commodities through the price oracle. The resulting system denominates transaction fees nominally in BECs and immediately converts them into ada. The payable amount fluctuates, depending on the value of BEC. The mechanism is otherwise identical, also facilitating unidirectional price discovery through the multiplier. The only disadvantage is that a prospective transaction issuer has no access to a native token that enables transaction processing predictably; transaction issuers must pay fees in ada. Still, the fees will continuously adjust and remain stable via the pegging mechanism with respect to the basket. As a result, a transaction issuer will be able to organize their off-chain asset portfolio to meet their transaction needs effectively.\n\n### The road ahead\n\nOur team is currently researching the granular details of the Stablefees mechanism. Once this research is complete, Stablefees can be integrated into Cardano to offer fair and predictable transaction pricing. Moreover, the price oracle and the global BEC (and regional variants, if included) will undoubtedly find uses beyond paying transaction fees, expanding the capabilities of decentralized applications in the Cardano ecosystem.',
                            uses_mathjax: false,
                            attachments: []
                        }
                    ],
                    lang: 'en',
                    title: 'Stablefees and the Decentralized Reserve System',
                    subtitle: 'Exploring a new mechanism to help make fees fair, stable, and more predictable over time',
                    audio: null,
                    soundcloud: [],
                    body_content: 'Facilitating transactions in cryptocurrency platforms stumbles on the dual utility of the platform’s underlying asset. On the one hand, users can hold and trade it as part of their investment portfolios. On the other hand, it supplies the necessary “fuel” for processing transactions. \n\nThis duality suggests that the system should have a mechanism for adjusting transaction costs, so they remain competitive and reasonable. Also, the bounded throughput of decentralized platforms per unit of time introduces another hurdle: the system should also allow the users to discover the correct price for timely transaction processing, depending on their individual needs. \n\nWhy not drop transaction fees altogether? Three reasons: One, transaction processing incurs costs on the system’s side (in terms of computation and storage). It is reasonable to allow transaction processors (stake pool operators, in the case of Cardano) to offset their costs. Two, even with a theoretically infinite capacity, it is important to prevent transaction issuers from saturating the network with worthless transactions. Three, it is appropriate to incentivize transaction processors to provide quality of service. A surge in demand should influence their payoffs accordingly.\n\nAdding a fee to each transaction can address the above considerations. \n\n### Bitcoin and beyond\n\nBitcoin set out the first mechanism for pricing transactions in distributed ledger platforms. This mechanism resembles a first-price auction: transactions bid for a place in a block naming a specific reward, and block producers select the transactions that they prefer to include. Block producers also get rewarded with the right to mint new coins, i.e., their operation is subsidized by the whole community via inflation of the total coin supply. Inflation drops geometrically over time, and transaction fees become increasingly dominant in the rewards. This mechanism, while enabling Bitcoin to run for well over a decade, has been criticized for its inefficiency. Transaction costs have also risen over time.\n\nIn this blog post, we explore a new mechanism that builds on Cardano\'s approach to ledger rules and system assets, and complements the [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) concept. The objective is making fees fair, stable, and predictable over time. We describe the mechanism in the context of Cardano. However, it can be adapted to any other cryptocurrency with similar characteristics.\n\n### Introducing \'Stablefees\'\n\nThe core idea behind Stablefees is to have a base price for transactions through pegging to a basket of commodities or currencies. Stablefees includes a native "decentralized reserve" contract that issues and manages a stablecoin pegged to the basket. A comparison in the fiat world might be the International Monetary Fund’s[ SDR](https://www.imf.org/en/About/Factsheets/Sheets/2016/08/01/14/51/Special-Drawing-Right-SDR), (established in 1969) and valued based on a basket of five currencies—the U.S. dollar, the euro, the Chinese renminbi, the Japanese yen, and the British pound sterling. The stablecoin --- let’s call it "Basket Equivalent Coin" (BEC) --- is the currency used for paying transaction fees (and all other real world pricing needs of the platform, e.g., SPO costs). \n\nIn this system, ada will play a dual role: Reserve asset of the decentralized reserve, and reward currency for staking. It will also be the fall-back currency in extreme scenarios where the reserve contract is in a liquidity crunch. Before a transaction, the issuer will have to obtain BECs, either via other third parties or directly by sending ada to the decentralized reserve contract. On what basis will the reserve issue BECs? The reserve contract will also issue equity shares -we will call them decentralized equity coins (DECs)-, in exchange of ada. Leveraging the value of DECs, the decentralized reserve will often adjust the value of BEC so it is pegged on the underlying basket of commodities. In other words, DECs will absorb the fluctuations of ada vs. the basket to ensure that the real-world value of BECs remains stable (cf. the [AgeUSD stablecoin design](https://github.com/Emurgo/age-usd) that has been already [deployed and used on Ergo](https://sigmausd.io/#/)). \n\nThis trinity of coinage, issued natively by the system, will attract different cohorts. BECs\' stability and liquidity might be attractive to risk-averse, transaction-intensive holders. DECs will offer the highest rewards if ada goes up, but also take the most significant hit when ada goes down. Long-term holders may find DECs more attractive. Also, since decentralized reserve prices these coins in ada, both BECs and DECs can facilitate participation in staking and governance. Returns can be issued at different rates, reflecting the different nature of each coin. Ultimately, rewards will always be denominated and payable in ada, which will remain the most versatile of all three coins.\n\n### Oracles\n\nThe centerpiece of this mechanism is an on-chain oracle that determines the price of the basket in ada. SPOs can implement this oracle in a decentralized manner. The reserve can offer extra rewards to all oracle contributors from the fees collected during BEC/DEC issuances. This will ensure two things: thousands of geographically-diverse contributors, and ledger rules calculating a synthesized exchange rate in some canonical way (through a weighted median across all price submissions in an epoch, for example). If oracle contributors manipulate their contributions, they can be held accountable by tracking their reputation and performance on-chain.\n\n### The pricing mechanism\n\nHow would one price transactions and reward block producers? Using the current approach in Cardano, each transaction will be deterministically mapped to a precise value denominated in BECs, using a formula determined by the ledger rules. The formula will take into account both transaction size and its computational requirements, and may also incorporate runtime metrics (such as the average system load). The resulting value will be the base fee guaranteeing that the transaction will be processed by the system. Given the base fee, end users will be able to apply a multiplier if they wish (which will be a value at least 1, e.g., 1.5x, 3x, etc.) to increase the fee and accelerate processing. This will become relevant at times of surging demand.  \n\nThis approach has one advantage when compared with the first-price auction model: the pricing mechanism is continuously stabilized to a reasonable default value. Users perform price discovery in one direction only to accelerate processing, if required. Also, transaction issuers can store BECs to secure their future transaction-issuing ability without being affected by ada price volatility.\n\n### Stablefees and Babel fees\n\nThe Stablefees mechanism can be considered a natural extension of [Babel fees](https://iohk.io/en/blog/posts/2021/02/25/babel-fees/) ---spot conversion of BECs into ada by the decentralized reserve. Both mechanisms complement (and are compatible with) each other. Babel fees can be deployed together with Stablefees with just one change: Using BECs to cover Babel fee liabilities, instead of ada. This also means that fees will always be payable in ada (via a Babel fee liability convertible in ada on the spot). Hence, the whole mechanism is backwards compatible: it won’t affect occasional users who just hold ada and do not wish to obtain BECs.  \n\nA final point about diversity. While the above narrative identifies a unique and global BEC, the same mechanism can be used to issue regional BECs pegged to different baskets of commodities, which could possibly be weighted differently. Such “regional” BECs will be able to increase system inclusivity, while enabling SPOs to have more fine-grained policies in terms of transaction inclusion.\n\n### Stablefees \'lite\'\n\nThe above mechanism requires a decentralized reserve contract and the issuance of BECs and DECs by the contract to buyers. A “lite” version avoids the reserve contract and directly adjusts the fee formula by pegging it onto the agreed basket of commodities through the price oracle. The resulting system denominates transaction fees nominally in BECs and immediately converts them into ada. The payable amount fluctuates, depending on the value of BEC. The mechanism is otherwise identical, also facilitating unidirectional price discovery through the multiplier. The only disadvantage is that a prospective transaction issuer has no access to a native token that enables transaction processing predictably; transaction issuers must pay fees in ada. Still, the fees will continuously adjust and remain stable via the pegging mechanism with respect to the basket. As a result, a transaction issuer will be able to organize their off-chain asset portfolio to meet their transaction needs effectively.\n\n### The road ahead\n\nOur team is currently researching the granular details of the Stablefees mechanism. Once this research is complete, Stablefees can be integrated into Cardano to offer fair and predictable transaction pricing. Moreover, the price oracle and the global BEC (and regional variants, if included) will undoubtedly find uses beyond paying transaction fees, expanding the capabilities of decentralized applications in the Cardano ecosystem.',
                    uses_mathjax: false,
                    attachments: [],
                    slug: 'stablefees-and-the-decentralized-reserve-system',
                    url: '/blog/posts/2021/06/10/stablefees-and-the-decentralized-reserve-system/',
                    read_time: 7
                },
                {
                    publish_date: '2021-06-08T00:00:00.000Z',
                    author: {
                        title: 'Niamh Ahern',
                        display_name: 'Niamh Ahern',
                        thumbnail: 'https://ucarecdn.com/8ac49795-0145-4168-8d90-d667340a7ac8/',
                        is_team_member: true,
                        is_active: true,
                        localized: [
                            {
                                job_titles: [
                                    {
                                        name: 'Technical Writer',
                                        primary: null
                                    },
                                    {
                                        name: 'Education',
                                        primary: null
                                    }
                                ],
                                lang: 'en',
                                profile_links: {
                                    email: 'niamh.ahern@iohk.io',
                                    youtube: '',
                                    linkedin: 'https://www.linkedin.com/in/niamh-ahern-67849949/',
                                    twitter: 'https://twitter.com/nahern_iohk?lang=en',
                                    github: 'https://github.com/nahern'
                                }
                            }
                        ],
                        job_titles: [
                            {
                                name: 'Technical Writer',
                                primary: null
                            },
                            {
                                name: 'Education',
                                primary: null
                            }
                        ],
                        lang: 'en',
                        profile_links: {
                            email: 'niamh.ahern@iohk.io',
                            youtube: '',
                            linkedin: 'https://www.linkedin.com/in/niamh-ahern-67849949/',
                            twitter: 'https://twitter.com/nahern_iohk?lang=en',
                            github: 'https://github.com/nahern'
                        },
                        profile_url: '/blog/authors/niamh-ahern/',
                        blog_posts: [
                            {
                                publish_date: '2021-06-08T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/350386c8-b07f-44f0-9787-0c898a3d0460/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'A close look at the software running Cardano',
                                        subtitle: 'Learn about the ‘stack’ of components that interact to run the blockchain platform',
                                        audio: null,
                                        soundcloud: [
                                            {
                                                trackid: 1066347517
                                            }
                                        ],
                                        body_content: 'Cardano has been designed in modules, with linked components that can be used in various ways. These components form the Cardano ‘platform stack’. They work together under the hood to support the construction and use of the live Cardano blockchain.\n\nWe are currently in the early testnet phase on the way to the Alonzo hard fork, which will bring full smart contract capability to Cardano. This process is highly complex, requiring the steady upgrade of the different elements which make up the Cardano platform, and their careful integration and testing. So, it is a good time to revisit these components, explain some of the terminology, and discover how they interact within the ‘platform stack’.\n\n## Elements of the Cardano platform stack\n\n![](https://ucarecdn.com/913ea221-dd67-4938-84be-3461f79b0baa/)\n\n**Figure 1. Components that communicate with the Cardano node**\n\nThe platform stack for Cardano includes these core components:\n\n* Cardano node (and associated processes)\n* Cardano wallet\n* Wallet command line interface (CLI)\n* DB Sync (synchronizes blockchain data with a relational database)\n* PostgreSQL database (which interacts with GraphQL, REST API, and Smash)\n* Smash server\n* Rosetta API (blockchain communication protocol)\n\nNote that the Daedalus wallet is not part of the core stack, but does communicate with the components (Figure 1). \n\n### The node and the networking layer\n\nFirst, let\'s take a look at the [Cardano node](https://github.com/input-output-hk/cardano-node). This software runs on your computer and underpins the network, enabling everyone to participate in the decentralized blockchain. The node integrates the consensus, ledger, and networking sub-components, providing top-level configuration, API, CLI, logging, memory management, and monitoring capabilities that can be used by other Cardano components or by skilled users. Daedalus is a full-node wallet, so if you are running that on your local machine, you are effectively helping to run the network. \n\n*The networking layer*\n\nNext, we have the networking layer. This links each Cardano node into a distributed system that manages the blockchain and associated services. The network consists of a collection of nodes that communicate with each other to maintain the distributed ledger, support transaction submission, and interact with user wallets and other services. The core of the network is built around the decentralized nodes – the stake pools – that collectively validate blocks, and add new blocks to the chain. They are supported by dedicated relay nodes that manage network connections and establish the structure of the network as a whole. The dedicated consumer nodes that are run by the Daedalus wallet and other services connect to this network to track and submit transactions on-chain.\n\nCardano nodes maintain connections with their peers. A set of mini-protocols enable communication between the nodes. Each mini-protocol implements a basic information exchange requirement, such as informing peers of the latest block, sharing blocks as needed, or sharing new transactions around the Cardano network. For connection purposes, mini-protocols are determined by the version of the network protocol. \n\n### Cardano wallet backend\n\nThe [Cardano wallet](https://github.com/input-output-hk/cardano-wallet) backend component supports the graphical user interface of the Daedalus wallet. It is used to send and receive ada. Behind the scenes, the wallet runs a full Cardano node. Unlike a light client wallet, it loads the entire shared ledger and validates all transactions, thus bolstering the security of the blockchain for everyone.\n\n### Wallet command line interface (CLI)\n\nThe wallet command line interface (CLI) supports interactions with the actual blockchain. More technically advanced users can use the CLI  to work with a collection of tools for generating keys, constructing transactions, creating certificates, and performing other tasks. It is organized in a hierarchy of subcommands, and each level comes with its own built-in documentation of command syntax and options.\n\n### DB Sync\n\n[DB Sync](https://github.com/input-output-hk/cardano-db-sync) is a component that follows the activities on the Cardano chain and stores blocks and transactions in PostgreSQL. As a ‘middleware’ component, it powers [cardano-graphql](https://github.com/input-output-hk/cardano-graphql). DB Sync stores blockchain data fetched from [cardano-node](https://github.com/input-output-hk/cardano-node) in an intermediate database to enable higher-level interfaces for blockchain exploration. It also provides a number of queries to fetch Cardano blockchain data from the PostgreSQL, and supports services such as the [Cardano Explorer](https://explorer.cardano.org/en.html), a graphical user interface that reflects the blockchain data in a straightforward way. Cardano GraphQL is a cross-platform API for the GraphQL data query language. \n\n### Rosetta API\n\nThe Rosetta application programming interface provides a high-level interface that aims to make the integration process easier, faster, and more reliable so that you can build once and integrate your blockchain everywhere. We have created a unique [cardano-rosetta](https://github.com/input-output-hk/cardano-rosetta) implementation to simplify the process of integration with Cardano. This interface is particularly useful for exchanges, since they can interact with the Cardano chain using the same interface that they use with other blockchains.\n\n### Looking forward\n\nWith [smart contracts](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) coming to Cardano soon, this means that [Plutus](https://iohk.io/en/blog/posts/2021/04/13/plutus-what-you-need-to-know/), the native smart contract language, and other smart contract development languages like [Marlowe](https://iohk.io/en/blog/posts/2021/05/26/reimagining-peer-to-peer-finance-with-marlowe/) for finance and [Glow](https://glow-lang.org/) for DApps will be integrated into the Cardano stack. IO Global’s engineers will provide new and extended components to compile Plutus, Marlowe, and Glow scripts, submit them on-chain, and interact with them (Figure 2).\n\n![](https://ucarecdn.com/49d00118-da94-4dde-9be2-1a721c698a39/)\n\n**Figure 2. Plutus, Marlowe, Glow, Solidity, and IELE can all be used to write Cardano smart contracts**\n\nThe [Alonzo protocol upgrade](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) will build on recent token upgrades and is being deployed to the mainnet via several testnets. Our Plutus partners and Plutus Pioneers will help us to test Plutus Core and will be part of the user acceptance phase before mainnet deployment. At this point we will officially add the Plutus and Marlowe components, such as both interpreters, to Cardano’s platform stack. \n\n*To keep up to date with the Alonzo rollout, please check our social channels and blog page.*',
                                        uses_mathjax: false,
                                        attachments: []
                                    },
                                    {
                                        lang: 'jp',
                                        title: 'Cardanoで稼働するソフトウェアに注目',
                                        subtitle: 'ブロックチェーンプラットフォームを実行するために相互作用するコンポーネントの「スタック」を知ろう',
                                        audio: null,
                                        soundcloud: [],
                                        body_content: 'Cardanoはモジュール単位で設計されています。ここには、さまざまな方法で使用できるコンポーネントがリンクされています。こうしたコンポーネントはCardano「プラットフォームスタック」を形成しています。これらは内部で共に作動し、稼働するCardanoブロックチェーンの構造と使用を支えています。\n現在は、Cardnaoに完全なスマートコントラクト機能をもたらすAlonzoハードフォークに向けた、初期テストネットの段階にあります。このプロセスは極めて複雑で、Cardanoプラットフォームを構成するさまざまな要素をしっかりとアップグレードし、慎重に統合、テストする必要があります。したがって、今こそこうしたコンポーネントを振り返り、一部の用語を説明し、「プラットフォームスタック」の中でこれらがいかに相互作用するかを考察するいい機会です。\n\n## Cardanoプラットフォームスタックの要素\n\n\n![](https://ucarecdn.com/913ea221-dd67-4938-84be-3461f79b0baa/)\n\n**図1：Cardanoノードと通信するコンポーネント**\n\nCardanoプラットフォームスタックには以下のコアコンポーネントが含まれます。\n\n* Cardanoノード（および関連プロセス）\n* Cardanoウォレット\n* ウォレットコマンドラインインターフェイス（CLI）\n* DB Sync（ブロックチェーンデータを関連するデータベースと同期)\n* PostgreSQLデータベース（GraphQL、REST API、SMASHと相互作用）\n* SMASHサーバー\n* Rosetta API（ブロックチェーン通信プロトコル）\n\n注：Daedalusはコアスタックに含まれませんが、コンポーネントと通信します（図1）。\n\n### ノードとネットワーク層\n\nはじめに、Cardanoノードを見てみましょう。このソフトウェアは個人のコンピューター上で実行されてネットワークを支え、誰もが分散型ブロックチェーンに参加できるようにするものです。ノードは、コンセンサス、台帳、ネットワークのサブコンポーネントを統合し、他のCardanoコンポーネントまたは熟練したユーザーが使用できるトップレベルの設定、API、CLI、ログ、メモリー管理、そして監視機能を提供します。Daedalusはフルノードウォレットで、ローカルマシンで実行することにより、実質的にネットワークの実行に貢献することになります。\n\n*ネットワーク層*\n\n次にネットワーク層です。これは各Cardanoノードを、ブロックチェーンを管理する1つの分散型システムと関連サービスにリンクさせます。ネットワークは、互いに通信しあって分散型台帳を維持し、トランザクションの送信を支え、ユーザーのウォレットや他のサービスとやり取りするノードの集合で構成されます。ネットワークのコアは、集団的にブロックを検証し、チェーンに新たなブロックを追加する分散型ノード（ステークプール）を中心に構築されています。これを支えるのは、ネットワーク接続を管理し、ネットワークの構造を全体として確立する専用のリレーノードです。Daedalusウォレットや他のサービスが実行する専用のコンシューマーノードはこのネットワークに接続し、チェーン上でトランザクションを追跡、送信します。\nCardanoノードはピアとの接続を維持します。一連のミニプロトコルがノード間の通信を可能にします。各ミニプロトコルは基本的な情報交換要件を実装しています。例えば、Cardanoネットワークのあちこちでピアに最新ブロックを伝える、必要に応じてブロックを共有する、新たなトランザクションを共有する、などです。ミニプロトコルは、接続を目的として、ネットワークプロトコルのバージョンによって決定されます。\n\n### Cardanoウォレットバックエンド\n\nCardanoウォレットバックエンドコンポーネントはDaedalusウォレットのグラフィカルユーザーインターフェイスをサポートしています。これは、ADAの送受信に使用されます。ウォレットはバックグラウンドでCardanoフルノードを実行しています。軽量クライアントウォレットとは異なり、これは共有された台帳全体をロードし、すべてのトランザクションを検証するため、全員にとってブロックチェーンのセキュリティが強化されます。\n\n### ウォレットコマンドラインインターフェイス（CLI）\n\nウォレットコマンドラインインターフェイス（CLI）は実際のブロックチェーンとのやり取りをサポートします。高度な技術を持つユーザーは、CLIにより、ツールのコレクションを使用して、鍵の生成やトランザクションの構築、証明書の作成、その他のタスクを実行することができます。これはサブコマンドの階層順に整理され、各レベルには、コマンドシンタックスやオプションのビルトインドキュメンテーションが付されています。\n\n### DB Sync\n\nDB SyncはCardanoチェーンのアクティビティに従い、PostgreSQLにブロックとトランザクションを保存するコンポーネントです。「ミドルウェア」コンポーネントとして、cardano-graphqlを強化します。DB Syncは、ブロックチェーン探索のための高レベルのインターフェイスを有効にするために、cardano-nodeからフェッチしたブロックチェーンを中間データベースに保存します。また、数多くのクエリを提供してPostgreSQLからCardanoブロックチェーンデータをフェッチし、ブロックチェーンデータをシンプルに反映するグラフィカルユーザーインターフェイス、Cardanoエクスプローラーなどのサービスをサポートします。Cardano GraphQLは、GraphQLデータクエリ言語用のクロスプラットフォームAPIです。\n\n### Rosetta API\n\nRosettaアプリケーションプログラミングインターフェイスは、統合プロセスをより簡単に、より速く、より信頼できるものにすることを目的とした高レベルインターフェイスを提供します。これにより、一度構築すると、どこでもブロックチェーンを統合できます。Cardanoとの統合プロセスを簡易化するために、私たちはユニークなcardano-rosettaを作成しました。このインターフェイスは、取引所に特に役立ちます。他のブロックチェーンで使用するものと同じインターフェイスを使って、Cardanoチェーンとやり取りすることができるためです。\n\n### 今後\n\nまもなくCardanoにスマートコントラクトが搭載されますが、これは、スマートコントラクトのネイティブ言語Plutusや、金融仕様のMarlowe、DApp仕様のGlowなど、その他のスマートコントラクト開発言語がCardanoスタックに統合されることを意味します。IO Globalのエンジニアは、Plutus、Marlowe、Glowのスクリプトをコンパイルし、チェーン上に送信し、やり取りするための新コンポーネントや拡張コンポーネントを提供します（図2）。\n\n![](https://ucarecdn.com/49d00118-da94-4dde-9be2-1a721c698a39/)\n\n**図2：Plutus、Marlowe、Glow、Solidity、IELEはすべて、Cardanoスマートコントラクトの作成に使用可能**\n\nAlonzoプロトコルアップグレードは、最近のトークンアップグレードの上に構築され、複数のテストネットを経てメインネットで展開されます。PlutusパートナーやPlutusパイオニアたちはPlutus Coreのテストに協力し、メインネットへの展開前のユーザー受け入れフェーズに参加します。この時点で、インタープリターなどのPlutusとMarloweコンポーネントはCardanoプラットフォームスタックへと公式に追加されます。\nAlonzoロールアウトの最新情報は、ソーシャルチャネルとブログをチェックしてください。\n',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'A close look at the software running Cardano',
                                subtitle: 'Learn about the ‘stack’ of components that interact to run the blockchain platform',
                                audio: null,
                                soundcloud: [
                                    {
                                        trackid: 1066347517
                                    }
                                ],
                                body_content: 'Cardano has been designed in modules, with linked components that can be used in various ways. These components form the Cardano ‘platform stack’. They work together under the hood to support the construction and use of the live Cardano blockchain.\n\nWe are currently in the early testnet phase on the way to the Alonzo hard fork, which will bring full smart contract capability to Cardano. This process is highly complex, requiring the steady upgrade of the different elements which make up the Cardano platform, and their careful integration and testing. So, it is a good time to revisit these components, explain some of the terminology, and discover how they interact within the ‘platform stack’.\n\n## Elements of the Cardano platform stack\n\n![](https://ucarecdn.com/913ea221-dd67-4938-84be-3461f79b0baa/)\n\n**Figure 1. Components that communicate with the Cardano node**\n\nThe platform stack for Cardano includes these core components:\n\n* Cardano node (and associated processes)\n* Cardano wallet\n* Wallet command line interface (CLI)\n* DB Sync (synchronizes blockchain data with a relational database)\n* PostgreSQL database (which interacts with GraphQL, REST API, and Smash)\n* Smash server\n* Rosetta API (blockchain communication protocol)\n\nNote that the Daedalus wallet is not part of the core stack, but does communicate with the components (Figure 1). \n\n### The node and the networking layer\n\nFirst, let\'s take a look at the [Cardano node](https://github.com/input-output-hk/cardano-node). This software runs on your computer and underpins the network, enabling everyone to participate in the decentralized blockchain. The node integrates the consensus, ledger, and networking sub-components, providing top-level configuration, API, CLI, logging, memory management, and monitoring capabilities that can be used by other Cardano components or by skilled users. Daedalus is a full-node wallet, so if you are running that on your local machine, you are effectively helping to run the network. \n\n*The networking layer*\n\nNext, we have the networking layer. This links each Cardano node into a distributed system that manages the blockchain and associated services. The network consists of a collection of nodes that communicate with each other to maintain the distributed ledger, support transaction submission, and interact with user wallets and other services. The core of the network is built around the decentralized nodes – the stake pools – that collectively validate blocks, and add new blocks to the chain. They are supported by dedicated relay nodes that manage network connections and establish the structure of the network as a whole. The dedicated consumer nodes that are run by the Daedalus wallet and other services connect to this network to track and submit transactions on-chain.\n\nCardano nodes maintain connections with their peers. A set of mini-protocols enable communication between the nodes. Each mini-protocol implements a basic information exchange requirement, such as informing peers of the latest block, sharing blocks as needed, or sharing new transactions around the Cardano network. For connection purposes, mini-protocols are determined by the version of the network protocol. \n\n### Cardano wallet backend\n\nThe [Cardano wallet](https://github.com/input-output-hk/cardano-wallet) backend component supports the graphical user interface of the Daedalus wallet. It is used to send and receive ada. Behind the scenes, the wallet runs a full Cardano node. Unlike a light client wallet, it loads the entire shared ledger and validates all transactions, thus bolstering the security of the blockchain for everyone.\n\n### Wallet command line interface (CLI)\n\nThe wallet command line interface (CLI) supports interactions with the actual blockchain. More technically advanced users can use the CLI  to work with a collection of tools for generating keys, constructing transactions, creating certificates, and performing other tasks. It is organized in a hierarchy of subcommands, and each level comes with its own built-in documentation of command syntax and options.\n\n### DB Sync\n\n[DB Sync](https://github.com/input-output-hk/cardano-db-sync) is a component that follows the activities on the Cardano chain and stores blocks and transactions in PostgreSQL. As a ‘middleware’ component, it powers [cardano-graphql](https://github.com/input-output-hk/cardano-graphql). DB Sync stores blockchain data fetched from [cardano-node](https://github.com/input-output-hk/cardano-node) in an intermediate database to enable higher-level interfaces for blockchain exploration. It also provides a number of queries to fetch Cardano blockchain data from the PostgreSQL, and supports services such as the [Cardano Explorer](https://explorer.cardano.org/en.html), a graphical user interface that reflects the blockchain data in a straightforward way. Cardano GraphQL is a cross-platform API for the GraphQL data query language. \n\n### Rosetta API\n\nThe Rosetta application programming interface provides a high-level interface that aims to make the integration process easier, faster, and more reliable so that you can build once and integrate your blockchain everywhere. We have created a unique [cardano-rosetta](https://github.com/input-output-hk/cardano-rosetta) implementation to simplify the process of integration with Cardano. This interface is particularly useful for exchanges, since they can interact with the Cardano chain using the same interface that they use with other blockchains.\n\n### Looking forward\n\nWith [smart contracts](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) coming to Cardano soon, this means that [Plutus](https://iohk.io/en/blog/posts/2021/04/13/plutus-what-you-need-to-know/), the native smart contract language, and other smart contract development languages like [Marlowe](https://iohk.io/en/blog/posts/2021/05/26/reimagining-peer-to-peer-finance-with-marlowe/) for finance and [Glow](https://glow-lang.org/) for DApps will be integrated into the Cardano stack. IO Global’s engineers will provide new and extended components to compile Plutus, Marlowe, and Glow scripts, submit them on-chain, and interact with them (Figure 2).\n\n![](https://ucarecdn.com/49d00118-da94-4dde-9be2-1a721c698a39/)\n\n**Figure 2. Plutus, Marlowe, Glow, Solidity, and IELE can all be used to write Cardano smart contracts**\n\nThe [Alonzo protocol upgrade](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) will build on recent token upgrades and is being deployed to the mainnet via several testnets. Our Plutus partners and Plutus Pioneers will help us to test Plutus Core and will be part of the user acceptance phase before mainnet deployment. At this point we will officially add the Plutus and Marlowe components, such as both interpreters, to Cardano’s platform stack. \n\n*To keep up to date with the Alonzo rollout, please check our social channels and blog page.*',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'a-close-look-at-the-software-running-cardano',
                                url: '/blog/posts/2021/06/08/a-close-look-at-the-software-running-cardano/',
                                read_time: 5
                            },
                            {
                                publish_date: '2021-04-30T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/65cf3157-04f6-4e3c-9c8e-4ef6f51dc047/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'The essential Cardano list - a new resource for the community',
                                        subtitle: 'Introducing a new central source for all things Cardano-related',
                                        audio: null,
                                        soundcloud: [],
                                        body_content: 'Today sees the publication of [the Essential Cardano list](https://github.com/input-output-hk/essential-cardano) – a new GitHub repository which will help you to find out everything you need to know about Cardano. Whether you want to understand what Cardano is and who our partners are, learn about our mission and roadmap, or get stuck in and build on Cardano, this is the place to start.\r\n\r\nInspired by GitHub\'s well known *Awesome* lists, the Essential Cardano list provides an outline of our thriving ecosystem, as well as a comprehensive list of resources to help you learn more and get started. As it grows and expands, this new list aims to become the canonical source of material for Cardano, including both official resources and community-generated materials. We are now looking for our community members to help us extend it even more by contributing their suggestions.\r\n\r\n## A central location of essential resources ##\r\nWe want to have a central location for all things Cardano, to bring everything together and make it easy for people to find what they need. We have provided links to all official sites, channels, and resources, as well as to a collection of material such as explainers, guides, developer resources, glossaries, primers, tutorials, and much more.\r\n\r\nOn top of that, we have identified assets developed by the community which we think provide great value and complement our own content that we produce. Our aim is that our community will now help us to grow it out and make it even better.\r\n\r\n## Navigate the Cardano ecosystem ##\r\nEssential Cardano provides an outline of all the core entities, partner groups, and facets that are part of our growing ecosystem to help orientate you to understand all the existing and new relationships that are being developed. \r\n\r\nInitially, our focus has been on curating links and references to what’s going on within our growing ecosystem. As we update the list, or additions are made by community members, the list will also grow. We also plan to add additional visual elements including infographics and ecosystem maps over time. We have included an existing [ecosystem map](https://github.com/input-output-hk/essential-cardano/blob/main/essential-cardano-list.md#navigate-the-cardano-ecosystem) which is currently being refreshed by our team to reflect new relationships and partnerships we have formed recently. We plan to release a May version of this map very soon, so if you would like to help us get this up to date as soon as possible, go ahead and raise a pull request with your suggestion! \r\n\r\nWe have also included all the Project Catalyst startups that currently exist so you can understand some of what is being planned for future development. \r\n \r\n## How do I contribute? ##\r\nWe are looking for you to help us to grow out and evolve this essential Cardano list. This list is fully open source so if you know of new content that is being produced by members of the community, new relationships that are not included, or new innovations, please let us know so that we can add them all to this list and promote them. The easiest way to do this is to [raise a pull request](https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request/) on the repository. We’ll evaluate these regularly and provide feedback within each pull request.\r\n\r\n## Growing this list ##\r\n2021 is already a very active year for growth and engagement on Cardano. Following on from yesterday\'s exciting announcements about our [vision for Africa](https://iohk.io/en/blog/posts/2021/04/28/decentralized-identity-on-the-blockchain-is-the-key-to-iohks-vision-for-africa/), and with upcoming [smart contracts](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) and other new products on the way, we expect lots of new and exciting additions. We have already included some contributions from our active [Plutus Pioneers course](https://iohk.io/en/blog/posts/2021/04/01/everything-you-need-to-know-about-our-new-plutus-pioneer-program/), which are very welcome, and we anticipate many more users, developers, and enterprises jumping on board in the coming months. We are happy to see the new [Cardano Q & A Stack Exchange](https://cardano.stackexchange.com/users/login?ssrc=beta&returnurl=%2f) being developed and would encourage our community members to submit their questions to help build this out. Stay tuned for announcements and updates here on our blog, social channels, and within the [Essential Cardano repository](https://github.com/input-output-hk/essential-cardano) itself.',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'The essential Cardano list - a new resource for the community',
                                subtitle: 'Introducing a new central source for all things Cardano-related',
                                audio: null,
                                soundcloud: [],
                                body_content: 'Today sees the publication of [the Essential Cardano list](https://github.com/input-output-hk/essential-cardano) – a new GitHub repository which will help you to find out everything you need to know about Cardano. Whether you want to understand what Cardano is and who our partners are, learn about our mission and roadmap, or get stuck in and build on Cardano, this is the place to start.\r\n\r\nInspired by GitHub\'s well known *Awesome* lists, the Essential Cardano list provides an outline of our thriving ecosystem, as well as a comprehensive list of resources to help you learn more and get started. As it grows and expands, this new list aims to become the canonical source of material for Cardano, including both official resources and community-generated materials. We are now looking for our community members to help us extend it even more by contributing their suggestions.\r\n\r\n## A central location of essential resources ##\r\nWe want to have a central location for all things Cardano, to bring everything together and make it easy for people to find what they need. We have provided links to all official sites, channels, and resources, as well as to a collection of material such as explainers, guides, developer resources, glossaries, primers, tutorials, and much more.\r\n\r\nOn top of that, we have identified assets developed by the community which we think provide great value and complement our own content that we produce. Our aim is that our community will now help us to grow it out and make it even better.\r\n\r\n## Navigate the Cardano ecosystem ##\r\nEssential Cardano provides an outline of all the core entities, partner groups, and facets that are part of our growing ecosystem to help orientate you to understand all the existing and new relationships that are being developed. \r\n\r\nInitially, our focus has been on curating links and references to what’s going on within our growing ecosystem. As we update the list, or additions are made by community members, the list will also grow. We also plan to add additional visual elements including infographics and ecosystem maps over time. We have included an existing [ecosystem map](https://github.com/input-output-hk/essential-cardano/blob/main/essential-cardano-list.md#navigate-the-cardano-ecosystem) which is currently being refreshed by our team to reflect new relationships and partnerships we have formed recently. We plan to release a May version of this map very soon, so if you would like to help us get this up to date as soon as possible, go ahead and raise a pull request with your suggestion! \r\n\r\nWe have also included all the Project Catalyst startups that currently exist so you can understand some of what is being planned for future development. \r\n \r\n## How do I contribute? ##\r\nWe are looking for you to help us to grow out and evolve this essential Cardano list. This list is fully open source so if you know of new content that is being produced by members of the community, new relationships that are not included, or new innovations, please let us know so that we can add them all to this list and promote them. The easiest way to do this is to [raise a pull request](https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request/) on the repository. We’ll evaluate these regularly and provide feedback within each pull request.\r\n\r\n## Growing this list ##\r\n2021 is already a very active year for growth and engagement on Cardano. Following on from yesterday\'s exciting announcements about our [vision for Africa](https://iohk.io/en/blog/posts/2021/04/28/decentralized-identity-on-the-blockchain-is-the-key-to-iohks-vision-for-africa/), and with upcoming [smart contracts](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) and other new products on the way, we expect lots of new and exciting additions. We have already included some contributions from our active [Plutus Pioneers course](https://iohk.io/en/blog/posts/2021/04/01/everything-you-need-to-know-about-our-new-plutus-pioneer-program/), which are very welcome, and we anticipate many more users, developers, and enterprises jumping on board in the coming months. We are happy to see the new [Cardano Q & A Stack Exchange](https://cardano.stackexchange.com/users/login?ssrc=beta&returnurl=%2f) being developed and would encourage our community members to submit their questions to help build this out. Stay tuned for announcements and updates here on our blog, social channels, and within the [Essential Cardano repository](https://github.com/input-output-hk/essential-cardano) itself.',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'the-essential-cardano-list-a-new-resource-for-the-community',
                                url: '/blog/posts/2021/04/30/the-essential-cardano-list-a-new-resource-for-the-community/',
                                read_time: 4
                            },
                            {
                                publish_date: '2021-04-01T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/722fd8a5-e3a7-4754-a5bd-207e9b89af3e/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Everything you need to know about our new Plutus Pioneer Program',
                                        subtitle: 'Learn Plutus and become a certified Plutus Pioneer with our new series of interactive training courses – starting next week',
                                        audio: null,
                                        soundcloud: [],
                                        body_content: 'Next week sees the start of the first in a series of our Plutus pioneer training programs where participants can learn the fundamentals of Plutus and help to test the code before the official release of our new smart contract language. This new innovative program aims to recruit and train developers within the ecosystem so that they are fully prepared when Plutus is deployed to the Cardano mainnet later this year.\n\n\r\n\r\nSince we announced this new course on [March’s Cardano360 show](https://youtu.be/ULBLgPgxtN8?t=3731) we have had a huge expression of interest from our developer community, both from developers who want to create decentralized applications (DApps), and smart contract programmers who want to work with Cardano’s principal development language. This week we have contacted everyone interested (over 2,000) to get a better idea of their experience and expertise. Those of you who have been selected for the first round of this program will hear from us very soon. If you don’t receive an invitation at this stage, don’t worry as we will be running several rounds of this program, so please do stay in touch!\n\n\r\n\r\n## Course structure ##\r\nThe first iteration of the new program starts next week.  The cohort joining this program will be true pioneers. As well as being part of a group that will have *early access* to a set of learning modules, your feedback will help us develop and iterate the overall learning experience.\n\n\r\n\r\nThe course will teach you the core principles of how to code in both Haskell and Plutus. The course modules will cover the building blocks of Haskell and Plutus, including functions and data types, type classes, monads, template Haskell, using the [Plutus Playground](https://iohk.io/en/blog/posts/2021/01/25/introducing-the-new-plutus-playground/), the [Extended UTXO model](https://iohk.io/en/blog/posts/2021/03/11/cardanos-extended-utxo-accounting-model/), working with Plutus on and off the chain, minting policies, state machines, the Plutus application framework, as well as some case studies and practical exercises. \n\r\n\r\nThe course will follow a modular approach and will be highly interactive – each week we will be releasing new teaching videos from our director of education, Lars Brünjes, along with a set of practical exercises to complete during the week as part of each module. We will also be holding regular Q&A sessions and you will have access to a dedicated community channel on Discord, created especially to help you to connect with other course participants as you learn. \r\n\r\nOutside the exercises and videos, students will be encouraged to learn at a pace that is right for them and to collaborate with fellow students. As with all learning experiences, the more you put in the more you will get out! We encourage all participants to *engage with each other* and work collaboratively to answer questions and solve problems. \r\n\r\nWe will have a small team of moderators who will check in from time to time to help facilitate and assist.  They can also  help triage issues or questions that may come up in your learning during the week. These moderators are all graduates of the [Mongolia class of 2020](https://iohk.io/en/blog/posts/2020/12/21/online-learning-with-haskell-the-mongolia-class-of-2020/) that completed the Haskell MOOC and are well placed to assist with questions and challenges. At the close of each week, Lars will engage directly with the group to resolve more complex technical questions and provide feedback on the subject matter covered that week. \r\n\r\n## Prior experience ##\r\nAs Plutus is based largely on Haskell, having some prior experience with Haskell (or another functional programming language), will be very helpful. At a minimum, you should have some programming experience and a mathematical and technical mindset. You should be as keen to learn as to help us; while we have run a number of successful courses already, this is the first time we have challenged ourselves to teach at this scale. So be prepared for road bumps along the way as we learn and improve, too!\r\n\r\nBear in mind that this course is not for coding beginners. While you do not need to be an expert in formal methods, programming  experience and a general aptitude for logical and mathematical thinking are highly desirable. The course will include advanced features like Template Haskell, type-level programming, and effect systems. If you need a refresher or get an introduction to Haskell, we recommend that you read the [Learn You a Haskell guide](http://learnyouahaskell.com/) before you participate in the course. We’ll open several new cohorts this year, so you won’t miss out.\r\n\r\n## When does the course start? ##\r\nThe course starts next week and will run concurrently for ten weeks through to mid June. It will involve approximately ten hours a week of your time and effort each week. \r\n\r\n## Will there be other pioneer programs? ##\r\nYes, we are keen to be as inclusive as we can on our path to rolling out smart contracts. We are also developing education programs for both [Marlowe](https://docs.cardano.org/en/latest/marlowe/marlowe-explainer.html) and [Glow](https://developers.cardano.org/en/programming-languages/glow/overview/), so don\'t feel like you have missed out if this Plutus course is not for you. We’re still keen to have you onboard, so do watch this space for details of these other courses!\r\n\r\n## Certification ##\r\nWe will reward participants for their efforts in participating in this course and certify those pioneers that complete the entire program and are successful. These Plutus pioneer certificates will be represented as non fungible tokens (on the testnet) and locked by a Plutus contract. Pioneers can demonstrate their knowledge and qualification by constructing an appropriate transaction to unlock their individual token.\r\n \r\n## Ready to start ##\r\nWe are excited to have so many developers from our ecosystem on board and ready to get started and learn Plutus. You’ll not only be learning yourselves, but acting as a pioneer to help us determine the best way to teach and deliver this course – truly helping pave the way for future cohorts who enroll! We look forward to bringing you on this learning journey before we launch Plutus to the world! ',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Everything you need to know about our new Plutus Pioneer Program',
                                subtitle: 'Learn Plutus and become a certified Plutus Pioneer with our new series of interactive training courses – starting next week',
                                audio: null,
                                soundcloud: [],
                                body_content: 'Next week sees the start of the first in a series of our Plutus pioneer training programs where participants can learn the fundamentals of Plutus and help to test the code before the official release of our new smart contract language. This new innovative program aims to recruit and train developers within the ecosystem so that they are fully prepared when Plutus is deployed to the Cardano mainnet later this year.\n\n\r\n\r\nSince we announced this new course on [March’s Cardano360 show](https://youtu.be/ULBLgPgxtN8?t=3731) we have had a huge expression of interest from our developer community, both from developers who want to create decentralized applications (DApps), and smart contract programmers who want to work with Cardano’s principal development language. This week we have contacted everyone interested (over 2,000) to get a better idea of their experience and expertise. Those of you who have been selected for the first round of this program will hear from us very soon. If you don’t receive an invitation at this stage, don’t worry as we will be running several rounds of this program, so please do stay in touch!\n\n\r\n\r\n## Course structure ##\r\nThe first iteration of the new program starts next week.  The cohort joining this program will be true pioneers. As well as being part of a group that will have *early access* to a set of learning modules, your feedback will help us develop and iterate the overall learning experience.\n\n\r\n\r\nThe course will teach you the core principles of how to code in both Haskell and Plutus. The course modules will cover the building blocks of Haskell and Plutus, including functions and data types, type classes, monads, template Haskell, using the [Plutus Playground](https://iohk.io/en/blog/posts/2021/01/25/introducing-the-new-plutus-playground/), the [Extended UTXO model](https://iohk.io/en/blog/posts/2021/03/11/cardanos-extended-utxo-accounting-model/), working with Plutus on and off the chain, minting policies, state machines, the Plutus application framework, as well as some case studies and practical exercises. \n\r\n\r\nThe course will follow a modular approach and will be highly interactive – each week we will be releasing new teaching videos from our director of education, Lars Brünjes, along with a set of practical exercises to complete during the week as part of each module. We will also be holding regular Q&A sessions and you will have access to a dedicated community channel on Discord, created especially to help you to connect with other course participants as you learn. \r\n\r\nOutside the exercises and videos, students will be encouraged to learn at a pace that is right for them and to collaborate with fellow students. As with all learning experiences, the more you put in the more you will get out! We encourage all participants to *engage with each other* and work collaboratively to answer questions and solve problems. \r\n\r\nWe will have a small team of moderators who will check in from time to time to help facilitate and assist.  They can also  help triage issues or questions that may come up in your learning during the week. These moderators are all graduates of the [Mongolia class of 2020](https://iohk.io/en/blog/posts/2020/12/21/online-learning-with-haskell-the-mongolia-class-of-2020/) that completed the Haskell MOOC and are well placed to assist with questions and challenges. At the close of each week, Lars will engage directly with the group to resolve more complex technical questions and provide feedback on the subject matter covered that week. \r\n\r\n## Prior experience ##\r\nAs Plutus is based largely on Haskell, having some prior experience with Haskell (or another functional programming language), will be very helpful. At a minimum, you should have some programming experience and a mathematical and technical mindset. You should be as keen to learn as to help us; while we have run a number of successful courses already, this is the first time we have challenged ourselves to teach at this scale. So be prepared for road bumps along the way as we learn and improve, too!\r\n\r\nBear in mind that this course is not for coding beginners. While you do not need to be an expert in formal methods, programming  experience and a general aptitude for logical and mathematical thinking are highly desirable. The course will include advanced features like Template Haskell, type-level programming, and effect systems. If you need a refresher or get an introduction to Haskell, we recommend that you read the [Learn You a Haskell guide](http://learnyouahaskell.com/) before you participate in the course. We’ll open several new cohorts this year, so you won’t miss out.\r\n\r\n## When does the course start? ##\r\nThe course starts next week and will run concurrently for ten weeks through to mid June. It will involve approximately ten hours a week of your time and effort each week. \r\n\r\n## Will there be other pioneer programs? ##\r\nYes, we are keen to be as inclusive as we can on our path to rolling out smart contracts. We are also developing education programs for both [Marlowe](https://docs.cardano.org/en/latest/marlowe/marlowe-explainer.html) and [Glow](https://developers.cardano.org/en/programming-languages/glow/overview/), so don\'t feel like you have missed out if this Plutus course is not for you. We’re still keen to have you onboard, so do watch this space for details of these other courses!\r\n\r\n## Certification ##\r\nWe will reward participants for their efforts in participating in this course and certify those pioneers that complete the entire program and are successful. These Plutus pioneer certificates will be represented as non fungible tokens (on the testnet) and locked by a Plutus contract. Pioneers can demonstrate their knowledge and qualification by constructing an appropriate transaction to unlock their individual token.\r\n \r\n## Ready to start ##\r\nWe are excited to have so many developers from our ecosystem on board and ready to get started and learn Plutus. You’ll not only be learning yourselves, but acting as a pioneer to help us determine the best way to teach and deliver this course – truly helping pave the way for future cohorts who enroll! We look forward to bringing you on this learning journey before we launch Plutus to the world! ',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'everything-you-need-to-know-about-our-new-plutus-pioneer-program',
                                url: '/blog/posts/2021/04/01/everything-you-need-to-know-about-our-new-plutus-pioneer-program/',
                                read_time: 5
                            },
                            {
                                publish_date: '2020-12-09T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/e08b30a4-e8e8-4978-b8df-d33299cca0ee/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'The new Mantis: Bringing security and stability to the Ethereum Classic ecosystem',
                                        subtitle: 'We’re committed to bringing innovation and fresh life to ETC and this is just the start',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'IOHK has a long association with Ethereum Classic (ETC) and its community, which preserves an untampered history free from external interference and subjective altering of transactions. Serving as the next-generation digital currency platform, ETC is built as an intuitive programming platform, which allows developers of all skill sets to build the next wave of market disrupting decentralized applications (DApps). \n\nThe goal of ETC is to securely and methodically establish a strong ecosystem underpinned by solid foundation and core immutability. However, recent 51% attacks have put the ETC ecosystem into a precarious position, denting its confidence and challenging the community’s ability to address this issue, while representing an existential threat to its future viability. \n\n## Driving innovation & future growth for ETC\n\nNew Mantis is the only client that is written natively for Ethereum Classic and it offers unrivalled levels of assurance, security, and usability. IOHK has relaunched the Mantis project to mitigate against the recent attacks, provide enhanced security, and establish a robust means of interacting with the ETC chain. A commitment to fostering innovation and sustainability lies at the heart of the project. We are aiming to provide a steady funding income with the establishment of a proto-treasury to nurture future development and growth. This Mantis re-launch represents the culmination of a project that we\'ve been working on for some time. Over the past few months, we have resurrected our code base, and gathered a dedicated Mantis team together who have worked hard to refine and improve the code and deliver important new features.\n\n## What is the Mantis project?\n\nMantis is a project that is built for the community, specifically designed for the developers, wallet users, and infrastructure providers to enable direct interaction with the ETC blockchain. Essentially, it is a place where future development can evolve and be tested by the community. The Mantis release includes the following components:\n- Mantis client - a CLI tool that connects to other clients in a peer-to-peer manner to allow users to communicate with the ETC chain, send and receive transactions, sync the blockchain data, execute and validate smart contracts, and deploy new smart contracts on-chain.\r\n- Mantis wallet - a node wallet with incorporated graphical user interface (GUI), which connects to both mainnet and the Sagano and Mordor testnets. \r\n- Mantis faucet - enables developers to receive testnet funds for use on the Sagano and Mordor testnets.\r\n- Mantis explorer - allows tracking recent activities and transactions in regards to the ETC chain, covering the ETC mainnet, and Sagano and Mordor testnets. \n\nPlease visit the [Mantis website](https://mantisclient.io/) where you can download the latest version of both the Mantis client and wallet.\r\n\r\nMantis software implements the official Ethereum Classic specification and Ethereum Classic Improvement Proposals [(ECIPs)](https://ecips.ethereumclassic.org/) introduced by ongoing efforts and discussed across teams in the ecosystem. The project has undergone a number of enhancements in terms of adding robustness and variety to the client offering, including optimizations and network upgrades that improve network security, sustainability, and performance in the long term. It has been developed from the ground up and built in 100% Scala code, a functional programming language that offers security guarantees that other languages do not. Mantis features include stable peer discovery, pruning, fast synchronization, and newly implemented checkpointing (for 51% attack resistance) and proto-treasury (for long-term sustainability). Let’s take a closer look at these features.\n\n## Checkpointing \r\n*Persistence* and *liveness* are two crucial properties that a transaction ledger should possess. It is a proven fact that both persistence and liveness suffer when the adversarial mining power in the proof of work surpasses 50%, and in the recent year, ETC has undergone several double-spending attacks prompted by the creation of large chain reorganizations. Considering that persistence and liveness were not guaranteed within the ETC network, we sought to implement protocol changes that will re-establish persistence and liveness under current network conditions, and *checkpointing* is one of the proposed solutions. \r\n\r\nCheckpointing ensures that the protocol is unaltered, by using the *k* parameter, or depth parameter, where every *k* block gets irreversibly "checkpointed", meaning that no one can ever drop or revert it. A trusted authority can choose the block on which to issue a checkpoint, which means that they can decide which block becomes the canonical chain that all parties should follow. This trusted authority must run continuously and is responsible for publishing the checkpoint to the network. Checkpointing ensures that the protocol is unaltered with regards to mining. The mining rewards are not affected and the checkpointing federation can only issue checkpoints on blocks that have valid proof of work and cannot mint blocks on its own. \r\n\r\nCheckpointing is now implemented within the Mantis project, and according to our recent [ECIP comparison for 51% attack resistance](https://static.iohk.io/docs/etc/ecip-comparison-for-51-attack-resistance.pdf), it provides far greater, and importantly formally proven, security against these types of attacks. It is important that any 51% attack mitigation is truly robust enough to give absolute certainty to ETC holders, users, and service providers that their transactions will be secure.\r\n\n## Proto-Treasury\r\nFor the longer-term health and success of the ETC ecosystem, we position network growth, sustainability, and innovation as key elements to ensure network security. With that in mind, we are implementing a proto-treasury system within the Mantis project to establish a steady funding income.  A well-developed governance strategy will enable effective, distributed funding for the long-term development of Mantis, whereas a decentralized treasury would ensure two important things for the future of the ecosystem:\r\n- Firstly, it would provide a permanent ongoing source of funding for the ETC network. while increasing the value of the ecosystem and promoting greater developer engagement. \r\n\r\n- Secondly, it would provide a distributed and transparent funding mechanism, which lets the ETC community determine its future growth and enable the sustainability required for innovation and growth.\r\n\r\nEstablishing the treasury for funding purposes ensures a clear vision of the substantial system maintenance focused to obtain innovation and diversity from other projects, including proof of stake (PoS) and newer blockchains. This solution is straightforward in its optimization for speed and implementation.\r\n\r\nThe proposal foresees to distribute 80% of existing mining rewards to miners and 20% to the proto-treasury smart contract. The treasury will be controlled by the community and will enable a decentralized, collaborative decision-making process, offering an opt-in type collaboration for those who are interested.\n\n## What’s next?\r\nAs much as we’re excited about the Mantis relaunch, it should be stressed that its capability won’t be limited to just the features outlined here. Mantis is an evolving project and right now we are establishing its foundational building blocks and running rigorous security audits. Further down the road, it will see more performance improvements in terms of CPU, GPU and ASICs compatibility, a new proof-of-work consensus protocol and algorithm introduction (PRISM consensus, Keccak256 algorithm) and, of course, additional enhancements for better interoperability and speed of transaction processing. You can also find out more by reading the [Mantis documentation](https://docs.mantisclient.io/) and joining the [Mantis discord](https://discord.com/invite/7vUyWrN33p) to stay up to date on all things Mantis or Ethereum Classic. Check out the Crowdcast launch event for the full Mantis showcase (and a keynote from Charles Hoskinson) and follow the Mantis team on [Twitter](https://twitter.com/Mantis_IO/) to get the latest updates! ',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'The new Mantis: Bringing security and stability to the Ethereum Classic ecosystem',
                                subtitle: 'We’re committed to bringing innovation and fresh life to ETC and this is just the start',
                                audio: null,
                                soundcloud: null,
                                body_content: 'IOHK has a long association with Ethereum Classic (ETC) and its community, which preserves an untampered history free from external interference and subjective altering of transactions. Serving as the next-generation digital currency platform, ETC is built as an intuitive programming platform, which allows developers of all skill sets to build the next wave of market disrupting decentralized applications (DApps). \n\nThe goal of ETC is to securely and methodically establish a strong ecosystem underpinned by solid foundation and core immutability. However, recent 51% attacks have put the ETC ecosystem into a precarious position, denting its confidence and challenging the community’s ability to address this issue, while representing an existential threat to its future viability. \n\n## Driving innovation & future growth for ETC\n\nNew Mantis is the only client that is written natively for Ethereum Classic and it offers unrivalled levels of assurance, security, and usability. IOHK has relaunched the Mantis project to mitigate against the recent attacks, provide enhanced security, and establish a robust means of interacting with the ETC chain. A commitment to fostering innovation and sustainability lies at the heart of the project. We are aiming to provide a steady funding income with the establishment of a proto-treasury to nurture future development and growth. This Mantis re-launch represents the culmination of a project that we\'ve been working on for some time. Over the past few months, we have resurrected our code base, and gathered a dedicated Mantis team together who have worked hard to refine and improve the code and deliver important new features.\n\n## What is the Mantis project?\n\nMantis is a project that is built for the community, specifically designed for the developers, wallet users, and infrastructure providers to enable direct interaction with the ETC blockchain. Essentially, it is a place where future development can evolve and be tested by the community. The Mantis release includes the following components:\n- Mantis client - a CLI tool that connects to other clients in a peer-to-peer manner to allow users to communicate with the ETC chain, send and receive transactions, sync the blockchain data, execute and validate smart contracts, and deploy new smart contracts on-chain.\r\n- Mantis wallet - a node wallet with incorporated graphical user interface (GUI), which connects to both mainnet and the Sagano and Mordor testnets. \r\n- Mantis faucet - enables developers to receive testnet funds for use on the Sagano and Mordor testnets.\r\n- Mantis explorer - allows tracking recent activities and transactions in regards to the ETC chain, covering the ETC mainnet, and Sagano and Mordor testnets. \n\nPlease visit the [Mantis website](https://mantisclient.io/) where you can download the latest version of both the Mantis client and wallet.\r\n\r\nMantis software implements the official Ethereum Classic specification and Ethereum Classic Improvement Proposals [(ECIPs)](https://ecips.ethereumclassic.org/) introduced by ongoing efforts and discussed across teams in the ecosystem. The project has undergone a number of enhancements in terms of adding robustness and variety to the client offering, including optimizations and network upgrades that improve network security, sustainability, and performance in the long term. It has been developed from the ground up and built in 100% Scala code, a functional programming language that offers security guarantees that other languages do not. Mantis features include stable peer discovery, pruning, fast synchronization, and newly implemented checkpointing (for 51% attack resistance) and proto-treasury (for long-term sustainability). Let’s take a closer look at these features.\n\n## Checkpointing \r\n*Persistence* and *liveness* are two crucial properties that a transaction ledger should possess. It is a proven fact that both persistence and liveness suffer when the adversarial mining power in the proof of work surpasses 50%, and in the recent year, ETC has undergone several double-spending attacks prompted by the creation of large chain reorganizations. Considering that persistence and liveness were not guaranteed within the ETC network, we sought to implement protocol changes that will re-establish persistence and liveness under current network conditions, and *checkpointing* is one of the proposed solutions. \r\n\r\nCheckpointing ensures that the protocol is unaltered, by using the *k* parameter, or depth parameter, where every *k* block gets irreversibly "checkpointed", meaning that no one can ever drop or revert it. A trusted authority can choose the block on which to issue a checkpoint, which means that they can decide which block becomes the canonical chain that all parties should follow. This trusted authority must run continuously and is responsible for publishing the checkpoint to the network. Checkpointing ensures that the protocol is unaltered with regards to mining. The mining rewards are not affected and the checkpointing federation can only issue checkpoints on blocks that have valid proof of work and cannot mint blocks on its own. \r\n\r\nCheckpointing is now implemented within the Mantis project, and according to our recent [ECIP comparison for 51% attack resistance](https://static.iohk.io/docs/etc/ecip-comparison-for-51-attack-resistance.pdf), it provides far greater, and importantly formally proven, security against these types of attacks. It is important that any 51% attack mitigation is truly robust enough to give absolute certainty to ETC holders, users, and service providers that their transactions will be secure.\r\n\n## Proto-Treasury\r\nFor the longer-term health and success of the ETC ecosystem, we position network growth, sustainability, and innovation as key elements to ensure network security. With that in mind, we are implementing a proto-treasury system within the Mantis project to establish a steady funding income.  A well-developed governance strategy will enable effective, distributed funding for the long-term development of Mantis, whereas a decentralized treasury would ensure two important things for the future of the ecosystem:\r\n- Firstly, it would provide a permanent ongoing source of funding for the ETC network. while increasing the value of the ecosystem and promoting greater developer engagement. \r\n\r\n- Secondly, it would provide a distributed and transparent funding mechanism, which lets the ETC community determine its future growth and enable the sustainability required for innovation and growth.\r\n\r\nEstablishing the treasury for funding purposes ensures a clear vision of the substantial system maintenance focused to obtain innovation and diversity from other projects, including proof of stake (PoS) and newer blockchains. This solution is straightforward in its optimization for speed and implementation.\r\n\r\nThe proposal foresees to distribute 80% of existing mining rewards to miners and 20% to the proto-treasury smart contract. The treasury will be controlled by the community and will enable a decentralized, collaborative decision-making process, offering an opt-in type collaboration for those who are interested.\n\n## What’s next?\r\nAs much as we’re excited about the Mantis relaunch, it should be stressed that its capability won’t be limited to just the features outlined here. Mantis is an evolving project and right now we are establishing its foundational building blocks and running rigorous security audits. Further down the road, it will see more performance improvements in terms of CPU, GPU and ASICs compatibility, a new proof-of-work consensus protocol and algorithm introduction (PRISM consensus, Keccak256 algorithm) and, of course, additional enhancements for better interoperability and speed of transaction processing. You can also find out more by reading the [Mantis documentation](https://docs.mantisclient.io/) and joining the [Mantis discord](https://discord.com/invite/7vUyWrN33p) to stay up to date on all things Mantis or Ethereum Classic. Check out the Crowdcast launch event for the full Mantis showcase (and a keynote from Charles Hoskinson) and follow the Mantis team on [Twitter](https://twitter.com/Mantis_IO/) to get the latest updates! ',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'the-new-mantis-bringing-security-and-stability-to-the-ethereum-classic-ecosystem-1',
                                url: '/blog/posts/2020/12/09/the-new-mantis-bringing-security-and-stability-to-the-ethereum-classic-ecosystem-1/',
                                read_time: 6
                            },
                            {
                                publish_date: '2020-02-27',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/53f9deb3-e57b-40a3-8c19-276aeae1a1da/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Educating the world on Cardano: initiatives and plans for 2020',
                                        subtitle: 'Learn more about the education team\'s plans for the upcoming year',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'Education has always been a key part of IOHK’s strategy. Our mission is to grow our global community and business through the medium of education, and to share what we have learned. By claiming leadership in worldwide education on blockchain technology, we have the chance to shape the field for generations and to leave a lasting legacy.\n\nA consistent theme from 2019 has been the demand for a broad range of educational content, as demonstrated by the feedback received about the Incentivized Testnet, as well as the steady flow of support requests to our helpdesk. A key focus in IOHK for 2020 is to develop and expand our education materials as we transition fully into the Shelley era and then to the Goguen era of Cardano.\n\nThe IOHK education team will be investing significant time and effort this year in broadening our range of materials. We aim to enhance understanding of our technologies using a variety of learning and training assets targeted at a wide range of stakeholder audiences, both internal and external. This will be vital as the use of IOHK technology moves into the mainstream. We also aim to provide knowledge and information to enterprise decision-makers so they know what business problems our technologies can solve. We have lots planned and many projects are underway as we grow Cardano into a global social and financial operating system.\n\n## What can you expect?\n\nWe started 2020 with lectures, by Dr Lars Brünjes, our director of education, at the University of Malta. The focus of these lectures was on Plutus and Marlowe, our programming languages for smart contracts. The fruits of these sessions will, in turn, form the foundation of some modular training materials that we plan to formalize and develop over the coming months.\n\nOur free Udemy courses on [Plutus](https://www.udemy.com/course/plutus-reliable-smart-contracts/) and [Marlowe](https://www.udemy.com/course/marlowe-programming-language/) by Alejandro Garcia have proven very popular, with over 5,000 students signed up. Feedback has been positive and, as a result of what we learned from our students, we’ve been making incremental improvements over the last year. We now want to take this to the next level and are planning to fully update both courses soon to bring them up to speed with the latest development changes and new features. We are also in the initial planning stages for a second edition of the ebook, [Plutus: Writing reliable smart contracts](https://leanpub.com/plutus-smart-contracts) by Lars Brünjes and Polina Vinogradova, which we will be publishing later this year. The writing team has started to identify improvements and we are also gathering feedback directly from readers. If you have suggestions, please raise a pull request in our [Plutus ebook GitHub repository](https://github.com/input-output-hk/plutus/tree/master/plutus-book) with your ideas.\n\nAn important step in bridging the gap between our academic papers and mainstream understanding of these concepts is to teach people about Ouroboros, the proof-of-stake protocol that powers Cardano and ada. In response to the valuable feedback we have received from running the Incentivized Testnet, we are planning to create varied educational content to help stake pool operators understand Ouroboros and how the protocol works on a practical level.\n\n## Broadening our reach\n\nTo broaden the reach of our training courses and content, we are also investigating a way to migrate our popular Haskell training course into a massive online course, or MOOC, while also making it more comprehensive with the inclusion of Plutus and Marlowe material. In this way, we hope our MOOC will make the course even more valuable, and provide access to the widest possible global community. In addition, we are planning a comprehensive classroom-based Haskell and Plutus course in Mongolia, details of which will be finalized soon. We plan to use the introductory part of the online Haskell course as a primer for this face-to-face training. This is an example of a core efficiency that we are embracing where we aim to reuse content on Haskell, Plutus, and Marlowe across a variety of stand-alone modular materials that we can use externally and within the company for developing our staff.\n\nWe appreciate the value of interactive and meaningful training workshops, so we intend to host many more this year in several locations around the world. These events are in the initial planning stages and the first in the series will take place in Quebec in the spring. We’ll announce more details through our official channels – Twitter, email, here – nearer the time. The IOHK education team are on hand to support and prepare the necessary learning tools for participants to use at these events.\n\nAlongside these materials and courses, we are mentoring an undergraduate student at the International University of Management (ISM), with her thesis on the topic of the power of blockchain in emerging markets. Additionally, Dr Jamie Gabbay has been invited to contribute to the book \'*Applications of new generation technology to cryptocurrencies, banking, and finance*’ by Devraj Basu.\n\n## Internal initiatives\n\nWe are also working with our human resources team to build the IOHK Training Academy: a new learning portal for our internal teams to upskill and develop professionally. This new resource is part of our learning and development strategy that aims to improve employee engagement, satisfaction, and retention. We want to provide access to a library of assets so our staff can easily find exactly what they need. We will be developing tailored ‘learning journeys’ by function, ready-made content that will help people develop skills in new areas, as well as creating specific onboarding journeys for new starters. This is a vital resource for a fast-growing company with staff and contractors spread across 43 countries and will prove to be an important asset for all our people.\n\n2020 is going to be a pivotal year for Cardano and we are looking forward to playing our part. It is our aim to teach both individuals and organizations how to use the protocol, and how it can help with their everyday lives. We have lots to do and we look forward to sharing all the educational content that we produce with our existing community, as well as those of you who are new to Cardano. ',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Educating the world on Cardano: initiatives and plans for 2020',
                                subtitle: 'Learn more about the education team\'s plans for the upcoming year',
                                audio: null,
                                soundcloud: null,
                                body_content: 'Education has always been a key part of IOHK’s strategy. Our mission is to grow our global community and business through the medium of education, and to share what we have learned. By claiming leadership in worldwide education on blockchain technology, we have the chance to shape the field for generations and to leave a lasting legacy.\n\nA consistent theme from 2019 has been the demand for a broad range of educational content, as demonstrated by the feedback received about the Incentivized Testnet, as well as the steady flow of support requests to our helpdesk. A key focus in IOHK for 2020 is to develop and expand our education materials as we transition fully into the Shelley era and then to the Goguen era of Cardano.\n\nThe IOHK education team will be investing significant time and effort this year in broadening our range of materials. We aim to enhance understanding of our technologies using a variety of learning and training assets targeted at a wide range of stakeholder audiences, both internal and external. This will be vital as the use of IOHK technology moves into the mainstream. We also aim to provide knowledge and information to enterprise decision-makers so they know what business problems our technologies can solve. We have lots planned and many projects are underway as we grow Cardano into a global social and financial operating system.\n\n## What can you expect?\n\nWe started 2020 with lectures, by Dr Lars Brünjes, our director of education, at the University of Malta. The focus of these lectures was on Plutus and Marlowe, our programming languages for smart contracts. The fruits of these sessions will, in turn, form the foundation of some modular training materials that we plan to formalize and develop over the coming months.\n\nOur free Udemy courses on [Plutus](https://www.udemy.com/course/plutus-reliable-smart-contracts/) and [Marlowe](https://www.udemy.com/course/marlowe-programming-language/) by Alejandro Garcia have proven very popular, with over 5,000 students signed up. Feedback has been positive and, as a result of what we learned from our students, we’ve been making incremental improvements over the last year. We now want to take this to the next level and are planning to fully update both courses soon to bring them up to speed with the latest development changes and new features. We are also in the initial planning stages for a second edition of the ebook, [Plutus: Writing reliable smart contracts](https://leanpub.com/plutus-smart-contracts) by Lars Brünjes and Polina Vinogradova, which we will be publishing later this year. The writing team has started to identify improvements and we are also gathering feedback directly from readers. If you have suggestions, please raise a pull request in our [Plutus ebook GitHub repository](https://github.com/input-output-hk/plutus/tree/master/plutus-book) with your ideas.\n\nAn important step in bridging the gap between our academic papers and mainstream understanding of these concepts is to teach people about Ouroboros, the proof-of-stake protocol that powers Cardano and ada. In response to the valuable feedback we have received from running the Incentivized Testnet, we are planning to create varied educational content to help stake pool operators understand Ouroboros and how the protocol works on a practical level.\n\n## Broadening our reach\n\nTo broaden the reach of our training courses and content, we are also investigating a way to migrate our popular Haskell training course into a massive online course, or MOOC, while also making it more comprehensive with the inclusion of Plutus and Marlowe material. In this way, we hope our MOOC will make the course even more valuable, and provide access to the widest possible global community. In addition, we are planning a comprehensive classroom-based Haskell and Plutus course in Mongolia, details of which will be finalized soon. We plan to use the introductory part of the online Haskell course as a primer for this face-to-face training. This is an example of a core efficiency that we are embracing where we aim to reuse content on Haskell, Plutus, and Marlowe across a variety of stand-alone modular materials that we can use externally and within the company for developing our staff.\n\nWe appreciate the value of interactive and meaningful training workshops, so we intend to host many more this year in several locations around the world. These events are in the initial planning stages and the first in the series will take place in Quebec in the spring. We’ll announce more details through our official channels – Twitter, email, here – nearer the time. The IOHK education team are on hand to support and prepare the necessary learning tools for participants to use at these events.\n\nAlongside these materials and courses, we are mentoring an undergraduate student at the International University of Management (ISM), with her thesis on the topic of the power of blockchain in emerging markets. Additionally, Dr Jamie Gabbay has been invited to contribute to the book \'*Applications of new generation technology to cryptocurrencies, banking, and finance*’ by Devraj Basu.\n\n## Internal initiatives\n\nWe are also working with our human resources team to build the IOHK Training Academy: a new learning portal for our internal teams to upskill and develop professionally. This new resource is part of our learning and development strategy that aims to improve employee engagement, satisfaction, and retention. We want to provide access to a library of assets so our staff can easily find exactly what they need. We will be developing tailored ‘learning journeys’ by function, ready-made content that will help people develop skills in new areas, as well as creating specific onboarding journeys for new starters. This is a vital resource for a fast-growing company with staff and contractors spread across 43 countries and will prove to be an important asset for all our people.\n\n2020 is going to be a pivotal year for Cardano and we are looking forward to playing our part. It is our aim to teach both individuals and organizations how to use the protocol, and how it can help with their everyday lives. We have lots to do and we look forward to sharing all the educational content that we produce with our existing community, as well as those of you who are new to Cardano. ',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'educating-the-world-on-cardano-initiatives-and-plans-for-2020',
                                url: '/blog/posts/2020/02/27/educating-the-world-on-cardano-initiatives-and-plans-for-2020/',
                                read_time: 6
                            },
                            {
                                publish_date: '2021-06-08T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/350386c8-b07f-44f0-9787-0c898a3d0460/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'A close look at the software running Cardano',
                                        subtitle: 'Learn about the ‘stack’ of components that interact to run the blockchain platform',
                                        audio: null,
                                        soundcloud: [
                                            {
                                                trackid: 1066347517
                                            }
                                        ],
                                        body_content: 'Cardano has been designed in modules, with linked components that can be used in various ways. These components form the Cardano ‘platform stack’. They work together under the hood to support the construction and use of the live Cardano blockchain.\n\nWe are currently in the early testnet phase on the way to the Alonzo hard fork, which will bring full smart contract capability to Cardano. This process is highly complex, requiring the steady upgrade of the different elements which make up the Cardano platform, and their careful integration and testing. So, it is a good time to revisit these components, explain some of the terminology, and discover how they interact within the ‘platform stack’.\n\n## Elements of the Cardano platform stack\n\n![](https://ucarecdn.com/913ea221-dd67-4938-84be-3461f79b0baa/)\n\n**Figure 1. Components that communicate with the Cardano node**\n\nThe platform stack for Cardano includes these core components:\n\n* Cardano node (and associated processes)\n* Cardano wallet\n* Wallet command line interface (CLI)\n* DB Sync (synchronizes blockchain data with a relational database)\n* PostgreSQL database (which interacts with GraphQL, REST API, and Smash)\n* Smash server\n* Rosetta API (blockchain communication protocol)\n\nNote that the Daedalus wallet is not part of the core stack, but does communicate with the components (Figure 1). \n\n### The node and the networking layer\n\nFirst, let\'s take a look at the [Cardano node](https://github.com/input-output-hk/cardano-node). This software runs on your computer and underpins the network, enabling everyone to participate in the decentralized blockchain. The node integrates the consensus, ledger, and networking sub-components, providing top-level configuration, API, CLI, logging, memory management, and monitoring capabilities that can be used by other Cardano components or by skilled users. Daedalus is a full-node wallet, so if you are running that on your local machine, you are effectively helping to run the network. \n\n*The networking layer*\n\nNext, we have the networking layer. This links each Cardano node into a distributed system that manages the blockchain and associated services. The network consists of a collection of nodes that communicate with each other to maintain the distributed ledger, support transaction submission, and interact with user wallets and other services. The core of the network is built around the decentralized nodes – the stake pools – that collectively validate blocks, and add new blocks to the chain. They are supported by dedicated relay nodes that manage network connections and establish the structure of the network as a whole. The dedicated consumer nodes that are run by the Daedalus wallet and other services connect to this network to track and submit transactions on-chain.\n\nCardano nodes maintain connections with their peers. A set of mini-protocols enable communication between the nodes. Each mini-protocol implements a basic information exchange requirement, such as informing peers of the latest block, sharing blocks as needed, or sharing new transactions around the Cardano network. For connection purposes, mini-protocols are determined by the version of the network protocol. \n\n### Cardano wallet backend\n\nThe [Cardano wallet](https://github.com/input-output-hk/cardano-wallet) backend component supports the graphical user interface of the Daedalus wallet. It is used to send and receive ada. Behind the scenes, the wallet runs a full Cardano node. Unlike a light client wallet, it loads the entire shared ledger and validates all transactions, thus bolstering the security of the blockchain for everyone.\n\n### Wallet command line interface (CLI)\n\nThe wallet command line interface (CLI) supports interactions with the actual blockchain. More technically advanced users can use the CLI  to work with a collection of tools for generating keys, constructing transactions, creating certificates, and performing other tasks. It is organized in a hierarchy of subcommands, and each level comes with its own built-in documentation of command syntax and options.\n\n### DB Sync\n\n[DB Sync](https://github.com/input-output-hk/cardano-db-sync) is a component that follows the activities on the Cardano chain and stores blocks and transactions in PostgreSQL. As a ‘middleware’ component, it powers [cardano-graphql](https://github.com/input-output-hk/cardano-graphql). DB Sync stores blockchain data fetched from [cardano-node](https://github.com/input-output-hk/cardano-node) in an intermediate database to enable higher-level interfaces for blockchain exploration. It also provides a number of queries to fetch Cardano blockchain data from the PostgreSQL, and supports services such as the [Cardano Explorer](https://explorer.cardano.org/en.html), a graphical user interface that reflects the blockchain data in a straightforward way. Cardano GraphQL is a cross-platform API for the GraphQL data query language. \n\n### Rosetta API\n\nThe Rosetta application programming interface provides a high-level interface that aims to make the integration process easier, faster, and more reliable so that you can build once and integrate your blockchain everywhere. We have created a unique [cardano-rosetta](https://github.com/input-output-hk/cardano-rosetta) implementation to simplify the process of integration with Cardano. This interface is particularly useful for exchanges, since they can interact with the Cardano chain using the same interface that they use with other blockchains.\n\n### Looking forward\n\nWith [smart contracts](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) coming to Cardano soon, this means that [Plutus](https://iohk.io/en/blog/posts/2021/04/13/plutus-what-you-need-to-know/), the native smart contract language, and other smart contract development languages like [Marlowe](https://iohk.io/en/blog/posts/2021/05/26/reimagining-peer-to-peer-finance-with-marlowe/) for finance and [Glow](https://glow-lang.org/) for DApps will be integrated into the Cardano stack. IO Global’s engineers will provide new and extended components to compile Plutus, Marlowe, and Glow scripts, submit them on-chain, and interact with them (Figure 2).\n\n![](https://ucarecdn.com/49d00118-da94-4dde-9be2-1a721c698a39/)\n\n**Figure 2. Plutus, Marlowe, Glow, Solidity, and IELE can all be used to write Cardano smart contracts**\n\nThe [Alonzo protocol upgrade](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) will build on recent token upgrades and is being deployed to the mainnet via several testnets. Our Plutus partners and Plutus Pioneers will help us to test Plutus Core and will be part of the user acceptance phase before mainnet deployment. At this point we will officially add the Plutus and Marlowe components, such as both interpreters, to Cardano’s platform stack. \n\n*To keep up to date with the Alonzo rollout, please check our social channels and blog page.*',
                                        uses_mathjax: false,
                                        attachments: []
                                    },
                                    {
                                        lang: 'jp',
                                        title: 'Cardanoで稼働するソフトウェアに注目',
                                        subtitle: 'ブロックチェーンプラットフォームを実行するために相互作用するコンポーネントの「スタック」を知ろう',
                                        audio: null,
                                        soundcloud: [],
                                        body_content: 'Cardanoはモジュール単位で設計されています。ここには、さまざまな方法で使用できるコンポーネントがリンクされています。こうしたコンポーネントはCardano「プラットフォームスタック」を形成しています。これらは内部で共に作動し、稼働するCardanoブロックチェーンの構造と使用を支えています。\n現在は、Cardnaoに完全なスマートコントラクト機能をもたらすAlonzoハードフォークに向けた、初期テストネットの段階にあります。このプロセスは極めて複雑で、Cardanoプラットフォームを構成するさまざまな要素をしっかりとアップグレードし、慎重に統合、テストする必要があります。したがって、今こそこうしたコンポーネントを振り返り、一部の用語を説明し、「プラットフォームスタック」の中でこれらがいかに相互作用するかを考察するいい機会です。\n\n## Cardanoプラットフォームスタックの要素\n\n\n![](https://ucarecdn.com/913ea221-dd67-4938-84be-3461f79b0baa/)\n\n**図1：Cardanoノードと通信するコンポーネント**\n\nCardanoプラットフォームスタックには以下のコアコンポーネントが含まれます。\n\n* Cardanoノード（および関連プロセス）\n* Cardanoウォレット\n* ウォレットコマンドラインインターフェイス（CLI）\n* DB Sync（ブロックチェーンデータを関連するデータベースと同期)\n* PostgreSQLデータベース（GraphQL、REST API、SMASHと相互作用）\n* SMASHサーバー\n* Rosetta API（ブロックチェーン通信プロトコル）\n\n注：Daedalusはコアスタックに含まれませんが、コンポーネントと通信します（図1）。\n\n### ノードとネットワーク層\n\nはじめに、Cardanoノードを見てみましょう。このソフトウェアは個人のコンピューター上で実行されてネットワークを支え、誰もが分散型ブロックチェーンに参加できるようにするものです。ノードは、コンセンサス、台帳、ネットワークのサブコンポーネントを統合し、他のCardanoコンポーネントまたは熟練したユーザーが使用できるトップレベルの設定、API、CLI、ログ、メモリー管理、そして監視機能を提供します。Daedalusはフルノードウォレットで、ローカルマシンで実行することにより、実質的にネットワークの実行に貢献することになります。\n\n*ネットワーク層*\n\n次にネットワーク層です。これは各Cardanoノードを、ブロックチェーンを管理する1つの分散型システムと関連サービスにリンクさせます。ネットワークは、互いに通信しあって分散型台帳を維持し、トランザクションの送信を支え、ユーザーのウォレットや他のサービスとやり取りするノードの集合で構成されます。ネットワークのコアは、集団的にブロックを検証し、チェーンに新たなブロックを追加する分散型ノード（ステークプール）を中心に構築されています。これを支えるのは、ネットワーク接続を管理し、ネットワークの構造を全体として確立する専用のリレーノードです。Daedalusウォレットや他のサービスが実行する専用のコンシューマーノードはこのネットワークに接続し、チェーン上でトランザクションを追跡、送信します。\nCardanoノードはピアとの接続を維持します。一連のミニプロトコルがノード間の通信を可能にします。各ミニプロトコルは基本的な情報交換要件を実装しています。例えば、Cardanoネットワークのあちこちでピアに最新ブロックを伝える、必要に応じてブロックを共有する、新たなトランザクションを共有する、などです。ミニプロトコルは、接続を目的として、ネットワークプロトコルのバージョンによって決定されます。\n\n### Cardanoウォレットバックエンド\n\nCardanoウォレットバックエンドコンポーネントはDaedalusウォレットのグラフィカルユーザーインターフェイスをサポートしています。これは、ADAの送受信に使用されます。ウォレットはバックグラウンドでCardanoフルノードを実行しています。軽量クライアントウォレットとは異なり、これは共有された台帳全体をロードし、すべてのトランザクションを検証するため、全員にとってブロックチェーンのセキュリティが強化されます。\n\n### ウォレットコマンドラインインターフェイス（CLI）\n\nウォレットコマンドラインインターフェイス（CLI）は実際のブロックチェーンとのやり取りをサポートします。高度な技術を持つユーザーは、CLIにより、ツールのコレクションを使用して、鍵の生成やトランザクションの構築、証明書の作成、その他のタスクを実行することができます。これはサブコマンドの階層順に整理され、各レベルには、コマンドシンタックスやオプションのビルトインドキュメンテーションが付されています。\n\n### DB Sync\n\nDB SyncはCardanoチェーンのアクティビティに従い、PostgreSQLにブロックとトランザクションを保存するコンポーネントです。「ミドルウェア」コンポーネントとして、cardano-graphqlを強化します。DB Syncは、ブロックチェーン探索のための高レベルのインターフェイスを有効にするために、cardano-nodeからフェッチしたブロックチェーンを中間データベースに保存します。また、数多くのクエリを提供してPostgreSQLからCardanoブロックチェーンデータをフェッチし、ブロックチェーンデータをシンプルに反映するグラフィカルユーザーインターフェイス、Cardanoエクスプローラーなどのサービスをサポートします。Cardano GraphQLは、GraphQLデータクエリ言語用のクロスプラットフォームAPIです。\n\n### Rosetta API\n\nRosettaアプリケーションプログラミングインターフェイスは、統合プロセスをより簡単に、より速く、より信頼できるものにすることを目的とした高レベルインターフェイスを提供します。これにより、一度構築すると、どこでもブロックチェーンを統合できます。Cardanoとの統合プロセスを簡易化するために、私たちはユニークなcardano-rosettaを作成しました。このインターフェイスは、取引所に特に役立ちます。他のブロックチェーンで使用するものと同じインターフェイスを使って、Cardanoチェーンとやり取りすることができるためです。\n\n### 今後\n\nまもなくCardanoにスマートコントラクトが搭載されますが、これは、スマートコントラクトのネイティブ言語Plutusや、金融仕様のMarlowe、DApp仕様のGlowなど、その他のスマートコントラクト開発言語がCardanoスタックに統合されることを意味します。IO Globalのエンジニアは、Plutus、Marlowe、Glowのスクリプトをコンパイルし、チェーン上に送信し、やり取りするための新コンポーネントや拡張コンポーネントを提供します（図2）。\n\n![](https://ucarecdn.com/49d00118-da94-4dde-9be2-1a721c698a39/)\n\n**図2：Plutus、Marlowe、Glow、Solidity、IELEはすべて、Cardanoスマートコントラクトの作成に使用可能**\n\nAlonzoプロトコルアップグレードは、最近のトークンアップグレードの上に構築され、複数のテストネットを経てメインネットで展開されます。PlutusパートナーやPlutusパイオニアたちはPlutus Coreのテストに協力し、メインネットへの展開前のユーザー受け入れフェーズに参加します。この時点で、インタープリターなどのPlutusとMarloweコンポーネントはCardanoプラットフォームスタックへと公式に追加されます。\nAlonzoロールアウトの最新情報は、ソーシャルチャネルとブログをチェックしてください。\n',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'jp',
                                title: 'Cardanoで稼働するソフトウェアに注目',
                                subtitle: 'ブロックチェーンプラットフォームを実行するために相互作用するコンポーネントの「スタック」を知ろう',
                                audio: null,
                                soundcloud: [],
                                body_content: 'Cardanoはモジュール単位で設計されています。ここには、さまざまな方法で使用できるコンポーネントがリンクされています。こうしたコンポーネントはCardano「プラットフォームスタック」を形成しています。これらは内部で共に作動し、稼働するCardanoブロックチェーンの構造と使用を支えています。\n現在は、Cardnaoに完全なスマートコントラクト機能をもたらすAlonzoハードフォークに向けた、初期テストネットの段階にあります。このプロセスは極めて複雑で、Cardanoプラットフォームを構成するさまざまな要素をしっかりとアップグレードし、慎重に統合、テストする必要があります。したがって、今こそこうしたコンポーネントを振り返り、一部の用語を説明し、「プラットフォームスタック」の中でこれらがいかに相互作用するかを考察するいい機会です。\n\n## Cardanoプラットフォームスタックの要素\n\n\n![](https://ucarecdn.com/913ea221-dd67-4938-84be-3461f79b0baa/)\n\n**図1：Cardanoノードと通信するコンポーネント**\n\nCardanoプラットフォームスタックには以下のコアコンポーネントが含まれます。\n\n* Cardanoノード（および関連プロセス）\n* Cardanoウォレット\n* ウォレットコマンドラインインターフェイス（CLI）\n* DB Sync（ブロックチェーンデータを関連するデータベースと同期)\n* PostgreSQLデータベース（GraphQL、REST API、SMASHと相互作用）\n* SMASHサーバー\n* Rosetta API（ブロックチェーン通信プロトコル）\n\n注：Daedalusはコアスタックに含まれませんが、コンポーネントと通信します（図1）。\n\n### ノードとネットワーク層\n\nはじめに、Cardanoノードを見てみましょう。このソフトウェアは個人のコンピューター上で実行されてネットワークを支え、誰もが分散型ブロックチェーンに参加できるようにするものです。ノードは、コンセンサス、台帳、ネットワークのサブコンポーネントを統合し、他のCardanoコンポーネントまたは熟練したユーザーが使用できるトップレベルの設定、API、CLI、ログ、メモリー管理、そして監視機能を提供します。Daedalusはフルノードウォレットで、ローカルマシンで実行することにより、実質的にネットワークの実行に貢献することになります。\n\n*ネットワーク層*\n\n次にネットワーク層です。これは各Cardanoノードを、ブロックチェーンを管理する1つの分散型システムと関連サービスにリンクさせます。ネットワークは、互いに通信しあって分散型台帳を維持し、トランザクションの送信を支え、ユーザーのウォレットや他のサービスとやり取りするノードの集合で構成されます。ネットワークのコアは、集団的にブロックを検証し、チェーンに新たなブロックを追加する分散型ノード（ステークプール）を中心に構築されています。これを支えるのは、ネットワーク接続を管理し、ネットワークの構造を全体として確立する専用のリレーノードです。Daedalusウォレットや他のサービスが実行する専用のコンシューマーノードはこのネットワークに接続し、チェーン上でトランザクションを追跡、送信します。\nCardanoノードはピアとの接続を維持します。一連のミニプロトコルがノード間の通信を可能にします。各ミニプロトコルは基本的な情報交換要件を実装しています。例えば、Cardanoネットワークのあちこちでピアに最新ブロックを伝える、必要に応じてブロックを共有する、新たなトランザクションを共有する、などです。ミニプロトコルは、接続を目的として、ネットワークプロトコルのバージョンによって決定されます。\n\n### Cardanoウォレットバックエンド\n\nCardanoウォレットバックエンドコンポーネントはDaedalusウォレットのグラフィカルユーザーインターフェイスをサポートしています。これは、ADAの送受信に使用されます。ウォレットはバックグラウンドでCardanoフルノードを実行しています。軽量クライアントウォレットとは異なり、これは共有された台帳全体をロードし、すべてのトランザクションを検証するため、全員にとってブロックチェーンのセキュリティが強化されます。\n\n### ウォレットコマンドラインインターフェイス（CLI）\n\nウォレットコマンドラインインターフェイス（CLI）は実際のブロックチェーンとのやり取りをサポートします。高度な技術を持つユーザーは、CLIにより、ツールのコレクションを使用して、鍵の生成やトランザクションの構築、証明書の作成、その他のタスクを実行することができます。これはサブコマンドの階層順に整理され、各レベルには、コマンドシンタックスやオプションのビルトインドキュメンテーションが付されています。\n\n### DB Sync\n\nDB SyncはCardanoチェーンのアクティビティに従い、PostgreSQLにブロックとトランザクションを保存するコンポーネントです。「ミドルウェア」コンポーネントとして、cardano-graphqlを強化します。DB Syncは、ブロックチェーン探索のための高レベルのインターフェイスを有効にするために、cardano-nodeからフェッチしたブロックチェーンを中間データベースに保存します。また、数多くのクエリを提供してPostgreSQLからCardanoブロックチェーンデータをフェッチし、ブロックチェーンデータをシンプルに反映するグラフィカルユーザーインターフェイス、Cardanoエクスプローラーなどのサービスをサポートします。Cardano GraphQLは、GraphQLデータクエリ言語用のクロスプラットフォームAPIです。\n\n### Rosetta API\n\nRosettaアプリケーションプログラミングインターフェイスは、統合プロセスをより簡単に、より速く、より信頼できるものにすることを目的とした高レベルインターフェイスを提供します。これにより、一度構築すると、どこでもブロックチェーンを統合できます。Cardanoとの統合プロセスを簡易化するために、私たちはユニークなcardano-rosettaを作成しました。このインターフェイスは、取引所に特に役立ちます。他のブロックチェーンで使用するものと同じインターフェイスを使って、Cardanoチェーンとやり取りすることができるためです。\n\n### 今後\n\nまもなくCardanoにスマートコントラクトが搭載されますが、これは、スマートコントラクトのネイティブ言語Plutusや、金融仕様のMarlowe、DApp仕様のGlowなど、その他のスマートコントラクト開発言語がCardanoスタックに統合されることを意味します。IO Globalのエンジニアは、Plutus、Marlowe、Glowのスクリプトをコンパイルし、チェーン上に送信し、やり取りするための新コンポーネントや拡張コンポーネントを提供します（図2）。\n\n![](https://ucarecdn.com/49d00118-da94-4dde-9be2-1a721c698a39/)\n\n**図2：Plutus、Marlowe、Glow、Solidity、IELEはすべて、Cardanoスマートコントラクトの作成に使用可能**\n\nAlonzoプロトコルアップグレードは、最近のトークンアップグレードの上に構築され、複数のテストネットを経てメインネットで展開されます。PlutusパートナーやPlutusパイオニアたちはPlutus Coreのテストに協力し、メインネットへの展開前のユーザー受け入れフェーズに参加します。この時点で、インタープリターなどのPlutusとMarloweコンポーネントはCardanoプラットフォームスタックへと公式に追加されます。\nAlonzoロールアウトの最新情報は、ソーシャルチャネルとブログをチェックしてください。\n',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'a-close-look-at-the-software-running-cardano',
                                url: '/blog/posts/2021/06/08/a-close-look-at-the-software-running-cardano/',
                                read_time: 1
                            },
                            {
                                publish_date: '2021-04-30T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/65cf3157-04f6-4e3c-9c8e-4ef6f51dc047/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'The essential Cardano list - a new resource for the community',
                                        subtitle: 'Introducing a new central source for all things Cardano-related',
                                        audio: null,
                                        soundcloud: [],
                                        body_content: 'Today sees the publication of [the Essential Cardano list](https://github.com/input-output-hk/essential-cardano) – a new GitHub repository which will help you to find out everything you need to know about Cardano. Whether you want to understand what Cardano is and who our partners are, learn about our mission and roadmap, or get stuck in and build on Cardano, this is the place to start.\r\n\r\nInspired by GitHub\'s well known *Awesome* lists, the Essential Cardano list provides an outline of our thriving ecosystem, as well as a comprehensive list of resources to help you learn more and get started. As it grows and expands, this new list aims to become the canonical source of material for Cardano, including both official resources and community-generated materials. We are now looking for our community members to help us extend it even more by contributing their suggestions.\r\n\r\n## A central location of essential resources ##\r\nWe want to have a central location for all things Cardano, to bring everything together and make it easy for people to find what they need. We have provided links to all official sites, channels, and resources, as well as to a collection of material such as explainers, guides, developer resources, glossaries, primers, tutorials, and much more.\r\n\r\nOn top of that, we have identified assets developed by the community which we think provide great value and complement our own content that we produce. Our aim is that our community will now help us to grow it out and make it even better.\r\n\r\n## Navigate the Cardano ecosystem ##\r\nEssential Cardano provides an outline of all the core entities, partner groups, and facets that are part of our growing ecosystem to help orientate you to understand all the existing and new relationships that are being developed. \r\n\r\nInitially, our focus has been on curating links and references to what’s going on within our growing ecosystem. As we update the list, or additions are made by community members, the list will also grow. We also plan to add additional visual elements including infographics and ecosystem maps over time. We have included an existing [ecosystem map](https://github.com/input-output-hk/essential-cardano/blob/main/essential-cardano-list.md#navigate-the-cardano-ecosystem) which is currently being refreshed by our team to reflect new relationships and partnerships we have formed recently. We plan to release a May version of this map very soon, so if you would like to help us get this up to date as soon as possible, go ahead and raise a pull request with your suggestion! \r\n\r\nWe have also included all the Project Catalyst startups that currently exist so you can understand some of what is being planned for future development. \r\n \r\n## How do I contribute? ##\r\nWe are looking for you to help us to grow out and evolve this essential Cardano list. This list is fully open source so if you know of new content that is being produced by members of the community, new relationships that are not included, or new innovations, please let us know so that we can add them all to this list and promote them. The easiest way to do this is to [raise a pull request](https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request/) on the repository. We’ll evaluate these regularly and provide feedback within each pull request.\r\n\r\n## Growing this list ##\r\n2021 is already a very active year for growth and engagement on Cardano. Following on from yesterday\'s exciting announcements about our [vision for Africa](https://iohk.io/en/blog/posts/2021/04/28/decentralized-identity-on-the-blockchain-is-the-key-to-iohks-vision-for-africa/), and with upcoming [smart contracts](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) and other new products on the way, we expect lots of new and exciting additions. We have already included some contributions from our active [Plutus Pioneers course](https://iohk.io/en/blog/posts/2021/04/01/everything-you-need-to-know-about-our-new-plutus-pioneer-program/), which are very welcome, and we anticipate many more users, developers, and enterprises jumping on board in the coming months. We are happy to see the new [Cardano Q & A Stack Exchange](https://cardano.stackexchange.com/users/login?ssrc=beta&returnurl=%2f) being developed and would encourage our community members to submit their questions to help build this out. Stay tuned for announcements and updates here on our blog, social channels, and within the [Essential Cardano repository](https://github.com/input-output-hk/essential-cardano) itself.',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'The essential Cardano list - a new resource for the community',
                                subtitle: 'Introducing a new central source for all things Cardano-related',
                                audio: null,
                                soundcloud: [],
                                body_content: 'Today sees the publication of [the Essential Cardano list](https://github.com/input-output-hk/essential-cardano) – a new GitHub repository which will help you to find out everything you need to know about Cardano. Whether you want to understand what Cardano is and who our partners are, learn about our mission and roadmap, or get stuck in and build on Cardano, this is the place to start.\r\n\r\nInspired by GitHub\'s well known *Awesome* lists, the Essential Cardano list provides an outline of our thriving ecosystem, as well as a comprehensive list of resources to help you learn more and get started. As it grows and expands, this new list aims to become the canonical source of material for Cardano, including both official resources and community-generated materials. We are now looking for our community members to help us extend it even more by contributing their suggestions.\r\n\r\n## A central location of essential resources ##\r\nWe want to have a central location for all things Cardano, to bring everything together and make it easy for people to find what they need. We have provided links to all official sites, channels, and resources, as well as to a collection of material such as explainers, guides, developer resources, glossaries, primers, tutorials, and much more.\r\n\r\nOn top of that, we have identified assets developed by the community which we think provide great value and complement our own content that we produce. Our aim is that our community will now help us to grow it out and make it even better.\r\n\r\n## Navigate the Cardano ecosystem ##\r\nEssential Cardano provides an outline of all the core entities, partner groups, and facets that are part of our growing ecosystem to help orientate you to understand all the existing and new relationships that are being developed. \r\n\r\nInitially, our focus has been on curating links and references to what’s going on within our growing ecosystem. As we update the list, or additions are made by community members, the list will also grow. We also plan to add additional visual elements including infographics and ecosystem maps over time. We have included an existing [ecosystem map](https://github.com/input-output-hk/essential-cardano/blob/main/essential-cardano-list.md#navigate-the-cardano-ecosystem) which is currently being refreshed by our team to reflect new relationships and partnerships we have formed recently. We plan to release a May version of this map very soon, so if you would like to help us get this up to date as soon as possible, go ahead and raise a pull request with your suggestion! \r\n\r\nWe have also included all the Project Catalyst startups that currently exist so you can understand some of what is being planned for future development. \r\n \r\n## How do I contribute? ##\r\nWe are looking for you to help us to grow out and evolve this essential Cardano list. This list is fully open source so if you know of new content that is being produced by members of the community, new relationships that are not included, or new innovations, please let us know so that we can add them all to this list and promote them. The easiest way to do this is to [raise a pull request](https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request/) on the repository. We’ll evaluate these regularly and provide feedback within each pull request.\r\n\r\n## Growing this list ##\r\n2021 is already a very active year for growth and engagement on Cardano. Following on from yesterday\'s exciting announcements about our [vision for Africa](https://iohk.io/en/blog/posts/2021/04/28/decentralized-identity-on-the-blockchain-is-the-key-to-iohks-vision-for-africa/), and with upcoming [smart contracts](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) and other new products on the way, we expect lots of new and exciting additions. We have already included some contributions from our active [Plutus Pioneers course](https://iohk.io/en/blog/posts/2021/04/01/everything-you-need-to-know-about-our-new-plutus-pioneer-program/), which are very welcome, and we anticipate many more users, developers, and enterprises jumping on board in the coming months. We are happy to see the new [Cardano Q & A Stack Exchange](https://cardano.stackexchange.com/users/login?ssrc=beta&returnurl=%2f) being developed and would encourage our community members to submit their questions to help build this out. Stay tuned for announcements and updates here on our blog, social channels, and within the [Essential Cardano repository](https://github.com/input-output-hk/essential-cardano) itself.',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'the-essential-cardano-list-a-new-resource-for-the-community',
                                url: '/blog/posts/2021/04/30/the-essential-cardano-list-a-new-resource-for-the-community/',
                                read_time: 4
                            },
                            {
                                publish_date: '2021-04-01T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/722fd8a5-e3a7-4754-a5bd-207e9b89af3e/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Everything you need to know about our new Plutus Pioneer Program',
                                        subtitle: 'Learn Plutus and become a certified Plutus Pioneer with our new series of interactive training courses – starting next week',
                                        audio: null,
                                        soundcloud: [],
                                        body_content: 'Next week sees the start of the first in a series of our Plutus pioneer training programs where participants can learn the fundamentals of Plutus and help to test the code before the official release of our new smart contract language. This new innovative program aims to recruit and train developers within the ecosystem so that they are fully prepared when Plutus is deployed to the Cardano mainnet later this year.\n\n\r\n\r\nSince we announced this new course on [March’s Cardano360 show](https://youtu.be/ULBLgPgxtN8?t=3731) we have had a huge expression of interest from our developer community, both from developers who want to create decentralized applications (DApps), and smart contract programmers who want to work with Cardano’s principal development language. This week we have contacted everyone interested (over 2,000) to get a better idea of their experience and expertise. Those of you who have been selected for the first round of this program will hear from us very soon. If you don’t receive an invitation at this stage, don’t worry as we will be running several rounds of this program, so please do stay in touch!\n\n\r\n\r\n## Course structure ##\r\nThe first iteration of the new program starts next week.  The cohort joining this program will be true pioneers. As well as being part of a group that will have *early access* to a set of learning modules, your feedback will help us develop and iterate the overall learning experience.\n\n\r\n\r\nThe course will teach you the core principles of how to code in both Haskell and Plutus. The course modules will cover the building blocks of Haskell and Plutus, including functions and data types, type classes, monads, template Haskell, using the [Plutus Playground](https://iohk.io/en/blog/posts/2021/01/25/introducing-the-new-plutus-playground/), the [Extended UTXO model](https://iohk.io/en/blog/posts/2021/03/11/cardanos-extended-utxo-accounting-model/), working with Plutus on and off the chain, minting policies, state machines, the Plutus application framework, as well as some case studies and practical exercises. \n\r\n\r\nThe course will follow a modular approach and will be highly interactive – each week we will be releasing new teaching videos from our director of education, Lars Brünjes, along with a set of practical exercises to complete during the week as part of each module. We will also be holding regular Q&A sessions and you will have access to a dedicated community channel on Discord, created especially to help you to connect with other course participants as you learn. \r\n\r\nOutside the exercises and videos, students will be encouraged to learn at a pace that is right for them and to collaborate with fellow students. As with all learning experiences, the more you put in the more you will get out! We encourage all participants to *engage with each other* and work collaboratively to answer questions and solve problems. \r\n\r\nWe will have a small team of moderators who will check in from time to time to help facilitate and assist.  They can also  help triage issues or questions that may come up in your learning during the week. These moderators are all graduates of the [Mongolia class of 2020](https://iohk.io/en/blog/posts/2020/12/21/online-learning-with-haskell-the-mongolia-class-of-2020/) that completed the Haskell MOOC and are well placed to assist with questions and challenges. At the close of each week, Lars will engage directly with the group to resolve more complex technical questions and provide feedback on the subject matter covered that week. \r\n\r\n## Prior experience ##\r\nAs Plutus is based largely on Haskell, having some prior experience with Haskell (or another functional programming language), will be very helpful. At a minimum, you should have some programming experience and a mathematical and technical mindset. You should be as keen to learn as to help us; while we have run a number of successful courses already, this is the first time we have challenged ourselves to teach at this scale. So be prepared for road bumps along the way as we learn and improve, too!\r\n\r\nBear in mind that this course is not for coding beginners. While you do not need to be an expert in formal methods, programming  experience and a general aptitude for logical and mathematical thinking are highly desirable. The course will include advanced features like Template Haskell, type-level programming, and effect systems. If you need a refresher or get an introduction to Haskell, we recommend that you read the [Learn You a Haskell guide](http://learnyouahaskell.com/) before you participate in the course. We’ll open several new cohorts this year, so you won’t miss out.\r\n\r\n## When does the course start? ##\r\nThe course starts next week and will run concurrently for ten weeks through to mid June. It will involve approximately ten hours a week of your time and effort each week. \r\n\r\n## Will there be other pioneer programs? ##\r\nYes, we are keen to be as inclusive as we can on our path to rolling out smart contracts. We are also developing education programs for both [Marlowe](https://docs.cardano.org/en/latest/marlowe/marlowe-explainer.html) and [Glow](https://developers.cardano.org/en/programming-languages/glow/overview/), so don\'t feel like you have missed out if this Plutus course is not for you. We’re still keen to have you onboard, so do watch this space for details of these other courses!\r\n\r\n## Certification ##\r\nWe will reward participants for their efforts in participating in this course and certify those pioneers that complete the entire program and are successful. These Plutus pioneer certificates will be represented as non fungible tokens (on the testnet) and locked by a Plutus contract. Pioneers can demonstrate their knowledge and qualification by constructing an appropriate transaction to unlock their individual token.\r\n \r\n## Ready to start ##\r\nWe are excited to have so many developers from our ecosystem on board and ready to get started and learn Plutus. You’ll not only be learning yourselves, but acting as a pioneer to help us determine the best way to teach and deliver this course – truly helping pave the way for future cohorts who enroll! We look forward to bringing you on this learning journey before we launch Plutus to the world! ',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Everything you need to know about our new Plutus Pioneer Program',
                                subtitle: 'Learn Plutus and become a certified Plutus Pioneer with our new series of interactive training courses – starting next week',
                                audio: null,
                                soundcloud: [],
                                body_content: 'Next week sees the start of the first in a series of our Plutus pioneer training programs where participants can learn the fundamentals of Plutus and help to test the code before the official release of our new smart contract language. This new innovative program aims to recruit and train developers within the ecosystem so that they are fully prepared when Plutus is deployed to the Cardano mainnet later this year.\n\n\r\n\r\nSince we announced this new course on [March’s Cardano360 show](https://youtu.be/ULBLgPgxtN8?t=3731) we have had a huge expression of interest from our developer community, both from developers who want to create decentralized applications (DApps), and smart contract programmers who want to work with Cardano’s principal development language. This week we have contacted everyone interested (over 2,000) to get a better idea of their experience and expertise. Those of you who have been selected for the first round of this program will hear from us very soon. If you don’t receive an invitation at this stage, don’t worry as we will be running several rounds of this program, so please do stay in touch!\n\n\r\n\r\n## Course structure ##\r\nThe first iteration of the new program starts next week.  The cohort joining this program will be true pioneers. As well as being part of a group that will have *early access* to a set of learning modules, your feedback will help us develop and iterate the overall learning experience.\n\n\r\n\r\nThe course will teach you the core principles of how to code in both Haskell and Plutus. The course modules will cover the building blocks of Haskell and Plutus, including functions and data types, type classes, monads, template Haskell, using the [Plutus Playground](https://iohk.io/en/blog/posts/2021/01/25/introducing-the-new-plutus-playground/), the [Extended UTXO model](https://iohk.io/en/blog/posts/2021/03/11/cardanos-extended-utxo-accounting-model/), working with Plutus on and off the chain, minting policies, state machines, the Plutus application framework, as well as some case studies and practical exercises. \n\r\n\r\nThe course will follow a modular approach and will be highly interactive – each week we will be releasing new teaching videos from our director of education, Lars Brünjes, along with a set of practical exercises to complete during the week as part of each module. We will also be holding regular Q&A sessions and you will have access to a dedicated community channel on Discord, created especially to help you to connect with other course participants as you learn. \r\n\r\nOutside the exercises and videos, students will be encouraged to learn at a pace that is right for them and to collaborate with fellow students. As with all learning experiences, the more you put in the more you will get out! We encourage all participants to *engage with each other* and work collaboratively to answer questions and solve problems. \r\n\r\nWe will have a small team of moderators who will check in from time to time to help facilitate and assist.  They can also  help triage issues or questions that may come up in your learning during the week. These moderators are all graduates of the [Mongolia class of 2020](https://iohk.io/en/blog/posts/2020/12/21/online-learning-with-haskell-the-mongolia-class-of-2020/) that completed the Haskell MOOC and are well placed to assist with questions and challenges. At the close of each week, Lars will engage directly with the group to resolve more complex technical questions and provide feedback on the subject matter covered that week. \r\n\r\n## Prior experience ##\r\nAs Plutus is based largely on Haskell, having some prior experience with Haskell (or another functional programming language), will be very helpful. At a minimum, you should have some programming experience and a mathematical and technical mindset. You should be as keen to learn as to help us; while we have run a number of successful courses already, this is the first time we have challenged ourselves to teach at this scale. So be prepared for road bumps along the way as we learn and improve, too!\r\n\r\nBear in mind that this course is not for coding beginners. While you do not need to be an expert in formal methods, programming  experience and a general aptitude for logical and mathematical thinking are highly desirable. The course will include advanced features like Template Haskell, type-level programming, and effect systems. If you need a refresher or get an introduction to Haskell, we recommend that you read the [Learn You a Haskell guide](http://learnyouahaskell.com/) before you participate in the course. We’ll open several new cohorts this year, so you won’t miss out.\r\n\r\n## When does the course start? ##\r\nThe course starts next week and will run concurrently for ten weeks through to mid June. It will involve approximately ten hours a week of your time and effort each week. \r\n\r\n## Will there be other pioneer programs? ##\r\nYes, we are keen to be as inclusive as we can on our path to rolling out smart contracts. We are also developing education programs for both [Marlowe](https://docs.cardano.org/en/latest/marlowe/marlowe-explainer.html) and [Glow](https://developers.cardano.org/en/programming-languages/glow/overview/), so don\'t feel like you have missed out if this Plutus course is not for you. We’re still keen to have you onboard, so do watch this space for details of these other courses!\r\n\r\n## Certification ##\r\nWe will reward participants for their efforts in participating in this course and certify those pioneers that complete the entire program and are successful. These Plutus pioneer certificates will be represented as non fungible tokens (on the testnet) and locked by a Plutus contract. Pioneers can demonstrate their knowledge and qualification by constructing an appropriate transaction to unlock their individual token.\r\n \r\n## Ready to start ##\r\nWe are excited to have so many developers from our ecosystem on board and ready to get started and learn Plutus. You’ll not only be learning yourselves, but acting as a pioneer to help us determine the best way to teach and deliver this course – truly helping pave the way for future cohorts who enroll! We look forward to bringing you on this learning journey before we launch Plutus to the world! ',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'everything-you-need-to-know-about-our-new-plutus-pioneer-program',
                                url: '/blog/posts/2021/04/01/everything-you-need-to-know-about-our-new-plutus-pioneer-program/',
                                read_time: 5
                            },
                            {
                                publish_date: '2020-12-09T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/e08b30a4-e8e8-4978-b8df-d33299cca0ee/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'The new Mantis: Bringing security and stability to the Ethereum Classic ecosystem',
                                        subtitle: 'We’re committed to bringing innovation and fresh life to ETC and this is just the start',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'IOHK has a long association with Ethereum Classic (ETC) and its community, which preserves an untampered history free from external interference and subjective altering of transactions. Serving as the next-generation digital currency platform, ETC is built as an intuitive programming platform, which allows developers of all skill sets to build the next wave of market disrupting decentralized applications (DApps). \n\nThe goal of ETC is to securely and methodically establish a strong ecosystem underpinned by solid foundation and core immutability. However, recent 51% attacks have put the ETC ecosystem into a precarious position, denting its confidence and challenging the community’s ability to address this issue, while representing an existential threat to its future viability. \n\n## Driving innovation & future growth for ETC\n\nNew Mantis is the only client that is written natively for Ethereum Classic and it offers unrivalled levels of assurance, security, and usability. IOHK has relaunched the Mantis project to mitigate against the recent attacks, provide enhanced security, and establish a robust means of interacting with the ETC chain. A commitment to fostering innovation and sustainability lies at the heart of the project. We are aiming to provide a steady funding income with the establishment of a proto-treasury to nurture future development and growth. This Mantis re-launch represents the culmination of a project that we\'ve been working on for some time. Over the past few months, we have resurrected our code base, and gathered a dedicated Mantis team together who have worked hard to refine and improve the code and deliver important new features.\n\n## What is the Mantis project?\n\nMantis is a project that is built for the community, specifically designed for the developers, wallet users, and infrastructure providers to enable direct interaction with the ETC blockchain. Essentially, it is a place where future development can evolve and be tested by the community. The Mantis release includes the following components:\n- Mantis client - a CLI tool that connects to other clients in a peer-to-peer manner to allow users to communicate with the ETC chain, send and receive transactions, sync the blockchain data, execute and validate smart contracts, and deploy new smart contracts on-chain.\r\n- Mantis wallet - a node wallet with incorporated graphical user interface (GUI), which connects to both mainnet and the Sagano and Mordor testnets. \r\n- Mantis faucet - enables developers to receive testnet funds for use on the Sagano and Mordor testnets.\r\n- Mantis explorer - allows tracking recent activities and transactions in regards to the ETC chain, covering the ETC mainnet, and Sagano and Mordor testnets. \n\nPlease visit the [Mantis website](https://mantisclient.io/) where you can download the latest version of both the Mantis client and wallet.\r\n\r\nMantis software implements the official Ethereum Classic specification and Ethereum Classic Improvement Proposals [(ECIPs)](https://ecips.ethereumclassic.org/) introduced by ongoing efforts and discussed across teams in the ecosystem. The project has undergone a number of enhancements in terms of adding robustness and variety to the client offering, including optimizations and network upgrades that improve network security, sustainability, and performance in the long term. It has been developed from the ground up and built in 100% Scala code, a functional programming language that offers security guarantees that other languages do not. Mantis features include stable peer discovery, pruning, fast synchronization, and newly implemented checkpointing (for 51% attack resistance) and proto-treasury (for long-term sustainability). Let’s take a closer look at these features.\n\n## Checkpointing \r\n*Persistence* and *liveness* are two crucial properties that a transaction ledger should possess. It is a proven fact that both persistence and liveness suffer when the adversarial mining power in the proof of work surpasses 50%, and in the recent year, ETC has undergone several double-spending attacks prompted by the creation of large chain reorganizations. Considering that persistence and liveness were not guaranteed within the ETC network, we sought to implement protocol changes that will re-establish persistence and liveness under current network conditions, and *checkpointing* is one of the proposed solutions. \r\n\r\nCheckpointing ensures that the protocol is unaltered, by using the *k* parameter, or depth parameter, where every *k* block gets irreversibly "checkpointed", meaning that no one can ever drop or revert it. A trusted authority can choose the block on which to issue a checkpoint, which means that they can decide which block becomes the canonical chain that all parties should follow. This trusted authority must run continuously and is responsible for publishing the checkpoint to the network. Checkpointing ensures that the protocol is unaltered with regards to mining. The mining rewards are not affected and the checkpointing federation can only issue checkpoints on blocks that have valid proof of work and cannot mint blocks on its own. \r\n\r\nCheckpointing is now implemented within the Mantis project, and according to our recent [ECIP comparison for 51% attack resistance](https://static.iohk.io/docs/etc/ecip-comparison-for-51-attack-resistance.pdf), it provides far greater, and importantly formally proven, security against these types of attacks. It is important that any 51% attack mitigation is truly robust enough to give absolute certainty to ETC holders, users, and service providers that their transactions will be secure.\r\n\n## Proto-Treasury\r\nFor the longer-term health and success of the ETC ecosystem, we position network growth, sustainability, and innovation as key elements to ensure network security. With that in mind, we are implementing a proto-treasury system within the Mantis project to establish a steady funding income.  A well-developed governance strategy will enable effective, distributed funding for the long-term development of Mantis, whereas a decentralized treasury would ensure two important things for the future of the ecosystem:\r\n- Firstly, it would provide a permanent ongoing source of funding for the ETC network. while increasing the value of the ecosystem and promoting greater developer engagement. \r\n\r\n- Secondly, it would provide a distributed and transparent funding mechanism, which lets the ETC community determine its future growth and enable the sustainability required for innovation and growth.\r\n\r\nEstablishing the treasury for funding purposes ensures a clear vision of the substantial system maintenance focused to obtain innovation and diversity from other projects, including proof of stake (PoS) and newer blockchains. This solution is straightforward in its optimization for speed and implementation.\r\n\r\nThe proposal foresees to distribute 80% of existing mining rewards to miners and 20% to the proto-treasury smart contract. The treasury will be controlled by the community and will enable a decentralized, collaborative decision-making process, offering an opt-in type collaboration for those who are interested.\n\n## What’s next?\r\nAs much as we’re excited about the Mantis relaunch, it should be stressed that its capability won’t be limited to just the features outlined here. Mantis is an evolving project and right now we are establishing its foundational building blocks and running rigorous security audits. Further down the road, it will see more performance improvements in terms of CPU, GPU and ASICs compatibility, a new proof-of-work consensus protocol and algorithm introduction (PRISM consensus, Keccak256 algorithm) and, of course, additional enhancements for better interoperability and speed of transaction processing. You can also find out more by reading the [Mantis documentation](https://docs.mantisclient.io/) and joining the [Mantis discord](https://discord.com/invite/7vUyWrN33p) to stay up to date on all things Mantis or Ethereum Classic. Check out the Crowdcast launch event for the full Mantis showcase (and a keynote from Charles Hoskinson) and follow the Mantis team on [Twitter](https://twitter.com/Mantis_IO/) to get the latest updates! ',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'The new Mantis: Bringing security and stability to the Ethereum Classic ecosystem',
                                subtitle: 'We’re committed to bringing innovation and fresh life to ETC and this is just the start',
                                audio: null,
                                soundcloud: null,
                                body_content: 'IOHK has a long association with Ethereum Classic (ETC) and its community, which preserves an untampered history free from external interference and subjective altering of transactions. Serving as the next-generation digital currency platform, ETC is built as an intuitive programming platform, which allows developers of all skill sets to build the next wave of market disrupting decentralized applications (DApps). \n\nThe goal of ETC is to securely and methodically establish a strong ecosystem underpinned by solid foundation and core immutability. However, recent 51% attacks have put the ETC ecosystem into a precarious position, denting its confidence and challenging the community’s ability to address this issue, while representing an existential threat to its future viability. \n\n## Driving innovation & future growth for ETC\n\nNew Mantis is the only client that is written natively for Ethereum Classic and it offers unrivalled levels of assurance, security, and usability. IOHK has relaunched the Mantis project to mitigate against the recent attacks, provide enhanced security, and establish a robust means of interacting with the ETC chain. A commitment to fostering innovation and sustainability lies at the heart of the project. We are aiming to provide a steady funding income with the establishment of a proto-treasury to nurture future development and growth. This Mantis re-launch represents the culmination of a project that we\'ve been working on for some time. Over the past few months, we have resurrected our code base, and gathered a dedicated Mantis team together who have worked hard to refine and improve the code and deliver important new features.\n\n## What is the Mantis project?\n\nMantis is a project that is built for the community, specifically designed for the developers, wallet users, and infrastructure providers to enable direct interaction with the ETC blockchain. Essentially, it is a place where future development can evolve and be tested by the community. The Mantis release includes the following components:\n- Mantis client - a CLI tool that connects to other clients in a peer-to-peer manner to allow users to communicate with the ETC chain, send and receive transactions, sync the blockchain data, execute and validate smart contracts, and deploy new smart contracts on-chain.\r\n- Mantis wallet - a node wallet with incorporated graphical user interface (GUI), which connects to both mainnet and the Sagano and Mordor testnets. \r\n- Mantis faucet - enables developers to receive testnet funds for use on the Sagano and Mordor testnets.\r\n- Mantis explorer - allows tracking recent activities and transactions in regards to the ETC chain, covering the ETC mainnet, and Sagano and Mordor testnets. \n\nPlease visit the [Mantis website](https://mantisclient.io/) where you can download the latest version of both the Mantis client and wallet.\r\n\r\nMantis software implements the official Ethereum Classic specification and Ethereum Classic Improvement Proposals [(ECIPs)](https://ecips.ethereumclassic.org/) introduced by ongoing efforts and discussed across teams in the ecosystem. The project has undergone a number of enhancements in terms of adding robustness and variety to the client offering, including optimizations and network upgrades that improve network security, sustainability, and performance in the long term. It has been developed from the ground up and built in 100% Scala code, a functional programming language that offers security guarantees that other languages do not. Mantis features include stable peer discovery, pruning, fast synchronization, and newly implemented checkpointing (for 51% attack resistance) and proto-treasury (for long-term sustainability). Let’s take a closer look at these features.\n\n## Checkpointing \r\n*Persistence* and *liveness* are two crucial properties that a transaction ledger should possess. It is a proven fact that both persistence and liveness suffer when the adversarial mining power in the proof of work surpasses 50%, and in the recent year, ETC has undergone several double-spending attacks prompted by the creation of large chain reorganizations. Considering that persistence and liveness were not guaranteed within the ETC network, we sought to implement protocol changes that will re-establish persistence and liveness under current network conditions, and *checkpointing* is one of the proposed solutions. \r\n\r\nCheckpointing ensures that the protocol is unaltered, by using the *k* parameter, or depth parameter, where every *k* block gets irreversibly "checkpointed", meaning that no one can ever drop or revert it. A trusted authority can choose the block on which to issue a checkpoint, which means that they can decide which block becomes the canonical chain that all parties should follow. This trusted authority must run continuously and is responsible for publishing the checkpoint to the network. Checkpointing ensures that the protocol is unaltered with regards to mining. The mining rewards are not affected and the checkpointing federation can only issue checkpoints on blocks that have valid proof of work and cannot mint blocks on its own. \r\n\r\nCheckpointing is now implemented within the Mantis project, and according to our recent [ECIP comparison for 51% attack resistance](https://static.iohk.io/docs/etc/ecip-comparison-for-51-attack-resistance.pdf), it provides far greater, and importantly formally proven, security against these types of attacks. It is important that any 51% attack mitigation is truly robust enough to give absolute certainty to ETC holders, users, and service providers that their transactions will be secure.\r\n\n## Proto-Treasury\r\nFor the longer-term health and success of the ETC ecosystem, we position network growth, sustainability, and innovation as key elements to ensure network security. With that in mind, we are implementing a proto-treasury system within the Mantis project to establish a steady funding income.  A well-developed governance strategy will enable effective, distributed funding for the long-term development of Mantis, whereas a decentralized treasury would ensure two important things for the future of the ecosystem:\r\n- Firstly, it would provide a permanent ongoing source of funding for the ETC network. while increasing the value of the ecosystem and promoting greater developer engagement. \r\n\r\n- Secondly, it would provide a distributed and transparent funding mechanism, which lets the ETC community determine its future growth and enable the sustainability required for innovation and growth.\r\n\r\nEstablishing the treasury for funding purposes ensures a clear vision of the substantial system maintenance focused to obtain innovation and diversity from other projects, including proof of stake (PoS) and newer blockchains. This solution is straightforward in its optimization for speed and implementation.\r\n\r\nThe proposal foresees to distribute 80% of existing mining rewards to miners and 20% to the proto-treasury smart contract. The treasury will be controlled by the community and will enable a decentralized, collaborative decision-making process, offering an opt-in type collaboration for those who are interested.\n\n## What’s next?\r\nAs much as we’re excited about the Mantis relaunch, it should be stressed that its capability won’t be limited to just the features outlined here. Mantis is an evolving project and right now we are establishing its foundational building blocks and running rigorous security audits. Further down the road, it will see more performance improvements in terms of CPU, GPU and ASICs compatibility, a new proof-of-work consensus protocol and algorithm introduction (PRISM consensus, Keccak256 algorithm) and, of course, additional enhancements for better interoperability and speed of transaction processing. You can also find out more by reading the [Mantis documentation](https://docs.mantisclient.io/) and joining the [Mantis discord](https://discord.com/invite/7vUyWrN33p) to stay up to date on all things Mantis or Ethereum Classic. Check out the Crowdcast launch event for the full Mantis showcase (and a keynote from Charles Hoskinson) and follow the Mantis team on [Twitter](https://twitter.com/Mantis_IO/) to get the latest updates! ',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'the-new-mantis-bringing-security-and-stability-to-the-ethereum-classic-ecosystem-1',
                                url: '/blog/posts/2020/12/09/the-new-mantis-bringing-security-and-stability-to-the-ethereum-classic-ecosystem-1/',
                                read_time: 6
                            },
                            {
                                publish_date: '2020-02-27',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/53f9deb3-e57b-40a3-8c19-276aeae1a1da/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Educating the world on Cardano: initiatives and plans for 2020',
                                        subtitle: 'Learn more about the education team\'s plans for the upcoming year',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'Education has always been a key part of IOHK’s strategy. Our mission is to grow our global community and business through the medium of education, and to share what we have learned. By claiming leadership in worldwide education on blockchain technology, we have the chance to shape the field for generations and to leave a lasting legacy.\n\nA consistent theme from 2019 has been the demand for a broad range of educational content, as demonstrated by the feedback received about the Incentivized Testnet, as well as the steady flow of support requests to our helpdesk. A key focus in IOHK for 2020 is to develop and expand our education materials as we transition fully into the Shelley era and then to the Goguen era of Cardano.\n\nThe IOHK education team will be investing significant time and effort this year in broadening our range of materials. We aim to enhance understanding of our technologies using a variety of learning and training assets targeted at a wide range of stakeholder audiences, both internal and external. This will be vital as the use of IOHK technology moves into the mainstream. We also aim to provide knowledge and information to enterprise decision-makers so they know what business problems our technologies can solve. We have lots planned and many projects are underway as we grow Cardano into a global social and financial operating system.\n\n## What can you expect?\n\nWe started 2020 with lectures, by Dr Lars Brünjes, our director of education, at the University of Malta. The focus of these lectures was on Plutus and Marlowe, our programming languages for smart contracts. The fruits of these sessions will, in turn, form the foundation of some modular training materials that we plan to formalize and develop over the coming months.\n\nOur free Udemy courses on [Plutus](https://www.udemy.com/course/plutus-reliable-smart-contracts/) and [Marlowe](https://www.udemy.com/course/marlowe-programming-language/) by Alejandro Garcia have proven very popular, with over 5,000 students signed up. Feedback has been positive and, as a result of what we learned from our students, we’ve been making incremental improvements over the last year. We now want to take this to the next level and are planning to fully update both courses soon to bring them up to speed with the latest development changes and new features. We are also in the initial planning stages for a second edition of the ebook, [Plutus: Writing reliable smart contracts](https://leanpub.com/plutus-smart-contracts) by Lars Brünjes and Polina Vinogradova, which we will be publishing later this year. The writing team has started to identify improvements and we are also gathering feedback directly from readers. If you have suggestions, please raise a pull request in our [Plutus ebook GitHub repository](https://github.com/input-output-hk/plutus/tree/master/plutus-book) with your ideas.\n\nAn important step in bridging the gap between our academic papers and mainstream understanding of these concepts is to teach people about Ouroboros, the proof-of-stake protocol that powers Cardano and ada. In response to the valuable feedback we have received from running the Incentivized Testnet, we are planning to create varied educational content to help stake pool operators understand Ouroboros and how the protocol works on a practical level.\n\n## Broadening our reach\n\nTo broaden the reach of our training courses and content, we are also investigating a way to migrate our popular Haskell training course into a massive online course, or MOOC, while also making it more comprehensive with the inclusion of Plutus and Marlowe material. In this way, we hope our MOOC will make the course even more valuable, and provide access to the widest possible global community. In addition, we are planning a comprehensive classroom-based Haskell and Plutus course in Mongolia, details of which will be finalized soon. We plan to use the introductory part of the online Haskell course as a primer for this face-to-face training. This is an example of a core efficiency that we are embracing where we aim to reuse content on Haskell, Plutus, and Marlowe across a variety of stand-alone modular materials that we can use externally and within the company for developing our staff.\n\nWe appreciate the value of interactive and meaningful training workshops, so we intend to host many more this year in several locations around the world. These events are in the initial planning stages and the first in the series will take place in Quebec in the spring. We’ll announce more details through our official channels – Twitter, email, here – nearer the time. The IOHK education team are on hand to support and prepare the necessary learning tools for participants to use at these events.\n\nAlongside these materials and courses, we are mentoring an undergraduate student at the International University of Management (ISM), with her thesis on the topic of the power of blockchain in emerging markets. Additionally, Dr Jamie Gabbay has been invited to contribute to the book \'*Applications of new generation technology to cryptocurrencies, banking, and finance*’ by Devraj Basu.\n\n## Internal initiatives\n\nWe are also working with our human resources team to build the IOHK Training Academy: a new learning portal for our internal teams to upskill and develop professionally. This new resource is part of our learning and development strategy that aims to improve employee engagement, satisfaction, and retention. We want to provide access to a library of assets so our staff can easily find exactly what they need. We will be developing tailored ‘learning journeys’ by function, ready-made content that will help people develop skills in new areas, as well as creating specific onboarding journeys for new starters. This is a vital resource for a fast-growing company with staff and contractors spread across 43 countries and will prove to be an important asset for all our people.\n\n2020 is going to be a pivotal year for Cardano and we are looking forward to playing our part. It is our aim to teach both individuals and organizations how to use the protocol, and how it can help with their everyday lives. We have lots to do and we look forward to sharing all the educational content that we produce with our existing community, as well as those of you who are new to Cardano. ',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Educating the world on Cardano: initiatives and plans for 2020',
                                subtitle: 'Learn more about the education team\'s plans for the upcoming year',
                                audio: null,
                                soundcloud: null,
                                body_content: 'Education has always been a key part of IOHK’s strategy. Our mission is to grow our global community and business through the medium of education, and to share what we have learned. By claiming leadership in worldwide education on blockchain technology, we have the chance to shape the field for generations and to leave a lasting legacy.\n\nA consistent theme from 2019 has been the demand for a broad range of educational content, as demonstrated by the feedback received about the Incentivized Testnet, as well as the steady flow of support requests to our helpdesk. A key focus in IOHK for 2020 is to develop and expand our education materials as we transition fully into the Shelley era and then to the Goguen era of Cardano.\n\nThe IOHK education team will be investing significant time and effort this year in broadening our range of materials. We aim to enhance understanding of our technologies using a variety of learning and training assets targeted at a wide range of stakeholder audiences, both internal and external. This will be vital as the use of IOHK technology moves into the mainstream. We also aim to provide knowledge and information to enterprise decision-makers so they know what business problems our technologies can solve. We have lots planned and many projects are underway as we grow Cardano into a global social and financial operating system.\n\n## What can you expect?\n\nWe started 2020 with lectures, by Dr Lars Brünjes, our director of education, at the University of Malta. The focus of these lectures was on Plutus and Marlowe, our programming languages for smart contracts. The fruits of these sessions will, in turn, form the foundation of some modular training materials that we plan to formalize and develop over the coming months.\n\nOur free Udemy courses on [Plutus](https://www.udemy.com/course/plutus-reliable-smart-contracts/) and [Marlowe](https://www.udemy.com/course/marlowe-programming-language/) by Alejandro Garcia have proven very popular, with over 5,000 students signed up. Feedback has been positive and, as a result of what we learned from our students, we’ve been making incremental improvements over the last year. We now want to take this to the next level and are planning to fully update both courses soon to bring them up to speed with the latest development changes and new features. We are also in the initial planning stages for a second edition of the ebook, [Plutus: Writing reliable smart contracts](https://leanpub.com/plutus-smart-contracts) by Lars Brünjes and Polina Vinogradova, which we will be publishing later this year. The writing team has started to identify improvements and we are also gathering feedback directly from readers. If you have suggestions, please raise a pull request in our [Plutus ebook GitHub repository](https://github.com/input-output-hk/plutus/tree/master/plutus-book) with your ideas.\n\nAn important step in bridging the gap between our academic papers and mainstream understanding of these concepts is to teach people about Ouroboros, the proof-of-stake protocol that powers Cardano and ada. In response to the valuable feedback we have received from running the Incentivized Testnet, we are planning to create varied educational content to help stake pool operators understand Ouroboros and how the protocol works on a practical level.\n\n## Broadening our reach\n\nTo broaden the reach of our training courses and content, we are also investigating a way to migrate our popular Haskell training course into a massive online course, or MOOC, while also making it more comprehensive with the inclusion of Plutus and Marlowe material. In this way, we hope our MOOC will make the course even more valuable, and provide access to the widest possible global community. In addition, we are planning a comprehensive classroom-based Haskell and Plutus course in Mongolia, details of which will be finalized soon. We plan to use the introductory part of the online Haskell course as a primer for this face-to-face training. This is an example of a core efficiency that we are embracing where we aim to reuse content on Haskell, Plutus, and Marlowe across a variety of stand-alone modular materials that we can use externally and within the company for developing our staff.\n\nWe appreciate the value of interactive and meaningful training workshops, so we intend to host many more this year in several locations around the world. These events are in the initial planning stages and the first in the series will take place in Quebec in the spring. We’ll announce more details through our official channels – Twitter, email, here – nearer the time. The IOHK education team are on hand to support and prepare the necessary learning tools for participants to use at these events.\n\nAlongside these materials and courses, we are mentoring an undergraduate student at the International University of Management (ISM), with her thesis on the topic of the power of blockchain in emerging markets. Additionally, Dr Jamie Gabbay has been invited to contribute to the book \'*Applications of new generation technology to cryptocurrencies, banking, and finance*’ by Devraj Basu.\n\n## Internal initiatives\n\nWe are also working with our human resources team to build the IOHK Training Academy: a new learning portal for our internal teams to upskill and develop professionally. This new resource is part of our learning and development strategy that aims to improve employee engagement, satisfaction, and retention. We want to provide access to a library of assets so our staff can easily find exactly what they need. We will be developing tailored ‘learning journeys’ by function, ready-made content that will help people develop skills in new areas, as well as creating specific onboarding journeys for new starters. This is a vital resource for a fast-growing company with staff and contractors spread across 43 countries and will prove to be an important asset for all our people.\n\n2020 is going to be a pivotal year for Cardano and we are looking forward to playing our part. It is our aim to teach both individuals and organizations how to use the protocol, and how it can help with their everyday lives. We have lots to do and we look forward to sharing all the educational content that we produce with our existing community, as well as those of you who are new to Cardano. ',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'educating-the-world-on-cardano-initiatives-and-plans-for-2020',
                                url: '/blog/posts/2020/02/27/educating-the-world-on-cardano-initiatives-and-plans-for-2020/',
                                read_time: 6
                            }
                        ]
                    },
                    video_id: null,
                    main_image: 'https://ucarecdn.com/350386c8-b07f-44f0-9787-0c898a3d0460/',
                    custom_meta_img: null,
                    old_url: null,
                    haskell: null,
                    localized: [
                        {
                            lang: 'en',
                            title: 'A close look at the software running Cardano',
                            subtitle: 'Learn about the ‘stack’ of components that interact to run the blockchain platform',
                            audio: null,
                            soundcloud: [
                                {
                                    trackid: 1066347517
                                }
                            ],
                            body_content: 'Cardano has been designed in modules, with linked components that can be used in various ways. These components form the Cardano ‘platform stack’. They work together under the hood to support the construction and use of the live Cardano blockchain.\n\nWe are currently in the early testnet phase on the way to the Alonzo hard fork, which will bring full smart contract capability to Cardano. This process is highly complex, requiring the steady upgrade of the different elements which make up the Cardano platform, and their careful integration and testing. So, it is a good time to revisit these components, explain some of the terminology, and discover how they interact within the ‘platform stack’.\n\n## Elements of the Cardano platform stack\n\n![](https://ucarecdn.com/913ea221-dd67-4938-84be-3461f79b0baa/)\n\n**Figure 1. Components that communicate with the Cardano node**\n\nThe platform stack for Cardano includes these core components:\n\n* Cardano node (and associated processes)\n* Cardano wallet\n* Wallet command line interface (CLI)\n* DB Sync (synchronizes blockchain data with a relational database)\n* PostgreSQL database (which interacts with GraphQL, REST API, and Smash)\n* Smash server\n* Rosetta API (blockchain communication protocol)\n\nNote that the Daedalus wallet is not part of the core stack, but does communicate with the components (Figure 1). \n\n### The node and the networking layer\n\nFirst, let\'s take a look at the [Cardano node](https://github.com/input-output-hk/cardano-node). This software runs on your computer and underpins the network, enabling everyone to participate in the decentralized blockchain. The node integrates the consensus, ledger, and networking sub-components, providing top-level configuration, API, CLI, logging, memory management, and monitoring capabilities that can be used by other Cardano components or by skilled users. Daedalus is a full-node wallet, so if you are running that on your local machine, you are effectively helping to run the network. \n\n*The networking layer*\n\nNext, we have the networking layer. This links each Cardano node into a distributed system that manages the blockchain and associated services. The network consists of a collection of nodes that communicate with each other to maintain the distributed ledger, support transaction submission, and interact with user wallets and other services. The core of the network is built around the decentralized nodes – the stake pools – that collectively validate blocks, and add new blocks to the chain. They are supported by dedicated relay nodes that manage network connections and establish the structure of the network as a whole. The dedicated consumer nodes that are run by the Daedalus wallet and other services connect to this network to track and submit transactions on-chain.\n\nCardano nodes maintain connections with their peers. A set of mini-protocols enable communication between the nodes. Each mini-protocol implements a basic information exchange requirement, such as informing peers of the latest block, sharing blocks as needed, or sharing new transactions around the Cardano network. For connection purposes, mini-protocols are determined by the version of the network protocol. \n\n### Cardano wallet backend\n\nThe [Cardano wallet](https://github.com/input-output-hk/cardano-wallet) backend component supports the graphical user interface of the Daedalus wallet. It is used to send and receive ada. Behind the scenes, the wallet runs a full Cardano node. Unlike a light client wallet, it loads the entire shared ledger and validates all transactions, thus bolstering the security of the blockchain for everyone.\n\n### Wallet command line interface (CLI)\n\nThe wallet command line interface (CLI) supports interactions with the actual blockchain. More technically advanced users can use the CLI  to work with a collection of tools for generating keys, constructing transactions, creating certificates, and performing other tasks. It is organized in a hierarchy of subcommands, and each level comes with its own built-in documentation of command syntax and options.\n\n### DB Sync\n\n[DB Sync](https://github.com/input-output-hk/cardano-db-sync) is a component that follows the activities on the Cardano chain and stores blocks and transactions in PostgreSQL. As a ‘middleware’ component, it powers [cardano-graphql](https://github.com/input-output-hk/cardano-graphql). DB Sync stores blockchain data fetched from [cardano-node](https://github.com/input-output-hk/cardano-node) in an intermediate database to enable higher-level interfaces for blockchain exploration. It also provides a number of queries to fetch Cardano blockchain data from the PostgreSQL, and supports services such as the [Cardano Explorer](https://explorer.cardano.org/en.html), a graphical user interface that reflects the blockchain data in a straightforward way. Cardano GraphQL is a cross-platform API for the GraphQL data query language. \n\n### Rosetta API\n\nThe Rosetta application programming interface provides a high-level interface that aims to make the integration process easier, faster, and more reliable so that you can build once and integrate your blockchain everywhere. We have created a unique [cardano-rosetta](https://github.com/input-output-hk/cardano-rosetta) implementation to simplify the process of integration with Cardano. This interface is particularly useful for exchanges, since they can interact with the Cardano chain using the same interface that they use with other blockchains.\n\n### Looking forward\n\nWith [smart contracts](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) coming to Cardano soon, this means that [Plutus](https://iohk.io/en/blog/posts/2021/04/13/plutus-what-you-need-to-know/), the native smart contract language, and other smart contract development languages like [Marlowe](https://iohk.io/en/blog/posts/2021/05/26/reimagining-peer-to-peer-finance-with-marlowe/) for finance and [Glow](https://glow-lang.org/) for DApps will be integrated into the Cardano stack. IO Global’s engineers will provide new and extended components to compile Plutus, Marlowe, and Glow scripts, submit them on-chain, and interact with them (Figure 2).\n\n![](https://ucarecdn.com/49d00118-da94-4dde-9be2-1a721c698a39/)\n\n**Figure 2. Plutus, Marlowe, Glow, Solidity, and IELE can all be used to write Cardano smart contracts**\n\nThe [Alonzo protocol upgrade](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) will build on recent token upgrades and is being deployed to the mainnet via several testnets. Our Plutus partners and Plutus Pioneers will help us to test Plutus Core and will be part of the user acceptance phase before mainnet deployment. At this point we will officially add the Plutus and Marlowe components, such as both interpreters, to Cardano’s platform stack. \n\n*To keep up to date with the Alonzo rollout, please check our social channels and blog page.*',
                            uses_mathjax: false,
                            attachments: []
                        },
                        {
                            lang: 'jp',
                            title: 'Cardanoで稼働するソフトウェアに注目',
                            subtitle: 'ブロックチェーンプラットフォームを実行するために相互作用するコンポーネントの「スタック」を知ろう',
                            audio: null,
                            soundcloud: [],
                            body_content: 'Cardanoはモジュール単位で設計されています。ここには、さまざまな方法で使用できるコンポーネントがリンクされています。こうしたコンポーネントはCardano「プラットフォームスタック」を形成しています。これらは内部で共に作動し、稼働するCardanoブロックチェーンの構造と使用を支えています。\n現在は、Cardnaoに完全なスマートコントラクト機能をもたらすAlonzoハードフォークに向けた、初期テストネットの段階にあります。このプロセスは極めて複雑で、Cardanoプラットフォームを構成するさまざまな要素をしっかりとアップグレードし、慎重に統合、テストする必要があります。したがって、今こそこうしたコンポーネントを振り返り、一部の用語を説明し、「プラットフォームスタック」の中でこれらがいかに相互作用するかを考察するいい機会です。\n\n## Cardanoプラットフォームスタックの要素\n\n\n![](https://ucarecdn.com/913ea221-dd67-4938-84be-3461f79b0baa/)\n\n**図1：Cardanoノードと通信するコンポーネント**\n\nCardanoプラットフォームスタックには以下のコアコンポーネントが含まれます。\n\n* Cardanoノード（および関連プロセス）\n* Cardanoウォレット\n* ウォレットコマンドラインインターフェイス（CLI）\n* DB Sync（ブロックチェーンデータを関連するデータベースと同期)\n* PostgreSQLデータベース（GraphQL、REST API、SMASHと相互作用）\n* SMASHサーバー\n* Rosetta API（ブロックチェーン通信プロトコル）\n\n注：Daedalusはコアスタックに含まれませんが、コンポーネントと通信します（図1）。\n\n### ノードとネットワーク層\n\nはじめに、Cardanoノードを見てみましょう。このソフトウェアは個人のコンピューター上で実行されてネットワークを支え、誰もが分散型ブロックチェーンに参加できるようにするものです。ノードは、コンセンサス、台帳、ネットワークのサブコンポーネントを統合し、他のCardanoコンポーネントまたは熟練したユーザーが使用できるトップレベルの設定、API、CLI、ログ、メモリー管理、そして監視機能を提供します。Daedalusはフルノードウォレットで、ローカルマシンで実行することにより、実質的にネットワークの実行に貢献することになります。\n\n*ネットワーク層*\n\n次にネットワーク層です。これは各Cardanoノードを、ブロックチェーンを管理する1つの分散型システムと関連サービスにリンクさせます。ネットワークは、互いに通信しあって分散型台帳を維持し、トランザクションの送信を支え、ユーザーのウォレットや他のサービスとやり取りするノードの集合で構成されます。ネットワークのコアは、集団的にブロックを検証し、チェーンに新たなブロックを追加する分散型ノード（ステークプール）を中心に構築されています。これを支えるのは、ネットワーク接続を管理し、ネットワークの構造を全体として確立する専用のリレーノードです。Daedalusウォレットや他のサービスが実行する専用のコンシューマーノードはこのネットワークに接続し、チェーン上でトランザクションを追跡、送信します。\nCardanoノードはピアとの接続を維持します。一連のミニプロトコルがノード間の通信を可能にします。各ミニプロトコルは基本的な情報交換要件を実装しています。例えば、Cardanoネットワークのあちこちでピアに最新ブロックを伝える、必要に応じてブロックを共有する、新たなトランザクションを共有する、などです。ミニプロトコルは、接続を目的として、ネットワークプロトコルのバージョンによって決定されます。\n\n### Cardanoウォレットバックエンド\n\nCardanoウォレットバックエンドコンポーネントはDaedalusウォレットのグラフィカルユーザーインターフェイスをサポートしています。これは、ADAの送受信に使用されます。ウォレットはバックグラウンドでCardanoフルノードを実行しています。軽量クライアントウォレットとは異なり、これは共有された台帳全体をロードし、すべてのトランザクションを検証するため、全員にとってブロックチェーンのセキュリティが強化されます。\n\n### ウォレットコマンドラインインターフェイス（CLI）\n\nウォレットコマンドラインインターフェイス（CLI）は実際のブロックチェーンとのやり取りをサポートします。高度な技術を持つユーザーは、CLIにより、ツールのコレクションを使用して、鍵の生成やトランザクションの構築、証明書の作成、その他のタスクを実行することができます。これはサブコマンドの階層順に整理され、各レベルには、コマンドシンタックスやオプションのビルトインドキュメンテーションが付されています。\n\n### DB Sync\n\nDB SyncはCardanoチェーンのアクティビティに従い、PostgreSQLにブロックとトランザクションを保存するコンポーネントです。「ミドルウェア」コンポーネントとして、cardano-graphqlを強化します。DB Syncは、ブロックチェーン探索のための高レベルのインターフェイスを有効にするために、cardano-nodeからフェッチしたブロックチェーンを中間データベースに保存します。また、数多くのクエリを提供してPostgreSQLからCardanoブロックチェーンデータをフェッチし、ブロックチェーンデータをシンプルに反映するグラフィカルユーザーインターフェイス、Cardanoエクスプローラーなどのサービスをサポートします。Cardano GraphQLは、GraphQLデータクエリ言語用のクロスプラットフォームAPIです。\n\n### Rosetta API\n\nRosettaアプリケーションプログラミングインターフェイスは、統合プロセスをより簡単に、より速く、より信頼できるものにすることを目的とした高レベルインターフェイスを提供します。これにより、一度構築すると、どこでもブロックチェーンを統合できます。Cardanoとの統合プロセスを簡易化するために、私たちはユニークなcardano-rosettaを作成しました。このインターフェイスは、取引所に特に役立ちます。他のブロックチェーンで使用するものと同じインターフェイスを使って、Cardanoチェーンとやり取りすることができるためです。\n\n### 今後\n\nまもなくCardanoにスマートコントラクトが搭載されますが、これは、スマートコントラクトのネイティブ言語Plutusや、金融仕様のMarlowe、DApp仕様のGlowなど、その他のスマートコントラクト開発言語がCardanoスタックに統合されることを意味します。IO Globalのエンジニアは、Plutus、Marlowe、Glowのスクリプトをコンパイルし、チェーン上に送信し、やり取りするための新コンポーネントや拡張コンポーネントを提供します（図2）。\n\n![](https://ucarecdn.com/49d00118-da94-4dde-9be2-1a721c698a39/)\n\n**図2：Plutus、Marlowe、Glow、Solidity、IELEはすべて、Cardanoスマートコントラクトの作成に使用可能**\n\nAlonzoプロトコルアップグレードは、最近のトークンアップグレードの上に構築され、複数のテストネットを経てメインネットで展開されます。PlutusパートナーやPlutusパイオニアたちはPlutus Coreのテストに協力し、メインネットへの展開前のユーザー受け入れフェーズに参加します。この時点で、インタープリターなどのPlutusとMarloweコンポーネントはCardanoプラットフォームスタックへと公式に追加されます。\nAlonzoロールアウトの最新情報は、ソーシャルチャネルとブログをチェックしてください。\n',
                            uses_mathjax: false,
                            attachments: []
                        }
                    ],
                    lang: 'en',
                    title: 'A close look at the software running Cardano',
                    subtitle: 'Learn about the ‘stack’ of components that interact to run the blockchain platform',
                    audio: null,
                    soundcloud: [
                        {
                            trackid: 1066347517
                        }
                    ],
                    body_content: 'Cardano has been designed in modules, with linked components that can be used in various ways. These components form the Cardano ‘platform stack’. They work together under the hood to support the construction and use of the live Cardano blockchain.\n\nWe are currently in the early testnet phase on the way to the Alonzo hard fork, which will bring full smart contract capability to Cardano. This process is highly complex, requiring the steady upgrade of the different elements which make up the Cardano platform, and their careful integration and testing. So, it is a good time to revisit these components, explain some of the terminology, and discover how they interact within the ‘platform stack’.\n\n## Elements of the Cardano platform stack\n\n![](https://ucarecdn.com/913ea221-dd67-4938-84be-3461f79b0baa/)\n\n**Figure 1. Components that communicate with the Cardano node**\n\nThe platform stack for Cardano includes these core components:\n\n* Cardano node (and associated processes)\n* Cardano wallet\n* Wallet command line interface (CLI)\n* DB Sync (synchronizes blockchain data with a relational database)\n* PostgreSQL database (which interacts with GraphQL, REST API, and Smash)\n* Smash server\n* Rosetta API (blockchain communication protocol)\n\nNote that the Daedalus wallet is not part of the core stack, but does communicate with the components (Figure 1). \n\n### The node and the networking layer\n\nFirst, let\'s take a look at the [Cardano node](https://github.com/input-output-hk/cardano-node). This software runs on your computer and underpins the network, enabling everyone to participate in the decentralized blockchain. The node integrates the consensus, ledger, and networking sub-components, providing top-level configuration, API, CLI, logging, memory management, and monitoring capabilities that can be used by other Cardano components or by skilled users. Daedalus is a full-node wallet, so if you are running that on your local machine, you are effectively helping to run the network. \n\n*The networking layer*\n\nNext, we have the networking layer. This links each Cardano node into a distributed system that manages the blockchain and associated services. The network consists of a collection of nodes that communicate with each other to maintain the distributed ledger, support transaction submission, and interact with user wallets and other services. The core of the network is built around the decentralized nodes – the stake pools – that collectively validate blocks, and add new blocks to the chain. They are supported by dedicated relay nodes that manage network connections and establish the structure of the network as a whole. The dedicated consumer nodes that are run by the Daedalus wallet and other services connect to this network to track and submit transactions on-chain.\n\nCardano nodes maintain connections with their peers. A set of mini-protocols enable communication between the nodes. Each mini-protocol implements a basic information exchange requirement, such as informing peers of the latest block, sharing blocks as needed, or sharing new transactions around the Cardano network. For connection purposes, mini-protocols are determined by the version of the network protocol. \n\n### Cardano wallet backend\n\nThe [Cardano wallet](https://github.com/input-output-hk/cardano-wallet) backend component supports the graphical user interface of the Daedalus wallet. It is used to send and receive ada. Behind the scenes, the wallet runs a full Cardano node. Unlike a light client wallet, it loads the entire shared ledger and validates all transactions, thus bolstering the security of the blockchain for everyone.\n\n### Wallet command line interface (CLI)\n\nThe wallet command line interface (CLI) supports interactions with the actual blockchain. More technically advanced users can use the CLI  to work with a collection of tools for generating keys, constructing transactions, creating certificates, and performing other tasks. It is organized in a hierarchy of subcommands, and each level comes with its own built-in documentation of command syntax and options.\n\n### DB Sync\n\n[DB Sync](https://github.com/input-output-hk/cardano-db-sync) is a component that follows the activities on the Cardano chain and stores blocks and transactions in PostgreSQL. As a ‘middleware’ component, it powers [cardano-graphql](https://github.com/input-output-hk/cardano-graphql). DB Sync stores blockchain data fetched from [cardano-node](https://github.com/input-output-hk/cardano-node) in an intermediate database to enable higher-level interfaces for blockchain exploration. It also provides a number of queries to fetch Cardano blockchain data from the PostgreSQL, and supports services such as the [Cardano Explorer](https://explorer.cardano.org/en.html), a graphical user interface that reflects the blockchain data in a straightforward way. Cardano GraphQL is a cross-platform API for the GraphQL data query language. \n\n### Rosetta API\n\nThe Rosetta application programming interface provides a high-level interface that aims to make the integration process easier, faster, and more reliable so that you can build once and integrate your blockchain everywhere. We have created a unique [cardano-rosetta](https://github.com/input-output-hk/cardano-rosetta) implementation to simplify the process of integration with Cardano. This interface is particularly useful for exchanges, since they can interact with the Cardano chain using the same interface that they use with other blockchains.\n\n### Looking forward\n\nWith [smart contracts](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) coming to Cardano soon, this means that [Plutus](https://iohk.io/en/blog/posts/2021/04/13/plutus-what-you-need-to-know/), the native smart contract language, and other smart contract development languages like [Marlowe](https://iohk.io/en/blog/posts/2021/05/26/reimagining-peer-to-peer-finance-with-marlowe/) for finance and [Glow](https://glow-lang.org/) for DApps will be integrated into the Cardano stack. IO Global’s engineers will provide new and extended components to compile Plutus, Marlowe, and Glow scripts, submit them on-chain, and interact with them (Figure 2).\n\n![](https://ucarecdn.com/49d00118-da94-4dde-9be2-1a721c698a39/)\n\n**Figure 2. Plutus, Marlowe, Glow, Solidity, and IELE can all be used to write Cardano smart contracts**\n\nThe [Alonzo protocol upgrade](https://iohk.io/en/blog/posts/2021/04/08/smart-contracts-%E2%80%93-here-we-come/) will build on recent token upgrades and is being deployed to the mainnet via several testnets. Our Plutus partners and Plutus Pioneers will help us to test Plutus Core and will be part of the user acceptance phase before mainnet deployment. At this point we will officially add the Plutus and Marlowe components, such as both interpreters, to Cardano’s platform stack. \n\n*To keep up to date with the Alonzo rollout, please check our social channels and blog page.*',
                    uses_mathjax: false,
                    attachments: [],
                    slug: 'a-close-look-at-the-software-running-cardano',
                    url: '/blog/posts/2021/06/08/a-close-look-at-the-software-running-cardano/',
                    read_time: 5
                },
                {
                    publish_date: '2021-06-02T00:00:00.000Z',
                    author: {
                        title: 'Eric Czuleger',
                        display_name: null,
                        thumbnail: 'https://ucarecdn.com/fd70c3a0-974f-406f-88e2-a9956d82cc86/',
                        is_team_member: true,
                        is_active: true,
                        localized: [
                            {
                                job_titles: [
                                    {
                                        name: 'Senior Content Editor',
                                        primary: null
                                    },
                                    {
                                        name: 'Marketing & Communications',
                                        primary: null
                                    }
                                ],
                                lang: 'en',
                                profile_links: {
                                    email: 'eric.czuleger@iohk.io',
                                    youtube: null,
                                    linkedin: 'https://www.linkedin.com/in/eric-czuleger-6b67a395/',
                                    twitter: 'https://twitter.com/eczuleger',
                                    github: null
                                }
                            }
                        ],
                        job_titles: [
                            {
                                name: 'Senior Content Editor',
                                primary: null
                            },
                            {
                                name: 'Marketing & Communications',
                                primary: null
                            }
                        ],
                        lang: 'en',
                        profile_links: {
                            email: 'eric.czuleger@iohk.io',
                            youtube: null,
                            linkedin: 'https://www.linkedin.com/in/eric-czuleger-6b67a395/',
                            twitter: 'https://twitter.com/eczuleger',
                            github: null
                        },
                        profile_url: '/blog/authors/eric-czuleger/',
                        blog_posts: [
                            {
                                publish_date: '2021-06-02T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/a654b860-da1e-415c-8eb9-0b6188229740/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Nervos partnership to build the first cross-chain bridge with Cardano',
                                        subtitle: ' Our new collab lets Cardano and Nervos token holders transmit their value across both platforms while building interoperability across the crypto space',
                                        audio: null,
                                        soundcloud: [
                                            {
                                                trackid: 1060596082
                                            }
                                        ],
                                        body_content: '<!--StartFragment-->\n\nIOHK and Nervos are teaming up to build a bridge of interoperability between Cardano and the Nervos Network. Once completed, this pioneering cross-chain bridge will enable users to transact assets between the two blockchains. The end goal is to foster greater interoperability while expanding the global reach and utility of both Nervos and Cardano.\n\n\n\nThe Nervos ‘Common Knowledge Base’ ([CKB](https://coinmarketcap.com/currencies/nervos-network/historical-data/)) is a permissionless, layer 1, open-source, proof-of-work blockchain protocol focused on creating the foundations for an interoperable universal public network. It allows any crypto asset to be kept in a secure, immutable, and permissionless environment with the added benefit of smart contracts and layer 2 scaling. \n\n\n\nNervos is developing this robust network through three key components. Together, these make up the Universal Passport, Nervos’ approach to next generation interoperability. \n\n\n\n* **PW Core** – enables developers to build applications on all chains\n* **Nervos’ Polyjuice** – an Ethereum-compatible layer that allows developers to port a smart contract from Ethereum to Nervos\n* **Force Bridge** – a trustless bridge that enables cross-chain transactions between Nervos and a spectrum of blockchains. Nervos will use Force Bridge to connect directly to Cardano, which means that users will be able to transact using their existing Cardano wallets.\n\n\n\n## Bridging blockchains with transportable tokens\n\n\n\nSo what does this mean in practice? Holders of Nervos CKByte (CKB) and ada will be able to transact both currencies interchangeably. Nervos users will also be able to take advantage of Cardano\'s native asset standard to create tokens that can be ported and used across both networks. On top of this, the bridge enables developers on both chains gain access to services and features to expand their DApp ecosystem and user bases. \n\n\n\n[Mousebelt](https://www.mousebelt.com/), a full-service blockchain accelerator, will build the bridge with financial support from Nervos. The Cardano team will contribute expertise and resources to connect Cardano to the bridge. Development work is already underway and it is expected to be completed in the next six weeks. \n\n\n\n\'Using the Force Bridge to link the Nervos Network and Cardano is especially exciting given the relationship we have already built with IOHK,\' said Kevin Wang, co-founder of Nervos. \'We have been growing our research and development partnership, but we will soon have a tangible bridge that will also showcase the power of the Force Bridge and push us further along the road to a functional and interoperable network.\'\n\n\n\nThis bridge is just part of our collaboration with Nervos. \'We share a vision of a world that works on a ‘constellation’ of interoperating blockchains,\' says Romain Pellerin, CTO at Input Output. \'We believe that academic research is also fundamental to advancing the entire crypto space. Together we will also be co-authoring academic papers to pioneer improvements to the UTXO model, explore universal accounting standards, and contribute to the future development of decentralized technology through open-source research.\'\n\n\n\nBlockchain technology will only achieve mainstream acceptance when end users are not locked into one blockchain or standard, but can seamlessly access value and utility, regardless of which blockchain they are using. \'Bridges like this are an absolute necessity in order to ensure that users have a seamless experience,\' continued Pellerin. ‘By connecting our communities and finding innovative new ways to work together, as we have been doing with Nervos, we can ensure that blockchain lives up to its promises of creating a fairer and more efficient global financial operating system.\'\n\n\n\n*Check out the [Nervos website](https://www.nervos.org/) for more information on upcoming partnerships and research initiatives.*\n\n\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    },
                                    {
                                        lang: 'jp',
                                        title: 'NervosとのパートナーシップでCardanoと初のクロスチェーンブリッジを構築',
                                        subtitle: '新たなコラボレーションにより、暗号資産界全体に相互運用性を構築。CardanoとNervosのトークン所有者は、両プラットフォーム間で資産取引が可能に',
                                        audio: null,
                                        soundcloud: [
                                            {
                                                trackid: 1060596082
                                            }
                                        ],
                                        body_content: '<!--StartFragment-->\n\nIOHKとNervosは協力してCardanoとNervosネットワーク間に相互運用性を構築します。完成すれば、この先駆的なクロスチェーンのブリッジにより、ユーザーは2つのブロックチェーン間で資産取引が可能になります。最終目標はより優れた相互運用性を促進すること。その間、NervosとCardano両者のグローバルリーチとユーティリティを拡張していきます。\n\n\nNervosの「Common Knowledge Base」（共通知識ベース：CKB）は、パーミッションレス、レイヤー1、オープンソースのプルーフオブワークブロックチェーンプロトコルで、相互運用可能なユニバーサルパブリックネットワークの基礎を築くことに主眼を置いています。これにより、あらゆる暗号資産は、スマートコントラクトとレイヤー2スケーリングのメリットが追加された、安全、不変、そしてパーミッションレスな環境に保管されます。 \n\n\nNervosはこの頑丈なネットワークを3つの主要コンポーネントを軸として開発しています。これらはともに、Nervosの次世代相互運用性へのアプローチであるユニバーサスパスポートを構成するものです。 \n\n\n\n* **PW Core**（PWコア）- 開発者がすべてのチェーンでアプリケーションを構築することを可能にします。\n* **Nervos’ Polyjuice**（Nervosポリジュース）- 開発者がイーサリアムからNervosへスマートコントラクトを移植できるようにするイーサリアム対応レイヤーです。\n\n* **Force Bridge** (フォースブリッジ - Nervosとさまざまなブロックチェーンとのクロスチェーントランザクションを可能にするトラストレスなブリッジです。NervosはForce Bridgeを使用してCardanoと直接接続し、ユーザーは既存のCardanoウォレットを使用してトランザクションを行うことができます。\n\n\n\n## 可搬トークンでブロックチェーンを橋渡しする\n\n\n\nこれは実際何を意味するのでしょうか。NervosのCKByte（CKB）とADA保有者は、両通貨を交換して取引することができます。NervosユーザーはCardanoのネイティブアセット規格を利用してトークンを作成し、両ネットワークを行き来させて、使用することができます。加えて、ブリッジにより開発者は両チェーン上でサービスや機能へアクセスし、自分たちのDAppエコシステムやユーザーベースを拡張することができます。 \n\n\nフルサービスのブロックチェーンアクセラレーター、[Mousebelt](https://www.mousebelt.com/)は、Nervosから財政支援を得てブリッジを構築します。Cardanoチームは、Cardanoとブリッジを接続するために、専門知識とリソースを提供します。開発作業は既に進行中で、今後6週間で完了する見込みです。 \n\n\n\n「Force Bridgeを使用してNervos NetworkとCardanoをリンクすることは、IOHKとの間に既に築き上げられている関係を考えても特にエキサイティングです」と、Nervosの共同創業者Kevin Wang氏は語ります。「私たちは研究開発パートナーシップを育ててきましたが、まもなく実際のブリッジを手にすることができます。これはForce Bridgeのパワーを示すショーケースでもあり、機能的かつ相互運用可能なネットワークへとつながる道にいる私たちをさらに前進させるものです」\n\n\n\nこのブリッジは、Nervosとのコラボレーションの一部に過ぎません。「私たちは、相互運用可能なブロックチェーンの「星座」で機能する世界というビジョンを共有しています」とInput OutputのCTO、Romain Pellerinは述べます。「学術研究も暗号界全体を前進させる基盤となっていると信じています。私たちはまた、UTXOモデルの画期的な改良に関する論文の共同執筆、ユニバーサル会計規格の検討、オープンソースの研究を介した分散型技術の今後の開発への協力を予定しています」\n\n\n\nブロックチェーン技術は、エンドユーザーが1つのブロックチェーンや規格に縛られることなく、どのブロックチェーンを使用していようとも、価値やユーティリティにシームレスにアクセスできて初めて、主流に受け入れられるようになります。「このようなブリッジは、ユーザーにシームレスなエクスペリエンスを提供するうえで絶対に欠かせません」とPellerinは続けます。「私たちとNervosが実行しているように、コミュニティを繋げ、協力するための革新的な方法を見つけることにより、より公正で効率的なグローバル金融オペレーティングシステムを創造するという約束を確実に果たすことができるのです」\n\n\n*予定されているパートナーシップと研究イニシアチブについての詳細は、[Nervos website](https://www.nervos.org/)をご覧ください。*\n\n\n\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Nervos partnership to build the first cross-chain bridge with Cardano',
                                subtitle: ' Our new collab lets Cardano and Nervos token holders transmit their value across both platforms while building interoperability across the crypto space',
                                audio: null,
                                soundcloud: [
                                    {
                                        trackid: 1060596082
                                    }
                                ],
                                body_content: '<!--StartFragment-->\n\nIOHK and Nervos are teaming up to build a bridge of interoperability between Cardano and the Nervos Network. Once completed, this pioneering cross-chain bridge will enable users to transact assets between the two blockchains. The end goal is to foster greater interoperability while expanding the global reach and utility of both Nervos and Cardano.\n\n\n\nThe Nervos ‘Common Knowledge Base’ ([CKB](https://coinmarketcap.com/currencies/nervos-network/historical-data/)) is a permissionless, layer 1, open-source, proof-of-work blockchain protocol focused on creating the foundations for an interoperable universal public network. It allows any crypto asset to be kept in a secure, immutable, and permissionless environment with the added benefit of smart contracts and layer 2 scaling. \n\n\n\nNervos is developing this robust network through three key components. Together, these make up the Universal Passport, Nervos’ approach to next generation interoperability. \n\n\n\n* **PW Core** – enables developers to build applications on all chains\n* **Nervos’ Polyjuice** – an Ethereum-compatible layer that allows developers to port a smart contract from Ethereum to Nervos\n* **Force Bridge** – a trustless bridge that enables cross-chain transactions between Nervos and a spectrum of blockchains. Nervos will use Force Bridge to connect directly to Cardano, which means that users will be able to transact using their existing Cardano wallets.\n\n\n\n## Bridging blockchains with transportable tokens\n\n\n\nSo what does this mean in practice? Holders of Nervos CKByte (CKB) and ada will be able to transact both currencies interchangeably. Nervos users will also be able to take advantage of Cardano\'s native asset standard to create tokens that can be ported and used across both networks. On top of this, the bridge enables developers on both chains gain access to services and features to expand their DApp ecosystem and user bases. \n\n\n\n[Mousebelt](https://www.mousebelt.com/), a full-service blockchain accelerator, will build the bridge with financial support from Nervos. The Cardano team will contribute expertise and resources to connect Cardano to the bridge. Development work is already underway and it is expected to be completed in the next six weeks. \n\n\n\n\'Using the Force Bridge to link the Nervos Network and Cardano is especially exciting given the relationship we have already built with IOHK,\' said Kevin Wang, co-founder of Nervos. \'We have been growing our research and development partnership, but we will soon have a tangible bridge that will also showcase the power of the Force Bridge and push us further along the road to a functional and interoperable network.\'\n\n\n\nThis bridge is just part of our collaboration with Nervos. \'We share a vision of a world that works on a ‘constellation’ of interoperating blockchains,\' says Romain Pellerin, CTO at Input Output. \'We believe that academic research is also fundamental to advancing the entire crypto space. Together we will also be co-authoring academic papers to pioneer improvements to the UTXO model, explore universal accounting standards, and contribute to the future development of decentralized technology through open-source research.\'\n\n\n\nBlockchain technology will only achieve mainstream acceptance when end users are not locked into one blockchain or standard, but can seamlessly access value and utility, regardless of which blockchain they are using. \'Bridges like this are an absolute necessity in order to ensure that users have a seamless experience,\' continued Pellerin. ‘By connecting our communities and finding innovative new ways to work together, as we have been doing with Nervos, we can ensure that blockchain lives up to its promises of creating a fairer and more efficient global financial operating system.\'\n\n\n\n*Check out the [Nervos website](https://www.nervos.org/) for more information on upcoming partnerships and research initiatives.*\n\n\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'nervos-partnership-to-build-the-first-cross-chain-bridge-with-cardano',
                                url: '/blog/posts/2021/06/02/nervos-partnership-to-build-the-first-cross-chain-bridge-with-cardano/',
                                read_time: 3
                            },
                            {
                                publish_date: '2021-02-26T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/b32a85c3-d8e4-4756-8972-df0fe7be0062/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Bringing Glow to Cardano',
                                        subtitle: ' We just spun up a devnet to support Glow, the very latest language Cardano will support. We talked to its creator about building a DSL for DApp development.',
                                        audio: null,
                                        soundcloud: [],
                                        body_content: '<!--StartFragment-->\n\n*At the end of 2020, we announced our devnets plan to support the longer-term strategic goal of opening up Cardano to multiple development languages – as outlined in the ‘‘[Island, Ocean, Pond](https://youtu.be/k8a6tX53YPs)’ video. This week, building on the [Ethereum Virtual Machine](https://developers.cardano.org/en/virtual-machines/welcome/), we’re rolling out a new [development environment](https://developers.cardano.org/en/programming-languages/glow/overview/) to support the Glow language.*\n\n*François-René Rideau of Mutual Knowledge Systems is the creator of Glow, a DSL that will allow anyone to write verifiable DApps from a single spec and deploy it on our EVM network. We caught up with Rideau (also known as Fare) to hear more about his vision for Glow and the Cardano journey so far. The following is a distillation of his thoughts from our previous interviews.*\n\n\n\n**We first introduced the community to GLOW and MuKn at the end of [last year](https://youtu.be/lj9SlvOIBgU?t=2902) when we announced our devnets approach –  but maybe you can remind us how you began working with IOHK?**\n\nI started as a researcher in formal methods for programming languages and distributed systems. But I wanted to build systems actually used by many, so I moved into the industry where I notably worked on proving the correctness of a centralized payment protocol and creating an airline reservation system. After a few years at Google and Bridgewater, I decided life wasn’t worth working under dysfunctional hierarchies, so I started my own cryptocurrency companies. Charles invited me to speak at the IOHK Summit 2019, and I realized how much I like the Cardano community: we have a similar focus on building robust software for the long term. That is why I wanted to port my domain specific language Glow to Cardano.\n\n\n\n**Tell us a bit why you started your company Mutual Knowledge Systems, or as you call it MuKn (Moon)?**\n\nOver three years ago, I was reviewing whitepapers. Most papers (about ¾) had interesting techniques but made no economic sense. Most of the rest (about ⅕) made economic sense but had no technical content. Only the top few (about 5%) actually made sense both technically and economically. At some point, I realized I could do better, so I designed a scaling solution using lessons learned from working on Tezos. Arthur Breitman challenged me to use smart contracts instead of trying to modify his protocol. \n\nWhile trying to prove his challenge absurd, I instead found that he was right and I was wrong—and I finally understood why and how to use smart contracts. I started a company around the resulting scaling solution, raised money, pivoted into building the scaling solution after the language capable of generating it from specification, fought with and fired my then-partner, became my own CEO, started a new company, and, after much struggle, finally found the right founding team. Together, we built Mutual Knowledge Systems around this new programming language, Glow—designed to be much better than existing languages to write decentralized applications.\n\n\n\n**When you say ‘better’, what do you really mean?**\n\nWriting a DApp is the single hardest thing to do in the world. This is because you can’t afford a mistake, or your users may lose significant funds. Furthermore, you are not confronting random situations, but active adversaries bent on attacking your code, who will contrive the very worst case scenarios to exploit for their profit. Yet, unlike the military, you can’t hide your code or protect access to your networks: all the critical pieces are necessarily public. On top of that, extant programming tools are not designed for these constraints and even traditional formal methods lack essential concepts to express the issues at stake.\n\nThus, we decided to make new tools fit for the challenge. Our domain-specific language (DSL) drastically simplifies DApp development, by abstracting away all the common blockchain infrastructure, so you can focus on your problem domain (trading, derivatives, insurance, supply chain, etc.). Your DApps can be thousands of lines of code that your users can afford to audit, instead of millions of lines of code that require leaps of blind faith. And the programming model will enable developers, auditors and automated verification tools to reason at the level of abstraction of participants exchanging assets, rather than at that of packets of bytes shipped around the Internet.\n\n\n\n**What is it about Cardano and its community that appeals?**\n\nI started like everyone else, on Ethereum, because its ecosystem is already mature. However, the Ethereum community has this attitude of building as fast as possible experiments that are good enough for now, but lack conceptual integrity and won’t last; I see a lot of value in that approach and have tremendous respect for those who can thrive this way—for I cannot. When I met the Cardano community, I felt much more at home because we share a common attitude. We want to do things that are correct by construction and will keep working in the long term. We build concrete towers on the bedrock, not stick shacks on the sand. At times, this can be frustrating because things go slow, but I am happy with the attention to detail and quality in the development of Cardano. Is it perfect? No, it’s not. But it’s got great fundamentals.\n\n\n\n**Can you talk about how you hope Glow will change the DApp developer experience?**\n\nGlow is portable. Today it works on Cardano and Ethereum but in the future it will work with any blockchain that is sufficiently advanced to support smart contracts. That means that you can write your DApp once and it will run on whichever platform has the users and the liquidity you seek. You don’t have to make a guess about where liquidity will be in the future then sink heavy investments to develop on a single chain that you bet your house on.\n\n\n\nWith Glow, developers can run their DApps on all blockchains. Glow will commoditize blockchains. Blockchains will then compete on technical and economic merits, not on user lock-in and inertia. And the value brought to users will increase.\n\n\n\n**What can the community expect from Glow?**\n\nWe have launched this early version of Glow on the Cardano EVM Devnet with a command-line interface. In many ways, it is not yet ready for use by end-users, but it can already demonstrate simple applications. Users can also see how they may write a 6 line application in Glow that would require hundreds of lines in a combination of Solidity and JavaScript. We have a roadmap over the next few months to add a lot of features: from ERC20 tokens (and, on Cardano, native tokens), to generalized state channels, to a web interface, to a more robust runtime, etc. Eventually, we want to become the development environment for all blockchain projects. And Glow is of course an open source software open to the community.\n\n**We’re rolling out the integration with Glow with our EVM and devnet program, so what are some of the benefits of this?**\n\nThe Cardano EVM side-chain will enable arbitrary contracts to run on Cardano that use the mature EVM platform, without waiting for Plutus to deliver its promise, to achieve feature-parity, to be considered stable, etc. And Glow can run on this EVM side-chain and provide the simplicity, safety and portability in DApp development that were not available before.\n\n**What is the rollout process like and how can our community get involved if they want to?**\n\nGlow is still in development. There are some things that it can do already and some it can’t do yet. We invite DApp developers to join the Glow community and use the language for what it can already do, and otherwise help us build the blockchain development environment of the future. You can build the missing features you need yourself, or contract MuKn to build them for you. Even if you can’t code and have no budget, you can help write the documentation, or even just tell us where it isn’t clear yet, or what features you need most so we know what to prioritize. Together, we can build great DApps that you just couldn’t have achieved safely and within budget with previous tools.\n\n*If you’re a developer, we encourage you to get involved with [Mutual Knowledge Systems and Glow](https://mukn.io/). See our full conversation with François-René Rideau and a demonstration of Glow during [Cardano360.](https://youtu.be/YXaK0cvgoFQ?t=4367)*\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Bringing Glow to Cardano',
                                subtitle: ' We just spun up a devnet to support Glow, the very latest language Cardano will support. We talked to its creator about building a DSL for DApp development.',
                                audio: null,
                                soundcloud: [],
                                body_content: '<!--StartFragment-->\n\n*At the end of 2020, we announced our devnets plan to support the longer-term strategic goal of opening up Cardano to multiple development languages – as outlined in the ‘‘[Island, Ocean, Pond](https://youtu.be/k8a6tX53YPs)’ video. This week, building on the [Ethereum Virtual Machine](https://developers.cardano.org/en/virtual-machines/welcome/), we’re rolling out a new [development environment](https://developers.cardano.org/en/programming-languages/glow/overview/) to support the Glow language.*\n\n*François-René Rideau of Mutual Knowledge Systems is the creator of Glow, a DSL that will allow anyone to write verifiable DApps from a single spec and deploy it on our EVM network. We caught up with Rideau (also known as Fare) to hear more about his vision for Glow and the Cardano journey so far. The following is a distillation of his thoughts from our previous interviews.*\n\n\n\n**We first introduced the community to GLOW and MuKn at the end of [last year](https://youtu.be/lj9SlvOIBgU?t=2902) when we announced our devnets approach –  but maybe you can remind us how you began working with IOHK?**\n\nI started as a researcher in formal methods for programming languages and distributed systems. But I wanted to build systems actually used by many, so I moved into the industry where I notably worked on proving the correctness of a centralized payment protocol and creating an airline reservation system. After a few years at Google and Bridgewater, I decided life wasn’t worth working under dysfunctional hierarchies, so I started my own cryptocurrency companies. Charles invited me to speak at the IOHK Summit 2019, and I realized how much I like the Cardano community: we have a similar focus on building robust software for the long term. That is why I wanted to port my domain specific language Glow to Cardano.\n\n\n\n**Tell us a bit why you started your company Mutual Knowledge Systems, or as you call it MuKn (Moon)?**\n\nOver three years ago, I was reviewing whitepapers. Most papers (about ¾) had interesting techniques but made no economic sense. Most of the rest (about ⅕) made economic sense but had no technical content. Only the top few (about 5%) actually made sense both technically and economically. At some point, I realized I could do better, so I designed a scaling solution using lessons learned from working on Tezos. Arthur Breitman challenged me to use smart contracts instead of trying to modify his protocol. \n\nWhile trying to prove his challenge absurd, I instead found that he was right and I was wrong—and I finally understood why and how to use smart contracts. I started a company around the resulting scaling solution, raised money, pivoted into building the scaling solution after the language capable of generating it from specification, fought with and fired my then-partner, became my own CEO, started a new company, and, after much struggle, finally found the right founding team. Together, we built Mutual Knowledge Systems around this new programming language, Glow—designed to be much better than existing languages to write decentralized applications.\n\n\n\n**When you say ‘better’, what do you really mean?**\n\nWriting a DApp is the single hardest thing to do in the world. This is because you can’t afford a mistake, or your users may lose significant funds. Furthermore, you are not confronting random situations, but active adversaries bent on attacking your code, who will contrive the very worst case scenarios to exploit for their profit. Yet, unlike the military, you can’t hide your code or protect access to your networks: all the critical pieces are necessarily public. On top of that, extant programming tools are not designed for these constraints and even traditional formal methods lack essential concepts to express the issues at stake.\n\nThus, we decided to make new tools fit for the challenge. Our domain-specific language (DSL) drastically simplifies DApp development, by abstracting away all the common blockchain infrastructure, so you can focus on your problem domain (trading, derivatives, insurance, supply chain, etc.). Your DApps can be thousands of lines of code that your users can afford to audit, instead of millions of lines of code that require leaps of blind faith. And the programming model will enable developers, auditors and automated verification tools to reason at the level of abstraction of participants exchanging assets, rather than at that of packets of bytes shipped around the Internet.\n\n\n\n**What is it about Cardano and its community that appeals?**\n\nI started like everyone else, on Ethereum, because its ecosystem is already mature. However, the Ethereum community has this attitude of building as fast as possible experiments that are good enough for now, but lack conceptual integrity and won’t last; I see a lot of value in that approach and have tremendous respect for those who can thrive this way—for I cannot. When I met the Cardano community, I felt much more at home because we share a common attitude. We want to do things that are correct by construction and will keep working in the long term. We build concrete towers on the bedrock, not stick shacks on the sand. At times, this can be frustrating because things go slow, but I am happy with the attention to detail and quality in the development of Cardano. Is it perfect? No, it’s not. But it’s got great fundamentals.\n\n\n\n**Can you talk about how you hope Glow will change the DApp developer experience?**\n\nGlow is portable. Today it works on Cardano and Ethereum but in the future it will work with any blockchain that is sufficiently advanced to support smart contracts. That means that you can write your DApp once and it will run on whichever platform has the users and the liquidity you seek. You don’t have to make a guess about where liquidity will be in the future then sink heavy investments to develop on a single chain that you bet your house on.\n\n\n\nWith Glow, developers can run their DApps on all blockchains. Glow will commoditize blockchains. Blockchains will then compete on technical and economic merits, not on user lock-in and inertia. And the value brought to users will increase.\n\n\n\n**What can the community expect from Glow?**\n\nWe have launched this early version of Glow on the Cardano EVM Devnet with a command-line interface. In many ways, it is not yet ready for use by end-users, but it can already demonstrate simple applications. Users can also see how they may write a 6 line application in Glow that would require hundreds of lines in a combination of Solidity and JavaScript. We have a roadmap over the next few months to add a lot of features: from ERC20 tokens (and, on Cardano, native tokens), to generalized state channels, to a web interface, to a more robust runtime, etc. Eventually, we want to become the development environment for all blockchain projects. And Glow is of course an open source software open to the community.\n\n**We’re rolling out the integration with Glow with our EVM and devnet program, so what are some of the benefits of this?**\n\nThe Cardano EVM side-chain will enable arbitrary contracts to run on Cardano that use the mature EVM platform, without waiting for Plutus to deliver its promise, to achieve feature-parity, to be considered stable, etc. And Glow can run on this EVM side-chain and provide the simplicity, safety and portability in DApp development that were not available before.\n\n**What is the rollout process like and how can our community get involved if they want to?**\n\nGlow is still in development. There are some things that it can do already and some it can’t do yet. We invite DApp developers to join the Glow community and use the language for what it can already do, and otherwise help us build the blockchain development environment of the future. You can build the missing features you need yourself, or contract MuKn to build them for you. Even if you can’t code and have no budget, you can help write the documentation, or even just tell us where it isn’t clear yet, or what features you need most so we know what to prioritize. Together, we can build great DApps that you just couldn’t have achieved safely and within budget with previous tools.\n\n*If you’re a developer, we encourage you to get involved with [Mutual Knowledge Systems and Glow](https://mukn.io/). See our full conversation with François-René Rideau and a demonstration of Glow during [Cardano360.](https://youtu.be/YXaK0cvgoFQ?t=4367)*\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'bringing-glow-to-cardano',
                                url: '/blog/posts/2021/02/26/bringing-glow-to-cardano/',
                                read_time: 7
                            },
                            {
                                publish_date: '2021-02-05T00:00:00.000Z',
                                author: null,
                                video_id: 'oVCGvSNBPlI',
                                main_image: '',
                                custom_meta_img: 'https://ucarecdn.com/322fc64b-f115-42e1-bcc2-e6edc76841cb/',
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Decentralizing social media: a conversation with Ben Goertzel and Charles Hoskinson',
                                        subtitle: 'The minds behind SingularityNET and Cardano come together to explore a vision of the future of decentralization, AI, and social media.',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: '<!--StartFragment-->\n\n*At the end of 2020, we announced our collaboration with SingularityNET, in an exclusive [fireside chat](https://www.youtube.com/watch?v=W3O5F_CCT8c) between Charles Hoskinson and SingularityNET founder & CEO, Ben Goertzel.* \n\n*SingularityNET recently shared further information on the partnership when they announced their exciting [Phase Two initiative](https://blog.singularitynet.io/singularitynet-phase-two-massive-token-utilization-toward-decentralized-beneficial-agi-6e3ac5a5b44a),* [](https://blog.singularitynet.io/singularitynet-phase-two-massive-token-utilization-toward-decentralized-beneficial-agi-6e3ac5a5b44a) *which includes a shift from Ethereum to Cardano, to achieve new network functionalities and launching a Stream of New AGI-ADA Tokens.*\n\n*Last week, Charles and Ben sat down again together in a special [SingularityNET podcast](https://www.youtube.com/watch?v=TNWJGGc7ESI). In a wide-ranging discussion, the pair explore decentralized social media, the Cardano collaboration, and how a benevolent general AI technology might help a healthier social discourse.*\n\n*Here, in this exclusive long read, we have transcribed the whole conversation for you to enjoy and savour.*\n\n*<!--EndFragment-->*\n\n**Ben Goertzel:** Alright. Pleasure to be chatting once more Charles. And I thought it\'ll be amazing to have an on air discussion on the topic that\'s been in so many people\'s minds recently, which is the perhaps of critical importance of decentralization for social media and social networks, because this is something we both been thinking about deeply for quite a long time and have been both moving toward action on for quite a long time in our own ways, maybe the AI spin and you with Cardano and blockchain. But now things seem to be coming to a head and the world seems to suddenly be concerned that a few large corporations are programming everyone\'s brains in bizarre ways. So, yeah, maybe it is cool to start out just by hearing your overview of the topic.\n\n**Charles Hoskinson:** Yeah, it\'s an interesting situation. So I\'m kind of conflicted. So, I\'m a big libertarian and the libertarian guys say, "Hey, let the market decide. So when someone gets de-platformed, we say, "Hey, it\'s a private company. They can do whatever they want." But the issue is collusion and so the watershed moment for me wasn\'t the de-platforming of Trump. I said, yeah, okay the guy violated the end user license agreement probably 9 million times. At some point you have to throw the guy out. The issue was the de-platforming of Parler, because that was a very different animal.\n\nSo the whole argument was, well, if you don\'t like Twitter, go compete with it, build your own social network. That\'s exactly what Parler did. And they had different moderation standards. But then what occurred was that all of Silicon Valley got together and they colluded and they basically jointly decided to completely de-platform Parler. So Amazon took them down, Apple took them down, Google took them down. And if you\'re put in a market position where 100% of the mobile market and most of the web market is basically blacklisting you and you have no way to be on a cell phone for an average consumer, no way to have a website for an average consumer without going to extraordinary lengths and it\'s almost like the pirate bay. You have to host servers in Afghanistan or something to escape it. That\'s very problematic. It feels like a standard oil controlling the shipping prices of oil back in the 19th century.\n\n**BG:** The appeal to ethics seems so disingenuous, right? It\'s like you can search Qanon on garbage on Google just fine. So then why is it so unethical for there to be Qanon garbage on Parler as some of the content, right?\n\nThe idea that these big tech companies are acting out of a moral necessity to save everyone\'s lives. I mean, it rings very hollow, right? And I mean, there\'s no doubt some people in those companies really are thinking that way. But the alignment of these marginal ethical arguments with obvious corporate profit interests as being advanced by explicit collusion among these big players. It makes it hard to take the ethical aspect one hundred percent seriously.\n\n**CH:** It\'s almost become like an ethical tautology in a certain respect. They say \'Don\'t be evil, except for the times you have to be.\' It\'s a crazy, crazy statement where these companies say, well, we\'re trying to be moral. And I say, \'Okay, but no one elected you. And why are you guys in charge of the totality and curation flow of all information?\' I very firmly believe what needs to happen is we need to split the protocols that carry the information from the interfaces that curate that information. And that feels to be a much more natural thing. The problem we have right now is the stack is vertically completely controlled by a company.\n\nSo, Google doesn\'t just curate what you see in the search engine. They also control the underlying engine. And so as a consequence, they can make a decision on pretty much anything and exclude people laterally. And it\'s the same for the app stores. It\'s the same for social networks. The level of collusion is very problematic. I mean, you can\'t tell me that they didn\'t talk to each other if they all de-platformed someone the same day in the same hour. It\'d be one thing if it was a gradual process where maybe Google and two weeks later, Amazon, something like that. But if it\'s all exactly at the same time, then it means they picked up the phone and they called each other and say, well, we just decided that this is no good for you.\n\nThe problem is that decentralization doesn\'t solve the underlying problem that they\'re complaining about, which is radicalization. The issue is that the way information is being presented, it\'s manipulating our cognitive biases. We\'re creatures of cognitive biases. No matter how smart we are, we have availability bias, and selection bias and confirmation biases. There\'s hundreds of them and social scientists, psychologists and neuroscientists, they think about these things and quantify them. And if you digitize those biases and you build algorithms to exploit them, then what ends up happening is you create echo chambers. So you create these silos. Each and every one of those silos they are incapable of getting out of it. There\'s no idea flow between them. So all you do when you decentralize that, if you don\'t solve that underlying problem is you make the silos more resilient.\n\n**BG:** I mean there\'s a problem when you\'re applying AIs to learn to win in games or video games, which is both a problem and a benefit is that the AI will learn to do what you asked it to do. So if you\'re asking it to get maximum points in this game, and there\'s a way to do it by hacking around the rules of the game in some weird way no human would ever think of, the AI will explore various options. And if it\'s working well, will find some route to achieve the objective function without taking into account whatever implicit constraints you had about what\'s the artful way to do it.\n\nI think something similar exists with social media companies. They have certain metrics and objectives they\'re working toward. Often very, systemically internally, right? I mean, they want people to be looking at their site as long as possible, for example, or they want them to be spending as much as possible clicking on ads. And they\'ll put a lot of human and algorithmic effort into optimizing toward that goal. And then we can\'t be very surprised that these groups of brilliant people make cool software build systems that are optimizing toward that goal, like via whatever hacks they can find. And those hacks include exploiting human cognitive biases and exploiting dynamics of addiction in the human brain and all sorts of human, emotional patterns. Exploiting human angst and the desperation and existential confusion. I mean the algorithms and the corporate systems will exploit whatever they can to achieve the goals they\'re given.\n\nAnd as you say, it\'s organized so that these corporate organisms, which are now hybrid human and digital computing process organisms. These corporate organisms are almost like a parasite on modern society and they\'re achieving their own goal pretty effectively. If you took a bird\'s eye view of human society and where we want to be and where we want to go during the next few years, and maybe leading towards the singularity and creation of AGI and all that. A situation where these corporate human/computer networks orient toward maximizing shareholder value by getting you to buy stuff online and stare at their website as long as possible.\n\nI mean, these sorts of organizations having that much power is not the optimal dynamic for shaping the collective mind, heart and soul of humanity, right? I mean it\'s pretty far off from where we want to be. You\'d imagine that extremism and siloeing and tribalism, which we\'re seeing online and in real life, I think that\'s probably the only scratching the surface of the screwed up patterns that are being fostered. That\'s the surface layer where it\'s easy to see how screwed up it is. And there\'s so many other screwed up individual and collective dynamics that are happening. I wouldn\'t say all caused by this organization of social media in the tech industry, but certainly co-evolving with it and codependent on it.\n\n**CH:** Well, it\'s an interesting thing. So I tend to agree with Max Tegmark in this respect where you invent the car first and then you invent the safety belt. With new technology or new processes, there\'s a lack of wisdom in the safety components of it until after you\'ve suffered the consequences. So, we looked at the oil and gas industry in the 19th century, they started drilling all these wells and only after they started doing that, did we start thinking about environmentalism. And we said, well, maybe it\'s not such a good idea just to have unrestricted oil well drilling. Maybe we need to think carefully about what this is actually doing to the environment.\n\nWell, the oil of the 21st century is really the attention economy and the data economy. And we have all this surveillance capitalism and we have all these early pioneering firms and they\'re effectively mining that. And they\'re creating a social environmental damage by this process, to use an analogy where these algorithms are built and these platforms were built away to exacerbate human nature. So to your point that they didn\'t cause it, but I\'d certainly say that they\'re exacerbating it and-\n\n**BG:** I always think of everything in human society from the end game of legacy humanity. Like we\'re working on creating AGI. If we can create a benevolent AGI, I mean, this is going to make our current problems seem so archaic and silly. Of course, things won\'t be perfect. There will be new problems we can\'t imagine there. But this is certainly the biggest threshold event in the history of humanity, perhaps of life on earth. We could be a few decades from that even less. If there\'s even a decent odds that this singularitarian view is true, I mean then how the collective mind of humanity is shaped is insanely important, right?\n\nBecause the first AGI probably isn\'t going to be just a stupid human, stupid mind in a box, totally separate from human society. The way things are going it\'s more likely to come out of the interaction of multiple different AI components made by multiple parties, serving useful economic functions in the world at large. If the first AGI, which triggers this singularity is coming out of the whole mess of the tech ecosystem and people using the technology to do useful things, I mean then how messy that mess is, is an extremely important thing. And that right now, the direction does not look like the internet AI tech ecosystem is evolving in a great configuration for spotting a benevolent super AGI, 5, 10 to 20 years from now, right? Maybe some redirection if some of the sub-networks in there, like the ones we\'re involved with could affect it. Some redirection would be highly beneficial.\n\n**CH:** Well, the problem with AGI is that that\'s kind of like the Deus ex Machina situation where you\'re saying, well, we could solve this problem if we have this insanely powerful tool. And it\'s like, well, yeah, but maybe we don\'t actually need a tool that powerful to make meaningful progress towards this problem.\n\n**BG:** Decentralized social networks you don\'t need AGI. Absolutely not. You can do a lot with blockchain networks.\n\n**CH:** Hang on. So I think an AI solution does provide a lot of value, but I look at it more like a cognitive crutch. So if you injure your leg you get on crutches or you walk with a cane or something like that. I recently had a gout attack and for two weeks I was on a cane. So it\'s kind of funny. We physically think about this, but for the mental stuff, we don\'t really think we need it. We say, oh, our brains are perfectly well functions. Like no, we\'re dopamine addicts. We\'re constantly manipulated by digital devices and we\'re in a situation where we\'re not acting rationally or objectively most of the time.\n\n**BG:** With access to our hardware and software. We can\'t fix the bugs in the direct way.\n\n**CH:** So the question is, what would be the simplest possible agent, intelligent agent that could be constructed that could act as a cognitive crutch to alert us if we are being manipulated or our behavior is exhibiting patterns that have been propagandized. That feels like it would be a massive step forward.\n\n**BG:** Now we\'re getting it. Some of this stuff that I\'m hoping we will be able to build together with a SingularityNET on the Cardano network over the next few years. I mean, if you look at intelligent virtual assistants now like an Alexa or Google assistant, I mean, A: these things are very stupid in many senses, right? I mean, I have a Google Home Max. I used to play music in my house and the system still hasn\'t realized I never listen to music with vocals during the day. I mean, it doesn\'t have that metadata there. It hasn\'t recognized that very simple pattern, so repeatedly throw stuff at me. I won\'t listen to it. It\'s not even able to understand extremely simple repeated patterns in human behavior, which would help them make more money, even by showing me more stuff I want to listen to, right?\n\nSo these systems are optimized very narrowly to serve certain functions and their functions certainly are not to help us navigate the universe of the internet and media, in a way that\'s optimal for our own growth and self understanding, achieving our own goals and optimizing the collective intelligence of humanity. Very, far from it. So one could envision a personal assistant that had a bit more general intelligence. So it understood at least a little bit of what we actually want and are doing, but also was not controlled by a mega corporation with the primary goal of making them money, but was controlled by us who were being assisted by the personal assistant, right?\n\nI mean, I don\'t want the human personal assistant working for me, helping me do things whose main goal is to make some other corporation money, right? I want the human personal assistant working for me whose goal is to help me because I hired them to help me, right?\n\nAnd we should have digital assistants like that and they\'re going to be building machine learning models of everything we\'re doing like a human assistant builds their own biological model of what their employer is doing. And we should be better than the human assistant. We should be able to explicitly inspect what that model is and edit and correct it if we didn\'t like it and delete that model if we want to, right? So, I mean, we need among other things, we need intelligent virtual agents to help guide our navigation of the whole internet information sphere, which are secure and decentralized and explainable to us. The thing is we can do that without AGI. We can do that with technology we have right now, and this technology can help along the path toward AGI.\n\n**CH:** Where do we get the training data from? That was the one thing I was thinking about is how do I train an agent like that?\n\n**BG:** I mean it\'s going into smartphones that we use all day, right? So the training day that Google and Amazon and so forth are using, where does it come from? It comes from all of us. In principle, you can download most of what Google is basing its training data on you on, but very few of us are doing it. We\'re not using it, right? So, I mean, clearly you need all the data that you\'re using to interact with devices and with people all day. I mean you need that data to be in a secure data world that\'s owned and controlled by you where you\'re confident it\'s being managed and secure. Yeah, but we got to get a little deeper. I mean, it\'s not just interaction use. You\'d have to clearly show an example of confirmation bias to an extent that an ML model would be able to understand that. And so how do you do that in an unsupervised way?\n\n**BG:** We show it all the time, right? And I mean if the AI has a view of a lot of people, I mean, even those of us who are especially clever in some ways and our basic human social, emotional interactions, there\'s a lot that we do, which is the same.\n\nEmotional interactions. There\'s a lot that we do, which is the same as a lot of other people are doing, right? Like in how you interact with an employee versus a romantic partner or a friend or someone who\'s arguing with you. I think the sort of dialogue meta games and the inner dialogue meta games that people are playing, they\'re within the scope of current advanced neuro AI tech to recognize it\'s just, that\'s not what\'s being focused on. What\'s being focused on is recognizing subtle patterns and who\'s going to click on what ad. And I mean, you don\'t need to tell that to predict who\'s going to click on what ad in the most concise and effective way. I mean, you don\'t care. Right?\n\nIt\'s just a principle problem that the tech industry is not currently trying very hard to solve, but yeah, you\'re right. You focus on the AI part and I focus on the blockchain part. But in reality, I mean, you need them because I guess the other guy\'s part is harder because we understand how to solve our part. But I mean, you need both of them. I mean, you need the secure, scalable data ecosystem, respecting data sovereignty and you need that to fuel intelligent virtual assistants that really serve the person that they\'re assisting is the prime directive. Plus this massive scale data analytics that really understands what\'s going on with each of us in a way that lets it genuinely help us.\n\nBecause what is giving a person what they want? Does it mean gratifying their most intense short-term impulse at each moment? Or does it mean giving them what they want in a sort of balance along multiple timescales? Which is at multiple levels of our being, which is what we try to do with our family and our human friends. And AI\'s, they\'re laughably far from making an effort to give us what we want and in the more profound sense at the moment.\n\n**CH:** Right? Well, the reason why I was focusing on the AI part is the biggest part, the blockchain part, the incentives engineering relies very heavily upon the users and the agents inside the system. And so we say, "Okay, how do we incentivize people to supervise and curate data and agents in a way that we get more dialogue and we get a great moderation?" The ideal form would be, if you take clique\'s that are disjoint and you put them in the system, then idea flow starts occurring between them. And over time they\'ll converge into kind of a great moderated middle.\n\nSo you can take a very extremist person and either the system acts like it has an immune system and it kind of kicks them out or that node over time, moderates. The incentives in the system have to be designed that way. The reason we have so many problems in my view with Facebook and Twitter is that it actually has the opposite incentive. You get more clicks and more interaction with the more polarized people become. So the system is built in a way to polarize people as much as possible and thus divide them as much as possible. Because it\'s actually boosting revenue.\n\n**BG:** I think that\'s an easier problem to solve. Righteous indignation and the glorious feeling being approved by others in your ingroup and jointly indignant of the guys in the next group. This is a really easy emotion to manipulate with people. It\'s sort of a low hanging fruit. And to an extent these networks implicitly got stuck in manipulating this low-hanging fruit because it was the easiest way to keep people staring at their app. I mean, just as the internet settled on porn with love, it\'s been with. Because that\'s a really low algorithmic complexity way to keep people staring at something, is to show them naked bodies. So, if something would give greater benefit and even get people to start their site longer in the long run, but it isn\'t quite as simple of a problem, it sort of gets bypassed in the loop of trying to incrementally achieve these metrics more and more each month.\n\nAnd what\'s interesting is that the thought that rearranging sort of the configuration of the tech stack as you suggest in the beginning of the conversation, so like rearranging the tech stack so that the protocols are separate from the applications and then the AI models and tools used to create the AI models and inspect the AI models, they\'re also separate from the applications. I mean, reorganizing things in this way, then it sort of opens up the dynamics of the whole ecosystem in a way that I believe has decent odds of leading to the evolution of social media tools that they give people what they want in a more profound sense. And in doing so, they\'re creating communication networks among people that are not focused entirely on sort of immediate gratification of the ego and soaking of inter tribal rivalries and so forth.\n\nBecause all these good and beautiful things we\'re alluding to, exist on the internet right now. They exist on the internet right now. There\'s love, there\'s compassion, there\'s true connection between people with rival political views or from different historical tribes and so forth. It\'s not that we\'re not capable of that or that it isn\'t there. People are capable of amazing deep connections with other people and have incredible self-awareness and uplifting of their own consciousness. It\'s just, you need networks that foster this rather than trying to squash it and channel you into tribalism and immediate ego gratification. And of course neither you or I nor our teams are going to build all the systems that solve this problem. So you\'re going to create the ecosystem and tool set in which the solutions are going to emerge.\n\n**CH:** Right. Well, that\'s the point of incentives engineering is that it\'s the initial push. And because you don\'t have friction to slow you down, you tend to accelerate and eventually you get to a great place. I mean, Bitcoin obviously got their incentives engineering right. And they went from a single miner to warehouses of miners all around the world. And now this colossal system. We can argue about the power consumption, but that model was quite competitive to a point that it created a trillion dollar ecosystem. So I often think, "Well, what incentives do we need?" And we kind of have three sets of distinct things we need to accomplish at the same time if the network is going to be sustainable and useful to society.\n\nSo one thing is that you would like information to be curated, where it can clearly separate objective reality from the subjective analysis of it and give people a diverse set of viewpoints and understand that stuff is nuanced. So if they get that, then you kind of get rid of the fake news. You also get some consensus in the network of baseline facts. Because right now we live in a reality where people can\'t even agree to basic things. Some people think coronavirus is a hoax. Some people think vaccines are poisoned, et cetera, et cetera. So there\'s just disjoint realities that people are in. It used to be we would have one set of facts. We\'d agree on that. But then our interpretation of what those means-\n\n**BG:** It\'s true. A lot of people really believed Donald Trump had the most people at his inauguration ever, and the New Yorker doctored those images. And of course, sometimes the mainstream media may have distorted something about Trump, but the thing is, that\'s like an image, right? And people didn\'t believe the photograph, they believed the photograph was fake. And when you\'re at that point where people don\'t believe the photographs, then it\'s very hard. Then you have to be on the ground there, observing it in a sort of very clear state of mind to believe anything.\n\nSo, I mean, I\'m not even a realist or materialist fundamentally. I don\'t know if there is an objective reality. But what people are doing is they\'re not thinking in a clear and coordinated way about this belief they have or this thing they\'d been told. What evidence is that grounded in? What\'s the process of grounding the abstraction or the claim in the evidence? That process is broken. And it\'s partly because of AI and advanced informatics tools. Because you can make a deep fake. I mean, it\'s actually hard to tell if this video is Goertzel and Hoskinson or is this video a deep fake of Goertzel and Hoskinson put up by someone to troll all of us. It\'s not immediate seeing is believing to tell that you have to think.\n\n**CH:** Oh yeah. Like the Collider, George Lucas, deep fakes are extraordinary. And that\'s last generation technology. Where they\'re going in a few years is going to be socially very damaging because you\'ll have these perfect simulacrums of major figures and there\'ll be saying and doing terrible things. So that\'s the first part, the curation, go ahead?\n\n**BG:** You need the social network to tell bullshit from reality. So if the social network is broken, then you can\'t tell because you can\'t tell by looking, you can only tell by what you read and what others are saying, right?\n\n**CH:** Right. And I think that\'s why they\'re proactively de-platforming people and controlling flow of information because there\'s a political terror about the consequences of deep fakes and what they\'re going to do to dialogue.\n\n**BG:** Yeah, the point they\'re going to come to.\n\n**CH:** Yeah. Put a pin in that because there\'s two more points. So, as I mentioned, the first is just the curation of the information itself. And putting it in a way that it promotes instead of siloing idea flow, idea quality, separation of objective reality from subjective reality. And then when you\'re looking at the subjective to give you a spectrum of viewpoints, almost like a next-generation Nolan chart to show you different viewpoints.\n\nOkay, so then second there\'s clearly a data economy that exists. And surveillance capitalism is not just a nice term. It\'s a multi-billion perhaps trillion dollar economy. It\'s very valuable to society in certain respects. It allows you to micro target people. It allows you to have more friction-free commerce. You get the right products to the right people. So there\'s a huge advertising model and that shouldn\'t go away, but it should respect the privacy of the individual.\n\nSo there\'s been a lot of attempts to explore better ad models like with Brave and BATs, for example. I think whatever social network you create, you have to move in that particular direction where people are able to monetize their data and preserve their privacy, and actually get a share of the profit from the interactions that they have. And then the third design goal has to be the infrastructure itself is horrendously expensive to maintain. I mean, you\'re talking about petabytes of data. All these systems have N squared plus interactions. And so as your social network gets to a billion people, that quadratic complexity becomes very difficult to curate and manage. So the computational cost of that infrastructure, there\'s a reason why Google is so big and Amazon is so big and Facebook is so big.\n\nSo you somehow have to figure out how you subsidize a decentralized distributed system to curate and store all of that information. And you actually have to make data and users an economic actor, or they get pruned out if they don\'t contribute enough to the system. And we haven\'t quite figured out how to do that in a much simpler sense with just smart contracts and these big systems.\n\nI mean, you see things like IPFS and Gollum and other attempts to distribute network and data and storage. But if those protocols are imperfect, and when you talk about a social network, you talk about people posting videos, every day, 4k videos. You talk about people posting pictures every day, sometimes 100s of them, millions of meaningful interactions, even a small clique. If you take an extended family, that\'s going to be over a month\'s time, probably a million plus interactions of various things from likes and thumbs up. And then you\'re adding these intelligent agents that also have to do an enormous amount of processing on a regular basis. And those agents are only going to get more sophisticated and be interacted with a lot. So you have to have a lot of that be handled by the edges, the end user.\n\n**BG:** Yeah, yeah, yeah, absolutely. And that\'s hard. I mean, we\'ve been working on that with a project called NewNET, which is spun off of SingularityNET. And I think we understand a lot about the architecture that has to be there and about how this sort of split up machine learning algorithms for this sort of a hardware infrastructure. But there\'s a lot of work to be done there. There\'s a lot of avenues for inter-operation of NewNET, SingularityNET, and Cardano there. But I mean, it\'s hard. It\'s hard to do computer science and software engineering. And on the other hand, obviously Google and Amazon and Microsoft have solved a lot of really hard large-scale software engineering problems, different ones. But I mean, I think with a fraction of the effort that they put in, I think we can solve that problem.\n\n**CH:** Yeah, they\'re cheating because they always have a trusted third party. And so that massively simplifies your protocol. Their problem is easier. This is a harder problem. But on the other hand, computer science and hardware have both advanced a lot since they started doing what they\'re doing. But yeah, the incentive engineering aspect, incentive design aspect is quite critical and quite fascinating and exists for end users and also just within the developer community. Because I mean, what you see now is the significant majority of AI PGS, and we\'re going to work for these big tech companies. Or start a startup, which then gets acquired by one of these big tech companies. So the incentive structures of end users and of developers have sort of been channeled. They\'ve been channeled around these large tech companies, which is an amazing achievement. I would be proud if I created one of them. On the other hand, it\'s not optimal, but it\'s doing the course of society.\n\nAnd I mean, this is one thing that interests me, in our own collaboration over the next few years. I\'ve been working with my team in SingularityNET to architect a five-year tentative plan for how to roll out and grow SingularityNET on Cardano platform. I mean, part of this involves the AGI token, the new AGI on the ada token that we\'re working to launch as a new version of Singularity AGI token. Because we need the AGI token to be the right sort of incentive mechanism, largely on the backend. For AI algorithm developers and for AI application developers who are building these applications backending on the AI, you need the incentivization there to work right in order to create the systems that will be creating the right incentive structures for end users.\n\n**BG:** And I think things like the Catalyst Program within Cardano or a very interesting step there. I mean, where in Catalyst community members democratically vote with some liquid democracy mechanisms that they vote on, which Cardano projects should get some tokens. And I\'ve been watching and participating now, and then on the Catalyst discussions. And I want to do something that\'s a lot like that with some added dimensions, for SingularityNET on Cardano for fostering the community and expanding the community to build AI applications on our shared decentralized network. Because you need the right incentive structures on all these different levels and they need to coordinate together, which is hard. But I mean, there I think Tokenomics sort of gives you an advantage over what the big tech has because it\'s more scriptable and it\'s more flexible than the money and stock options and the incentive mechanisms they have.\n\n**CH:** Well, what\'s so cool about Catalyst is there\'s at the end of this year, going to be at least probably a $100 million worth of value that\'s available to the community. And the partnership with IdeaScale is just the beginning. We keep adding more and more firms to assist us with figuring out how to build a productive voting community, because it\'s not just the raw participation. So we say, "Hey, I think about two, 3% of ada holders are right now in idea scale, Because it\'s still kind of in a beta form. Our goal is to get that to 50% before the end of the year." But then we were trying to identify what meaningful participation means?\n\nBecause I would argue the American election system is not meaningful at all. You just show up and vote, but whether you spent hours thinking carefully about it, or you just voted randomly, it doesn\'t really matter. And the system doesn\'t differentiate that. So you end up with very poor outcomes and rational ignorance and a race to the bottom, effectively. So, meaningful participation is something we\'re definitely very interested in. And our hypothesis is that\'s going to lead to significantly better funding outcomes. So our return on intention is quite good for the system. \n\nIt gives you this M & M thing. It feels so empty without M & M, maintenance and moonshots. So maintenance means that you can maintain the system as it is and iterate and refine and evolve, and moonshots means that you have enough money to go pursue a high risk, high return research. And most great societies do this through some vehicle. It can be the Horizons program, the European Union, or it can be DARPA in the United States where they say, "All right, we\'re going to throw a bunch of money at some crazy stuff." And the odds are, it\'s probably not all going to work out. In fact, we seldom get exactly what we want, but then every now and then, we get fiber optic cables and satellites and the internet, and we get self-driving cars, and we get CALO and these other cool things.\n\nThe value to any DApp that comes over to Cardano is that you get to reuse the catalyst stack at some point, and then you can start entertaining, "Well, what does a treasury system look like within our ecosystem?" So, let\'s look three, five years out into the future, and let\'s say SingularityNET\'s gotten a lot of adoption. There\'s tons of transaction volume. You could put a slight tax on each transaction that can go into a treasury system for all the AGI holders. And then suddenly, you now have a mini catalyst just for AGI, and you can follow your own M & M strategy. So one part can say, "Hey, we just want to add more agents and more capabilities," and the other part can say, "Let\'s go tackle a super hard problem in the AI space." And it\'s really risky to go chase that problem. It may be the Holy Grail AGI, or it could be a subset of that or a compositional subset where you can decompose that problem to a collection of subproblems, and you\'re solving one of them. And if you fail, it\'s okay. And if you succeed, that solution lives in the open domain, and it\'s not controlled by a company. It\'s controlled by a protocol, so it\'s ubiquitously accessible.\n\n**BG:** So with what we\'re planning out now with a certain amount of AGI ADA tokens, I think we can do something catalyst based that can help get AI developers on the SingularityNET on Cardano platform and can help build toward both applied narrow AI in domains from social media to medicine, to DeFi as well as other components toward AGI. But there\'s also much bigger things. Like if you think about it, we\'re competing with these trillion-dollar companies, right, so I mean, eventually, we need custom hardware for decentralized AGI. If there is enough usage, as you say, a modest fee on usage can, can drive catalyst-based funding of research. And I mean, you could fund the design and prototyping of decentralized AGI chips, right?\n\nI mean, ultimately, we need to be seeding these exponential economic growth processes to the point where there\'s more wealth in the decentralized AI ecosystem than there is in the centralized AI ecosystem, which sounds very fanciful now. But I mean, I\'m a lot older than you. I\'m old enough to remember the computer \n\ncompanies were like Honeywell right? No one believed that PC companies were going to supply them, let alone internet companies like online ad agencies. Right? But this is how things go. And I mean, in the same way, the potential for network effects and exponential growth based on the right incentive mechanisms on multiple layers... The potential is there for a decentralized AI ecosystem to grow much bigger than the current trillion dollar companies. I mean, you just need to see the right growth processes in place. And I think, between our communities and codebases, we\'re able to see what those are right now, but of course, getting that seeding to work involves an endless number of difficult subproblems, both technological and human.\n\n**CH:** Right. Well, that\'s the value of trade. Bob makes the spear, and Alice makes the rope. So one of the things we\'re trying to focus on in Cardano is abstracting the toolsets and capabilities of the protocol so that each DApp that comes can reuse that, and they don\'t have to be a domain expert.\n\n**BG:** That\'s what got me to fall in love with Cardano in the first place. It\'s like, this is actually a reasonable software architecture, right? I mean, you\'re using functional programming. You\'re breaking things down into pieces. So if I want to take some AI algorithm and make it do homomorphic encryption or multi-party computing, so it runs in a secure and scalable way, I don\'t need to write all that code myself. There\'s actually tools within the blockchain infrastructure that are useful as code when you\'re on the AI level. I mean, Ethereum is super cool. Launching smart contracts into the world was a landmark thing, but I mean, the Ethereum codebase is not like that. There\'s nothing in there you\'re going to reference or use within your secure AI layer.\n\n**CH:** Well, the computation model is just wrong. It\'s got a global state, and so you can\'t grow beyond a certain amount.\n\n**BG:** It\'s supposed to be a world computer, but you cannot build a functional world computer that way.\n\n**CH:** No. You have to go from global to local. And then you just have so many problems in that model. In fact, we just had a lecture this morning with Manuel Chavravarty talking about the differences with the extended UTX cell model to the Ethereum style accounts model. And we\'ll publish that video probably next week, but it just becomes so obviously self-evident that while it\'s a great proof of concept, the system... First, it can\'t scale. And second, the use of other utilities comes at the same resources for everything. So whether you\'re using a voting system, or you\'re using a stablecoin or a DEX, it all comes from one pool of finite resources. So if one of those resources gets over consumed by a Crypto Kitties, it makes all the other resources in the system more expensive. And that\'s a bizarre and asinine model. If a catalyst, for example, runs as a side chain of Cardano\'s... So let\'s say we have tons of DApps bombarding that, using that for the voting systems for their DApp, that will have no impact at all on the main chain performance.\n\n**BG:** A hundred US dollars in gas for you to swap transactions.\n\n**CH:** I know.\n\n**BG:** And how can you obsolete Wall Street that way? I mean, it\'s going to be tough, right? But on the other hand, I think the foundational algorithms to get around those problems are there in Cardano. And then, in SingularityNET, we have foundational algorithms for distributing and decentralizing secure AI. So, I mean, I think ingredients are there for what needs to be done. On the downside, none of us has the war chest that Google and Amazon and Apple and Microsoft do, so we have to work around that by being cleverer than them and designing the right incentive mechanisms so that you get positive feedback effects and network effects, and things can really grow. And I think that this year is going to be pivotal actually, but we\'re going to... I mean, you\'ve got native assets coming out, and we\'ll be putting AGI token as a native asset, and then a few other SingularityNET spin offs as native assets.\n\nBut I mean, we\'re going to get to a flourishing native asset ecosystem in Cardano, and then SingularityDAO, which is a DeFi system we\'re building on SingularityNET, I mean, we can use to help coordinate getting liquidity into all these Cardano native assets. I\'m super psyched about that coming out publicly because not many people are thinking about what you can do when you have a real programming language as a smart contract framework, which security by design is built in. So, I mean, I think we\'re really providing stuff that is prepared to explode in an incredible way in 2021.\n\n**CH:** Yeah. So first about the treasury management, Tesla 2008 was a day away from bankruptcy, and now it\'s worth more than Toyota, Honda, Nissan, and Ford and GM combined. I mean, it\'s just crazy how fast they grew. So treasuries can grow exponentially if you get to a certain... It\'s almost like a standing ovation model where a few people stand up and clap, and then eventually you hit this point, and then everybody just gets up and claps. And it\'s the same thing, I think, with capital and companies. There\'s a few pivotal moments that you have where you\'re just right at this explosive growth, and then boom, the hockey stick happens, and then suddenly you have a lot there. And I think that\'s happening in the crypto industry. I remember when we hit a billion dollars with Bitcoin, and I was like, "Wow, this is incredible." We could never fathom a trillion dollars. It was a crazy concept, and that had happened within eight years of that point. It took nearly five years for it to get to a billion. So it\'s extraordinary how quickly things can grow.\n\nThen in terms of the collaboration, getting to that, Plutus is coming very soon, and we have this test net coming out. What we\'re doing is we\'re going to beat the hell out of it. So we\'d love for your guys to beat the hell out of it with the SingularityDAO.\n\n**BG:** Beat the hell out of it. That\'s right. Yeah.\n\n**CH:** We\'re a little easier because we have the Hard Fork Combinator, but your mistakes tend to sit around forever. Like we made a lot of protocol design mistakes with Byron, and we still have to support them. And so we found a really nice way of doing that. But when we released version one of Plutus and the extended UTXO model and native asset standard, that\'s probably not going to be perfect because nothing is. As an engineer, version one\'s there, but yet we have to be backwards compatible. So when you go to version two, you still have to support version one. So to me, it\'s super important that we get as many people as quickly as possible, beat the hell out of the native assets standard, beat the hell out of, especially Plutus, before we do the next hard fork to bring that in because I would rather not be backwards compatible with obviously wrong things as we are with Byron.\n\nSo it\'s great to have you guys around. I know that the code you\'re going to write is very novel, and it\'s also going to push the system to its limits. And you\'re going to create a very strong demand for performance and scale, I think. And I can already see several areas where we would like to use AI, for example, transaction fees. We have this fee parameter, and that\'s right now set with the update system, so the minimum transaction fee is a DDoS parameter. It\'d be so cool once we have Oracles and DEXs within the system, and we have some notion of the value of ada relative to the US dollar, to create an automated transaction monetary policy that can take those data points and compare them to other networks real-time, and then try to make sure that we always have a compatible-\n\n**BG:** This is actually a subtle point that we\'ve been discussing between SingularityNET platform team and Cardano platform team, right? Because I mean, the transaction framework for Cardano now, and that\'s planned for common native assets, it\'s fine from what we\'re doing with SingularityNet at this moment, but if we want to go to a swarm AI or microservices model, where you have a whole bunch of little AIs that within the second, one AI is consulting others to create others. I mean, if you really want to get AI by this dynamic microservices architecture, I want to have this using the blockchain rather than all off on the side. I mean, you need a way for some sub-networks to have substantially lower transaction fees, but then you need some system that\'s intelligent in some sense to regulate and moderate that because you still need to protect against DDoS attacks and then all sorts of other things, right. So there\'s a lot of areas like that where some machine learning, participating in the infrastructure can help a lot. And one of the things it can help with is to help make the system better able to manifest the emergence of higher levels of intelligence and learning, right, so you got a lot of positive cycles there.\n\n**CH:** Yeah, and you want it to be deterministic yet dynamic. And you would also like it to be globally aware of competition. So you\'d like the agents to be able to parse all the competing blockchains and look at their monetary policies, look at their transaction policies or transaction rates and their relative values to each other, and then be able to pull that into Cardano and form a transaction policy based on that.\n\n**BG:** It is there, right. I mean, the data is there online. You can download it into your AI, and I think that\'s quite feasible. So, yeah, going back to decentralized social networks, where we started, I mean, there\'s been, as you know, and you\'ve looked at this in more depth than me even... I mean, there\'s been loads and loads of attempts to make decentralized social networks. There\'s dozens of cool projects started by smart well-intentioned people with the right vision. Obviously, none of them has yet become the next Facebook or Twitter. I mean, some like Minds.com from Bill Ottman, I think, is really cool, but I log on there not yet as often, even as I log onto Facebook, which is not that often, right. I mean, Mines is great. It just doesn\'t have such a critical mass of people yet, although it\'s done a way, way better job than the vast majority of decentralized social networks, right?\n\nSo how do we get Minds and Everipedia and dozens of other decentralized social network platforms and the new ones that haven\'t been heard of yet... How do we get these to really take off? And I think we share the conclusion that a lot of what\'s needed there is to make the underlying stack more amenable to lower costs, larger-scale operations of the needed kinds, both in data storage and processing distribution, and then the distributed AI, also. It\'s interesting, Jack Dorsey from Twitter has seen this also, and they\'re looking at making a decentralized protocol and reorganizing the Twitter stack. The question there is, can you really make that work with incentive structures that are implicit in Twitter as the company that it is?\n\n**CH:** That\'s why I separate the base protocol from the interface, like what Steem did. They had the Steem protocol and then Steem at the interface, and their problem was that they didn\'t have a full end to end monetary policies, so they had value leakage. There was no incentive to buy the token, but they used the token to curate information. Had they solved that problem, it would be still around and much larger, but I think that Twitter can survive with a decentralized social network protocol because it would just be a very popular, curated interface to it, and they\'d still have their network effect. It\'s just the customers, and the data would be ephemeral. They could flow from one interface to another interface and get that same experience. The problem right now is you have to rebuild the network effect every time you launch a new one of these things. Every time we want to do an internet application, we have to completely rebuild the internet underneath it. It\'s a preposterous thing, right? Yeah.\n\n**BG:** It makes sense, and I think it\'s visionary of Jack Dorsey to even entertain the notion, right? I mean, not many corporations of that scale are willing to-\n\n**CH:** Well, it\'s a proactive solution to a big problem he has because if he plays censor and chief and he has to de-platform people from the protocol, then he can never win.\n\n**BG:** I wouldn\'t want that job either because, I mean, you got people that are clearly colluding to kill someone. Fine. You ban them. You have people who are saying stuff that\'s nasty but not yet criminal. And then I don\'t want them to be in the job of telling what\'s too nasty and what\'s okay. I mean, court systems aren\'t perfect at that, but I mean, they\'ve been honed for that over significant periods of time, and you don\'t want to have to do that at fast speed and large scale as part of operating your tech company. And I mean, none of these tech companies actually want that job, right. That\'s not why they got into the business, like how can I censor people\'s political speech? So, I mean, of course, if things can be reorganized so that that job is done by the community for the community, rather than having to be done by the CEO. I mean, that\'s far, far better. And the community won\'t do it perfectly, but actually, it will do a better job than these centralized authorities. And I mean, it\'s completely possible to do that. \n\nWe did a lot of simulations of Singularity \'s machine learning-moderated reputation system over the last couple of years. You can make decentralized, AI-guided rating and reputation systems and you can tune them and you can see if I tune it one way, you get information silos, if you tune it another way, you just get trolls and spammers and so forth. If you tune it in a different way, you get a system that self-policing and fosters a healthy level of interaction. And you can do this to get networks that self-regulate without anyone giving top level control. If this is operating within the current global political systems, which I have my issues with too, as I\'m sure you do, but it\'s there, then you still have top level control over things that are clear crimes, according to the nation states people\'s bodies are sitting in, but you don\'t need top level control for anything else.\n\nAnd I think that not just would avoid garbage like minds are proud of being de-platformed. It would also create something that\'s a breeding ground for positive and creative and beneficial content in which people\'s minds are being nudged toward positive growth, rather than channeled into this site and click on this ad. I think potential is there to do that. What\'s a little scary is that handful of us in the decentralized AI space, the two of us, probably understand more about how to achieve this than anyone else on the planet. It\'s actually a very big and significant problem, both in terms of setting the stage for a positive singularity and just making life less shitty for humanity on the planet at this moment.\n\n**CH:** The one thing I\'ve always learned from being a cryptocurrency guy is that incentives are king, and it\'s always been an incentives problem. How many people were, in 1990, being paid to think about social networks? You\'d probably be in the sociology department at Harvard or something that, or toying around in an MIT AI group or something. But it wasn\'t a real job and nobody would understand. How many people who are experts in how to build effective social networks are floating around now? There\'s thousands of them. They\'re fabulously wealthy. So if you show that in a free market system you can achieve great wealth, or at least the prospect of great wealth by building a system of a certain design, then you\'ll end up getting a lot of it.\n\nThe cryptocurrency space was exactly the same. How many people were experts in Bitcoin-like systems in 2010? Very few. Now in 2021, now the existing chairman of the Securities Exchange Commission, Gensler, he was lecturing at MIT on cryptocurrencies. That\'s how far we\'ve gone in just such a short period of time because the incentives are right. So when I look at this problem, I say, "Well, how do we get the incentives in the right way to encourage a large clique of people to come in and actually start applying serious hardcore brainpower to these types of problems?" So it\'s a first mover situation. Now, to the minds and these other guys, to that earlier point you brought up, I look at them almost like mechanical horses. When we were first thinking, how do we build a better horse? If we all let\'s build a robot horse, or a steam powered horse or something like that. Well now there\'s this automobile idea that we\'ve been toying around with. Maybe that\'s just a fundamentally more competitive or better model.\n\nOr similarly, when people are thinking about vacuum tubes, you can certainly optimize them, and I\'m sure you could build a much better vacuum tube today than they were building back in the 1940s. But obviously that was superseded by the transistor. So similarly, when you look at social networks, we have to say what is our automobile moment to replace the horse?" And minds is not it. I think that if those things existed, they\'d actually just be worse than Facebook or Twitter. They\'d get far more siloed. The three problems I outlined, the great moderation, the incentives models being aligned so that people can actually make money and produce money and do useful things with the system, and the infrastructure funding problem.\n\nYou have to solve all three of those with one protocol design and one incentives design. And if you do that, then it\'s going to be this massive beacon that will attract tons of people to come in and start working on an augmented system and evolve it. And it doesn\'t matter if it starts very small. It\'ll go very viral and eventually get to that Tesla-style hockey stick, when Tesla figured out the entire model. Plenty of battery-powered cars before, but their particular model was the one that everything came together and then it had exponential.\n\n**BG:** In terms of tokenomics systems, it\'s quite interesting. Because having a unified scheme and dynamic for promoting the right incentives doesn\'t mean just one token. So you\'re sculpting multiple tokens in a multi-token ecosystem where they interoperate. So say we have ada, we the AGI token on ada, and for, say, a decentralized social network running on ada, leveraging SingularityNET AI, potentially could involve a different token for a certain purpose within that network. You have to think through the inter interoperation of these different networks. And I think that this is one of the things I\'m most excited about in collaboration between the two of us and between SingularityNET and Cardano. I think you guys have done very well in thinking through incentive structures and how they boil down into tokenomic structures. I look forward to some cognitive synergy among us on that.\n\n**CH:** We learned how much we don\'t know. We started this program at Oxford with Elias, and he\'s an algorithmic game theorist. He won the Gödel Prize and all these things. He\'s a really good guy, and he\'s got some... Yeah, Oxford, he\'s got some really good graduate students too, so we said, "Okay, between him and his graduate students, we\'re done. Put a fork in it. We should easily be able to tackle all these consensus incentives problems in Ouroboros." It took two years to refine the entire incentive model just for a consensus algorithm, and now we\'re talking about incentives for the curation of information. So it\'s going to be fun to collaborate. I agree there. It\'s such a hard problem.\n\n**BG:** Curation of information that\'s being created by just decentralized AI algorithms, not just of existing information.\n\n**CH:** Yeah, because you need to create demand for a token and you need to be able to use that token because it\'s demanded and it\'s valuable to incentivize a certain collection of human behavior. You also need to be able to use that to incentivize people to interact with agents in a way that they could become trained to become good cognitive crutches to reinforce the network, and then that token also has to incentivize the hosting of decentralized infrastructure that eventually can scale to petabyte scale storage and huge network capacity and massive computational capacity. It\'s a tall order. It\'s a lot of incentive engineering, and that\'s why I don\'t think these networks exist yet.\n\n**BG:** They don\'t. As you say, once it\'s gotten to a certain level, the potential to gain both personal wealth and to help promote broad benefit to a huge degree, those are both there in a very clear way, which I think can cause a rush of talent into the space of decentralized AI and decentralized AI guided social networks. We\'re at a pivotal moment now, I think, in terms of both the readiness and even eagerness of the world for these technologies and the existence of the needed tools, or at least a significant fraction of the needed tools to create them. This conversation is occurring in a quite interesting time.\n\n**CH:** But the good news is that there\'s a lot of almost right attempts, like the creation of Bitcoin, we had HashCash and bit gold and DigiCash. They were wrong, but they were wrong in the right direction, so you just had to pull them along enough and then eventually it fell through. So you have things like BATs, and I mentioned that before, and suddenly now you\'ve created demand for a token. Steem had enormous growth, but the problem was there was no demand for the token, but there was good payment for content creation and curation. So they got a lot of users, but they had too much value leakage, so they couldn\'t sustain network value and then the system fell apart.\n\nI almost felt if you could combine BATs and Steem together, then you\'ve created a feedback loop where the system will sustain and it\'ll continue to grow at a very rapid rate. However, they had to use the token to subsidize the actual running of the infrastructure. They didn\'t have a sustainable model there. So even though it was the protocol Steem and Steemit was just the company, the Steemit company had all the power and control because they were the people that could afford to run that protocol.\n\n**BG:** We\'ve got a hive now, right? I mean, that\'s the beauty of open source code and decentralized communities.\n\n**CH:** It\'s a Pareto problem where a small group runs the vast majority of everything and there\'s no economic diversity there. With Cardano, we spent five years on Ouroboros because we wanted a system that would get naturally more decentralized over time. So as the price of ADA increases, the K factor increases, and then suddenly you go from 1,000 to 10,000 stake pools and then 100,000, and then all the infrastructure is federated with those stake pools, so suddenly you have 10,000 Hydra channels and suddenly you have 10,000 oracle entry points et cetera, et cetera. So the system, when we get to Bitcoin scale, could have 100,000 stake pool operators that run that, and that scales quite nicely.\n\n**BG:** I\'m sort of thinking into the growth of SingularityNET during the next phase. I think that the platform as we\'ve built it now does something good. If you create multiple AI agents all over the place that collaborate and cooperate to solve hard problems. But we need to architect the next stages of development in a way that will incentivize massive increase of utilization of the platform using AGI ADA, but also that will ensure that increasing decentralized control of the network happens along with this massive increasing utilization. I think we can do it, and I think a lot of the thinking you guys have put into growing Cardano was actually helpful there in ways that we probably don\'t have time to explore in this podcast.\n\n**CH:** Well you get the democracy stack for free with Catalyst, and you also get the decentralized infrastructure for free. One thing we\'d love to do is see if we can get outsourceable computation. I\'ve been following that for God knows how many years. Pinocchio and Geppetto over at MSR, can you do the computation on an untrusted computer, but then provide a proof that the computation was done correctly? And then you know that whatever the result was given is right, regardless of who did it.\n\n**BG:** That\'s there on the computer science level, but it\'s not yet there on the scalable, usable software level.\n\n**CH:** We have some proof that perhaps these algorithms work, but a lot of them are exponential time.\n\n**BG:** One of the things I\'ve been doing with my non-existent spare time is going through all the core cognitive algorithms of OpenCog, which is the AI architecture I\'m working on, expressing all the core algorithms of OpenCog in terms of Galois connections over metagraphs and the chrono morphisms and stuff. So you get the right elegant formalization of your core cognitive algorithms. And then once you\'ve done that, then you can deploy the kind of math you\'re saying so that this core AGI computation could be done by outsourced computing. So the math and CS is there for a lot of these different things, but there\'s a number of stages yet to go through before that kind of thing is rolled out scalably.\n\n**CH:** That\'s an interesting mathematical expression. Do you deal with a dependent type system?\n\n**BG:** It\'s an independent pair of consistent probabilistic type systems, so yeah.\n\n**CH:** That\'s a mouthful. But can you prove anything interesting? You can show certain things that are isomorphic to each other or what you are looking for with those.\n\n**BG:** We are working on that right now, actually. But this would probably lead us too deep down some usually interesting rabbit holes for a broad audience podcast.\n\n**CH:** Okay, fair enough. All right. Well, Ben, this has been so much fun. I have another meeting I got to jump into, but I really enjoyed our time.\n\n**BG:** Yeah, this is fantastic. It\'s both broad and deep, and I think decentralized social networks, it\'s both really important on its own, and I think we can work together to solve it, but it also highlights a bunch of other more general points, both about bringing Singularity and Cardano together and about just what we need blockchain and AI together to do. So yeah, very cool. Look forward to the next one.\n\n**CH:** I guess a closing point is platforms tend to get defined by the killer apps that are on the platforms, and I\'m very glad that one of the most meaningful and significant applications on our platform is SingularityNET. I would hate to see us be defined by Crypto Kitties or something like that. It\'s great to have you guys around. I think this collaboration is going to result in an enormous amount of evolution of our own platform and an acid testing of things in a way that\'s very productive for everybody. And my hope is you guys become one of the most successful pieces of infrastructure on top of a Cardano and it leads to a lot of user growth. And we\'re not just collaborating technologically. I think we\'re going to share some office space at some point in Ethiopia.\n\n**BG:** The space has been found, actually. So our Addis team and your Addis team will co-locate.\n\n**CH:** John was very excited about it, so I imagine the office is quite nice.\n\n**BG:** It\'s in Bole, which is a great neighborhood. It was a very pleasant and surprising coincidence that we actually both had flourishing teams in Addis Ababa contributing to the development of our various platforms. Very cool that maybe the next time we meet face to face will be over some injera in Addis.\n\n**CH:** That\'d be a lot of fun. That\'d be a lot of it just to have to get rid of the civil war and the COVID, but those are just minor technical details,  All right. Thank you so much, Ben.\n\n**BG:** Great. Thanks a lot.\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Decentralizing social media: a conversation with Ben Goertzel and Charles Hoskinson',
                                subtitle: 'The minds behind SingularityNET and Cardano come together to explore a vision of the future of decentralization, AI, and social media.',
                                audio: null,
                                soundcloud: null,
                                body_content: '<!--StartFragment-->\n\n*At the end of 2020, we announced our collaboration with SingularityNET, in an exclusive [fireside chat](https://www.youtube.com/watch?v=W3O5F_CCT8c) between Charles Hoskinson and SingularityNET founder & CEO, Ben Goertzel.* \n\n*SingularityNET recently shared further information on the partnership when they announced their exciting [Phase Two initiative](https://blog.singularitynet.io/singularitynet-phase-two-massive-token-utilization-toward-decentralized-beneficial-agi-6e3ac5a5b44a),* [](https://blog.singularitynet.io/singularitynet-phase-two-massive-token-utilization-toward-decentralized-beneficial-agi-6e3ac5a5b44a) *which includes a shift from Ethereum to Cardano, to achieve new network functionalities and launching a Stream of New AGI-ADA Tokens.*\n\n*Last week, Charles and Ben sat down again together in a special [SingularityNET podcast](https://www.youtube.com/watch?v=TNWJGGc7ESI). In a wide-ranging discussion, the pair explore decentralized social media, the Cardano collaboration, and how a benevolent general AI technology might help a healthier social discourse.*\n\n*Here, in this exclusive long read, we have transcribed the whole conversation for you to enjoy and savour.*\n\n*<!--EndFragment-->*\n\n**Ben Goertzel:** Alright. Pleasure to be chatting once more Charles. And I thought it\'ll be amazing to have an on air discussion on the topic that\'s been in so many people\'s minds recently, which is the perhaps of critical importance of decentralization for social media and social networks, because this is something we both been thinking about deeply for quite a long time and have been both moving toward action on for quite a long time in our own ways, maybe the AI spin and you with Cardano and blockchain. But now things seem to be coming to a head and the world seems to suddenly be concerned that a few large corporations are programming everyone\'s brains in bizarre ways. So, yeah, maybe it is cool to start out just by hearing your overview of the topic.\n\n**Charles Hoskinson:** Yeah, it\'s an interesting situation. So I\'m kind of conflicted. So, I\'m a big libertarian and the libertarian guys say, "Hey, let the market decide. So when someone gets de-platformed, we say, "Hey, it\'s a private company. They can do whatever they want." But the issue is collusion and so the watershed moment for me wasn\'t the de-platforming of Trump. I said, yeah, okay the guy violated the end user license agreement probably 9 million times. At some point you have to throw the guy out. The issue was the de-platforming of Parler, because that was a very different animal.\n\nSo the whole argument was, well, if you don\'t like Twitter, go compete with it, build your own social network. That\'s exactly what Parler did. And they had different moderation standards. But then what occurred was that all of Silicon Valley got together and they colluded and they basically jointly decided to completely de-platform Parler. So Amazon took them down, Apple took them down, Google took them down. And if you\'re put in a market position where 100% of the mobile market and most of the web market is basically blacklisting you and you have no way to be on a cell phone for an average consumer, no way to have a website for an average consumer without going to extraordinary lengths and it\'s almost like the pirate bay. You have to host servers in Afghanistan or something to escape it. That\'s very problematic. It feels like a standard oil controlling the shipping prices of oil back in the 19th century.\n\n**BG:** The appeal to ethics seems so disingenuous, right? It\'s like you can search Qanon on garbage on Google just fine. So then why is it so unethical for there to be Qanon garbage on Parler as some of the content, right?\n\nThe idea that these big tech companies are acting out of a moral necessity to save everyone\'s lives. I mean, it rings very hollow, right? And I mean, there\'s no doubt some people in those companies really are thinking that way. But the alignment of these marginal ethical arguments with obvious corporate profit interests as being advanced by explicit collusion among these big players. It makes it hard to take the ethical aspect one hundred percent seriously.\n\n**CH:** It\'s almost become like an ethical tautology in a certain respect. They say \'Don\'t be evil, except for the times you have to be.\' It\'s a crazy, crazy statement where these companies say, well, we\'re trying to be moral. And I say, \'Okay, but no one elected you. And why are you guys in charge of the totality and curation flow of all information?\' I very firmly believe what needs to happen is we need to split the protocols that carry the information from the interfaces that curate that information. And that feels to be a much more natural thing. The problem we have right now is the stack is vertically completely controlled by a company.\n\nSo, Google doesn\'t just curate what you see in the search engine. They also control the underlying engine. And so as a consequence, they can make a decision on pretty much anything and exclude people laterally. And it\'s the same for the app stores. It\'s the same for social networks. The level of collusion is very problematic. I mean, you can\'t tell me that they didn\'t talk to each other if they all de-platformed someone the same day in the same hour. It\'d be one thing if it was a gradual process where maybe Google and two weeks later, Amazon, something like that. But if it\'s all exactly at the same time, then it means they picked up the phone and they called each other and say, well, we just decided that this is no good for you.\n\nThe problem is that decentralization doesn\'t solve the underlying problem that they\'re complaining about, which is radicalization. The issue is that the way information is being presented, it\'s manipulating our cognitive biases. We\'re creatures of cognitive biases. No matter how smart we are, we have availability bias, and selection bias and confirmation biases. There\'s hundreds of them and social scientists, psychologists and neuroscientists, they think about these things and quantify them. And if you digitize those biases and you build algorithms to exploit them, then what ends up happening is you create echo chambers. So you create these silos. Each and every one of those silos they are incapable of getting out of it. There\'s no idea flow between them. So all you do when you decentralize that, if you don\'t solve that underlying problem is you make the silos more resilient.\n\n**BG:** I mean there\'s a problem when you\'re applying AIs to learn to win in games or video games, which is both a problem and a benefit is that the AI will learn to do what you asked it to do. So if you\'re asking it to get maximum points in this game, and there\'s a way to do it by hacking around the rules of the game in some weird way no human would ever think of, the AI will explore various options. And if it\'s working well, will find some route to achieve the objective function without taking into account whatever implicit constraints you had about what\'s the artful way to do it.\n\nI think something similar exists with social media companies. They have certain metrics and objectives they\'re working toward. Often very, systemically internally, right? I mean, they want people to be looking at their site as long as possible, for example, or they want them to be spending as much as possible clicking on ads. And they\'ll put a lot of human and algorithmic effort into optimizing toward that goal. And then we can\'t be very surprised that these groups of brilliant people make cool software build systems that are optimizing toward that goal, like via whatever hacks they can find. And those hacks include exploiting human cognitive biases and exploiting dynamics of addiction in the human brain and all sorts of human, emotional patterns. Exploiting human angst and the desperation and existential confusion. I mean the algorithms and the corporate systems will exploit whatever they can to achieve the goals they\'re given.\n\nAnd as you say, it\'s organized so that these corporate organisms, which are now hybrid human and digital computing process organisms. These corporate organisms are almost like a parasite on modern society and they\'re achieving their own goal pretty effectively. If you took a bird\'s eye view of human society and where we want to be and where we want to go during the next few years, and maybe leading towards the singularity and creation of AGI and all that. A situation where these corporate human/computer networks orient toward maximizing shareholder value by getting you to buy stuff online and stare at their website as long as possible.\n\nI mean, these sorts of organizations having that much power is not the optimal dynamic for shaping the collective mind, heart and soul of humanity, right? I mean it\'s pretty far off from where we want to be. You\'d imagine that extremism and siloeing and tribalism, which we\'re seeing online and in real life, I think that\'s probably the only scratching the surface of the screwed up patterns that are being fostered. That\'s the surface layer where it\'s easy to see how screwed up it is. And there\'s so many other screwed up individual and collective dynamics that are happening. I wouldn\'t say all caused by this organization of social media in the tech industry, but certainly co-evolving with it and codependent on it.\n\n**CH:** Well, it\'s an interesting thing. So I tend to agree with Max Tegmark in this respect where you invent the car first and then you invent the safety belt. With new technology or new processes, there\'s a lack of wisdom in the safety components of it until after you\'ve suffered the consequences. So, we looked at the oil and gas industry in the 19th century, they started drilling all these wells and only after they started doing that, did we start thinking about environmentalism. And we said, well, maybe it\'s not such a good idea just to have unrestricted oil well drilling. Maybe we need to think carefully about what this is actually doing to the environment.\n\nWell, the oil of the 21st century is really the attention economy and the data economy. And we have all this surveillance capitalism and we have all these early pioneering firms and they\'re effectively mining that. And they\'re creating a social environmental damage by this process, to use an analogy where these algorithms are built and these platforms were built away to exacerbate human nature. So to your point that they didn\'t cause it, but I\'d certainly say that they\'re exacerbating it and-\n\n**BG:** I always think of everything in human society from the end game of legacy humanity. Like we\'re working on creating AGI. If we can create a benevolent AGI, I mean, this is going to make our current problems seem so archaic and silly. Of course, things won\'t be perfect. There will be new problems we can\'t imagine there. But this is certainly the biggest threshold event in the history of humanity, perhaps of life on earth. We could be a few decades from that even less. If there\'s even a decent odds that this singularitarian view is true, I mean then how the collective mind of humanity is shaped is insanely important, right?\n\nBecause the first AGI probably isn\'t going to be just a stupid human, stupid mind in a box, totally separate from human society. The way things are going it\'s more likely to come out of the interaction of multiple different AI components made by multiple parties, serving useful economic functions in the world at large. If the first AGI, which triggers this singularity is coming out of the whole mess of the tech ecosystem and people using the technology to do useful things, I mean then how messy that mess is, is an extremely important thing. And that right now, the direction does not look like the internet AI tech ecosystem is evolving in a great configuration for spotting a benevolent super AGI, 5, 10 to 20 years from now, right? Maybe some redirection if some of the sub-networks in there, like the ones we\'re involved with could affect it. Some redirection would be highly beneficial.\n\n**CH:** Well, the problem with AGI is that that\'s kind of like the Deus ex Machina situation where you\'re saying, well, we could solve this problem if we have this insanely powerful tool. And it\'s like, well, yeah, but maybe we don\'t actually need a tool that powerful to make meaningful progress towards this problem.\n\n**BG:** Decentralized social networks you don\'t need AGI. Absolutely not. You can do a lot with blockchain networks.\n\n**CH:** Hang on. So I think an AI solution does provide a lot of value, but I look at it more like a cognitive crutch. So if you injure your leg you get on crutches or you walk with a cane or something like that. I recently had a gout attack and for two weeks I was on a cane. So it\'s kind of funny. We physically think about this, but for the mental stuff, we don\'t really think we need it. We say, oh, our brains are perfectly well functions. Like no, we\'re dopamine addicts. We\'re constantly manipulated by digital devices and we\'re in a situation where we\'re not acting rationally or objectively most of the time.\n\n**BG:** With access to our hardware and software. We can\'t fix the bugs in the direct way.\n\n**CH:** So the question is, what would be the simplest possible agent, intelligent agent that could be constructed that could act as a cognitive crutch to alert us if we are being manipulated or our behavior is exhibiting patterns that have been propagandized. That feels like it would be a massive step forward.\n\n**BG:** Now we\'re getting it. Some of this stuff that I\'m hoping we will be able to build together with a SingularityNET on the Cardano network over the next few years. I mean, if you look at intelligent virtual assistants now like an Alexa or Google assistant, I mean, A: these things are very stupid in many senses, right? I mean, I have a Google Home Max. I used to play music in my house and the system still hasn\'t realized I never listen to music with vocals during the day. I mean, it doesn\'t have that metadata there. It hasn\'t recognized that very simple pattern, so repeatedly throw stuff at me. I won\'t listen to it. It\'s not even able to understand extremely simple repeated patterns in human behavior, which would help them make more money, even by showing me more stuff I want to listen to, right?\n\nSo these systems are optimized very narrowly to serve certain functions and their functions certainly are not to help us navigate the universe of the internet and media, in a way that\'s optimal for our own growth and self understanding, achieving our own goals and optimizing the collective intelligence of humanity. Very, far from it. So one could envision a personal assistant that had a bit more general intelligence. So it understood at least a little bit of what we actually want and are doing, but also was not controlled by a mega corporation with the primary goal of making them money, but was controlled by us who were being assisted by the personal assistant, right?\n\nI mean, I don\'t want the human personal assistant working for me, helping me do things whose main goal is to make some other corporation money, right? I want the human personal assistant working for me whose goal is to help me because I hired them to help me, right?\n\nAnd we should have digital assistants like that and they\'re going to be building machine learning models of everything we\'re doing like a human assistant builds their own biological model of what their employer is doing. And we should be better than the human assistant. We should be able to explicitly inspect what that model is and edit and correct it if we didn\'t like it and delete that model if we want to, right? So, I mean, we need among other things, we need intelligent virtual agents to help guide our navigation of the whole internet information sphere, which are secure and decentralized and explainable to us. The thing is we can do that without AGI. We can do that with technology we have right now, and this technology can help along the path toward AGI.\n\n**CH:** Where do we get the training data from? That was the one thing I was thinking about is how do I train an agent like that?\n\n**BG:** I mean it\'s going into smartphones that we use all day, right? So the training day that Google and Amazon and so forth are using, where does it come from? It comes from all of us. In principle, you can download most of what Google is basing its training data on you on, but very few of us are doing it. We\'re not using it, right? So, I mean, clearly you need all the data that you\'re using to interact with devices and with people all day. I mean you need that data to be in a secure data world that\'s owned and controlled by you where you\'re confident it\'s being managed and secure. Yeah, but we got to get a little deeper. I mean, it\'s not just interaction use. You\'d have to clearly show an example of confirmation bias to an extent that an ML model would be able to understand that. And so how do you do that in an unsupervised way?\n\n**BG:** We show it all the time, right? And I mean if the AI has a view of a lot of people, I mean, even those of us who are especially clever in some ways and our basic human social, emotional interactions, there\'s a lot that we do, which is the same.\n\nEmotional interactions. There\'s a lot that we do, which is the same as a lot of other people are doing, right? Like in how you interact with an employee versus a romantic partner or a friend or someone who\'s arguing with you. I think the sort of dialogue meta games and the inner dialogue meta games that people are playing, they\'re within the scope of current advanced neuro AI tech to recognize it\'s just, that\'s not what\'s being focused on. What\'s being focused on is recognizing subtle patterns and who\'s going to click on what ad. And I mean, you don\'t need to tell that to predict who\'s going to click on what ad in the most concise and effective way. I mean, you don\'t care. Right?\n\nIt\'s just a principle problem that the tech industry is not currently trying very hard to solve, but yeah, you\'re right. You focus on the AI part and I focus on the blockchain part. But in reality, I mean, you need them because I guess the other guy\'s part is harder because we understand how to solve our part. But I mean, you need both of them. I mean, you need the secure, scalable data ecosystem, respecting data sovereignty and you need that to fuel intelligent virtual assistants that really serve the person that they\'re assisting is the prime directive. Plus this massive scale data analytics that really understands what\'s going on with each of us in a way that lets it genuinely help us.\n\nBecause what is giving a person what they want? Does it mean gratifying their most intense short-term impulse at each moment? Or does it mean giving them what they want in a sort of balance along multiple timescales? Which is at multiple levels of our being, which is what we try to do with our family and our human friends. And AI\'s, they\'re laughably far from making an effort to give us what we want and in the more profound sense at the moment.\n\n**CH:** Right? Well, the reason why I was focusing on the AI part is the biggest part, the blockchain part, the incentives engineering relies very heavily upon the users and the agents inside the system. And so we say, "Okay, how do we incentivize people to supervise and curate data and agents in a way that we get more dialogue and we get a great moderation?" The ideal form would be, if you take clique\'s that are disjoint and you put them in the system, then idea flow starts occurring between them. And over time they\'ll converge into kind of a great moderated middle.\n\nSo you can take a very extremist person and either the system acts like it has an immune system and it kind of kicks them out or that node over time, moderates. The incentives in the system have to be designed that way. The reason we have so many problems in my view with Facebook and Twitter is that it actually has the opposite incentive. You get more clicks and more interaction with the more polarized people become. So the system is built in a way to polarize people as much as possible and thus divide them as much as possible. Because it\'s actually boosting revenue.\n\n**BG:** I think that\'s an easier problem to solve. Righteous indignation and the glorious feeling being approved by others in your ingroup and jointly indignant of the guys in the next group. This is a really easy emotion to manipulate with people. It\'s sort of a low hanging fruit. And to an extent these networks implicitly got stuck in manipulating this low-hanging fruit because it was the easiest way to keep people staring at their app. I mean, just as the internet settled on porn with love, it\'s been with. Because that\'s a really low algorithmic complexity way to keep people staring at something, is to show them naked bodies. So, if something would give greater benefit and even get people to start their site longer in the long run, but it isn\'t quite as simple of a problem, it sort of gets bypassed in the loop of trying to incrementally achieve these metrics more and more each month.\n\nAnd what\'s interesting is that the thought that rearranging sort of the configuration of the tech stack as you suggest in the beginning of the conversation, so like rearranging the tech stack so that the protocols are separate from the applications and then the AI models and tools used to create the AI models and inspect the AI models, they\'re also separate from the applications. I mean, reorganizing things in this way, then it sort of opens up the dynamics of the whole ecosystem in a way that I believe has decent odds of leading to the evolution of social media tools that they give people what they want in a more profound sense. And in doing so, they\'re creating communication networks among people that are not focused entirely on sort of immediate gratification of the ego and soaking of inter tribal rivalries and so forth.\n\nBecause all these good and beautiful things we\'re alluding to, exist on the internet right now. They exist on the internet right now. There\'s love, there\'s compassion, there\'s true connection between people with rival political views or from different historical tribes and so forth. It\'s not that we\'re not capable of that or that it isn\'t there. People are capable of amazing deep connections with other people and have incredible self-awareness and uplifting of their own consciousness. It\'s just, you need networks that foster this rather than trying to squash it and channel you into tribalism and immediate ego gratification. And of course neither you or I nor our teams are going to build all the systems that solve this problem. So you\'re going to create the ecosystem and tool set in which the solutions are going to emerge.\n\n**CH:** Right. Well, that\'s the point of incentives engineering is that it\'s the initial push. And because you don\'t have friction to slow you down, you tend to accelerate and eventually you get to a great place. I mean, Bitcoin obviously got their incentives engineering right. And they went from a single miner to warehouses of miners all around the world. And now this colossal system. We can argue about the power consumption, but that model was quite competitive to a point that it created a trillion dollar ecosystem. So I often think, "Well, what incentives do we need?" And we kind of have three sets of distinct things we need to accomplish at the same time if the network is going to be sustainable and useful to society.\n\nSo one thing is that you would like information to be curated, where it can clearly separate objective reality from the subjective analysis of it and give people a diverse set of viewpoints and understand that stuff is nuanced. So if they get that, then you kind of get rid of the fake news. You also get some consensus in the network of baseline facts. Because right now we live in a reality where people can\'t even agree to basic things. Some people think coronavirus is a hoax. Some people think vaccines are poisoned, et cetera, et cetera. So there\'s just disjoint realities that people are in. It used to be we would have one set of facts. We\'d agree on that. But then our interpretation of what those means-\n\n**BG:** It\'s true. A lot of people really believed Donald Trump had the most people at his inauguration ever, and the New Yorker doctored those images. And of course, sometimes the mainstream media may have distorted something about Trump, but the thing is, that\'s like an image, right? And people didn\'t believe the photograph, they believed the photograph was fake. And when you\'re at that point where people don\'t believe the photographs, then it\'s very hard. Then you have to be on the ground there, observing it in a sort of very clear state of mind to believe anything.\n\nSo, I mean, I\'m not even a realist or materialist fundamentally. I don\'t know if there is an objective reality. But what people are doing is they\'re not thinking in a clear and coordinated way about this belief they have or this thing they\'d been told. What evidence is that grounded in? What\'s the process of grounding the abstraction or the claim in the evidence? That process is broken. And it\'s partly because of AI and advanced informatics tools. Because you can make a deep fake. I mean, it\'s actually hard to tell if this video is Goertzel and Hoskinson or is this video a deep fake of Goertzel and Hoskinson put up by someone to troll all of us. It\'s not immediate seeing is believing to tell that you have to think.\n\n**CH:** Oh yeah. Like the Collider, George Lucas, deep fakes are extraordinary. And that\'s last generation technology. Where they\'re going in a few years is going to be socially very damaging because you\'ll have these perfect simulacrums of major figures and there\'ll be saying and doing terrible things. So that\'s the first part, the curation, go ahead?\n\n**BG:** You need the social network to tell bullshit from reality. So if the social network is broken, then you can\'t tell because you can\'t tell by looking, you can only tell by what you read and what others are saying, right?\n\n**CH:** Right. And I think that\'s why they\'re proactively de-platforming people and controlling flow of information because there\'s a political terror about the consequences of deep fakes and what they\'re going to do to dialogue.\n\n**BG:** Yeah, the point they\'re going to come to.\n\n**CH:** Yeah. Put a pin in that because there\'s two more points. So, as I mentioned, the first is just the curation of the information itself. And putting it in a way that it promotes instead of siloing idea flow, idea quality, separation of objective reality from subjective reality. And then when you\'re looking at the subjective to give you a spectrum of viewpoints, almost like a next-generation Nolan chart to show you different viewpoints.\n\nOkay, so then second there\'s clearly a data economy that exists. And surveillance capitalism is not just a nice term. It\'s a multi-billion perhaps trillion dollar economy. It\'s very valuable to society in certain respects. It allows you to micro target people. It allows you to have more friction-free commerce. You get the right products to the right people. So there\'s a huge advertising model and that shouldn\'t go away, but it should respect the privacy of the individual.\n\nSo there\'s been a lot of attempts to explore better ad models like with Brave and BATs, for example. I think whatever social network you create, you have to move in that particular direction where people are able to monetize their data and preserve their privacy, and actually get a share of the profit from the interactions that they have. And then the third design goal has to be the infrastructure itself is horrendously expensive to maintain. I mean, you\'re talking about petabytes of data. All these systems have N squared plus interactions. And so as your social network gets to a billion people, that quadratic complexity becomes very difficult to curate and manage. So the computational cost of that infrastructure, there\'s a reason why Google is so big and Amazon is so big and Facebook is so big.\n\nSo you somehow have to figure out how you subsidize a decentralized distributed system to curate and store all of that information. And you actually have to make data and users an economic actor, or they get pruned out if they don\'t contribute enough to the system. And we haven\'t quite figured out how to do that in a much simpler sense with just smart contracts and these big systems.\n\nI mean, you see things like IPFS and Gollum and other attempts to distribute network and data and storage. But if those protocols are imperfect, and when you talk about a social network, you talk about people posting videos, every day, 4k videos. You talk about people posting pictures every day, sometimes 100s of them, millions of meaningful interactions, even a small clique. If you take an extended family, that\'s going to be over a month\'s time, probably a million plus interactions of various things from likes and thumbs up. And then you\'re adding these intelligent agents that also have to do an enormous amount of processing on a regular basis. And those agents are only going to get more sophisticated and be interacted with a lot. So you have to have a lot of that be handled by the edges, the end user.\n\n**BG:** Yeah, yeah, yeah, absolutely. And that\'s hard. I mean, we\'ve been working on that with a project called NewNET, which is spun off of SingularityNET. And I think we understand a lot about the architecture that has to be there and about how this sort of split up machine learning algorithms for this sort of a hardware infrastructure. But there\'s a lot of work to be done there. There\'s a lot of avenues for inter-operation of NewNET, SingularityNET, and Cardano there. But I mean, it\'s hard. It\'s hard to do computer science and software engineering. And on the other hand, obviously Google and Amazon and Microsoft have solved a lot of really hard large-scale software engineering problems, different ones. But I mean, I think with a fraction of the effort that they put in, I think we can solve that problem.\n\n**CH:** Yeah, they\'re cheating because they always have a trusted third party. And so that massively simplifies your protocol. Their problem is easier. This is a harder problem. But on the other hand, computer science and hardware have both advanced a lot since they started doing what they\'re doing. But yeah, the incentive engineering aspect, incentive design aspect is quite critical and quite fascinating and exists for end users and also just within the developer community. Because I mean, what you see now is the significant majority of AI PGS, and we\'re going to work for these big tech companies. Or start a startup, which then gets acquired by one of these big tech companies. So the incentive structures of end users and of developers have sort of been channeled. They\'ve been channeled around these large tech companies, which is an amazing achievement. I would be proud if I created one of them. On the other hand, it\'s not optimal, but it\'s doing the course of society.\n\nAnd I mean, this is one thing that interests me, in our own collaboration over the next few years. I\'ve been working with my team in SingularityNET to architect a five-year tentative plan for how to roll out and grow SingularityNET on Cardano platform. I mean, part of this involves the AGI token, the new AGI on the ada token that we\'re working to launch as a new version of Singularity AGI token. Because we need the AGI token to be the right sort of incentive mechanism, largely on the backend. For AI algorithm developers and for AI application developers who are building these applications backending on the AI, you need the incentivization there to work right in order to create the systems that will be creating the right incentive structures for end users.\n\n**BG:** And I think things like the Catalyst Program within Cardano or a very interesting step there. I mean, where in Catalyst community members democratically vote with some liquid democracy mechanisms that they vote on, which Cardano projects should get some tokens. And I\'ve been watching and participating now, and then on the Catalyst discussions. And I want to do something that\'s a lot like that with some added dimensions, for SingularityNET on Cardano for fostering the community and expanding the community to build AI applications on our shared decentralized network. Because you need the right incentive structures on all these different levels and they need to coordinate together, which is hard. But I mean, there I think Tokenomics sort of gives you an advantage over what the big tech has because it\'s more scriptable and it\'s more flexible than the money and stock options and the incentive mechanisms they have.\n\n**CH:** Well, what\'s so cool about Catalyst is there\'s at the end of this year, going to be at least probably a $100 million worth of value that\'s available to the community. And the partnership with IdeaScale is just the beginning. We keep adding more and more firms to assist us with figuring out how to build a productive voting community, because it\'s not just the raw participation. So we say, "Hey, I think about two, 3% of ada holders are right now in idea scale, Because it\'s still kind of in a beta form. Our goal is to get that to 50% before the end of the year." But then we were trying to identify what meaningful participation means?\n\nBecause I would argue the American election system is not meaningful at all. You just show up and vote, but whether you spent hours thinking carefully about it, or you just voted randomly, it doesn\'t really matter. And the system doesn\'t differentiate that. So you end up with very poor outcomes and rational ignorance and a race to the bottom, effectively. So, meaningful participation is something we\'re definitely very interested in. And our hypothesis is that\'s going to lead to significantly better funding outcomes. So our return on intention is quite good for the system. \n\nIt gives you this M & M thing. It feels so empty without M & M, maintenance and moonshots. So maintenance means that you can maintain the system as it is and iterate and refine and evolve, and moonshots means that you have enough money to go pursue a high risk, high return research. And most great societies do this through some vehicle. It can be the Horizons program, the European Union, or it can be DARPA in the United States where they say, "All right, we\'re going to throw a bunch of money at some crazy stuff." And the odds are, it\'s probably not all going to work out. In fact, we seldom get exactly what we want, but then every now and then, we get fiber optic cables and satellites and the internet, and we get self-driving cars, and we get CALO and these other cool things.\n\nThe value to any DApp that comes over to Cardano is that you get to reuse the catalyst stack at some point, and then you can start entertaining, "Well, what does a treasury system look like within our ecosystem?" So, let\'s look three, five years out into the future, and let\'s say SingularityNET\'s gotten a lot of adoption. There\'s tons of transaction volume. You could put a slight tax on each transaction that can go into a treasury system for all the AGI holders. And then suddenly, you now have a mini catalyst just for AGI, and you can follow your own M & M strategy. So one part can say, "Hey, we just want to add more agents and more capabilities," and the other part can say, "Let\'s go tackle a super hard problem in the AI space." And it\'s really risky to go chase that problem. It may be the Holy Grail AGI, or it could be a subset of that or a compositional subset where you can decompose that problem to a collection of subproblems, and you\'re solving one of them. And if you fail, it\'s okay. And if you succeed, that solution lives in the open domain, and it\'s not controlled by a company. It\'s controlled by a protocol, so it\'s ubiquitously accessible.\n\n**BG:** So with what we\'re planning out now with a certain amount of AGI ADA tokens, I think we can do something catalyst based that can help get AI developers on the SingularityNET on Cardano platform and can help build toward both applied narrow AI in domains from social media to medicine, to DeFi as well as other components toward AGI. But there\'s also much bigger things. Like if you think about it, we\'re competing with these trillion-dollar companies, right, so I mean, eventually, we need custom hardware for decentralized AGI. If there is enough usage, as you say, a modest fee on usage can, can drive catalyst-based funding of research. And I mean, you could fund the design and prototyping of decentralized AGI chips, right?\n\nI mean, ultimately, we need to be seeding these exponential economic growth processes to the point where there\'s more wealth in the decentralized AI ecosystem than there is in the centralized AI ecosystem, which sounds very fanciful now. But I mean, I\'m a lot older than you. I\'m old enough to remember the computer \n\ncompanies were like Honeywell right? No one believed that PC companies were going to supply them, let alone internet companies like online ad agencies. Right? But this is how things go. And I mean, in the same way, the potential for network effects and exponential growth based on the right incentive mechanisms on multiple layers... The potential is there for a decentralized AI ecosystem to grow much bigger than the current trillion dollar companies. I mean, you just need to see the right growth processes in place. And I think, between our communities and codebases, we\'re able to see what those are right now, but of course, getting that seeding to work involves an endless number of difficult subproblems, both technological and human.\n\n**CH:** Right. Well, that\'s the value of trade. Bob makes the spear, and Alice makes the rope. So one of the things we\'re trying to focus on in Cardano is abstracting the toolsets and capabilities of the protocol so that each DApp that comes can reuse that, and they don\'t have to be a domain expert.\n\n**BG:** That\'s what got me to fall in love with Cardano in the first place. It\'s like, this is actually a reasonable software architecture, right? I mean, you\'re using functional programming. You\'re breaking things down into pieces. So if I want to take some AI algorithm and make it do homomorphic encryption or multi-party computing, so it runs in a secure and scalable way, I don\'t need to write all that code myself. There\'s actually tools within the blockchain infrastructure that are useful as code when you\'re on the AI level. I mean, Ethereum is super cool. Launching smart contracts into the world was a landmark thing, but I mean, the Ethereum codebase is not like that. There\'s nothing in there you\'re going to reference or use within your secure AI layer.\n\n**CH:** Well, the computation model is just wrong. It\'s got a global state, and so you can\'t grow beyond a certain amount.\n\n**BG:** It\'s supposed to be a world computer, but you cannot build a functional world computer that way.\n\n**CH:** No. You have to go from global to local. And then you just have so many problems in that model. In fact, we just had a lecture this morning with Manuel Chavravarty talking about the differences with the extended UTX cell model to the Ethereum style accounts model. And we\'ll publish that video probably next week, but it just becomes so obviously self-evident that while it\'s a great proof of concept, the system... First, it can\'t scale. And second, the use of other utilities comes at the same resources for everything. So whether you\'re using a voting system, or you\'re using a stablecoin or a DEX, it all comes from one pool of finite resources. So if one of those resources gets over consumed by a Crypto Kitties, it makes all the other resources in the system more expensive. And that\'s a bizarre and asinine model. If a catalyst, for example, runs as a side chain of Cardano\'s... So let\'s say we have tons of DApps bombarding that, using that for the voting systems for their DApp, that will have no impact at all on the main chain performance.\n\n**BG:** A hundred US dollars in gas for you to swap transactions.\n\n**CH:** I know.\n\n**BG:** And how can you obsolete Wall Street that way? I mean, it\'s going to be tough, right? But on the other hand, I think the foundational algorithms to get around those problems are there in Cardano. And then, in SingularityNET, we have foundational algorithms for distributing and decentralizing secure AI. So, I mean, I think ingredients are there for what needs to be done. On the downside, none of us has the war chest that Google and Amazon and Apple and Microsoft do, so we have to work around that by being cleverer than them and designing the right incentive mechanisms so that you get positive feedback effects and network effects, and things can really grow. And I think that this year is going to be pivotal actually, but we\'re going to... I mean, you\'ve got native assets coming out, and we\'ll be putting AGI token as a native asset, and then a few other SingularityNET spin offs as native assets.\n\nBut I mean, we\'re going to get to a flourishing native asset ecosystem in Cardano, and then SingularityDAO, which is a DeFi system we\'re building on SingularityNET, I mean, we can use to help coordinate getting liquidity into all these Cardano native assets. I\'m super psyched about that coming out publicly because not many people are thinking about what you can do when you have a real programming language as a smart contract framework, which security by design is built in. So, I mean, I think we\'re really providing stuff that is prepared to explode in an incredible way in 2021.\n\n**CH:** Yeah. So first about the treasury management, Tesla 2008 was a day away from bankruptcy, and now it\'s worth more than Toyota, Honda, Nissan, and Ford and GM combined. I mean, it\'s just crazy how fast they grew. So treasuries can grow exponentially if you get to a certain... It\'s almost like a standing ovation model where a few people stand up and clap, and then eventually you hit this point, and then everybody just gets up and claps. And it\'s the same thing, I think, with capital and companies. There\'s a few pivotal moments that you have where you\'re just right at this explosive growth, and then boom, the hockey stick happens, and then suddenly you have a lot there. And I think that\'s happening in the crypto industry. I remember when we hit a billion dollars with Bitcoin, and I was like, "Wow, this is incredible." We could never fathom a trillion dollars. It was a crazy concept, and that had happened within eight years of that point. It took nearly five years for it to get to a billion. So it\'s extraordinary how quickly things can grow.\n\nThen in terms of the collaboration, getting to that, Plutus is coming very soon, and we have this test net coming out. What we\'re doing is we\'re going to beat the hell out of it. So we\'d love for your guys to beat the hell out of it with the SingularityDAO.\n\n**BG:** Beat the hell out of it. That\'s right. Yeah.\n\n**CH:** We\'re a little easier because we have the Hard Fork Combinator, but your mistakes tend to sit around forever. Like we made a lot of protocol design mistakes with Byron, and we still have to support them. And so we found a really nice way of doing that. But when we released version one of Plutus and the extended UTXO model and native asset standard, that\'s probably not going to be perfect because nothing is. As an engineer, version one\'s there, but yet we have to be backwards compatible. So when you go to version two, you still have to support version one. So to me, it\'s super important that we get as many people as quickly as possible, beat the hell out of the native assets standard, beat the hell out of, especially Plutus, before we do the next hard fork to bring that in because I would rather not be backwards compatible with obviously wrong things as we are with Byron.\n\nSo it\'s great to have you guys around. I know that the code you\'re going to write is very novel, and it\'s also going to push the system to its limits. And you\'re going to create a very strong demand for performance and scale, I think. And I can already see several areas where we would like to use AI, for example, transaction fees. We have this fee parameter, and that\'s right now set with the update system, so the minimum transaction fee is a DDoS parameter. It\'d be so cool once we have Oracles and DEXs within the system, and we have some notion of the value of ada relative to the US dollar, to create an automated transaction monetary policy that can take those data points and compare them to other networks real-time, and then try to make sure that we always have a compatible-\n\n**BG:** This is actually a subtle point that we\'ve been discussing between SingularityNET platform team and Cardano platform team, right? Because I mean, the transaction framework for Cardano now, and that\'s planned for common native assets, it\'s fine from what we\'re doing with SingularityNet at this moment, but if we want to go to a swarm AI or microservices model, where you have a whole bunch of little AIs that within the second, one AI is consulting others to create others. I mean, if you really want to get AI by this dynamic microservices architecture, I want to have this using the blockchain rather than all off on the side. I mean, you need a way for some sub-networks to have substantially lower transaction fees, but then you need some system that\'s intelligent in some sense to regulate and moderate that because you still need to protect against DDoS attacks and then all sorts of other things, right. So there\'s a lot of areas like that where some machine learning, participating in the infrastructure can help a lot. And one of the things it can help with is to help make the system better able to manifest the emergence of higher levels of intelligence and learning, right, so you got a lot of positive cycles there.\n\n**CH:** Yeah, and you want it to be deterministic yet dynamic. And you would also like it to be globally aware of competition. So you\'d like the agents to be able to parse all the competing blockchains and look at their monetary policies, look at their transaction policies or transaction rates and their relative values to each other, and then be able to pull that into Cardano and form a transaction policy based on that.\n\n**BG:** It is there, right. I mean, the data is there online. You can download it into your AI, and I think that\'s quite feasible. So, yeah, going back to decentralized social networks, where we started, I mean, there\'s been, as you know, and you\'ve looked at this in more depth than me even... I mean, there\'s been loads and loads of attempts to make decentralized social networks. There\'s dozens of cool projects started by smart well-intentioned people with the right vision. Obviously, none of them has yet become the next Facebook or Twitter. I mean, some like Minds.com from Bill Ottman, I think, is really cool, but I log on there not yet as often, even as I log onto Facebook, which is not that often, right. I mean, Mines is great. It just doesn\'t have such a critical mass of people yet, although it\'s done a way, way better job than the vast majority of decentralized social networks, right?\n\nSo how do we get Minds and Everipedia and dozens of other decentralized social network platforms and the new ones that haven\'t been heard of yet... How do we get these to really take off? And I think we share the conclusion that a lot of what\'s needed there is to make the underlying stack more amenable to lower costs, larger-scale operations of the needed kinds, both in data storage and processing distribution, and then the distributed AI, also. It\'s interesting, Jack Dorsey from Twitter has seen this also, and they\'re looking at making a decentralized protocol and reorganizing the Twitter stack. The question there is, can you really make that work with incentive structures that are implicit in Twitter as the company that it is?\n\n**CH:** That\'s why I separate the base protocol from the interface, like what Steem did. They had the Steem protocol and then Steem at the interface, and their problem was that they didn\'t have a full end to end monetary policies, so they had value leakage. There was no incentive to buy the token, but they used the token to curate information. Had they solved that problem, it would be still around and much larger, but I think that Twitter can survive with a decentralized social network protocol because it would just be a very popular, curated interface to it, and they\'d still have their network effect. It\'s just the customers, and the data would be ephemeral. They could flow from one interface to another interface and get that same experience. The problem right now is you have to rebuild the network effect every time you launch a new one of these things. Every time we want to do an internet application, we have to completely rebuild the internet underneath it. It\'s a preposterous thing, right? Yeah.\n\n**BG:** It makes sense, and I think it\'s visionary of Jack Dorsey to even entertain the notion, right? I mean, not many corporations of that scale are willing to-\n\n**CH:** Well, it\'s a proactive solution to a big problem he has because if he plays censor and chief and he has to de-platform people from the protocol, then he can never win.\n\n**BG:** I wouldn\'t want that job either because, I mean, you got people that are clearly colluding to kill someone. Fine. You ban them. You have people who are saying stuff that\'s nasty but not yet criminal. And then I don\'t want them to be in the job of telling what\'s too nasty and what\'s okay. I mean, court systems aren\'t perfect at that, but I mean, they\'ve been honed for that over significant periods of time, and you don\'t want to have to do that at fast speed and large scale as part of operating your tech company. And I mean, none of these tech companies actually want that job, right. That\'s not why they got into the business, like how can I censor people\'s political speech? So, I mean, of course, if things can be reorganized so that that job is done by the community for the community, rather than having to be done by the CEO. I mean, that\'s far, far better. And the community won\'t do it perfectly, but actually, it will do a better job than these centralized authorities. And I mean, it\'s completely possible to do that. \n\nWe did a lot of simulations of Singularity \'s machine learning-moderated reputation system over the last couple of years. You can make decentralized, AI-guided rating and reputation systems and you can tune them and you can see if I tune it one way, you get information silos, if you tune it another way, you just get trolls and spammers and so forth. If you tune it in a different way, you get a system that self-policing and fosters a healthy level of interaction. And you can do this to get networks that self-regulate without anyone giving top level control. If this is operating within the current global political systems, which I have my issues with too, as I\'m sure you do, but it\'s there, then you still have top level control over things that are clear crimes, according to the nation states people\'s bodies are sitting in, but you don\'t need top level control for anything else.\n\nAnd I think that not just would avoid garbage like minds are proud of being de-platformed. It would also create something that\'s a breeding ground for positive and creative and beneficial content in which people\'s minds are being nudged toward positive growth, rather than channeled into this site and click on this ad. I think potential is there to do that. What\'s a little scary is that handful of us in the decentralized AI space, the two of us, probably understand more about how to achieve this than anyone else on the planet. It\'s actually a very big and significant problem, both in terms of setting the stage for a positive singularity and just making life less shitty for humanity on the planet at this moment.\n\n**CH:** The one thing I\'ve always learned from being a cryptocurrency guy is that incentives are king, and it\'s always been an incentives problem. How many people were, in 1990, being paid to think about social networks? You\'d probably be in the sociology department at Harvard or something that, or toying around in an MIT AI group or something. But it wasn\'t a real job and nobody would understand. How many people who are experts in how to build effective social networks are floating around now? There\'s thousands of them. They\'re fabulously wealthy. So if you show that in a free market system you can achieve great wealth, or at least the prospect of great wealth by building a system of a certain design, then you\'ll end up getting a lot of it.\n\nThe cryptocurrency space was exactly the same. How many people were experts in Bitcoin-like systems in 2010? Very few. Now in 2021, now the existing chairman of the Securities Exchange Commission, Gensler, he was lecturing at MIT on cryptocurrencies. That\'s how far we\'ve gone in just such a short period of time because the incentives are right. So when I look at this problem, I say, "Well, how do we get the incentives in the right way to encourage a large clique of people to come in and actually start applying serious hardcore brainpower to these types of problems?" So it\'s a first mover situation. Now, to the minds and these other guys, to that earlier point you brought up, I look at them almost like mechanical horses. When we were first thinking, how do we build a better horse? If we all let\'s build a robot horse, or a steam powered horse or something like that. Well now there\'s this automobile idea that we\'ve been toying around with. Maybe that\'s just a fundamentally more competitive or better model.\n\nOr similarly, when people are thinking about vacuum tubes, you can certainly optimize them, and I\'m sure you could build a much better vacuum tube today than they were building back in the 1940s. But obviously that was superseded by the transistor. So similarly, when you look at social networks, we have to say what is our automobile moment to replace the horse?" And minds is not it. I think that if those things existed, they\'d actually just be worse than Facebook or Twitter. They\'d get far more siloed. The three problems I outlined, the great moderation, the incentives models being aligned so that people can actually make money and produce money and do useful things with the system, and the infrastructure funding problem.\n\nYou have to solve all three of those with one protocol design and one incentives design. And if you do that, then it\'s going to be this massive beacon that will attract tons of people to come in and start working on an augmented system and evolve it. And it doesn\'t matter if it starts very small. It\'ll go very viral and eventually get to that Tesla-style hockey stick, when Tesla figured out the entire model. Plenty of battery-powered cars before, but their particular model was the one that everything came together and then it had exponential.\n\n**BG:** In terms of tokenomics systems, it\'s quite interesting. Because having a unified scheme and dynamic for promoting the right incentives doesn\'t mean just one token. So you\'re sculpting multiple tokens in a multi-token ecosystem where they interoperate. So say we have ada, we the AGI token on ada, and for, say, a decentralized social network running on ada, leveraging SingularityNET AI, potentially could involve a different token for a certain purpose within that network. You have to think through the inter interoperation of these different networks. And I think that this is one of the things I\'m most excited about in collaboration between the two of us and between SingularityNET and Cardano. I think you guys have done very well in thinking through incentive structures and how they boil down into tokenomic structures. I look forward to some cognitive synergy among us on that.\n\n**CH:** We learned how much we don\'t know. We started this program at Oxford with Elias, and he\'s an algorithmic game theorist. He won the Gödel Prize and all these things. He\'s a really good guy, and he\'s got some... Yeah, Oxford, he\'s got some really good graduate students too, so we said, "Okay, between him and his graduate students, we\'re done. Put a fork in it. We should easily be able to tackle all these consensus incentives problems in Ouroboros." It took two years to refine the entire incentive model just for a consensus algorithm, and now we\'re talking about incentives for the curation of information. So it\'s going to be fun to collaborate. I agree there. It\'s such a hard problem.\n\n**BG:** Curation of information that\'s being created by just decentralized AI algorithms, not just of existing information.\n\n**CH:** Yeah, because you need to create demand for a token and you need to be able to use that token because it\'s demanded and it\'s valuable to incentivize a certain collection of human behavior. You also need to be able to use that to incentivize people to interact with agents in a way that they could become trained to become good cognitive crutches to reinforce the network, and then that token also has to incentivize the hosting of decentralized infrastructure that eventually can scale to petabyte scale storage and huge network capacity and massive computational capacity. It\'s a tall order. It\'s a lot of incentive engineering, and that\'s why I don\'t think these networks exist yet.\n\n**BG:** They don\'t. As you say, once it\'s gotten to a certain level, the potential to gain both personal wealth and to help promote broad benefit to a huge degree, those are both there in a very clear way, which I think can cause a rush of talent into the space of decentralized AI and decentralized AI guided social networks. We\'re at a pivotal moment now, I think, in terms of both the readiness and even eagerness of the world for these technologies and the existence of the needed tools, or at least a significant fraction of the needed tools to create them. This conversation is occurring in a quite interesting time.\n\n**CH:** But the good news is that there\'s a lot of almost right attempts, like the creation of Bitcoin, we had HashCash and bit gold and DigiCash. They were wrong, but they were wrong in the right direction, so you just had to pull them along enough and then eventually it fell through. So you have things like BATs, and I mentioned that before, and suddenly now you\'ve created demand for a token. Steem had enormous growth, but the problem was there was no demand for the token, but there was good payment for content creation and curation. So they got a lot of users, but they had too much value leakage, so they couldn\'t sustain network value and then the system fell apart.\n\nI almost felt if you could combine BATs and Steem together, then you\'ve created a feedback loop where the system will sustain and it\'ll continue to grow at a very rapid rate. However, they had to use the token to subsidize the actual running of the infrastructure. They didn\'t have a sustainable model there. So even though it was the protocol Steem and Steemit was just the company, the Steemit company had all the power and control because they were the people that could afford to run that protocol.\n\n**BG:** We\'ve got a hive now, right? I mean, that\'s the beauty of open source code and decentralized communities.\n\n**CH:** It\'s a Pareto problem where a small group runs the vast majority of everything and there\'s no economic diversity there. With Cardano, we spent five years on Ouroboros because we wanted a system that would get naturally more decentralized over time. So as the price of ADA increases, the K factor increases, and then suddenly you go from 1,000 to 10,000 stake pools and then 100,000, and then all the infrastructure is federated with those stake pools, so suddenly you have 10,000 Hydra channels and suddenly you have 10,000 oracle entry points et cetera, et cetera. So the system, when we get to Bitcoin scale, could have 100,000 stake pool operators that run that, and that scales quite nicely.\n\n**BG:** I\'m sort of thinking into the growth of SingularityNET during the next phase. I think that the platform as we\'ve built it now does something good. If you create multiple AI agents all over the place that collaborate and cooperate to solve hard problems. But we need to architect the next stages of development in a way that will incentivize massive increase of utilization of the platform using AGI ADA, but also that will ensure that increasing decentralized control of the network happens along with this massive increasing utilization. I think we can do it, and I think a lot of the thinking you guys have put into growing Cardano was actually helpful there in ways that we probably don\'t have time to explore in this podcast.\n\n**CH:** Well you get the democracy stack for free with Catalyst, and you also get the decentralized infrastructure for free. One thing we\'d love to do is see if we can get outsourceable computation. I\'ve been following that for God knows how many years. Pinocchio and Geppetto over at MSR, can you do the computation on an untrusted computer, but then provide a proof that the computation was done correctly? And then you know that whatever the result was given is right, regardless of who did it.\n\n**BG:** That\'s there on the computer science level, but it\'s not yet there on the scalable, usable software level.\n\n**CH:** We have some proof that perhaps these algorithms work, but a lot of them are exponential time.\n\n**BG:** One of the things I\'ve been doing with my non-existent spare time is going through all the core cognitive algorithms of OpenCog, which is the AI architecture I\'m working on, expressing all the core algorithms of OpenCog in terms of Galois connections over metagraphs and the chrono morphisms and stuff. So you get the right elegant formalization of your core cognitive algorithms. And then once you\'ve done that, then you can deploy the kind of math you\'re saying so that this core AGI computation could be done by outsourced computing. So the math and CS is there for a lot of these different things, but there\'s a number of stages yet to go through before that kind of thing is rolled out scalably.\n\n**CH:** That\'s an interesting mathematical expression. Do you deal with a dependent type system?\n\n**BG:** It\'s an independent pair of consistent probabilistic type systems, so yeah.\n\n**CH:** That\'s a mouthful. But can you prove anything interesting? You can show certain things that are isomorphic to each other or what you are looking for with those.\n\n**BG:** We are working on that right now, actually. But this would probably lead us too deep down some usually interesting rabbit holes for a broad audience podcast.\n\n**CH:** Okay, fair enough. All right. Well, Ben, this has been so much fun. I have another meeting I got to jump into, but I really enjoyed our time.\n\n**BG:** Yeah, this is fantastic. It\'s both broad and deep, and I think decentralized social networks, it\'s both really important on its own, and I think we can work together to solve it, but it also highlights a bunch of other more general points, both about bringing Singularity and Cardano together and about just what we need blockchain and AI together to do. So yeah, very cool. Look forward to the next one.\n\n**CH:** I guess a closing point is platforms tend to get defined by the killer apps that are on the platforms, and I\'m very glad that one of the most meaningful and significant applications on our platform is SingularityNET. I would hate to see us be defined by Crypto Kitties or something like that. It\'s great to have you guys around. I think this collaboration is going to result in an enormous amount of evolution of our own platform and an acid testing of things in a way that\'s very productive for everybody. And my hope is you guys become one of the most successful pieces of infrastructure on top of a Cardano and it leads to a lot of user growth. And we\'re not just collaborating technologically. I think we\'re going to share some office space at some point in Ethiopia.\n\n**BG:** The space has been found, actually. So our Addis team and your Addis team will co-locate.\n\n**CH:** John was very excited about it, so I imagine the office is quite nice.\n\n**BG:** It\'s in Bole, which is a great neighborhood. It was a very pleasant and surprising coincidence that we actually both had flourishing teams in Addis Ababa contributing to the development of our various platforms. Very cool that maybe the next time we meet face to face will be over some injera in Addis.\n\n**CH:** That\'d be a lot of fun. That\'d be a lot of it just to have to get rid of the civil war and the COVID, but those are just minor technical details,  All right. Thank you so much, Ben.\n\n**BG:** Great. Thanks a lot.\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'decentralizing-social-media',
                                url: '/blog/posts/2021/02/05/decentralizing-social-media/',
                                read_time: 57
                            },
                            {
                                publish_date: '2021-01-06T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/344fa779-3928-4439-870f-7977abbfec51/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: ' Project Catalyst blasts off into 2021 ',
                                        subtitle: 'New fund will commit $500k in ada to find groundbreaking ideas which accelerate Cardano development',
                                        audio: '',
                                        soundcloud: [
                                            {
                                                trackid: 987296944
                                            }
                                        ],
                                        body_content: '<!--StartFragment-->\n\nProject Catalyst is the first stage in our Voltaire roadmap, created to bring best-in-class governance to Cardano. Effective governance is vital to Cardano because it gives the power to shape the blockchain to its users. Anyone who signs up to Catalyst will be able to propose ideas, and then registered ada holders will vote on funding proposals focused on the continued evolution of Cardano as a platform and a community. This will not only accelerate development but also sustain the Cardano ecosystem in the long term. \n\n\n\nThis journey began with two test funds, and then Catalyst swung into action for real with [Fund2 in September](https://iohk.io/en/blog/posts/2020/09/16/project-catalyst-introducing-our-first-public-fund-for-cardano-community-innovation/). With it we saw a very early – and remarkable – example of decentralized collaboration. Thousands of people came together – proposing teams, community advisers and ada-holding voters – to generate, refine and prioritize funding for proposals to drive Cardano forward.\n\n\n\nVoting on Fund2 has just concluded and tallying of the votes is under way. Soon, the winning teams will receive funding to help make their proposals a reality. [Join our dedicated Telegram channel for Catalyst](https://t.me/cardanocatalyst) and stay tuned to our social channels for updates on this.\n\n\n\n**Challenge accepted**\n\nMeanwhile, with barely a beat, we’re moving forward with even greater purpose by harnessing the community momentum integral to Catalyst. Fund3 launches today and we want to expand the Catalyst community with every fund, encouraging ever more people to get involved.\n\n\n\nIf you’re not familiar with Project Catalyst, this is how it works. Every funding round begins with a defined set of challenges. Each challenge represents an ‘intention’ by the Cardano community, a collective goal we’d like to achieve – we like to talk of return on intention as the way of measuring progress for the project! Each challenge is designed to be broad enough to inspire both technical and general ideas, while being specific enough to provide focus. As long as an idea addresses a challenge and makes a strong case for meeting the intended outcome, it will be considered. So we welcome all proposals, from marketing initiatives and infrastructure development, to content production and product enhancement. \n\n\n\nProject Catalyst relies on the ingenuity of a global network of participants so all ideas are encouraged and can always be ‘re-entered’ for future funds if they do not meet the challenge criteria at hand.\n\n\n\nFund2 contained a pool of ada worth $250,000 and Fund3 doubles that, distributing $500,000 in ada between proposers, voters, and community advisers. Fund3 has three challenges:\n\n\n\n1. **Developer ecosystem challenge:** How can we encourage developers to build on Cardano in the next six months?\n2. **DApp creation challenge:** What decentralized applications (DApps) should be funded to drive user adoption in the next six months?\n3. **‘Community choice’ challenge:** This new category is where we ask the community itself to set one or more challenges, which will have their own funding round in Fund5. An additional $500,000 pool will be available to cover any goal the community wishes to set, whether it’s about executing the community roadmap, funding content or podcasts, encouraging non-profit work or whatever else is determined to be a priority.\n\nSo how do you participate in Project Catalyst?\n\n\n\n**From sharing insights to submitting ideas** \n\n\n\nFirst of all, anyone wishing to get involved with the project, whether as a proposer, adviser or simply a voter, should sign up to our [collaboration platform](https://cardano.ideascale.com/a/index). You do not have to be an ada holder to propose an idea or take part in the discussion phase. \n\n\n\nFund3 begins with an insight-sharing phase in which people can give their perspectives on the challenge before proposals are launched. Think of this phase as a community brainstorming forum to inspire proposers.\n\n\n\nAfter the discussion of the challenge, participants with proposals will publicly submit an initial draft.\n\n\n\n**Refining ideas, finalizing proposals and review**\n\nCommunity members will be invited to provide constructive criticism, offer suggestions, give positive affirmations in the form of ‘kudos’, and even offer to form partnerships and collaborations with proposing teams. The goal is to pool community knowledge and expertise – and Catalyst members are a diverse crew with valuable life and professional experience to offer. The following graph shows the makeup of people who signed up for Fund2:\n\n\n\n![](https://lh4.googleusercontent.com/8LBEdMEm001aTnHnR8Kq0RPyjg_ggwT_8lPmGOPjcum8nnMg1phpEdbPYFUzhzsLX3pNqES1tR1YcQ0Pwh9XeD3sZzINuOJmlzMCPcUAXGhuMzAjbVhxhMqQWp5OTyqclOGaFJvW)\n\n\n\nAfter community feedback is given, proposers are afforded the opportunity to revise and finalize their plans.\n\nOnce proposals are ready, a group of expert reviewers, recruited as community advisers, will give a rating for how well each one addresses the challenge. After this, ada holders can register and then cast their vote. The votes, which are weighted according to the size of each voter’s holding, are then counted and requested funds distributed to the winning proposals.\n\n\n\n**Looking forward**\n\nFund2 generated incredible creativity and strong proposals, some of which will soon be funded into reality. We expect even greater things from Fund3 as we start building a thriving DApp ecosystem on Cardano. We call Project Catalyst an ‘experiment’ – and we intend to encourage this spirit for some time to come. But our intent is very real and very determined. Every week that goes by presents opportunities to improve and refine this groundbreaking program for, and with, the Cardano community.\n\n\n\n*Join us in developing Cardano’s on-chain governance by signing up to our [IdeaScale](https://cardano.ideascale.com/) collaboration platform and our dedicated Catalyst [Telegram](https://t.me/cardanocatalyst) channel.*\n\n\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: ' Project Catalyst blasts off into 2021 ',
                                subtitle: 'New fund will commit $500k in ada to find groundbreaking ideas which accelerate Cardano development',
                                audio: '',
                                soundcloud: [
                                    {
                                        trackid: 987296944
                                    }
                                ],
                                body_content: '<!--StartFragment-->\n\nProject Catalyst is the first stage in our Voltaire roadmap, created to bring best-in-class governance to Cardano. Effective governance is vital to Cardano because it gives the power to shape the blockchain to its users. Anyone who signs up to Catalyst will be able to propose ideas, and then registered ada holders will vote on funding proposals focused on the continued evolution of Cardano as a platform and a community. This will not only accelerate development but also sustain the Cardano ecosystem in the long term. \n\n\n\nThis journey began with two test funds, and then Catalyst swung into action for real with [Fund2 in September](https://iohk.io/en/blog/posts/2020/09/16/project-catalyst-introducing-our-first-public-fund-for-cardano-community-innovation/). With it we saw a very early – and remarkable – example of decentralized collaboration. Thousands of people came together – proposing teams, community advisers and ada-holding voters – to generate, refine and prioritize funding for proposals to drive Cardano forward.\n\n\n\nVoting on Fund2 has just concluded and tallying of the votes is under way. Soon, the winning teams will receive funding to help make their proposals a reality. [Join our dedicated Telegram channel for Catalyst](https://t.me/cardanocatalyst) and stay tuned to our social channels for updates on this.\n\n\n\n**Challenge accepted**\n\nMeanwhile, with barely a beat, we’re moving forward with even greater purpose by harnessing the community momentum integral to Catalyst. Fund3 launches today and we want to expand the Catalyst community with every fund, encouraging ever more people to get involved.\n\n\n\nIf you’re not familiar with Project Catalyst, this is how it works. Every funding round begins with a defined set of challenges. Each challenge represents an ‘intention’ by the Cardano community, a collective goal we’d like to achieve – we like to talk of return on intention as the way of measuring progress for the project! Each challenge is designed to be broad enough to inspire both technical and general ideas, while being specific enough to provide focus. As long as an idea addresses a challenge and makes a strong case for meeting the intended outcome, it will be considered. So we welcome all proposals, from marketing initiatives and infrastructure development, to content production and product enhancement. \n\n\n\nProject Catalyst relies on the ingenuity of a global network of participants so all ideas are encouraged and can always be ‘re-entered’ for future funds if they do not meet the challenge criteria at hand.\n\n\n\nFund2 contained a pool of ada worth $250,000 and Fund3 doubles that, distributing $500,000 in ada between proposers, voters, and community advisers. Fund3 has three challenges:\n\n\n\n1. **Developer ecosystem challenge:** How can we encourage developers to build on Cardano in the next six months?\n2. **DApp creation challenge:** What decentralized applications (DApps) should be funded to drive user adoption in the next six months?\n3. **‘Community choice’ challenge:** This new category is where we ask the community itself to set one or more challenges, which will have their own funding round in Fund5. An additional $500,000 pool will be available to cover any goal the community wishes to set, whether it’s about executing the community roadmap, funding content or podcasts, encouraging non-profit work or whatever else is determined to be a priority.\n\nSo how do you participate in Project Catalyst?\n\n\n\n**From sharing insights to submitting ideas** \n\n\n\nFirst of all, anyone wishing to get involved with the project, whether as a proposer, adviser or simply a voter, should sign up to our [collaboration platform](https://cardano.ideascale.com/a/index). You do not have to be an ada holder to propose an idea or take part in the discussion phase. \n\n\n\nFund3 begins with an insight-sharing phase in which people can give their perspectives on the challenge before proposals are launched. Think of this phase as a community brainstorming forum to inspire proposers.\n\n\n\nAfter the discussion of the challenge, participants with proposals will publicly submit an initial draft.\n\n\n\n**Refining ideas, finalizing proposals and review**\n\nCommunity members will be invited to provide constructive criticism, offer suggestions, give positive affirmations in the form of ‘kudos’, and even offer to form partnerships and collaborations with proposing teams. The goal is to pool community knowledge and expertise – and Catalyst members are a diverse crew with valuable life and professional experience to offer. The following graph shows the makeup of people who signed up for Fund2:\n\n\n\n![](https://lh4.googleusercontent.com/8LBEdMEm001aTnHnR8Kq0RPyjg_ggwT_8lPmGOPjcum8nnMg1phpEdbPYFUzhzsLX3pNqES1tR1YcQ0Pwh9XeD3sZzINuOJmlzMCPcUAXGhuMzAjbVhxhMqQWp5OTyqclOGaFJvW)\n\n\n\nAfter community feedback is given, proposers are afforded the opportunity to revise and finalize their plans.\n\nOnce proposals are ready, a group of expert reviewers, recruited as community advisers, will give a rating for how well each one addresses the challenge. After this, ada holders can register and then cast their vote. The votes, which are weighted according to the size of each voter’s holding, are then counted and requested funds distributed to the winning proposals.\n\n\n\n**Looking forward**\n\nFund2 generated incredible creativity and strong proposals, some of which will soon be funded into reality. We expect even greater things from Fund3 as we start building a thriving DApp ecosystem on Cardano. We call Project Catalyst an ‘experiment’ – and we intend to encourage this spirit for some time to come. But our intent is very real and very determined. Every week that goes by presents opportunities to improve and refine this groundbreaking program for, and with, the Cardano community.\n\n\n\n*Join us in developing Cardano’s on-chain governance by signing up to our [IdeaScale](https://cardano.ideascale.com/) collaboration platform and our dedicated Catalyst [Telegram](https://t.me/cardanocatalyst) channel.*\n\n\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'project-catalyst-blasts-off-into-2021',
                                url: '/blog/posts/2021/01/06/project-catalyst-blasts-off-into-2021/',
                                read_time: 5
                            },
                            {
                                publish_date: '2020-12-17T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/7f85ed71-17c6-4fdd-8d69-5b6c1d77c6d8/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: ' IOHK partners with Wolfram to power Cardano',
                                        subtitle: 'Cardano joins Bitcoin and Ethereum in integrating into Wolfram’s industry leading technology and knowledge base, Wolfram Alpha. But this is only the beginning of an exciting new partnership.',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: '\n\n<!--StartFragment-->\n\nIOHK is dedicated to making Cardano an industry leading blockchain project. This has led us to collaborating with global leaders in technology, business and finance. Now, we’re pleased to announce a new partnership with Wolfram. As a part of this relationship, Cardano data will be integrated into the Wolfram Alpha computational intelligence engine. This places Cardano alongside Ethereum and the Bitcoin as blockchain data to be included within Wolfram Alpha.\n\n\n\nWolfram and IOHK have historically enjoyed close ties, with Stephen Wolfram presenting at [\\#Cardano2020](https://www.youtube.com/watch?v=h94VrSuPFJc&t=17s) as well as at the IOHK Miami 2019 summit. The company has consistently proven itself to be a leader in pushing open source intelligence across a variety of fields including computation, mathematics, and now, blockchain technology. The inclusion of Cardano data into Wolfram Alpha is a landmark moment for IOHK, but it is just the beginning of our collaboration.\n\n\n\nWe are currently defining a scope of work which would leverage Wolfram Alpha to provide Oracle services for Cardano. Oracles are a crucial component of powering smart contracts. They allow data to be transported from a variety of sources into the blockchain. This information can be anything from election results and sports scores to currency exchange rates and statistical data. This greatly expands Cardano’s ability to offer new ways for developers to integrate advanced external information into their smart contacts.\n\n\n\nAs a part of this ongoing roll out IOHK will also work closely with Wolfram Blockchain Labs. Wolfram Blockchain Labs provides blockchain ecosystems with necessary tools to assist in DLT-based commerce and business innovation. The educational teams at IOHK and Wolfram will collaborate to provide Cardano-specific course material. This will help draw developers and users into the Cardano ecosystem by promoting understanding of the platform. \n\n\n\nIntegrating with Wolfram Alpha also boasts industry leading natural language processing capabilities. This makes Cardano’s information available to virtual assistants like Alexa and Siri. Once integrated, users will be able to query the system to find information or solve computational problems as easily as asking their virtual assistant. We anticipate the initial phases of integration with Wolfram will occur Q2/Q3 of next year.\n\n\n\nIOHK and Wolfram are currently building out a collaborative framework, so we’ll have lots more to share over the months ahead. Meanwhile, if you would like to hear more about the partnership between Wolfram and Cardano, check out our interview with Wolfram Blockchain Labs’ (WBL) Jon Woodard on December’s monthly [Cardano product update](https://www.youtube.com/watch?v=32A3878DLnk&feature=youtu.be).\n\n\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: ' IOHK partners with Wolfram to power Cardano',
                                subtitle: 'Cardano joins Bitcoin and Ethereum in integrating into Wolfram’s industry leading technology and knowledge base, Wolfram Alpha. But this is only the beginning of an exciting new partnership.',
                                audio: null,
                                soundcloud: null,
                                body_content: '\n\n<!--StartFragment-->\n\nIOHK is dedicated to making Cardano an industry leading blockchain project. This has led us to collaborating with global leaders in technology, business and finance. Now, we’re pleased to announce a new partnership with Wolfram. As a part of this relationship, Cardano data will be integrated into the Wolfram Alpha computational intelligence engine. This places Cardano alongside Ethereum and the Bitcoin as blockchain data to be included within Wolfram Alpha.\n\n\n\nWolfram and IOHK have historically enjoyed close ties, with Stephen Wolfram presenting at [\\#Cardano2020](https://www.youtube.com/watch?v=h94VrSuPFJc&t=17s) as well as at the IOHK Miami 2019 summit. The company has consistently proven itself to be a leader in pushing open source intelligence across a variety of fields including computation, mathematics, and now, blockchain technology. The inclusion of Cardano data into Wolfram Alpha is a landmark moment for IOHK, but it is just the beginning of our collaboration.\n\n\n\nWe are currently defining a scope of work which would leverage Wolfram Alpha to provide Oracle services for Cardano. Oracles are a crucial component of powering smart contracts. They allow data to be transported from a variety of sources into the blockchain. This information can be anything from election results and sports scores to currency exchange rates and statistical data. This greatly expands Cardano’s ability to offer new ways for developers to integrate advanced external information into their smart contacts.\n\n\n\nAs a part of this ongoing roll out IOHK will also work closely with Wolfram Blockchain Labs. Wolfram Blockchain Labs provides blockchain ecosystems with necessary tools to assist in DLT-based commerce and business innovation. The educational teams at IOHK and Wolfram will collaborate to provide Cardano-specific course material. This will help draw developers and users into the Cardano ecosystem by promoting understanding of the platform. \n\n\n\nIntegrating with Wolfram Alpha also boasts industry leading natural language processing capabilities. This makes Cardano’s information available to virtual assistants like Alexa and Siri. Once integrated, users will be able to query the system to find information or solve computational problems as easily as asking their virtual assistant. We anticipate the initial phases of integration with Wolfram will occur Q2/Q3 of next year.\n\n\n\nIOHK and Wolfram are currently building out a collaborative framework, so we’ll have lots more to share over the months ahead. Meanwhile, if you would like to hear more about the partnership between Wolfram and Cardano, check out our interview with Wolfram Blockchain Labs’ (WBL) Jon Woodard on December’s monthly [Cardano product update](https://www.youtube.com/watch?v=32A3878DLnk&feature=youtu.be).\n\n\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'iohk-partners-with-wolfram-to-power-cardano',
                                url: '/blog/posts/2020/12/17/iohk-partners-with-wolfram-to-power-cardano/',
                                read_time: 2
                            },
                            {
                                publish_date: '2020-10-06T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/0b407539-3d27-4de5-a711-06e1626dcbd8/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Developer challenge: using blockchain to support the UN’s sustainable development goals',
                                        subtitle: 'IOHK has set up a $10,000 fund to invest in ideas for sustainable development based on Cardano.',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: '<!--StartFragment-->\n\nCreating a decentralized financial and social operating system for the world is the core mission of Cardano. But it’s not one that we can accomplish alone. That’s why we are always on the lookout for relationships which help us build a global foundation for growth. So, we’re thrilled to announce our hackathon challenge to support the UN’s sustainable development goals (SDGs) designed to accelerate progress on fighting hunger, injustice, and climate change.\n\n## Sustainability and blockchain\n\nIn this hackathon challenge we aim to give the blockchain community an opportunity to make an impact on international development. The challenge will draw on IOHK’s expertise in community-focused funding developed with Project Catalyst. This initiative brings innovation, voting, and decentralized funding to Cardano by crowdsourcing development proposals, and financing their implementation.\n\nIOHK and United Nations personnel will use the Project Catalyst platform to find and fund initiatives that align with the UN’s Sustainable Development Goals. These goals were adopted by 193 world leaders in 2015. Each of the 17 targets focus on ending extreme poverty and hunger, fighting inequality and injustice, and tackling climate change by 2030.\n\nThis IOHK-sponsored challenge hopes to promote projects based in the digitization of finance which increase the efficacy and transparency of funding for the UN’s Decade of Action. In the run-up to the 2030 deadline for achieving the global sustainability goals, the UN is marking 75 years since its establishment. Given that the transnational organization works on global collective action problems it has engaged with blockchain technology as a solution.\n\n## Crowdsourcing the future\n\nParticipants in the program can put forward ideas focused on any of the 17 goals. To encourage participation, IOHK is sponsoring a prize fund of ada worth $10,000 as well as ongoing support to bring the projects to fruition. Proposals will be judged by a panel of IOHK and UN employees. They will determine the winners based on an idea’s technical prowess, scalability and social impact, as well as its financial and volunteer support. The winning ideas will be able to seek the advice of experts from both the UN and IOHK to ensure that they are implemented in the most impactful way.\n\nTo qualify for the scheme, entries must be open source and be created for use on the Cardano blockchain. Example code should be written in Marlowe, a domain specific language developed for financial contracts on Cardano. These do not need to be fully coded submissions. Instead they can be ideas which inspire anyone to get involved with blockchain technology and sustainable development. The proposal submission period opens on Saturday October 10th. Participants must be registered by then in order to submit. Entries must be finalized by October 18 at 11:59 MDT. Make sure to check the [official rules](https://static.iohk.io/docs/IOHK_UN_challenge.pdf) to learn more.\n\nWinners will be announced on October 24, United Nations Day, which marks the anniversary of the charter of the organization. We encourage everyone with an interest in using Cardano to achieve sustainability goals to get involved. Make your voice heard to help the UN’s [Decade of Action](https://www.un.org/sustainabledevelopment/decade-of-action/) now. If you are interested more generally in developing Cardano, join Project Catalyst on [Ideascale](https://cardano.ideascale.com/).\n\n<!--EndFragment-->\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Developer challenge: using blockchain to support the UN’s sustainable development goals',
                                subtitle: 'IOHK has set up a $10,000 fund to invest in ideas for sustainable development based on Cardano.',
                                audio: null,
                                soundcloud: null,
                                body_content: '<!--StartFragment-->\n\nCreating a decentralized financial and social operating system for the world is the core mission of Cardano. But it’s not one that we can accomplish alone. That’s why we are always on the lookout for relationships which help us build a global foundation for growth. So, we’re thrilled to announce our hackathon challenge to support the UN’s sustainable development goals (SDGs) designed to accelerate progress on fighting hunger, injustice, and climate change.\n\n## Sustainability and blockchain\n\nIn this hackathon challenge we aim to give the blockchain community an opportunity to make an impact on international development. The challenge will draw on IOHK’s expertise in community-focused funding developed with Project Catalyst. This initiative brings innovation, voting, and decentralized funding to Cardano by crowdsourcing development proposals, and financing their implementation.\n\nIOHK and United Nations personnel will use the Project Catalyst platform to find and fund initiatives that align with the UN’s Sustainable Development Goals. These goals were adopted by 193 world leaders in 2015. Each of the 17 targets focus on ending extreme poverty and hunger, fighting inequality and injustice, and tackling climate change by 2030.\n\nThis IOHK-sponsored challenge hopes to promote projects based in the digitization of finance which increase the efficacy and transparency of funding for the UN’s Decade of Action. In the run-up to the 2030 deadline for achieving the global sustainability goals, the UN is marking 75 years since its establishment. Given that the transnational organization works on global collective action problems it has engaged with blockchain technology as a solution.\n\n## Crowdsourcing the future\n\nParticipants in the program can put forward ideas focused on any of the 17 goals. To encourage participation, IOHK is sponsoring a prize fund of ada worth $10,000 as well as ongoing support to bring the projects to fruition. Proposals will be judged by a panel of IOHK and UN employees. They will determine the winners based on an idea’s technical prowess, scalability and social impact, as well as its financial and volunteer support. The winning ideas will be able to seek the advice of experts from both the UN and IOHK to ensure that they are implemented in the most impactful way.\n\nTo qualify for the scheme, entries must be open source and be created for use on the Cardano blockchain. Example code should be written in Marlowe, a domain specific language developed for financial contracts on Cardano. These do not need to be fully coded submissions. Instead they can be ideas which inspire anyone to get involved with blockchain technology and sustainable development. The proposal submission period opens on Saturday October 10th. Participants must be registered by then in order to submit. Entries must be finalized by October 18 at 11:59 MDT. Make sure to check the [official rules](https://static.iohk.io/docs/IOHK_UN_challenge.pdf) to learn more.\n\nWinners will be announced on October 24, United Nations Day, which marks the anniversary of the charter of the organization. We encourage everyone with an interest in using Cardano to achieve sustainability goals to get involved. Make your voice heard to help the UN’s [Decade of Action](https://www.un.org/sustainabledevelopment/decade-of-action/) now. If you are interested more generally in developing Cardano, join Project Catalyst on [Ideascale](https://cardano.ideascale.com/).\n\n<!--EndFragment-->\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'united-nations-and-iohk-join-forces-to-use-blockchain-for-development-goals',
                                url: '/blog/posts/2020/10/06/united-nations-and-iohk-join-forces-to-use-blockchain-for-development-goals/',
                                read_time: 3
                            },
                            {
                                publish_date: '2020-06-30T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/2f814404-79f8-4459-86d4-f0199e4ecfe1/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Bringing the community together for the Cardano Virtual Summit 2020: Shelley Edition',
                                        subtitle: 'Celebrating the journey and making way for the future with IOHK',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: '<!--StartFragment-->\n\nShelley has arrived and IOHK is gearing up to celebrate with the [Cardano Virtual Summit 2020: Shelley Edition](https://cardanosummit.iohk.io/) on July 2nd and 3rd. Every presentation, panel and guest speaker at this online event, has been chosen to represent the many faces of Cardano. From world-class foundational research to the latest advances in cryptographic development; from the passion and dedication of the wider community to some of the innovators who have created our world and are lighting the path to the future. The event is meant to honor the hard work and dedication of the Cardano community, developers and contributors, and the wider ecosystem.\n\nThe virtual summit, much like IOHK’s 2019 Miami summit will include presentations from IOHK team members, special guest appearances by thought leaders and a keynote speech by IOHK CEO, Charles Hoskinson. We were proud to announce that our guest of honor is internet co-creator and lead internet evangelist for Google, Vint Cerf. As one of the lead architects of the internet Vint is uniquely positioned to give us insight into building world changing technology.\n\nWe’ll also be joined by Caitlin Long of the Wyoming Blockchain Select Committee. The Wall Street professional turned crypto pioneer has been blazing the trail for adoption in the state of Wyoming. She will give us a look at the challenges and opportunities she has faced while pushing for wider adoption of decentralization. Our final special guest, Stephen Wolfram is the creator of the computational knowledge platform Wolfram Alpha and the CEO of Wolfram Research. Cardano shares his dedication to advancing technology through open source research and a commitment to academic excellence. Between each of these important discussions our colleagues at IOHK will take center stage.\n\n## Thought leadership\n\nIOHK’s chief scientist, Aggelos Kiayias, and director of African operations John O’Connor will talk about research and outreach in the Cardano Blockchain. Our panel entitled ‘Haskell, then, now, and the future’ will examine the impact the functional programming language has had and where it is heading. The virtual summit also serves as the launchpad for new advancements like ‘Prism’ our decentralized identity solution. More guest speakers will be announced over the week ahead and we’ll also have a number of special announcements over the 2-day summit itself; we’re keeping those under our hats until then.\n\nThe two day [agenda](https://cardanosummit.iohk.io/images/virtual-summit-agenda.pdf) includes five digital stages with programs dedicated to the ideology of blockchain technology; the science of decentralization, and building distributed ledgers for business and enterprise. We will be discussing next steps for growing the Cardano community alongside oncoming blockchain regulations, governance, and opportunities. In combination, we hope the summit tracks will offer something for anyone interested in the future of Cardano, by the science and ideas that surround it, by the great minds making it all happen and by the incredible community that has brought us here and will take us forward.\n\nSessions will encompass the philosophical as well as the technical. Brian Behlendorf, the CEO of the Hyperledger Consortium will form part of a panel focused on the importance of open source development. IOHK recently [joined](https://iohk.io/en/blog/posts/2020/06/11/why-we-are-joining-hyperledger/) the Hyperledger Consortium, to better exploit our common vision of a future made better through shared knowledge. Following on the philosophy track, artificial intelligence researcher, Ben Goertzel will speak on the intersection of AI and decentralized technology. We hope to announce more exciting sessions in the days leading up to the event. At the end of the day, building the next generation of technology means bringing the best minds of many fields into the same room, even if it’s a virtual one.\n\n## Building community\n\nThe Cardano Virtual Summit 2020: Shelley Edition, won’t be all work and no play. The Covid crisis has forced every conference online in past months. While we can’t recreate the full physical conference experience in the virtual space, we’re keen to provide some of the networking and downtime opportunities you might expect. So we’ve added a virtual ‘chill-out’ zone, with guided meditations, a DJ set, and even an online calligraphy lesson/demonstration. Our virtual platform will allow attendees to enjoy the digital expo space through avatars. We’ll even get the conversation flowing with a digital Shelley cocktail ‘happy hour’ between meetings.\n\nRecent events have made it difficult to meet in person but we see The Cardano Virtual Summit as an opportunity to invite everyone from around the world to participate. Attendance for anyone interested in the summit is absolutely free of charge. To join in, simply [reserve](https://www.ubivent.com/register/cardanovirtualsummit) your spot.\n\nShelley is the culmination of over 5 years of research and development, the creation of a multi-disciplinary team and a remarkable community. The virtual summit is just a single point of time – a time to take stock, reflect and celebrate. But it marks just the start of a groundbreaking new era of decentralization, growth and adoption.\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Bringing the community together for the Cardano Virtual Summit 2020: Shelley Edition',
                                subtitle: 'Celebrating the journey and making way for the future with IOHK',
                                audio: null,
                                soundcloud: null,
                                body_content: '<!--StartFragment-->\n\nShelley has arrived and IOHK is gearing up to celebrate with the [Cardano Virtual Summit 2020: Shelley Edition](https://cardanosummit.iohk.io/) on July 2nd and 3rd. Every presentation, panel and guest speaker at this online event, has been chosen to represent the many faces of Cardano. From world-class foundational research to the latest advances in cryptographic development; from the passion and dedication of the wider community to some of the innovators who have created our world and are lighting the path to the future. The event is meant to honor the hard work and dedication of the Cardano community, developers and contributors, and the wider ecosystem.\n\nThe virtual summit, much like IOHK’s 2019 Miami summit will include presentations from IOHK team members, special guest appearances by thought leaders and a keynote speech by IOHK CEO, Charles Hoskinson. We were proud to announce that our guest of honor is internet co-creator and lead internet evangelist for Google, Vint Cerf. As one of the lead architects of the internet Vint is uniquely positioned to give us insight into building world changing technology.\n\nWe’ll also be joined by Caitlin Long of the Wyoming Blockchain Select Committee. The Wall Street professional turned crypto pioneer has been blazing the trail for adoption in the state of Wyoming. She will give us a look at the challenges and opportunities she has faced while pushing for wider adoption of decentralization. Our final special guest, Stephen Wolfram is the creator of the computational knowledge platform Wolfram Alpha and the CEO of Wolfram Research. Cardano shares his dedication to advancing technology through open source research and a commitment to academic excellence. Between each of these important discussions our colleagues at IOHK will take center stage.\n\n## Thought leadership\n\nIOHK’s chief scientist, Aggelos Kiayias, and director of African operations John O’Connor will talk about research and outreach in the Cardano Blockchain. Our panel entitled ‘Haskell, then, now, and the future’ will examine the impact the functional programming language has had and where it is heading. The virtual summit also serves as the launchpad for new advancements like ‘Prism’ our decentralized identity solution. More guest speakers will be announced over the week ahead and we’ll also have a number of special announcements over the 2-day summit itself; we’re keeping those under our hats until then.\n\nThe two day [agenda](https://cardanosummit.iohk.io/images/virtual-summit-agenda.pdf) includes five digital stages with programs dedicated to the ideology of blockchain technology; the science of decentralization, and building distributed ledgers for business and enterprise. We will be discussing next steps for growing the Cardano community alongside oncoming blockchain regulations, governance, and opportunities. In combination, we hope the summit tracks will offer something for anyone interested in the future of Cardano, by the science and ideas that surround it, by the great minds making it all happen and by the incredible community that has brought us here and will take us forward.\n\nSessions will encompass the philosophical as well as the technical. Brian Behlendorf, the CEO of the Hyperledger Consortium will form part of a panel focused on the importance of open source development. IOHK recently [joined](https://iohk.io/en/blog/posts/2020/06/11/why-we-are-joining-hyperledger/) the Hyperledger Consortium, to better exploit our common vision of a future made better through shared knowledge. Following on the philosophy track, artificial intelligence researcher, Ben Goertzel will speak on the intersection of AI and decentralized technology. We hope to announce more exciting sessions in the days leading up to the event. At the end of the day, building the next generation of technology means bringing the best minds of many fields into the same room, even if it’s a virtual one.\n\n## Building community\n\nThe Cardano Virtual Summit 2020: Shelley Edition, won’t be all work and no play. The Covid crisis has forced every conference online in past months. While we can’t recreate the full physical conference experience in the virtual space, we’re keen to provide some of the networking and downtime opportunities you might expect. So we’ve added a virtual ‘chill-out’ zone, with guided meditations, a DJ set, and even an online calligraphy lesson/demonstration. Our virtual platform will allow attendees to enjoy the digital expo space through avatars. We’ll even get the conversation flowing with a digital Shelley cocktail ‘happy hour’ between meetings.\n\nRecent events have made it difficult to meet in person but we see The Cardano Virtual Summit as an opportunity to invite everyone from around the world to participate. Attendance for anyone interested in the summit is absolutely free of charge. To join in, simply [reserve](https://www.ubivent.com/register/cardanovirtualsummit) your spot.\n\nShelley is the culmination of over 5 years of research and development, the creation of a multi-disciplinary team and a remarkable community. The virtual summit is just a single point of time – a time to take stock, reflect and celebrate. But it marks just the start of a groundbreaking new era of decentralization, growth and adoption.\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'bringing-the-community-together-for-the-cardano-virtual-summit-2020-shelley-edition',
                                url: '/blog/posts/2020/06/30/bringing-the-community-together-for-the-cardano-virtual-summit-2020-shelley-edition/',
                                read_time: 4
                            },
                            {
                                publish_date: '2020-06-15T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/d7ff7981-5871-4a03-b7e9-2cc8765843a5/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Integrating and advancing with Adrestia',
                                        subtitle: 'Taking the challenge out of fast-paced blockchain development',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: '<!--StartFragment-->\n\nFor exchanges and developer partners, integrating with any blockchain can be challenging. The technology often moves so quickly that keeping up with the pace of change can be unrealistic. Cardano’s development and release process are now driving things forward apace. Managing parallel software development workstreams moving at different speeds can feel a bit like changing the tires on a truck while it’s driving at 60 miles per hour. \n\nCardano’s vision is to provide unparalleled security and sustainability to decentralized applications, systems, and societies. It has been created to be the most technologically advanced and environmentally sustainable blockchain platform, offering a secure, transparent, and scalable template for how we work, interact, and create, as individuals, businesses, and societies.\n\nIn line with these ambitions, we needed to devise a way that our partners could swiftly, easily and reliably integrate with Cardano, regardless of what was going on under the hood. Whatever the pace and cadence of future rollouts, we wanted to develop a consistent method by which all updates to the core node could be easily adopted by everyone.\n\nIn order to make that integration and interaction with Cardano easier and faster, IOHK engineers formed the Adrestia team, to take responsibility for building all the web APIs and libraries that make Cardano accessible to developers and application builders. Developments to the node can then focus on performance and scalability, while users will always be able to interact with it effortlessly. The name Adrestia was chosen after the goddess of revolt because with these new interfaces we expect everyone to be able to integrate with Cardano, creating a ‘revolution’ in accessibility.\n\n## Enabling developers to keep pace with change\n\nThe goal of the Adrestia team is to provide – via Web APIs – a consistent integration experience so that developers can know what to expect between Cardano roadmap releases. Whether they are a wallet developer or an exchange, users can flexibly explore the chain, make transactions and more.\n\nThe APIs are as follows:\n\n* cardano-wallet: HTTP ReST API for managing UTXOs, and much more.\n* cardano-submit-api: HTTP API for submitting signed transactions.\n* cardano-graphql: HTTP GraphQL API for exploring the blockchain.\n\nThe SDK consists of several low-level libraries:\n\n* cardano-addresses: Address generation, derivation & mnemonic manipulation.\n* cardano-coin-selection: Algorithms for coin selection and fee balancing.\n* cardano-transactions: Utilities for constructing and signing transactions.\n* bech32: Haskell implementation of the Bech32 address format (BIP 0173).\n\nIn addition to providing a flexible and productive way to integrate with Cardano, maintenance is also made easier. With consistency, it can often require less time to update integrations between releases. This familiarity reduces maintenance costs. New software can then deploy in days rather than weeks. Ultimately, anyone can keep pace with change.\n\n## Get Started\n\nThe results are now live in the Byron era of Cardano. Exchanges or third-party wallets using Cardano-SL, should now be integrating to prepare for the new Byron and upgrading to Shelley wallet. These need to happen consecutively to avoid any outages. Full details have been added to the Adrestia team repo and we continue to work with our partners to ensure there is no interruption in service for ada holders keeping their funds on exchanges or in third-party wallets. The chart below shows the difference between the Cardano-SL node and the upcoming Shelley node. The components in red are non-Shelley compatible and will break after the hard fork, while the other components are Shelley compatible and will be supported during and after the hard fork.\n\n![](https://lh5.googleusercontent.com/j_lrO83Ixg29ne93vH3dhw3qnHBGhuPcZcUG36ZCCqK9sV5V5WCPf1VoUh2XH9khEeVxFJGpZb3eBlEgw4aQX6Ejyk3tMta4ARVXrQOE9bQQcsBbWM40xPDbSvEkUrvd2vE2EFUv)\n\nConsistency is key in creating a blockchain network that works for everyone. Cardano is not being built for the next five or ten years, but for the next fifty. Change to the system is inevitable in that time but Adrestia was made to ensure that everyone can connect with the Cardano node. To get started, check out the Adrestia project [repo](https://github.com/input-output-hk/adrestia) and read the[ user guide](https://input-output-hk.github.io/adrestia/).\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Integrating and advancing with Adrestia',
                                subtitle: 'Taking the challenge out of fast-paced blockchain development',
                                audio: null,
                                soundcloud: null,
                                body_content: '<!--StartFragment-->\n\nFor exchanges and developer partners, integrating with any blockchain can be challenging. The technology often moves so quickly that keeping up with the pace of change can be unrealistic. Cardano’s development and release process are now driving things forward apace. Managing parallel software development workstreams moving at different speeds can feel a bit like changing the tires on a truck while it’s driving at 60 miles per hour. \n\nCardano’s vision is to provide unparalleled security and sustainability to decentralized applications, systems, and societies. It has been created to be the most technologically advanced and environmentally sustainable blockchain platform, offering a secure, transparent, and scalable template for how we work, interact, and create, as individuals, businesses, and societies.\n\nIn line with these ambitions, we needed to devise a way that our partners could swiftly, easily and reliably integrate with Cardano, regardless of what was going on under the hood. Whatever the pace and cadence of future rollouts, we wanted to develop a consistent method by which all updates to the core node could be easily adopted by everyone.\n\nIn order to make that integration and interaction with Cardano easier and faster, IOHK engineers formed the Adrestia team, to take responsibility for building all the web APIs and libraries that make Cardano accessible to developers and application builders. Developments to the node can then focus on performance and scalability, while users will always be able to interact with it effortlessly. The name Adrestia was chosen after the goddess of revolt because with these new interfaces we expect everyone to be able to integrate with Cardano, creating a ‘revolution’ in accessibility.\n\n## Enabling developers to keep pace with change\n\nThe goal of the Adrestia team is to provide – via Web APIs – a consistent integration experience so that developers can know what to expect between Cardano roadmap releases. Whether they are a wallet developer or an exchange, users can flexibly explore the chain, make transactions and more.\n\nThe APIs are as follows:\n\n* cardano-wallet: HTTP ReST API for managing UTXOs, and much more.\n* cardano-submit-api: HTTP API for submitting signed transactions.\n* cardano-graphql: HTTP GraphQL API for exploring the blockchain.\n\nThe SDK consists of several low-level libraries:\n\n* cardano-addresses: Address generation, derivation & mnemonic manipulation.\n* cardano-coin-selection: Algorithms for coin selection and fee balancing.\n* cardano-transactions: Utilities for constructing and signing transactions.\n* bech32: Haskell implementation of the Bech32 address format (BIP 0173).\n\nIn addition to providing a flexible and productive way to integrate with Cardano, maintenance is also made easier. With consistency, it can often require less time to update integrations between releases. This familiarity reduces maintenance costs. New software can then deploy in days rather than weeks. Ultimately, anyone can keep pace with change.\n\n## Get Started\n\nThe results are now live in the Byron era of Cardano. Exchanges or third-party wallets using Cardano-SL, should now be integrating to prepare for the new Byron and upgrading to Shelley wallet. These need to happen consecutively to avoid any outages. Full details have been added to the Adrestia team repo and we continue to work with our partners to ensure there is no interruption in service for ada holders keeping their funds on exchanges or in third-party wallets. The chart below shows the difference between the Cardano-SL node and the upcoming Shelley node. The components in red are non-Shelley compatible and will break after the hard fork, while the other components are Shelley compatible and will be supported during and after the hard fork.\n\n![](https://lh5.googleusercontent.com/j_lrO83Ixg29ne93vH3dhw3qnHBGhuPcZcUG36ZCCqK9sV5V5WCPf1VoUh2XH9khEeVxFJGpZb3eBlEgw4aQX6Ejyk3tMta4ARVXrQOE9bQQcsBbWM40xPDbSvEkUrvd2vE2EFUv)\n\nConsistency is key in creating a blockchain network that works for everyone. Cardano is not being built for the next five or ten years, but for the next fifty. Change to the system is inevitable in that time but Adrestia was made to ensure that everyone can connect with the Cardano node. To get started, check out the Adrestia project [repo](https://github.com/input-output-hk/adrestia) and read the[ user guide](https://input-output-hk.github.io/adrestia/).\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'integrating-and-advancing-with-adrestia',
                                url: '/blog/posts/2020/06/15/integrating-and-advancing-with-adrestia/',
                                read_time: 4
                            },
                            {
                                publish_date: '2020-04-07',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/7ff3d68c-a443-44ae-b104-a74a1a686d78/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Architecting Shelley: an interview with Duncan Coutts',
                                        subtitle: 'A fireside chat with Duncan Coutts, Cardano\'s chief technical architect, about Haskell and delivering Shelley',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'Duncan Coutts has been an important guide on the road to the Cardano Shelley mainnet. Long time supporters of IOHK are likely familiar with his signature long hair, beard, and penchant for drinking tea while discussing decentralization in front of a [white board](https://www.youtube.com/watch?v=TZGVgNsJSnA&t=572s). He recently sat down for an interview to discuss the upcoming Byron reboot, the Haskell Shelley testnet, and the conclusion of the pre-Shelley development cycle. Coutts, who has been working with IOHK since 2016, brings a wealth of knowledge from working with the Haskell programming language for nearly 20 years and helping found the Well-Typed consultancy.\n\n**What’s your role at IOHK?**\n\nI’m the chief technical architect for the Cardano project and I’m primarily responsible for the design and implementation of the node. This means that I collaborate with the teams that work on consensus, ledger, networking, and other things. Ultimately, I work to bring everyone together around the same design after a discussion with the team leaders. The design of Cardano is the product of joint work by many individuals working together.\n\n**What does the Haskell programming language bring to Cardano?**\n\nHaskell is an enabler. It makes it easier for us to follow the approach that we believe is right, which is driven by computer science. We know how to do things properly; computer science tells us how. We just need to pick the appropriate techniques to do that. Haskell makes that easier.\n\nIt’s a good fit for Cardano because it suits the high-assurance, specification-driven software that is vital for a blockchain. Haskell helps us find systematic ways of avoiding mistakes. In essence, it’s a better mousetrap.\n\n**You’ve been working with Haskell for a long time. How have you seen the landscape of functional programming change?**\n\nPeople take it seriously now. When I started as an undergraduate in 1999, I thought that Haskell was amazing. Other students thought, ‘Wow that’s totally impractical. How will you ever get a job?’\n\nAt the time, functional programming was an academic curiosity. There wasn’t any prebuilt code and it wasn’t machine readable, which meant that Haskell wasn’t usable for a wide range of people. There wasn’t the tooling, range of libraries, or experience. That has changed over the years: the tooling got better, the libraries got better. IOHK has helped develop the infrastructure for building and distributing open-source Haskell code and the number of libraries exploded. That, combined with more teaching and a gradual change of attitude in the industry, means that people take it more seriously now. Haskell hasn’t changed as much as the industry around us has.\n\n**What’s the biggest change from an industry point of view?**\n\nThere are two things. The first is that attitudes are changing, albeit slowly. People are changing their opinions about what they consider a sensible language choice. Previously, everything had to be in C or Java or maybe Python, but eventually good ideas make progress, even if it takes a long time. You can make a lot of progress by just recognizing that a good idea is a good idea. The mainstream does pick up on important developments, even if it does take 10 or 15 years. The industry has not embraced functional programming wholesale yet, but individual programmers have taken up various ideas. That makes Haskell look less radical.\n\nIf you look at a language like Rust, it has some of the clever type systems of Haskell, although it doesn’t have any functional programming ideas. Even Java and C++ have some functional programming ideas in them these days, so Haskell is not quite so far from the mainstream as it used to be.\n\nThe second major change has been performance, which is getting much better. We’ve recently become competitive with Java in terms of performance. It makes people say, ‘Wow, Haskell is so fast,’ but that’s because they’re comparing it to Python and PHP rather than C. So that’s another way of saying that Haskell has improved slightly, but the industry environment around it has changed as well.\n\n**You have been heavily involved in the Byron reboot which was kicked off last week. Why was this work important?**\n\nThe [Byron reboot](https://iohk.io/en/blog/posts/2020/03/30/what-the-byron-reboot-means-for-cardano/) is the culmination of over 18 months of hard work across multiple IOHK development teams, and constitutes a complete overhaul of the node infrastructure with 100% fresh code. The reboot introduces an extensible, modular design within the node itself, separating out the ledger, consensus, and networking components, as well as improvements and new functionality in the wallet backend and the Cardano explorer.\n\nFor Daedalus users, the Byron reboot will see us moving to a regular update cadence [see our recent piece on [Daedalus Flight](https://iohk.io/en/blog/posts/2020/04/01/we-need-you-for-the-daedalus-flight-testing-program/) for more on that], after which they should find that Daedalus is faster, more reliable, and uses less memory. A lot of the issues users have experienced with Daedalus in the past were due to the underlying node, rather than Daedalus itself. The Byron reboot will go a long way to improving things, and users should see Daedalus syncing and restoring wallets within minutes, even when downloading the entire Cardano blockchain.\n\n**As the chief architect, your job is to lay the foundation for Cardano’s future. What have you focused on to achieve this?**\n\nThe most important aspect in terms of flexibility for the future is keeping different functions separate. One of the big improvements of the Byron reboot is that the ledger rules will be totally independent of the consensus implementation; this modularity means that the ledger rules are perfectly clean mathematical functions, which is a core aspect of functional programming.\n\nAs a result, everything is easier to test, tweak, and change, both now and in the future. The consensus algorithm isn’t entangled with the details of the ledger rules, so we can alter the ledger rules without changing the consensus implementation. This makes integrating Plutus and smart contracts functionality much easier and will also help in the future when we are adding treasury and governance features.\n\nThe consensus implementation itself has also been parameterized so that we can transition from the Ouroboros Classic consensus protocol to BFT and then Praos, which also provides flexibility for future versions of the protocol that haven\'t been developed yet.\n\n**Shelley is a big step towards the future of Cardano, but what is the significance of compiling Haskell into JavaScript and WebAssembly?**\n\nWe’re interested in compiling to JavaScript or WebAssembly because of Plutus. We want to have Plutus contracts or Plutus applications that can be distributed to users, which would include custom interfaces and custom logic with the user rather than in a server. Compiling to JavaScript allows us to do that; you can compile the Plutus code once and distribute it to users on different platforms.\n\n- - -\n\nThanks to Duncan Coutts for his time. As chief technical architect, he’s a cornerstone of the Cardano project and has been fundamental to the ongoing success of the platform. For more interviews with the team, stay tuned to our social channels and the IOHK blog.',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Architecting Shelley: an interview with Duncan Coutts',
                                subtitle: 'A fireside chat with Duncan Coutts, Cardano\'s chief technical architect, about Haskell and delivering Shelley',
                                audio: null,
                                soundcloud: null,
                                body_content: 'Duncan Coutts has been an important guide on the road to the Cardano Shelley mainnet. Long time supporters of IOHK are likely familiar with his signature long hair, beard, and penchant for drinking tea while discussing decentralization in front of a [white board](https://www.youtube.com/watch?v=TZGVgNsJSnA&t=572s). He recently sat down for an interview to discuss the upcoming Byron reboot, the Haskell Shelley testnet, and the conclusion of the pre-Shelley development cycle. Coutts, who has been working with IOHK since 2016, brings a wealth of knowledge from working with the Haskell programming language for nearly 20 years and helping found the Well-Typed consultancy.\n\n**What’s your role at IOHK?**\n\nI’m the chief technical architect for the Cardano project and I’m primarily responsible for the design and implementation of the node. This means that I collaborate with the teams that work on consensus, ledger, networking, and other things. Ultimately, I work to bring everyone together around the same design after a discussion with the team leaders. The design of Cardano is the product of joint work by many individuals working together.\n\n**What does the Haskell programming language bring to Cardano?**\n\nHaskell is an enabler. It makes it easier for us to follow the approach that we believe is right, which is driven by computer science. We know how to do things properly; computer science tells us how. We just need to pick the appropriate techniques to do that. Haskell makes that easier.\n\nIt’s a good fit for Cardano because it suits the high-assurance, specification-driven software that is vital for a blockchain. Haskell helps us find systematic ways of avoiding mistakes. In essence, it’s a better mousetrap.\n\n**You’ve been working with Haskell for a long time. How have you seen the landscape of functional programming change?**\n\nPeople take it seriously now. When I started as an undergraduate in 1999, I thought that Haskell was amazing. Other students thought, ‘Wow that’s totally impractical. How will you ever get a job?’\n\nAt the time, functional programming was an academic curiosity. There wasn’t any prebuilt code and it wasn’t machine readable, which meant that Haskell wasn’t usable for a wide range of people. There wasn’t the tooling, range of libraries, or experience. That has changed over the years: the tooling got better, the libraries got better. IOHK has helped develop the infrastructure for building and distributing open-source Haskell code and the number of libraries exploded. That, combined with more teaching and a gradual change of attitude in the industry, means that people take it more seriously now. Haskell hasn’t changed as much as the industry around us has.\n\n**What’s the biggest change from an industry point of view?**\n\nThere are two things. The first is that attitudes are changing, albeit slowly. People are changing their opinions about what they consider a sensible language choice. Previously, everything had to be in C or Java or maybe Python, but eventually good ideas make progress, even if it takes a long time. You can make a lot of progress by just recognizing that a good idea is a good idea. The mainstream does pick up on important developments, even if it does take 10 or 15 years. The industry has not embraced functional programming wholesale yet, but individual programmers have taken up various ideas. That makes Haskell look less radical.\n\nIf you look at a language like Rust, it has some of the clever type systems of Haskell, although it doesn’t have any functional programming ideas. Even Java and C++ have some functional programming ideas in them these days, so Haskell is not quite so far from the mainstream as it used to be.\n\nThe second major change has been performance, which is getting much better. We’ve recently become competitive with Java in terms of performance. It makes people say, ‘Wow, Haskell is so fast,’ but that’s because they’re comparing it to Python and PHP rather than C. So that’s another way of saying that Haskell has improved slightly, but the industry environment around it has changed as well.\n\n**You have been heavily involved in the Byron reboot which was kicked off last week. Why was this work important?**\n\nThe [Byron reboot](https://iohk.io/en/blog/posts/2020/03/30/what-the-byron-reboot-means-for-cardano/) is the culmination of over 18 months of hard work across multiple IOHK development teams, and constitutes a complete overhaul of the node infrastructure with 100% fresh code. The reboot introduces an extensible, modular design within the node itself, separating out the ledger, consensus, and networking components, as well as improvements and new functionality in the wallet backend and the Cardano explorer.\n\nFor Daedalus users, the Byron reboot will see us moving to a regular update cadence [see our recent piece on [Daedalus Flight](https://iohk.io/en/blog/posts/2020/04/01/we-need-you-for-the-daedalus-flight-testing-program/) for more on that], after which they should find that Daedalus is faster, more reliable, and uses less memory. A lot of the issues users have experienced with Daedalus in the past were due to the underlying node, rather than Daedalus itself. The Byron reboot will go a long way to improving things, and users should see Daedalus syncing and restoring wallets within minutes, even when downloading the entire Cardano blockchain.\n\n**As the chief architect, your job is to lay the foundation for Cardano’s future. What have you focused on to achieve this?**\n\nThe most important aspect in terms of flexibility for the future is keeping different functions separate. One of the big improvements of the Byron reboot is that the ledger rules will be totally independent of the consensus implementation; this modularity means that the ledger rules are perfectly clean mathematical functions, which is a core aspect of functional programming.\n\nAs a result, everything is easier to test, tweak, and change, both now and in the future. The consensus algorithm isn’t entangled with the details of the ledger rules, so we can alter the ledger rules without changing the consensus implementation. This makes integrating Plutus and smart contracts functionality much easier and will also help in the future when we are adding treasury and governance features.\n\nThe consensus implementation itself has also been parameterized so that we can transition from the Ouroboros Classic consensus protocol to BFT and then Praos, which also provides flexibility for future versions of the protocol that haven\'t been developed yet.\n\n**Shelley is a big step towards the future of Cardano, but what is the significance of compiling Haskell into JavaScript and WebAssembly?**\n\nWe’re interested in compiling to JavaScript or WebAssembly because of Plutus. We want to have Plutus contracts or Plutus applications that can be distributed to users, which would include custom interfaces and custom logic with the user rather than in a server. Compiling to JavaScript allows us to do that; you can compile the Plutus code once and distribute it to users on different platforms.\n\n- - -\n\nThanks to Duncan Coutts for his time. As chief technical architect, he’s a cornerstone of the Cardano project and has been fundamental to the ongoing success of the platform. For more interviews with the team, stay tuned to our social channels and the IOHK blog.',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'architecting-shelley-an-interview-with-duncan-coutts-1',
                                url: '/blog/posts/2020/04/07/architecting-shelley-an-interview-with-duncan-coutts-1/',
                                read_time: 6
                            },
                            {
                                publish_date: '2019-09-20',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/fc951213-a949-471f-95a8-b10bd350d2e7/',
                                custom_meta_img: null,
                                old_url: '/blog/plutus-and-marlowe-in-spotlight-at-wyohackathon-2019/',
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Plutus and Marlowe in the spotlight at WyoHackathon 2019',
                                        subtitle: 'Plutus and Marlowe, IOHK\'s smart contract programming languages, will have their next generations released at the 2019 WyoHackathon',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'The Cardano network was engineered to be the best possible foundation for the future of decentralized technology – but a foundation is only as good as what can be built upon it. Smart contracts are one of the most powerful ways a distributed network can generate value, allowing individuals and organizations to agree to conditions and automatically execute exchanges of information and wealth, all in a trustless way without relying on third parties. But smart contracts are still code, which means that the languages and tools they’re written with make a difference to their final level of security, efficiency, and reliability.\n\nThat said, understanding the potential of smart contracts is different from realizing their integration and adoption. Existing smart contract languages provide the basis for a solution, but are not the final answer. Current smart contracts are complex and difficult to program, partly because they’re built with languages created at the emergence of distributed technologies, and are vulnerable to malicious actors. Blockchain technology has changed drastically since it first emerged, and the conditions that underpinned the first languages are no longer true. The first answer to a problem is rarely the best, and any enterprise-focused solution cannot be gated by complexity or threaten network security.\n\n## Bringing functional programming to smart contracts with Plutus\n\nWe’re big fans of functional programming here at IOHK and are proud to be able to say that the code underpinning the Cardano network is written in Haskell, the world’s foremost functional programming language. Plutus is no different. Compared to their object-oriented counterparts, functional programming languages are less prone to ambiguity and human error – always a good thing – as well as being easier to verify and test. By using Plutus to write smart contracts on the Cardano network, developers benefit from all of the above, as well as the ability to use the same language for both on and off-chain code.\n\nWhile developers will have to wait for the Goguen era to launch smart contracts on the Cardano network, they can begin testing their smart contract skills in the [Plutus Playground](https://testnet.iohkdev.io/plutus/tools/playground/ "Plutus Playground, testnet.iohkdev.io"). IOHK has also created a [Plutus ebook](https://www.amazon.co.uk/Plutus-Writing-reliable-smart-contracts-ebook/dp/B07V46LWTW "Plutus ebook, amazon.com") and [Udemy course](https://www.udemy.com/course/plutus-reliable-smart-contracts/ "Plutus Udemy course, udemy.com") to help developers hit the ground running once Plutus is available on the Cardano mainnet.\n\n## And bringing Plutus to everyone with Marlowe\n\nThe problem with smart contracts, however, is that sometimes the people who know how to write the code don’t have the industry expertise to know how to structure the contracts themselves. Enter Marlowe, IOHK’s domain-specific language (DSL). Marlowe is designed for use by anyone that wants to write a financial smart contract without the programming skills to implement it. Users can try out Marlowe via the [Marlowe Playground](https://testnet.iohkdev.io/marlowe/get-started/sample-marlowe-smart-contracts/ "Marlowe Playground, testnet.iohkdev.io"), a web utility with a user-friendly GUI and drag and drop components, where they can create financial smart contracts which, when complete, will generate fully-functional, implementation-ready Plutus code.\n\nMarlowe gives anyone the ability to gain familiarity with smart contracts while protecting them from unexpected outcomes. It also protects the developer and the system by ensuring that ill-formed smart contracts cannot be run. Finally, Marlowe focuses on commitment-of-funds and time-outs. These make certain that both parties have dedicated funds in the agreement while ensuring that money will not be left in the system after a contract has concluded.\n\n## Laying solid foundations\n\nPlutus, Marlowe, and the Cardano ecosystem continue to evolve to provide the safest and most efficient conditions to build decentralized applications. The next generations of Plutus and Marlowe will be announced at the WyoHackathon at the University of Wyoming on September 20, ahead of their release on mainnet at the start of the Goguen era. Marlowe advances include a high-fidelity development system that aids the writing of executable contracts and the new iteration of Plutus will allow users to access their contracts from web or mobile applications. To get the latest news from the event, you can follow the [WyoHackathon’s Twitter feed](https://twitter.com/hashtag/wyohackathon?lang=en "#wyohackathon, twitter.com").\n\nAt IOHK, we\'re focused on creating the safest, most efficient platform for the building of decentralized applications. Plutus and Marlowe will be the first building blocks to be placed on the foundation which is the Cardano network – and they won\'t be the last. With this new suite of accessible, inclusive tools, Cardano becomes more capable of serving the diverse audiences that stand to benefit from a secure, decentralized network platform.\n\n<small>Artwork, [<i class="fa fa-creative-commons" aria-hidden="true"></i>](https://creativecommons.org/licenses/by/4.0/ "Creative Commons") [Stephen Walker](https://unsplash.com/photos/297SaBStwnQ)</small>\n',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Plutus and Marlowe in the spotlight at WyoHackathon 2019',
                                subtitle: 'Plutus and Marlowe, IOHK\'s smart contract programming languages, will have their next generations released at the 2019 WyoHackathon',
                                audio: null,
                                soundcloud: null,
                                body_content: 'The Cardano network was engineered to be the best possible foundation for the future of decentralized technology – but a foundation is only as good as what can be built upon it. Smart contracts are one of the most powerful ways a distributed network can generate value, allowing individuals and organizations to agree to conditions and automatically execute exchanges of information and wealth, all in a trustless way without relying on third parties. But smart contracts are still code, which means that the languages and tools they’re written with make a difference to their final level of security, efficiency, and reliability.\n\nThat said, understanding the potential of smart contracts is different from realizing their integration and adoption. Existing smart contract languages provide the basis for a solution, but are not the final answer. Current smart contracts are complex and difficult to program, partly because they’re built with languages created at the emergence of distributed technologies, and are vulnerable to malicious actors. Blockchain technology has changed drastically since it first emerged, and the conditions that underpinned the first languages are no longer true. The first answer to a problem is rarely the best, and any enterprise-focused solution cannot be gated by complexity or threaten network security.\n\n## Bringing functional programming to smart contracts with Plutus\n\nWe’re big fans of functional programming here at IOHK and are proud to be able to say that the code underpinning the Cardano network is written in Haskell, the world’s foremost functional programming language. Plutus is no different. Compared to their object-oriented counterparts, functional programming languages are less prone to ambiguity and human error – always a good thing – as well as being easier to verify and test. By using Plutus to write smart contracts on the Cardano network, developers benefit from all of the above, as well as the ability to use the same language for both on and off-chain code.\n\nWhile developers will have to wait for the Goguen era to launch smart contracts on the Cardano network, they can begin testing their smart contract skills in the [Plutus Playground](https://testnet.iohkdev.io/plutus/tools/playground/ "Plutus Playground, testnet.iohkdev.io"). IOHK has also created a [Plutus ebook](https://www.amazon.co.uk/Plutus-Writing-reliable-smart-contracts-ebook/dp/B07V46LWTW "Plutus ebook, amazon.com") and [Udemy course](https://www.udemy.com/course/plutus-reliable-smart-contracts/ "Plutus Udemy course, udemy.com") to help developers hit the ground running once Plutus is available on the Cardano mainnet.\n\n## And bringing Plutus to everyone with Marlowe\n\nThe problem with smart contracts, however, is that sometimes the people who know how to write the code don’t have the industry expertise to know how to structure the contracts themselves. Enter Marlowe, IOHK’s domain-specific language (DSL). Marlowe is designed for use by anyone that wants to write a financial smart contract without the programming skills to implement it. Users can try out Marlowe via the [Marlowe Playground](https://testnet.iohkdev.io/marlowe/get-started/sample-marlowe-smart-contracts/ "Marlowe Playground, testnet.iohkdev.io"), a web utility with a user-friendly GUI and drag and drop components, where they can create financial smart contracts which, when complete, will generate fully-functional, implementation-ready Plutus code.\n\nMarlowe gives anyone the ability to gain familiarity with smart contracts while protecting them from unexpected outcomes. It also protects the developer and the system by ensuring that ill-formed smart contracts cannot be run. Finally, Marlowe focuses on commitment-of-funds and time-outs. These make certain that both parties have dedicated funds in the agreement while ensuring that money will not be left in the system after a contract has concluded.\n\n## Laying solid foundations\n\nPlutus, Marlowe, and the Cardano ecosystem continue to evolve to provide the safest and most efficient conditions to build decentralized applications. The next generations of Plutus and Marlowe will be announced at the WyoHackathon at the University of Wyoming on September 20, ahead of their release on mainnet at the start of the Goguen era. Marlowe advances include a high-fidelity development system that aids the writing of executable contracts and the new iteration of Plutus will allow users to access their contracts from web or mobile applications. To get the latest news from the event, you can follow the [WyoHackathon’s Twitter feed](https://twitter.com/hashtag/wyohackathon?lang=en "#wyohackathon, twitter.com").\n\nAt IOHK, we\'re focused on creating the safest, most efficient platform for the building of decentralized applications. Plutus and Marlowe will be the first building blocks to be placed on the foundation which is the Cardano network – and they won\'t be the last. With this new suite of accessible, inclusive tools, Cardano becomes more capable of serving the diverse audiences that stand to benefit from a secure, decentralized network platform.\n\n<small>Artwork, [<i class="fa fa-creative-commons" aria-hidden="true"></i>](https://creativecommons.org/licenses/by/4.0/ "Creative Commons") [Stephen Walker](https://unsplash.com/photos/297SaBStwnQ)</small>\n',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'plutus-and-marlowe-in-the-spotlight-at-wyohackathon-2019-1',
                                url: '/blog/posts/2019/09/20/plutus-and-marlowe-in-the-spotlight-at-wyohackathon-2019-1/',
                                read_time: 4
                            },
                            {
                                publish_date: '2019-09-12',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/a49c56d4-ed92-4b92-88f3-4e3a23c08186/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'IOHK brings Plutus to Wyoming\'s hackathon',
                                        subtitle: 'Cardano engineers introduce next phase of the smart contract platform to the Cowboy State',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'The state of Wyoming is famous for being part of the American frontier, but it has also established a new reputation, with blockchain pioneers blazing trails in the Cowboy State. But why Wyoming?\n\n\n\nThe blockchain revolution in Wyoming is the result of a series of laws and regulations passed within its borders. These key pieces of legislation include exemptions from money transmitting laws for virtual assets, as well as a blockchain ‘sandbox’ bill that would allow decentralized businesses to operate free from the red tape encountered elsewhere in the US. The state is also home to the Wyoming Blockchain Coalition, headed by former Wall Street corporate financier Caitlin Long, which has worked to make Wyoming the standard-bearer of blockchain in the country.\n\n\n\nIn 2018, IOHK relocated its headquarters to Wyoming to take advantage of the state’s legislative embracing of distributed ledger technology, making it the biggest decentralized company in the state. As a result, IOHK has become a nexus for developers, crypto enthusiasts, businesses, and government officials in the area. Events like the 2019 WyoHackathon bring these groups together to advance the cutting edge of blockchain innovation.\n\n‘We’re thrilled to welcome the Cardano community to this special event in IOHK’s home state,’ says Caitlin Long. The event has also inspired a group of high school students from a remote part of Wyoming to make the journey to participate in the hackathon and meet IOHK CEO, Charles Hoskinson. ‘There is something special building between the University of Wyoming computer science department and Cardano!’ she adds.\n\n\n\nThe hackathon will see hundreds of developers participating in workshops, presenting papers, and acquainting themselves with new technology. Charles Hoskinson and Cardano’s senior product manager David Esser will be among the speakers at the event, alongside prominent leaders in the blockchain industry such as Jesse Powell of Kraken and Anthony Pompliano of Morgan Creek Digital. September marks the second anniversary of the Cardano project and is a milestone for IOHK, with several major advances to Cardano being delivered. Plutus engineers Jann Müller and Michael Peyton Jones will be at the event to explain how work on Cardano is progressing to create the ideal environment for smart contract development and execution.\n\n\n\nLast but certainly not least, the next iteration of the Plutus framework will be released during the hackathon. Plutus is a functional programming language and smart contract platform that allows developers of all kinds to launch smart contracts on the Cardano network. While Ethereum paved the way for programmable blockchains, it also has some significant barriers to entry. IOHK aims to bring greater scalability, sustainability, and interoperability to the crypto sphere by allowing anyone to build on a distributed ledger. Ultimately, it is developers that will build the businesses which will solve local and international problems. Plutus was created to enable those developers, and is supported by an IOHK-created \\[programming book](https://www.amazon.com/Plutus-Writing-reliable-smart-contracts-ebook/dp/B07V46LWTW "Plutus ebook on Amazon, amazon.com").\n\n\n\nBoth Wyoming and IOHK have aligned their interests in supporting the next generation of thinkers in distributed ledger technology. Events like the hackathon help to inspire and elevate those who will build the decentralized infrastructure of the future. We hope that the 2019 WyoHackathon will be another pioneering step on the road towards better, more comprehensive adoption and use of both blockchain and crypto technology.\n\n\n\n_To find out more, check out the \\[WyoHackathon 2019 website](https://wyohackathon.io/ "WyoHackathon 2019 website, wyohackathon.io")._',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'IOHK brings Plutus to Wyoming\'s hackathon',
                                subtitle: 'Cardano engineers introduce next phase of the smart contract platform to the Cowboy State',
                                audio: null,
                                soundcloud: null,
                                body_content: 'The state of Wyoming is famous for being part of the American frontier, but it has also established a new reputation, with blockchain pioneers blazing trails in the Cowboy State. But why Wyoming?\n\n\n\nThe blockchain revolution in Wyoming is the result of a series of laws and regulations passed within its borders. These key pieces of legislation include exemptions from money transmitting laws for virtual assets, as well as a blockchain ‘sandbox’ bill that would allow decentralized businesses to operate free from the red tape encountered elsewhere in the US. The state is also home to the Wyoming Blockchain Coalition, headed by former Wall Street corporate financier Caitlin Long, which has worked to make Wyoming the standard-bearer of blockchain in the country.\n\n\n\nIn 2018, IOHK relocated its headquarters to Wyoming to take advantage of the state’s legislative embracing of distributed ledger technology, making it the biggest decentralized company in the state. As a result, IOHK has become a nexus for developers, crypto enthusiasts, businesses, and government officials in the area. Events like the 2019 WyoHackathon bring these groups together to advance the cutting edge of blockchain innovation.\n\n‘We’re thrilled to welcome the Cardano community to this special event in IOHK’s home state,’ says Caitlin Long. The event has also inspired a group of high school students from a remote part of Wyoming to make the journey to participate in the hackathon and meet IOHK CEO, Charles Hoskinson. ‘There is something special building between the University of Wyoming computer science department and Cardano!’ she adds.\n\n\n\nThe hackathon will see hundreds of developers participating in workshops, presenting papers, and acquainting themselves with new technology. Charles Hoskinson and Cardano’s senior product manager David Esser will be among the speakers at the event, alongside prominent leaders in the blockchain industry such as Jesse Powell of Kraken and Anthony Pompliano of Morgan Creek Digital. September marks the second anniversary of the Cardano project and is a milestone for IOHK, with several major advances to Cardano being delivered. Plutus engineers Jann Müller and Michael Peyton Jones will be at the event to explain how work on Cardano is progressing to create the ideal environment for smart contract development and execution.\n\n\n\nLast but certainly not least, the next iteration of the Plutus framework will be released during the hackathon. Plutus is a functional programming language and smart contract platform that allows developers of all kinds to launch smart contracts on the Cardano network. While Ethereum paved the way for programmable blockchains, it also has some significant barriers to entry. IOHK aims to bring greater scalability, sustainability, and interoperability to the crypto sphere by allowing anyone to build on a distributed ledger. Ultimately, it is developers that will build the businesses which will solve local and international problems. Plutus was created to enable those developers, and is supported by an IOHK-created \\[programming book](https://www.amazon.com/Plutus-Writing-reliable-smart-contracts-ebook/dp/B07V46LWTW "Plutus ebook on Amazon, amazon.com").\n\n\n\nBoth Wyoming and IOHK have aligned their interests in supporting the next generation of thinkers in distributed ledger technology. Events like the hackathon help to inspire and elevate those who will build the decentralized infrastructure of the future. We hope that the 2019 WyoHackathon will be another pioneering step on the road towards better, more comprehensive adoption and use of both blockchain and crypto technology.\n\n\n\n_To find out more, check out the \\[WyoHackathon 2019 website](https://wyohackathon.io/ "WyoHackathon 2019 website, wyohackathon.io")._',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'iohk-brings-plutus-to-wyomings-hackathon',
                                url: '/blog/posts/2019/09/12/iohk-brings-plutus-to-wyomings-hackathon/',
                                read_time: 3
                            },
                            {
                                publish_date: '2021-06-02T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/a654b860-da1e-415c-8eb9-0b6188229740/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Nervos partnership to build the first cross-chain bridge with Cardano',
                                        subtitle: ' Our new collab lets Cardano and Nervos token holders transmit their value across both platforms while building interoperability across the crypto space',
                                        audio: null,
                                        soundcloud: [
                                            {
                                                trackid: 1060596082
                                            }
                                        ],
                                        body_content: '<!--StartFragment-->\n\nIOHK and Nervos are teaming up to build a bridge of interoperability between Cardano and the Nervos Network. Once completed, this pioneering cross-chain bridge will enable users to transact assets between the two blockchains. The end goal is to foster greater interoperability while expanding the global reach and utility of both Nervos and Cardano.\n\n\n\nThe Nervos ‘Common Knowledge Base’ ([CKB](https://coinmarketcap.com/currencies/nervos-network/historical-data/)) is a permissionless, layer 1, open-source, proof-of-work blockchain protocol focused on creating the foundations for an interoperable universal public network. It allows any crypto asset to be kept in a secure, immutable, and permissionless environment with the added benefit of smart contracts and layer 2 scaling. \n\n\n\nNervos is developing this robust network through three key components. Together, these make up the Universal Passport, Nervos’ approach to next generation interoperability. \n\n\n\n* **PW Core** – enables developers to build applications on all chains\n* **Nervos’ Polyjuice** – an Ethereum-compatible layer that allows developers to port a smart contract from Ethereum to Nervos\n* **Force Bridge** – a trustless bridge that enables cross-chain transactions between Nervos and a spectrum of blockchains. Nervos will use Force Bridge to connect directly to Cardano, which means that users will be able to transact using their existing Cardano wallets.\n\n\n\n## Bridging blockchains with transportable tokens\n\n\n\nSo what does this mean in practice? Holders of Nervos CKByte (CKB) and ada will be able to transact both currencies interchangeably. Nervos users will also be able to take advantage of Cardano\'s native asset standard to create tokens that can be ported and used across both networks. On top of this, the bridge enables developers on both chains gain access to services and features to expand their DApp ecosystem and user bases. \n\n\n\n[Mousebelt](https://www.mousebelt.com/), a full-service blockchain accelerator, will build the bridge with financial support from Nervos. The Cardano team will contribute expertise and resources to connect Cardano to the bridge. Development work is already underway and it is expected to be completed in the next six weeks. \n\n\n\n\'Using the Force Bridge to link the Nervos Network and Cardano is especially exciting given the relationship we have already built with IOHK,\' said Kevin Wang, co-founder of Nervos. \'We have been growing our research and development partnership, but we will soon have a tangible bridge that will also showcase the power of the Force Bridge and push us further along the road to a functional and interoperable network.\'\n\n\n\nThis bridge is just part of our collaboration with Nervos. \'We share a vision of a world that works on a ‘constellation’ of interoperating blockchains,\' says Romain Pellerin, CTO at Input Output. \'We believe that academic research is also fundamental to advancing the entire crypto space. Together we will also be co-authoring academic papers to pioneer improvements to the UTXO model, explore universal accounting standards, and contribute to the future development of decentralized technology through open-source research.\'\n\n\n\nBlockchain technology will only achieve mainstream acceptance when end users are not locked into one blockchain or standard, but can seamlessly access value and utility, regardless of which blockchain they are using. \'Bridges like this are an absolute necessity in order to ensure that users have a seamless experience,\' continued Pellerin. ‘By connecting our communities and finding innovative new ways to work together, as we have been doing with Nervos, we can ensure that blockchain lives up to its promises of creating a fairer and more efficient global financial operating system.\'\n\n\n\n*Check out the [Nervos website](https://www.nervos.org/) for more information on upcoming partnerships and research initiatives.*\n\n\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    },
                                    {
                                        lang: 'jp',
                                        title: 'NervosとのパートナーシップでCardanoと初のクロスチェーンブリッジを構築',
                                        subtitle: '新たなコラボレーションにより、暗号資産界全体に相互運用性を構築。CardanoとNervosのトークン所有者は、両プラットフォーム間で資産取引が可能に',
                                        audio: null,
                                        soundcloud: [
                                            {
                                                trackid: 1060596082
                                            }
                                        ],
                                        body_content: '<!--StartFragment-->\n\nIOHKとNervosは協力してCardanoとNervosネットワーク間に相互運用性を構築します。完成すれば、この先駆的なクロスチェーンのブリッジにより、ユーザーは2つのブロックチェーン間で資産取引が可能になります。最終目標はより優れた相互運用性を促進すること。その間、NervosとCardano両者のグローバルリーチとユーティリティを拡張していきます。\n\n\nNervosの「Common Knowledge Base」（共通知識ベース：CKB）は、パーミッションレス、レイヤー1、オープンソースのプルーフオブワークブロックチェーンプロトコルで、相互運用可能なユニバーサルパブリックネットワークの基礎を築くことに主眼を置いています。これにより、あらゆる暗号資産は、スマートコントラクトとレイヤー2スケーリングのメリットが追加された、安全、不変、そしてパーミッションレスな環境に保管されます。 \n\n\nNervosはこの頑丈なネットワークを3つの主要コンポーネントを軸として開発しています。これらはともに、Nervosの次世代相互運用性へのアプローチであるユニバーサスパスポートを構成するものです。 \n\n\n\n* **PW Core**（PWコア）- 開発者がすべてのチェーンでアプリケーションを構築することを可能にします。\n* **Nervos’ Polyjuice**（Nervosポリジュース）- 開発者がイーサリアムからNervosへスマートコントラクトを移植できるようにするイーサリアム対応レイヤーです。\n\n* **Force Bridge** (フォースブリッジ - Nervosとさまざまなブロックチェーンとのクロスチェーントランザクションを可能にするトラストレスなブリッジです。NervosはForce Bridgeを使用してCardanoと直接接続し、ユーザーは既存のCardanoウォレットを使用してトランザクションを行うことができます。\n\n\n\n## 可搬トークンでブロックチェーンを橋渡しする\n\n\n\nこれは実際何を意味するのでしょうか。NervosのCKByte（CKB）とADA保有者は、両通貨を交換して取引することができます。NervosユーザーはCardanoのネイティブアセット規格を利用してトークンを作成し、両ネットワークを行き来させて、使用することができます。加えて、ブリッジにより開発者は両チェーン上でサービスや機能へアクセスし、自分たちのDAppエコシステムやユーザーベースを拡張することができます。 \n\n\nフルサービスのブロックチェーンアクセラレーター、[Mousebelt](https://www.mousebelt.com/)は、Nervosから財政支援を得てブリッジを構築します。Cardanoチームは、Cardanoとブリッジを接続するために、専門知識とリソースを提供します。開発作業は既に進行中で、今後6週間で完了する見込みです。 \n\n\n\n「Force Bridgeを使用してNervos NetworkとCardanoをリンクすることは、IOHKとの間に既に築き上げられている関係を考えても特にエキサイティングです」と、Nervosの共同創業者Kevin Wang氏は語ります。「私たちは研究開発パートナーシップを育ててきましたが、まもなく実際のブリッジを手にすることができます。これはForce Bridgeのパワーを示すショーケースでもあり、機能的かつ相互運用可能なネットワークへとつながる道にいる私たちをさらに前進させるものです」\n\n\n\nこのブリッジは、Nervosとのコラボレーションの一部に過ぎません。「私たちは、相互運用可能なブロックチェーンの「星座」で機能する世界というビジョンを共有しています」とInput OutputのCTO、Romain Pellerinは述べます。「学術研究も暗号界全体を前進させる基盤となっていると信じています。私たちはまた、UTXOモデルの画期的な改良に関する論文の共同執筆、ユニバーサル会計規格の検討、オープンソースの研究を介した分散型技術の今後の開発への協力を予定しています」\n\n\n\nブロックチェーン技術は、エンドユーザーが1つのブロックチェーンや規格に縛られることなく、どのブロックチェーンを使用していようとも、価値やユーティリティにシームレスにアクセスできて初めて、主流に受け入れられるようになります。「このようなブリッジは、ユーザーにシームレスなエクスペリエンスを提供するうえで絶対に欠かせません」とPellerinは続けます。「私たちとNervosが実行しているように、コミュニティを繋げ、協力するための革新的な方法を見つけることにより、より公正で効率的なグローバル金融オペレーティングシステムを創造するという約束を確実に果たすことができるのです」\n\n\n*予定されているパートナーシップと研究イニシアチブについての詳細は、[Nervos website](https://www.nervos.org/)をご覧ください。*\n\n\n\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'jp',
                                title: 'NervosとのパートナーシップでCardanoと初のクロスチェーンブリッジを構築',
                                subtitle: '新たなコラボレーションにより、暗号資産界全体に相互運用性を構築。CardanoとNervosのトークン所有者は、両プラットフォーム間で資産取引が可能に',
                                audio: null,
                                soundcloud: [
                                    {
                                        trackid: 1060596082
                                    }
                                ],
                                body_content: '<!--StartFragment-->\n\nIOHKとNervosは協力してCardanoとNervosネットワーク間に相互運用性を構築します。完成すれば、この先駆的なクロスチェーンのブリッジにより、ユーザーは2つのブロックチェーン間で資産取引が可能になります。最終目標はより優れた相互運用性を促進すること。その間、NervosとCardano両者のグローバルリーチとユーティリティを拡張していきます。\n\n\nNervosの「Common Knowledge Base」（共通知識ベース：CKB）は、パーミッションレス、レイヤー1、オープンソースのプルーフオブワークブロックチェーンプロトコルで、相互運用可能なユニバーサルパブリックネットワークの基礎を築くことに主眼を置いています。これにより、あらゆる暗号資産は、スマートコントラクトとレイヤー2スケーリングのメリットが追加された、安全、不変、そしてパーミッションレスな環境に保管されます。 \n\n\nNervosはこの頑丈なネットワークを3つの主要コンポーネントを軸として開発しています。これらはともに、Nervosの次世代相互運用性へのアプローチであるユニバーサスパスポートを構成するものです。 \n\n\n\n* **PW Core**（PWコア）- 開発者がすべてのチェーンでアプリケーションを構築することを可能にします。\n* **Nervos’ Polyjuice**（Nervosポリジュース）- 開発者がイーサリアムからNervosへスマートコントラクトを移植できるようにするイーサリアム対応レイヤーです。\n\n* **Force Bridge** (フォースブリッジ - Nervosとさまざまなブロックチェーンとのクロスチェーントランザクションを可能にするトラストレスなブリッジです。NervosはForce Bridgeを使用してCardanoと直接接続し、ユーザーは既存のCardanoウォレットを使用してトランザクションを行うことができます。\n\n\n\n## 可搬トークンでブロックチェーンを橋渡しする\n\n\n\nこれは実際何を意味するのでしょうか。NervosのCKByte（CKB）とADA保有者は、両通貨を交換して取引することができます。NervosユーザーはCardanoのネイティブアセット規格を利用してトークンを作成し、両ネットワークを行き来させて、使用することができます。加えて、ブリッジにより開発者は両チェーン上でサービスや機能へアクセスし、自分たちのDAppエコシステムやユーザーベースを拡張することができます。 \n\n\nフルサービスのブロックチェーンアクセラレーター、[Mousebelt](https://www.mousebelt.com/)は、Nervosから財政支援を得てブリッジを構築します。Cardanoチームは、Cardanoとブリッジを接続するために、専門知識とリソースを提供します。開発作業は既に進行中で、今後6週間で完了する見込みです。 \n\n\n\n「Force Bridgeを使用してNervos NetworkとCardanoをリンクすることは、IOHKとの間に既に築き上げられている関係を考えても特にエキサイティングです」と、Nervosの共同創業者Kevin Wang氏は語ります。「私たちは研究開発パートナーシップを育ててきましたが、まもなく実際のブリッジを手にすることができます。これはForce Bridgeのパワーを示すショーケースでもあり、機能的かつ相互運用可能なネットワークへとつながる道にいる私たちをさらに前進させるものです」\n\n\n\nこのブリッジは、Nervosとのコラボレーションの一部に過ぎません。「私たちは、相互運用可能なブロックチェーンの「星座」で機能する世界というビジョンを共有しています」とInput OutputのCTO、Romain Pellerinは述べます。「学術研究も暗号界全体を前進させる基盤となっていると信じています。私たちはまた、UTXOモデルの画期的な改良に関する論文の共同執筆、ユニバーサル会計規格の検討、オープンソースの研究を介した分散型技術の今後の開発への協力を予定しています」\n\n\n\nブロックチェーン技術は、エンドユーザーが1つのブロックチェーンや規格に縛られることなく、どのブロックチェーンを使用していようとも、価値やユーティリティにシームレスにアクセスできて初めて、主流に受け入れられるようになります。「このようなブリッジは、ユーザーにシームレスなエクスペリエンスを提供するうえで絶対に欠かせません」とPellerinは続けます。「私たちとNervosが実行しているように、コミュニティを繋げ、協力するための革新的な方法を見つけることにより、より公正で効率的なグローバル金融オペレーティングシステムを創造するという約束を確実に果たすことができるのです」\n\n\n*予定されているパートナーシップと研究イニシアチブについての詳細は、[Nervos website](https://www.nervos.org/)をご覧ください。*\n\n\n\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'nervos-partnership-to-build-the-first-cross-chain-bridge-with-cardano',
                                url: '/blog/posts/2021/06/02/nervos-partnership-to-build-the-first-cross-chain-bridge-with-cardano/',
                                read_time: 1
                            },
                            {
                                publish_date: '2021-02-26T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/b32a85c3-d8e4-4756-8972-df0fe7be0062/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Bringing Glow to Cardano',
                                        subtitle: ' We just spun up a devnet to support Glow, the very latest language Cardano will support. We talked to its creator about building a DSL for DApp development.',
                                        audio: null,
                                        soundcloud: [],
                                        body_content: '<!--StartFragment-->\n\n*At the end of 2020, we announced our devnets plan to support the longer-term strategic goal of opening up Cardano to multiple development languages – as outlined in the ‘‘[Island, Ocean, Pond](https://youtu.be/k8a6tX53YPs)’ video. This week, building on the [Ethereum Virtual Machine](https://developers.cardano.org/en/virtual-machines/welcome/), we’re rolling out a new [development environment](https://developers.cardano.org/en/programming-languages/glow/overview/) to support the Glow language.*\n\n*François-René Rideau of Mutual Knowledge Systems is the creator of Glow, a DSL that will allow anyone to write verifiable DApps from a single spec and deploy it on our EVM network. We caught up with Rideau (also known as Fare) to hear more about his vision for Glow and the Cardano journey so far. The following is a distillation of his thoughts from our previous interviews.*\n\n\n\n**We first introduced the community to GLOW and MuKn at the end of [last year](https://youtu.be/lj9SlvOIBgU?t=2902) when we announced our devnets approach –  but maybe you can remind us how you began working with IOHK?**\n\nI started as a researcher in formal methods for programming languages and distributed systems. But I wanted to build systems actually used by many, so I moved into the industry where I notably worked on proving the correctness of a centralized payment protocol and creating an airline reservation system. After a few years at Google and Bridgewater, I decided life wasn’t worth working under dysfunctional hierarchies, so I started my own cryptocurrency companies. Charles invited me to speak at the IOHK Summit 2019, and I realized how much I like the Cardano community: we have a similar focus on building robust software for the long term. That is why I wanted to port my domain specific language Glow to Cardano.\n\n\n\n**Tell us a bit why you started your company Mutual Knowledge Systems, or as you call it MuKn (Moon)?**\n\nOver three years ago, I was reviewing whitepapers. Most papers (about ¾) had interesting techniques but made no economic sense. Most of the rest (about ⅕) made economic sense but had no technical content. Only the top few (about 5%) actually made sense both technically and economically. At some point, I realized I could do better, so I designed a scaling solution using lessons learned from working on Tezos. Arthur Breitman challenged me to use smart contracts instead of trying to modify his protocol. \n\nWhile trying to prove his challenge absurd, I instead found that he was right and I was wrong—and I finally understood why and how to use smart contracts. I started a company around the resulting scaling solution, raised money, pivoted into building the scaling solution after the language capable of generating it from specification, fought with and fired my then-partner, became my own CEO, started a new company, and, after much struggle, finally found the right founding team. Together, we built Mutual Knowledge Systems around this new programming language, Glow—designed to be much better than existing languages to write decentralized applications.\n\n\n\n**When you say ‘better’, what do you really mean?**\n\nWriting a DApp is the single hardest thing to do in the world. This is because you can’t afford a mistake, or your users may lose significant funds. Furthermore, you are not confronting random situations, but active adversaries bent on attacking your code, who will contrive the very worst case scenarios to exploit for their profit. Yet, unlike the military, you can’t hide your code or protect access to your networks: all the critical pieces are necessarily public. On top of that, extant programming tools are not designed for these constraints and even traditional formal methods lack essential concepts to express the issues at stake.\n\nThus, we decided to make new tools fit for the challenge. Our domain-specific language (DSL) drastically simplifies DApp development, by abstracting away all the common blockchain infrastructure, so you can focus on your problem domain (trading, derivatives, insurance, supply chain, etc.). Your DApps can be thousands of lines of code that your users can afford to audit, instead of millions of lines of code that require leaps of blind faith. And the programming model will enable developers, auditors and automated verification tools to reason at the level of abstraction of participants exchanging assets, rather than at that of packets of bytes shipped around the Internet.\n\n\n\n**What is it about Cardano and its community that appeals?**\n\nI started like everyone else, on Ethereum, because its ecosystem is already mature. However, the Ethereum community has this attitude of building as fast as possible experiments that are good enough for now, but lack conceptual integrity and won’t last; I see a lot of value in that approach and have tremendous respect for those who can thrive this way—for I cannot. When I met the Cardano community, I felt much more at home because we share a common attitude. We want to do things that are correct by construction and will keep working in the long term. We build concrete towers on the bedrock, not stick shacks on the sand. At times, this can be frustrating because things go slow, but I am happy with the attention to detail and quality in the development of Cardano. Is it perfect? No, it’s not. But it’s got great fundamentals.\n\n\n\n**Can you talk about how you hope Glow will change the DApp developer experience?**\n\nGlow is portable. Today it works on Cardano and Ethereum but in the future it will work with any blockchain that is sufficiently advanced to support smart contracts. That means that you can write your DApp once and it will run on whichever platform has the users and the liquidity you seek. You don’t have to make a guess about where liquidity will be in the future then sink heavy investments to develop on a single chain that you bet your house on.\n\n\n\nWith Glow, developers can run their DApps on all blockchains. Glow will commoditize blockchains. Blockchains will then compete on technical and economic merits, not on user lock-in and inertia. And the value brought to users will increase.\n\n\n\n**What can the community expect from Glow?**\n\nWe have launched this early version of Glow on the Cardano EVM Devnet with a command-line interface. In many ways, it is not yet ready for use by end-users, but it can already demonstrate simple applications. Users can also see how they may write a 6 line application in Glow that would require hundreds of lines in a combination of Solidity and JavaScript. We have a roadmap over the next few months to add a lot of features: from ERC20 tokens (and, on Cardano, native tokens), to generalized state channels, to a web interface, to a more robust runtime, etc. Eventually, we want to become the development environment for all blockchain projects. And Glow is of course an open source software open to the community.\n\n**We’re rolling out the integration with Glow with our EVM and devnet program, so what are some of the benefits of this?**\n\nThe Cardano EVM side-chain will enable arbitrary contracts to run on Cardano that use the mature EVM platform, without waiting for Plutus to deliver its promise, to achieve feature-parity, to be considered stable, etc. And Glow can run on this EVM side-chain and provide the simplicity, safety and portability in DApp development that were not available before.\n\n**What is the rollout process like and how can our community get involved if they want to?**\n\nGlow is still in development. There are some things that it can do already and some it can’t do yet. We invite DApp developers to join the Glow community and use the language for what it can already do, and otherwise help us build the blockchain development environment of the future. You can build the missing features you need yourself, or contract MuKn to build them for you. Even if you can’t code and have no budget, you can help write the documentation, or even just tell us where it isn’t clear yet, or what features you need most so we know what to prioritize. Together, we can build great DApps that you just couldn’t have achieved safely and within budget with previous tools.\n\n*If you’re a developer, we encourage you to get involved with [Mutual Knowledge Systems and Glow](https://mukn.io/). See our full conversation with François-René Rideau and a demonstration of Glow during [Cardano360.](https://youtu.be/YXaK0cvgoFQ?t=4367)*\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Bringing Glow to Cardano',
                                subtitle: ' We just spun up a devnet to support Glow, the very latest language Cardano will support. We talked to its creator about building a DSL for DApp development.',
                                audio: null,
                                soundcloud: [],
                                body_content: '<!--StartFragment-->\n\n*At the end of 2020, we announced our devnets plan to support the longer-term strategic goal of opening up Cardano to multiple development languages – as outlined in the ‘‘[Island, Ocean, Pond](https://youtu.be/k8a6tX53YPs)’ video. This week, building on the [Ethereum Virtual Machine](https://developers.cardano.org/en/virtual-machines/welcome/), we’re rolling out a new [development environment](https://developers.cardano.org/en/programming-languages/glow/overview/) to support the Glow language.*\n\n*François-René Rideau of Mutual Knowledge Systems is the creator of Glow, a DSL that will allow anyone to write verifiable DApps from a single spec and deploy it on our EVM network. We caught up with Rideau (also known as Fare) to hear more about his vision for Glow and the Cardano journey so far. The following is a distillation of his thoughts from our previous interviews.*\n\n\n\n**We first introduced the community to GLOW and MuKn at the end of [last year](https://youtu.be/lj9SlvOIBgU?t=2902) when we announced our devnets approach –  but maybe you can remind us how you began working with IOHK?**\n\nI started as a researcher in formal methods for programming languages and distributed systems. But I wanted to build systems actually used by many, so I moved into the industry where I notably worked on proving the correctness of a centralized payment protocol and creating an airline reservation system. After a few years at Google and Bridgewater, I decided life wasn’t worth working under dysfunctional hierarchies, so I started my own cryptocurrency companies. Charles invited me to speak at the IOHK Summit 2019, and I realized how much I like the Cardano community: we have a similar focus on building robust software for the long term. That is why I wanted to port my domain specific language Glow to Cardano.\n\n\n\n**Tell us a bit why you started your company Mutual Knowledge Systems, or as you call it MuKn (Moon)?**\n\nOver three years ago, I was reviewing whitepapers. Most papers (about ¾) had interesting techniques but made no economic sense. Most of the rest (about ⅕) made economic sense but had no technical content. Only the top few (about 5%) actually made sense both technically and economically. At some point, I realized I could do better, so I designed a scaling solution using lessons learned from working on Tezos. Arthur Breitman challenged me to use smart contracts instead of trying to modify his protocol. \n\nWhile trying to prove his challenge absurd, I instead found that he was right and I was wrong—and I finally understood why and how to use smart contracts. I started a company around the resulting scaling solution, raised money, pivoted into building the scaling solution after the language capable of generating it from specification, fought with and fired my then-partner, became my own CEO, started a new company, and, after much struggle, finally found the right founding team. Together, we built Mutual Knowledge Systems around this new programming language, Glow—designed to be much better than existing languages to write decentralized applications.\n\n\n\n**When you say ‘better’, what do you really mean?**\n\nWriting a DApp is the single hardest thing to do in the world. This is because you can’t afford a mistake, or your users may lose significant funds. Furthermore, you are not confronting random situations, but active adversaries bent on attacking your code, who will contrive the very worst case scenarios to exploit for their profit. Yet, unlike the military, you can’t hide your code or protect access to your networks: all the critical pieces are necessarily public. On top of that, extant programming tools are not designed for these constraints and even traditional formal methods lack essential concepts to express the issues at stake.\n\nThus, we decided to make new tools fit for the challenge. Our domain-specific language (DSL) drastically simplifies DApp development, by abstracting away all the common blockchain infrastructure, so you can focus on your problem domain (trading, derivatives, insurance, supply chain, etc.). Your DApps can be thousands of lines of code that your users can afford to audit, instead of millions of lines of code that require leaps of blind faith. And the programming model will enable developers, auditors and automated verification tools to reason at the level of abstraction of participants exchanging assets, rather than at that of packets of bytes shipped around the Internet.\n\n\n\n**What is it about Cardano and its community that appeals?**\n\nI started like everyone else, on Ethereum, because its ecosystem is already mature. However, the Ethereum community has this attitude of building as fast as possible experiments that are good enough for now, but lack conceptual integrity and won’t last; I see a lot of value in that approach and have tremendous respect for those who can thrive this way—for I cannot. When I met the Cardano community, I felt much more at home because we share a common attitude. We want to do things that are correct by construction and will keep working in the long term. We build concrete towers on the bedrock, not stick shacks on the sand. At times, this can be frustrating because things go slow, but I am happy with the attention to detail and quality in the development of Cardano. Is it perfect? No, it’s not. But it’s got great fundamentals.\n\n\n\n**Can you talk about how you hope Glow will change the DApp developer experience?**\n\nGlow is portable. Today it works on Cardano and Ethereum but in the future it will work with any blockchain that is sufficiently advanced to support smart contracts. That means that you can write your DApp once and it will run on whichever platform has the users and the liquidity you seek. You don’t have to make a guess about where liquidity will be in the future then sink heavy investments to develop on a single chain that you bet your house on.\n\n\n\nWith Glow, developers can run their DApps on all blockchains. Glow will commoditize blockchains. Blockchains will then compete on technical and economic merits, not on user lock-in and inertia. And the value brought to users will increase.\n\n\n\n**What can the community expect from Glow?**\n\nWe have launched this early version of Glow on the Cardano EVM Devnet with a command-line interface. In many ways, it is not yet ready for use by end-users, but it can already demonstrate simple applications. Users can also see how they may write a 6 line application in Glow that would require hundreds of lines in a combination of Solidity and JavaScript. We have a roadmap over the next few months to add a lot of features: from ERC20 tokens (and, on Cardano, native tokens), to generalized state channels, to a web interface, to a more robust runtime, etc. Eventually, we want to become the development environment for all blockchain projects. And Glow is of course an open source software open to the community.\n\n**We’re rolling out the integration with Glow with our EVM and devnet program, so what are some of the benefits of this?**\n\nThe Cardano EVM side-chain will enable arbitrary contracts to run on Cardano that use the mature EVM platform, without waiting for Plutus to deliver its promise, to achieve feature-parity, to be considered stable, etc. And Glow can run on this EVM side-chain and provide the simplicity, safety and portability in DApp development that were not available before.\n\n**What is the rollout process like and how can our community get involved if they want to?**\n\nGlow is still in development. There are some things that it can do already and some it can’t do yet. We invite DApp developers to join the Glow community and use the language for what it can already do, and otherwise help us build the blockchain development environment of the future. You can build the missing features you need yourself, or contract MuKn to build them for you. Even if you can’t code and have no budget, you can help write the documentation, or even just tell us where it isn’t clear yet, or what features you need most so we know what to prioritize. Together, we can build great DApps that you just couldn’t have achieved safely and within budget with previous tools.\n\n*If you’re a developer, we encourage you to get involved with [Mutual Knowledge Systems and Glow](https://mukn.io/). See our full conversation with François-René Rideau and a demonstration of Glow during [Cardano360.](https://youtu.be/YXaK0cvgoFQ?t=4367)*\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'bringing-glow-to-cardano',
                                url: '/blog/posts/2021/02/26/bringing-glow-to-cardano/',
                                read_time: 7
                            },
                            {
                                publish_date: '2021-02-05T00:00:00.000Z',
                                author: null,
                                video_id: 'oVCGvSNBPlI',
                                main_image: '',
                                custom_meta_img: 'https://ucarecdn.com/322fc64b-f115-42e1-bcc2-e6edc76841cb/',
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Decentralizing social media: a conversation with Ben Goertzel and Charles Hoskinson',
                                        subtitle: 'The minds behind SingularityNET and Cardano come together to explore a vision of the future of decentralization, AI, and social media.',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: '<!--StartFragment-->\n\n*At the end of 2020, we announced our collaboration with SingularityNET, in an exclusive [fireside chat](https://www.youtube.com/watch?v=W3O5F_CCT8c) between Charles Hoskinson and SingularityNET founder & CEO, Ben Goertzel.* \n\n*SingularityNET recently shared further information on the partnership when they announced their exciting [Phase Two initiative](https://blog.singularitynet.io/singularitynet-phase-two-massive-token-utilization-toward-decentralized-beneficial-agi-6e3ac5a5b44a),* [](https://blog.singularitynet.io/singularitynet-phase-two-massive-token-utilization-toward-decentralized-beneficial-agi-6e3ac5a5b44a) *which includes a shift from Ethereum to Cardano, to achieve new network functionalities and launching a Stream of New AGI-ADA Tokens.*\n\n*Last week, Charles and Ben sat down again together in a special [SingularityNET podcast](https://www.youtube.com/watch?v=TNWJGGc7ESI). In a wide-ranging discussion, the pair explore decentralized social media, the Cardano collaboration, and how a benevolent general AI technology might help a healthier social discourse.*\n\n*Here, in this exclusive long read, we have transcribed the whole conversation for you to enjoy and savour.*\n\n*<!--EndFragment-->*\n\n**Ben Goertzel:** Alright. Pleasure to be chatting once more Charles. And I thought it\'ll be amazing to have an on air discussion on the topic that\'s been in so many people\'s minds recently, which is the perhaps of critical importance of decentralization for social media and social networks, because this is something we both been thinking about deeply for quite a long time and have been both moving toward action on for quite a long time in our own ways, maybe the AI spin and you with Cardano and blockchain. But now things seem to be coming to a head and the world seems to suddenly be concerned that a few large corporations are programming everyone\'s brains in bizarre ways. So, yeah, maybe it is cool to start out just by hearing your overview of the topic.\n\n**Charles Hoskinson:** Yeah, it\'s an interesting situation. So I\'m kind of conflicted. So, I\'m a big libertarian and the libertarian guys say, "Hey, let the market decide. So when someone gets de-platformed, we say, "Hey, it\'s a private company. They can do whatever they want." But the issue is collusion and so the watershed moment for me wasn\'t the de-platforming of Trump. I said, yeah, okay the guy violated the end user license agreement probably 9 million times. At some point you have to throw the guy out. The issue was the de-platforming of Parler, because that was a very different animal.\n\nSo the whole argument was, well, if you don\'t like Twitter, go compete with it, build your own social network. That\'s exactly what Parler did. And they had different moderation standards. But then what occurred was that all of Silicon Valley got together and they colluded and they basically jointly decided to completely de-platform Parler. So Amazon took them down, Apple took them down, Google took them down. And if you\'re put in a market position where 100% of the mobile market and most of the web market is basically blacklisting you and you have no way to be on a cell phone for an average consumer, no way to have a website for an average consumer without going to extraordinary lengths and it\'s almost like the pirate bay. You have to host servers in Afghanistan or something to escape it. That\'s very problematic. It feels like a standard oil controlling the shipping prices of oil back in the 19th century.\n\n**BG:** The appeal to ethics seems so disingenuous, right? It\'s like you can search Qanon on garbage on Google just fine. So then why is it so unethical for there to be Qanon garbage on Parler as some of the content, right?\n\nThe idea that these big tech companies are acting out of a moral necessity to save everyone\'s lives. I mean, it rings very hollow, right? And I mean, there\'s no doubt some people in those companies really are thinking that way. But the alignment of these marginal ethical arguments with obvious corporate profit interests as being advanced by explicit collusion among these big players. It makes it hard to take the ethical aspect one hundred percent seriously.\n\n**CH:** It\'s almost become like an ethical tautology in a certain respect. They say \'Don\'t be evil, except for the times you have to be.\' It\'s a crazy, crazy statement where these companies say, well, we\'re trying to be moral. And I say, \'Okay, but no one elected you. And why are you guys in charge of the totality and curation flow of all information?\' I very firmly believe what needs to happen is we need to split the protocols that carry the information from the interfaces that curate that information. And that feels to be a much more natural thing. The problem we have right now is the stack is vertically completely controlled by a company.\n\nSo, Google doesn\'t just curate what you see in the search engine. They also control the underlying engine. And so as a consequence, they can make a decision on pretty much anything and exclude people laterally. And it\'s the same for the app stores. It\'s the same for social networks. The level of collusion is very problematic. I mean, you can\'t tell me that they didn\'t talk to each other if they all de-platformed someone the same day in the same hour. It\'d be one thing if it was a gradual process where maybe Google and two weeks later, Amazon, something like that. But if it\'s all exactly at the same time, then it means they picked up the phone and they called each other and say, well, we just decided that this is no good for you.\n\nThe problem is that decentralization doesn\'t solve the underlying problem that they\'re complaining about, which is radicalization. The issue is that the way information is being presented, it\'s manipulating our cognitive biases. We\'re creatures of cognitive biases. No matter how smart we are, we have availability bias, and selection bias and confirmation biases. There\'s hundreds of them and social scientists, psychologists and neuroscientists, they think about these things and quantify them. And if you digitize those biases and you build algorithms to exploit them, then what ends up happening is you create echo chambers. So you create these silos. Each and every one of those silos they are incapable of getting out of it. There\'s no idea flow between them. So all you do when you decentralize that, if you don\'t solve that underlying problem is you make the silos more resilient.\n\n**BG:** I mean there\'s a problem when you\'re applying AIs to learn to win in games or video games, which is both a problem and a benefit is that the AI will learn to do what you asked it to do. So if you\'re asking it to get maximum points in this game, and there\'s a way to do it by hacking around the rules of the game in some weird way no human would ever think of, the AI will explore various options. And if it\'s working well, will find some route to achieve the objective function without taking into account whatever implicit constraints you had about what\'s the artful way to do it.\n\nI think something similar exists with social media companies. They have certain metrics and objectives they\'re working toward. Often very, systemically internally, right? I mean, they want people to be looking at their site as long as possible, for example, or they want them to be spending as much as possible clicking on ads. And they\'ll put a lot of human and algorithmic effort into optimizing toward that goal. And then we can\'t be very surprised that these groups of brilliant people make cool software build systems that are optimizing toward that goal, like via whatever hacks they can find. And those hacks include exploiting human cognitive biases and exploiting dynamics of addiction in the human brain and all sorts of human, emotional patterns. Exploiting human angst and the desperation and existential confusion. I mean the algorithms and the corporate systems will exploit whatever they can to achieve the goals they\'re given.\n\nAnd as you say, it\'s organized so that these corporate organisms, which are now hybrid human and digital computing process organisms. These corporate organisms are almost like a parasite on modern society and they\'re achieving their own goal pretty effectively. If you took a bird\'s eye view of human society and where we want to be and where we want to go during the next few years, and maybe leading towards the singularity and creation of AGI and all that. A situation where these corporate human/computer networks orient toward maximizing shareholder value by getting you to buy stuff online and stare at their website as long as possible.\n\nI mean, these sorts of organizations having that much power is not the optimal dynamic for shaping the collective mind, heart and soul of humanity, right? I mean it\'s pretty far off from where we want to be. You\'d imagine that extremism and siloeing and tribalism, which we\'re seeing online and in real life, I think that\'s probably the only scratching the surface of the screwed up patterns that are being fostered. That\'s the surface layer where it\'s easy to see how screwed up it is. And there\'s so many other screwed up individual and collective dynamics that are happening. I wouldn\'t say all caused by this organization of social media in the tech industry, but certainly co-evolving with it and codependent on it.\n\n**CH:** Well, it\'s an interesting thing. So I tend to agree with Max Tegmark in this respect where you invent the car first and then you invent the safety belt. With new technology or new processes, there\'s a lack of wisdom in the safety components of it until after you\'ve suffered the consequences. So, we looked at the oil and gas industry in the 19th century, they started drilling all these wells and only after they started doing that, did we start thinking about environmentalism. And we said, well, maybe it\'s not such a good idea just to have unrestricted oil well drilling. Maybe we need to think carefully about what this is actually doing to the environment.\n\nWell, the oil of the 21st century is really the attention economy and the data economy. And we have all this surveillance capitalism and we have all these early pioneering firms and they\'re effectively mining that. And they\'re creating a social environmental damage by this process, to use an analogy where these algorithms are built and these platforms were built away to exacerbate human nature. So to your point that they didn\'t cause it, but I\'d certainly say that they\'re exacerbating it and-\n\n**BG:** I always think of everything in human society from the end game of legacy humanity. Like we\'re working on creating AGI. If we can create a benevolent AGI, I mean, this is going to make our current problems seem so archaic and silly. Of course, things won\'t be perfect. There will be new problems we can\'t imagine there. But this is certainly the biggest threshold event in the history of humanity, perhaps of life on earth. We could be a few decades from that even less. If there\'s even a decent odds that this singularitarian view is true, I mean then how the collective mind of humanity is shaped is insanely important, right?\n\nBecause the first AGI probably isn\'t going to be just a stupid human, stupid mind in a box, totally separate from human society. The way things are going it\'s more likely to come out of the interaction of multiple different AI components made by multiple parties, serving useful economic functions in the world at large. If the first AGI, which triggers this singularity is coming out of the whole mess of the tech ecosystem and people using the technology to do useful things, I mean then how messy that mess is, is an extremely important thing. And that right now, the direction does not look like the internet AI tech ecosystem is evolving in a great configuration for spotting a benevolent super AGI, 5, 10 to 20 years from now, right? Maybe some redirection if some of the sub-networks in there, like the ones we\'re involved with could affect it. Some redirection would be highly beneficial.\n\n**CH:** Well, the problem with AGI is that that\'s kind of like the Deus ex Machina situation where you\'re saying, well, we could solve this problem if we have this insanely powerful tool. And it\'s like, well, yeah, but maybe we don\'t actually need a tool that powerful to make meaningful progress towards this problem.\n\n**BG:** Decentralized social networks you don\'t need AGI. Absolutely not. You can do a lot with blockchain networks.\n\n**CH:** Hang on. So I think an AI solution does provide a lot of value, but I look at it more like a cognitive crutch. So if you injure your leg you get on crutches or you walk with a cane or something like that. I recently had a gout attack and for two weeks I was on a cane. So it\'s kind of funny. We physically think about this, but for the mental stuff, we don\'t really think we need it. We say, oh, our brains are perfectly well functions. Like no, we\'re dopamine addicts. We\'re constantly manipulated by digital devices and we\'re in a situation where we\'re not acting rationally or objectively most of the time.\n\n**BG:** With access to our hardware and software. We can\'t fix the bugs in the direct way.\n\n**CH:** So the question is, what would be the simplest possible agent, intelligent agent that could be constructed that could act as a cognitive crutch to alert us if we are being manipulated or our behavior is exhibiting patterns that have been propagandized. That feels like it would be a massive step forward.\n\n**BG:** Now we\'re getting it. Some of this stuff that I\'m hoping we will be able to build together with a SingularityNET on the Cardano network over the next few years. I mean, if you look at intelligent virtual assistants now like an Alexa or Google assistant, I mean, A: these things are very stupid in many senses, right? I mean, I have a Google Home Max. I used to play music in my house and the system still hasn\'t realized I never listen to music with vocals during the day. I mean, it doesn\'t have that metadata there. It hasn\'t recognized that very simple pattern, so repeatedly throw stuff at me. I won\'t listen to it. It\'s not even able to understand extremely simple repeated patterns in human behavior, which would help them make more money, even by showing me more stuff I want to listen to, right?\n\nSo these systems are optimized very narrowly to serve certain functions and their functions certainly are not to help us navigate the universe of the internet and media, in a way that\'s optimal for our own growth and self understanding, achieving our own goals and optimizing the collective intelligence of humanity. Very, far from it. So one could envision a personal assistant that had a bit more general intelligence. So it understood at least a little bit of what we actually want and are doing, but also was not controlled by a mega corporation with the primary goal of making them money, but was controlled by us who were being assisted by the personal assistant, right?\n\nI mean, I don\'t want the human personal assistant working for me, helping me do things whose main goal is to make some other corporation money, right? I want the human personal assistant working for me whose goal is to help me because I hired them to help me, right?\n\nAnd we should have digital assistants like that and they\'re going to be building machine learning models of everything we\'re doing like a human assistant builds their own biological model of what their employer is doing. And we should be better than the human assistant. We should be able to explicitly inspect what that model is and edit and correct it if we didn\'t like it and delete that model if we want to, right? So, I mean, we need among other things, we need intelligent virtual agents to help guide our navigation of the whole internet information sphere, which are secure and decentralized and explainable to us. The thing is we can do that without AGI. We can do that with technology we have right now, and this technology can help along the path toward AGI.\n\n**CH:** Where do we get the training data from? That was the one thing I was thinking about is how do I train an agent like that?\n\n**BG:** I mean it\'s going into smartphones that we use all day, right? So the training day that Google and Amazon and so forth are using, where does it come from? It comes from all of us. In principle, you can download most of what Google is basing its training data on you on, but very few of us are doing it. We\'re not using it, right? So, I mean, clearly you need all the data that you\'re using to interact with devices and with people all day. I mean you need that data to be in a secure data world that\'s owned and controlled by you where you\'re confident it\'s being managed and secure. Yeah, but we got to get a little deeper. I mean, it\'s not just interaction use. You\'d have to clearly show an example of confirmation bias to an extent that an ML model would be able to understand that. And so how do you do that in an unsupervised way?\n\n**BG:** We show it all the time, right? And I mean if the AI has a view of a lot of people, I mean, even those of us who are especially clever in some ways and our basic human social, emotional interactions, there\'s a lot that we do, which is the same.\n\nEmotional interactions. There\'s a lot that we do, which is the same as a lot of other people are doing, right? Like in how you interact with an employee versus a romantic partner or a friend or someone who\'s arguing with you. I think the sort of dialogue meta games and the inner dialogue meta games that people are playing, they\'re within the scope of current advanced neuro AI tech to recognize it\'s just, that\'s not what\'s being focused on. What\'s being focused on is recognizing subtle patterns and who\'s going to click on what ad. And I mean, you don\'t need to tell that to predict who\'s going to click on what ad in the most concise and effective way. I mean, you don\'t care. Right?\n\nIt\'s just a principle problem that the tech industry is not currently trying very hard to solve, but yeah, you\'re right. You focus on the AI part and I focus on the blockchain part. But in reality, I mean, you need them because I guess the other guy\'s part is harder because we understand how to solve our part. But I mean, you need both of them. I mean, you need the secure, scalable data ecosystem, respecting data sovereignty and you need that to fuel intelligent virtual assistants that really serve the person that they\'re assisting is the prime directive. Plus this massive scale data analytics that really understands what\'s going on with each of us in a way that lets it genuinely help us.\n\nBecause what is giving a person what they want? Does it mean gratifying their most intense short-term impulse at each moment? Or does it mean giving them what they want in a sort of balance along multiple timescales? Which is at multiple levels of our being, which is what we try to do with our family and our human friends. And AI\'s, they\'re laughably far from making an effort to give us what we want and in the more profound sense at the moment.\n\n**CH:** Right? Well, the reason why I was focusing on the AI part is the biggest part, the blockchain part, the incentives engineering relies very heavily upon the users and the agents inside the system. And so we say, "Okay, how do we incentivize people to supervise and curate data and agents in a way that we get more dialogue and we get a great moderation?" The ideal form would be, if you take clique\'s that are disjoint and you put them in the system, then idea flow starts occurring between them. And over time they\'ll converge into kind of a great moderated middle.\n\nSo you can take a very extremist person and either the system acts like it has an immune system and it kind of kicks them out or that node over time, moderates. The incentives in the system have to be designed that way. The reason we have so many problems in my view with Facebook and Twitter is that it actually has the opposite incentive. You get more clicks and more interaction with the more polarized people become. So the system is built in a way to polarize people as much as possible and thus divide them as much as possible. Because it\'s actually boosting revenue.\n\n**BG:** I think that\'s an easier problem to solve. Righteous indignation and the glorious feeling being approved by others in your ingroup and jointly indignant of the guys in the next group. This is a really easy emotion to manipulate with people. It\'s sort of a low hanging fruit. And to an extent these networks implicitly got stuck in manipulating this low-hanging fruit because it was the easiest way to keep people staring at their app. I mean, just as the internet settled on porn with love, it\'s been with. Because that\'s a really low algorithmic complexity way to keep people staring at something, is to show them naked bodies. So, if something would give greater benefit and even get people to start their site longer in the long run, but it isn\'t quite as simple of a problem, it sort of gets bypassed in the loop of trying to incrementally achieve these metrics more and more each month.\n\nAnd what\'s interesting is that the thought that rearranging sort of the configuration of the tech stack as you suggest in the beginning of the conversation, so like rearranging the tech stack so that the protocols are separate from the applications and then the AI models and tools used to create the AI models and inspect the AI models, they\'re also separate from the applications. I mean, reorganizing things in this way, then it sort of opens up the dynamics of the whole ecosystem in a way that I believe has decent odds of leading to the evolution of social media tools that they give people what they want in a more profound sense. And in doing so, they\'re creating communication networks among people that are not focused entirely on sort of immediate gratification of the ego and soaking of inter tribal rivalries and so forth.\n\nBecause all these good and beautiful things we\'re alluding to, exist on the internet right now. They exist on the internet right now. There\'s love, there\'s compassion, there\'s true connection between people with rival political views or from different historical tribes and so forth. It\'s not that we\'re not capable of that or that it isn\'t there. People are capable of amazing deep connections with other people and have incredible self-awareness and uplifting of their own consciousness. It\'s just, you need networks that foster this rather than trying to squash it and channel you into tribalism and immediate ego gratification. And of course neither you or I nor our teams are going to build all the systems that solve this problem. So you\'re going to create the ecosystem and tool set in which the solutions are going to emerge.\n\n**CH:** Right. Well, that\'s the point of incentives engineering is that it\'s the initial push. And because you don\'t have friction to slow you down, you tend to accelerate and eventually you get to a great place. I mean, Bitcoin obviously got their incentives engineering right. And they went from a single miner to warehouses of miners all around the world. And now this colossal system. We can argue about the power consumption, but that model was quite competitive to a point that it created a trillion dollar ecosystem. So I often think, "Well, what incentives do we need?" And we kind of have three sets of distinct things we need to accomplish at the same time if the network is going to be sustainable and useful to society.\n\nSo one thing is that you would like information to be curated, where it can clearly separate objective reality from the subjective analysis of it and give people a diverse set of viewpoints and understand that stuff is nuanced. So if they get that, then you kind of get rid of the fake news. You also get some consensus in the network of baseline facts. Because right now we live in a reality where people can\'t even agree to basic things. Some people think coronavirus is a hoax. Some people think vaccines are poisoned, et cetera, et cetera. So there\'s just disjoint realities that people are in. It used to be we would have one set of facts. We\'d agree on that. But then our interpretation of what those means-\n\n**BG:** It\'s true. A lot of people really believed Donald Trump had the most people at his inauguration ever, and the New Yorker doctored those images. And of course, sometimes the mainstream media may have distorted something about Trump, but the thing is, that\'s like an image, right? And people didn\'t believe the photograph, they believed the photograph was fake. And when you\'re at that point where people don\'t believe the photographs, then it\'s very hard. Then you have to be on the ground there, observing it in a sort of very clear state of mind to believe anything.\n\nSo, I mean, I\'m not even a realist or materialist fundamentally. I don\'t know if there is an objective reality. But what people are doing is they\'re not thinking in a clear and coordinated way about this belief they have or this thing they\'d been told. What evidence is that grounded in? What\'s the process of grounding the abstraction or the claim in the evidence? That process is broken. And it\'s partly because of AI and advanced informatics tools. Because you can make a deep fake. I mean, it\'s actually hard to tell if this video is Goertzel and Hoskinson or is this video a deep fake of Goertzel and Hoskinson put up by someone to troll all of us. It\'s not immediate seeing is believing to tell that you have to think.\n\n**CH:** Oh yeah. Like the Collider, George Lucas, deep fakes are extraordinary. And that\'s last generation technology. Where they\'re going in a few years is going to be socially very damaging because you\'ll have these perfect simulacrums of major figures and there\'ll be saying and doing terrible things. So that\'s the first part, the curation, go ahead?\n\n**BG:** You need the social network to tell bullshit from reality. So if the social network is broken, then you can\'t tell because you can\'t tell by looking, you can only tell by what you read and what others are saying, right?\n\n**CH:** Right. And I think that\'s why they\'re proactively de-platforming people and controlling flow of information because there\'s a political terror about the consequences of deep fakes and what they\'re going to do to dialogue.\n\n**BG:** Yeah, the point they\'re going to come to.\n\n**CH:** Yeah. Put a pin in that because there\'s two more points. So, as I mentioned, the first is just the curation of the information itself. And putting it in a way that it promotes instead of siloing idea flow, idea quality, separation of objective reality from subjective reality. And then when you\'re looking at the subjective to give you a spectrum of viewpoints, almost like a next-generation Nolan chart to show you different viewpoints.\n\nOkay, so then second there\'s clearly a data economy that exists. And surveillance capitalism is not just a nice term. It\'s a multi-billion perhaps trillion dollar economy. It\'s very valuable to society in certain respects. It allows you to micro target people. It allows you to have more friction-free commerce. You get the right products to the right people. So there\'s a huge advertising model and that shouldn\'t go away, but it should respect the privacy of the individual.\n\nSo there\'s been a lot of attempts to explore better ad models like with Brave and BATs, for example. I think whatever social network you create, you have to move in that particular direction where people are able to monetize their data and preserve their privacy, and actually get a share of the profit from the interactions that they have. And then the third design goal has to be the infrastructure itself is horrendously expensive to maintain. I mean, you\'re talking about petabytes of data. All these systems have N squared plus interactions. And so as your social network gets to a billion people, that quadratic complexity becomes very difficult to curate and manage. So the computational cost of that infrastructure, there\'s a reason why Google is so big and Amazon is so big and Facebook is so big.\n\nSo you somehow have to figure out how you subsidize a decentralized distributed system to curate and store all of that information. And you actually have to make data and users an economic actor, or they get pruned out if they don\'t contribute enough to the system. And we haven\'t quite figured out how to do that in a much simpler sense with just smart contracts and these big systems.\n\nI mean, you see things like IPFS and Gollum and other attempts to distribute network and data and storage. But if those protocols are imperfect, and when you talk about a social network, you talk about people posting videos, every day, 4k videos. You talk about people posting pictures every day, sometimes 100s of them, millions of meaningful interactions, even a small clique. If you take an extended family, that\'s going to be over a month\'s time, probably a million plus interactions of various things from likes and thumbs up. And then you\'re adding these intelligent agents that also have to do an enormous amount of processing on a regular basis. And those agents are only going to get more sophisticated and be interacted with a lot. So you have to have a lot of that be handled by the edges, the end user.\n\n**BG:** Yeah, yeah, yeah, absolutely. And that\'s hard. I mean, we\'ve been working on that with a project called NewNET, which is spun off of SingularityNET. And I think we understand a lot about the architecture that has to be there and about how this sort of split up machine learning algorithms for this sort of a hardware infrastructure. But there\'s a lot of work to be done there. There\'s a lot of avenues for inter-operation of NewNET, SingularityNET, and Cardano there. But I mean, it\'s hard. It\'s hard to do computer science and software engineering. And on the other hand, obviously Google and Amazon and Microsoft have solved a lot of really hard large-scale software engineering problems, different ones. But I mean, I think with a fraction of the effort that they put in, I think we can solve that problem.\n\n**CH:** Yeah, they\'re cheating because they always have a trusted third party. And so that massively simplifies your protocol. Their problem is easier. This is a harder problem. But on the other hand, computer science and hardware have both advanced a lot since they started doing what they\'re doing. But yeah, the incentive engineering aspect, incentive design aspect is quite critical and quite fascinating and exists for end users and also just within the developer community. Because I mean, what you see now is the significant majority of AI PGS, and we\'re going to work for these big tech companies. Or start a startup, which then gets acquired by one of these big tech companies. So the incentive structures of end users and of developers have sort of been channeled. They\'ve been channeled around these large tech companies, which is an amazing achievement. I would be proud if I created one of them. On the other hand, it\'s not optimal, but it\'s doing the course of society.\n\nAnd I mean, this is one thing that interests me, in our own collaboration over the next few years. I\'ve been working with my team in SingularityNET to architect a five-year tentative plan for how to roll out and grow SingularityNET on Cardano platform. I mean, part of this involves the AGI token, the new AGI on the ada token that we\'re working to launch as a new version of Singularity AGI token. Because we need the AGI token to be the right sort of incentive mechanism, largely on the backend. For AI algorithm developers and for AI application developers who are building these applications backending on the AI, you need the incentivization there to work right in order to create the systems that will be creating the right incentive structures for end users.\n\n**BG:** And I think things like the Catalyst Program within Cardano or a very interesting step there. I mean, where in Catalyst community members democratically vote with some liquid democracy mechanisms that they vote on, which Cardano projects should get some tokens. And I\'ve been watching and participating now, and then on the Catalyst discussions. And I want to do something that\'s a lot like that with some added dimensions, for SingularityNET on Cardano for fostering the community and expanding the community to build AI applications on our shared decentralized network. Because you need the right incentive structures on all these different levels and they need to coordinate together, which is hard. But I mean, there I think Tokenomics sort of gives you an advantage over what the big tech has because it\'s more scriptable and it\'s more flexible than the money and stock options and the incentive mechanisms they have.\n\n**CH:** Well, what\'s so cool about Catalyst is there\'s at the end of this year, going to be at least probably a $100 million worth of value that\'s available to the community. And the partnership with IdeaScale is just the beginning. We keep adding more and more firms to assist us with figuring out how to build a productive voting community, because it\'s not just the raw participation. So we say, "Hey, I think about two, 3% of ada holders are right now in idea scale, Because it\'s still kind of in a beta form. Our goal is to get that to 50% before the end of the year." But then we were trying to identify what meaningful participation means?\n\nBecause I would argue the American election system is not meaningful at all. You just show up and vote, but whether you spent hours thinking carefully about it, or you just voted randomly, it doesn\'t really matter. And the system doesn\'t differentiate that. So you end up with very poor outcomes and rational ignorance and a race to the bottom, effectively. So, meaningful participation is something we\'re definitely very interested in. And our hypothesis is that\'s going to lead to significantly better funding outcomes. So our return on intention is quite good for the system. \n\nIt gives you this M & M thing. It feels so empty without M & M, maintenance and moonshots. So maintenance means that you can maintain the system as it is and iterate and refine and evolve, and moonshots means that you have enough money to go pursue a high risk, high return research. And most great societies do this through some vehicle. It can be the Horizons program, the European Union, or it can be DARPA in the United States where they say, "All right, we\'re going to throw a bunch of money at some crazy stuff." And the odds are, it\'s probably not all going to work out. In fact, we seldom get exactly what we want, but then every now and then, we get fiber optic cables and satellites and the internet, and we get self-driving cars, and we get CALO and these other cool things.\n\nThe value to any DApp that comes over to Cardano is that you get to reuse the catalyst stack at some point, and then you can start entertaining, "Well, what does a treasury system look like within our ecosystem?" So, let\'s look three, five years out into the future, and let\'s say SingularityNET\'s gotten a lot of adoption. There\'s tons of transaction volume. You could put a slight tax on each transaction that can go into a treasury system for all the AGI holders. And then suddenly, you now have a mini catalyst just for AGI, and you can follow your own M & M strategy. So one part can say, "Hey, we just want to add more agents and more capabilities," and the other part can say, "Let\'s go tackle a super hard problem in the AI space." And it\'s really risky to go chase that problem. It may be the Holy Grail AGI, or it could be a subset of that or a compositional subset where you can decompose that problem to a collection of subproblems, and you\'re solving one of them. And if you fail, it\'s okay. And if you succeed, that solution lives in the open domain, and it\'s not controlled by a company. It\'s controlled by a protocol, so it\'s ubiquitously accessible.\n\n**BG:** So with what we\'re planning out now with a certain amount of AGI ADA tokens, I think we can do something catalyst based that can help get AI developers on the SingularityNET on Cardano platform and can help build toward both applied narrow AI in domains from social media to medicine, to DeFi as well as other components toward AGI. But there\'s also much bigger things. Like if you think about it, we\'re competing with these trillion-dollar companies, right, so I mean, eventually, we need custom hardware for decentralized AGI. If there is enough usage, as you say, a modest fee on usage can, can drive catalyst-based funding of research. And I mean, you could fund the design and prototyping of decentralized AGI chips, right?\n\nI mean, ultimately, we need to be seeding these exponential economic growth processes to the point where there\'s more wealth in the decentralized AI ecosystem than there is in the centralized AI ecosystem, which sounds very fanciful now. But I mean, I\'m a lot older than you. I\'m old enough to remember the computer \n\ncompanies were like Honeywell right? No one believed that PC companies were going to supply them, let alone internet companies like online ad agencies. Right? But this is how things go. And I mean, in the same way, the potential for network effects and exponential growth based on the right incentive mechanisms on multiple layers... The potential is there for a decentralized AI ecosystem to grow much bigger than the current trillion dollar companies. I mean, you just need to see the right growth processes in place. And I think, between our communities and codebases, we\'re able to see what those are right now, but of course, getting that seeding to work involves an endless number of difficult subproblems, both technological and human.\n\n**CH:** Right. Well, that\'s the value of trade. Bob makes the spear, and Alice makes the rope. So one of the things we\'re trying to focus on in Cardano is abstracting the toolsets and capabilities of the protocol so that each DApp that comes can reuse that, and they don\'t have to be a domain expert.\n\n**BG:** That\'s what got me to fall in love with Cardano in the first place. It\'s like, this is actually a reasonable software architecture, right? I mean, you\'re using functional programming. You\'re breaking things down into pieces. So if I want to take some AI algorithm and make it do homomorphic encryption or multi-party computing, so it runs in a secure and scalable way, I don\'t need to write all that code myself. There\'s actually tools within the blockchain infrastructure that are useful as code when you\'re on the AI level. I mean, Ethereum is super cool. Launching smart contracts into the world was a landmark thing, but I mean, the Ethereum codebase is not like that. There\'s nothing in there you\'re going to reference or use within your secure AI layer.\n\n**CH:** Well, the computation model is just wrong. It\'s got a global state, and so you can\'t grow beyond a certain amount.\n\n**BG:** It\'s supposed to be a world computer, but you cannot build a functional world computer that way.\n\n**CH:** No. You have to go from global to local. And then you just have so many problems in that model. In fact, we just had a lecture this morning with Manuel Chavravarty talking about the differences with the extended UTX cell model to the Ethereum style accounts model. And we\'ll publish that video probably next week, but it just becomes so obviously self-evident that while it\'s a great proof of concept, the system... First, it can\'t scale. And second, the use of other utilities comes at the same resources for everything. So whether you\'re using a voting system, or you\'re using a stablecoin or a DEX, it all comes from one pool of finite resources. So if one of those resources gets over consumed by a Crypto Kitties, it makes all the other resources in the system more expensive. And that\'s a bizarre and asinine model. If a catalyst, for example, runs as a side chain of Cardano\'s... So let\'s say we have tons of DApps bombarding that, using that for the voting systems for their DApp, that will have no impact at all on the main chain performance.\n\n**BG:** A hundred US dollars in gas for you to swap transactions.\n\n**CH:** I know.\n\n**BG:** And how can you obsolete Wall Street that way? I mean, it\'s going to be tough, right? But on the other hand, I think the foundational algorithms to get around those problems are there in Cardano. And then, in SingularityNET, we have foundational algorithms for distributing and decentralizing secure AI. So, I mean, I think ingredients are there for what needs to be done. On the downside, none of us has the war chest that Google and Amazon and Apple and Microsoft do, so we have to work around that by being cleverer than them and designing the right incentive mechanisms so that you get positive feedback effects and network effects, and things can really grow. And I think that this year is going to be pivotal actually, but we\'re going to... I mean, you\'ve got native assets coming out, and we\'ll be putting AGI token as a native asset, and then a few other SingularityNET spin offs as native assets.\n\nBut I mean, we\'re going to get to a flourishing native asset ecosystem in Cardano, and then SingularityDAO, which is a DeFi system we\'re building on SingularityNET, I mean, we can use to help coordinate getting liquidity into all these Cardano native assets. I\'m super psyched about that coming out publicly because not many people are thinking about what you can do when you have a real programming language as a smart contract framework, which security by design is built in. So, I mean, I think we\'re really providing stuff that is prepared to explode in an incredible way in 2021.\n\n**CH:** Yeah. So first about the treasury management, Tesla 2008 was a day away from bankruptcy, and now it\'s worth more than Toyota, Honda, Nissan, and Ford and GM combined. I mean, it\'s just crazy how fast they grew. So treasuries can grow exponentially if you get to a certain... It\'s almost like a standing ovation model where a few people stand up and clap, and then eventually you hit this point, and then everybody just gets up and claps. And it\'s the same thing, I think, with capital and companies. There\'s a few pivotal moments that you have where you\'re just right at this explosive growth, and then boom, the hockey stick happens, and then suddenly you have a lot there. And I think that\'s happening in the crypto industry. I remember when we hit a billion dollars with Bitcoin, and I was like, "Wow, this is incredible." We could never fathom a trillion dollars. It was a crazy concept, and that had happened within eight years of that point. It took nearly five years for it to get to a billion. So it\'s extraordinary how quickly things can grow.\n\nThen in terms of the collaboration, getting to that, Plutus is coming very soon, and we have this test net coming out. What we\'re doing is we\'re going to beat the hell out of it. So we\'d love for your guys to beat the hell out of it with the SingularityDAO.\n\n**BG:** Beat the hell out of it. That\'s right. Yeah.\n\n**CH:** We\'re a little easier because we have the Hard Fork Combinator, but your mistakes tend to sit around forever. Like we made a lot of protocol design mistakes with Byron, and we still have to support them. And so we found a really nice way of doing that. But when we released version one of Plutus and the extended UTXO model and native asset standard, that\'s probably not going to be perfect because nothing is. As an engineer, version one\'s there, but yet we have to be backwards compatible. So when you go to version two, you still have to support version one. So to me, it\'s super important that we get as many people as quickly as possible, beat the hell out of the native assets standard, beat the hell out of, especially Plutus, before we do the next hard fork to bring that in because I would rather not be backwards compatible with obviously wrong things as we are with Byron.\n\nSo it\'s great to have you guys around. I know that the code you\'re going to write is very novel, and it\'s also going to push the system to its limits. And you\'re going to create a very strong demand for performance and scale, I think. And I can already see several areas where we would like to use AI, for example, transaction fees. We have this fee parameter, and that\'s right now set with the update system, so the minimum transaction fee is a DDoS parameter. It\'d be so cool once we have Oracles and DEXs within the system, and we have some notion of the value of ada relative to the US dollar, to create an automated transaction monetary policy that can take those data points and compare them to other networks real-time, and then try to make sure that we always have a compatible-\n\n**BG:** This is actually a subtle point that we\'ve been discussing between SingularityNET platform team and Cardano platform team, right? Because I mean, the transaction framework for Cardano now, and that\'s planned for common native assets, it\'s fine from what we\'re doing with SingularityNet at this moment, but if we want to go to a swarm AI or microservices model, where you have a whole bunch of little AIs that within the second, one AI is consulting others to create others. I mean, if you really want to get AI by this dynamic microservices architecture, I want to have this using the blockchain rather than all off on the side. I mean, you need a way for some sub-networks to have substantially lower transaction fees, but then you need some system that\'s intelligent in some sense to regulate and moderate that because you still need to protect against DDoS attacks and then all sorts of other things, right. So there\'s a lot of areas like that where some machine learning, participating in the infrastructure can help a lot. And one of the things it can help with is to help make the system better able to manifest the emergence of higher levels of intelligence and learning, right, so you got a lot of positive cycles there.\n\n**CH:** Yeah, and you want it to be deterministic yet dynamic. And you would also like it to be globally aware of competition. So you\'d like the agents to be able to parse all the competing blockchains and look at their monetary policies, look at their transaction policies or transaction rates and their relative values to each other, and then be able to pull that into Cardano and form a transaction policy based on that.\n\n**BG:** It is there, right. I mean, the data is there online. You can download it into your AI, and I think that\'s quite feasible. So, yeah, going back to decentralized social networks, where we started, I mean, there\'s been, as you know, and you\'ve looked at this in more depth than me even... I mean, there\'s been loads and loads of attempts to make decentralized social networks. There\'s dozens of cool projects started by smart well-intentioned people with the right vision. Obviously, none of them has yet become the next Facebook or Twitter. I mean, some like Minds.com from Bill Ottman, I think, is really cool, but I log on there not yet as often, even as I log onto Facebook, which is not that often, right. I mean, Mines is great. It just doesn\'t have such a critical mass of people yet, although it\'s done a way, way better job than the vast majority of decentralized social networks, right?\n\nSo how do we get Minds and Everipedia and dozens of other decentralized social network platforms and the new ones that haven\'t been heard of yet... How do we get these to really take off? And I think we share the conclusion that a lot of what\'s needed there is to make the underlying stack more amenable to lower costs, larger-scale operations of the needed kinds, both in data storage and processing distribution, and then the distributed AI, also. It\'s interesting, Jack Dorsey from Twitter has seen this also, and they\'re looking at making a decentralized protocol and reorganizing the Twitter stack. The question there is, can you really make that work with incentive structures that are implicit in Twitter as the company that it is?\n\n**CH:** That\'s why I separate the base protocol from the interface, like what Steem did. They had the Steem protocol and then Steem at the interface, and their problem was that they didn\'t have a full end to end monetary policies, so they had value leakage. There was no incentive to buy the token, but they used the token to curate information. Had they solved that problem, it would be still around and much larger, but I think that Twitter can survive with a decentralized social network protocol because it would just be a very popular, curated interface to it, and they\'d still have their network effect. It\'s just the customers, and the data would be ephemeral. They could flow from one interface to another interface and get that same experience. The problem right now is you have to rebuild the network effect every time you launch a new one of these things. Every time we want to do an internet application, we have to completely rebuild the internet underneath it. It\'s a preposterous thing, right? Yeah.\n\n**BG:** It makes sense, and I think it\'s visionary of Jack Dorsey to even entertain the notion, right? I mean, not many corporations of that scale are willing to-\n\n**CH:** Well, it\'s a proactive solution to a big problem he has because if he plays censor and chief and he has to de-platform people from the protocol, then he can never win.\n\n**BG:** I wouldn\'t want that job either because, I mean, you got people that are clearly colluding to kill someone. Fine. You ban them. You have people who are saying stuff that\'s nasty but not yet criminal. And then I don\'t want them to be in the job of telling what\'s too nasty and what\'s okay. I mean, court systems aren\'t perfect at that, but I mean, they\'ve been honed for that over significant periods of time, and you don\'t want to have to do that at fast speed and large scale as part of operating your tech company. And I mean, none of these tech companies actually want that job, right. That\'s not why they got into the business, like how can I censor people\'s political speech? So, I mean, of course, if things can be reorganized so that that job is done by the community for the community, rather than having to be done by the CEO. I mean, that\'s far, far better. And the community won\'t do it perfectly, but actually, it will do a better job than these centralized authorities. And I mean, it\'s completely possible to do that. \n\nWe did a lot of simulations of Singularity \'s machine learning-moderated reputation system over the last couple of years. You can make decentralized, AI-guided rating and reputation systems and you can tune them and you can see if I tune it one way, you get information silos, if you tune it another way, you just get trolls and spammers and so forth. If you tune it in a different way, you get a system that self-policing and fosters a healthy level of interaction. And you can do this to get networks that self-regulate without anyone giving top level control. If this is operating within the current global political systems, which I have my issues with too, as I\'m sure you do, but it\'s there, then you still have top level control over things that are clear crimes, according to the nation states people\'s bodies are sitting in, but you don\'t need top level control for anything else.\n\nAnd I think that not just would avoid garbage like minds are proud of being de-platformed. It would also create something that\'s a breeding ground for positive and creative and beneficial content in which people\'s minds are being nudged toward positive growth, rather than channeled into this site and click on this ad. I think potential is there to do that. What\'s a little scary is that handful of us in the decentralized AI space, the two of us, probably understand more about how to achieve this than anyone else on the planet. It\'s actually a very big and significant problem, both in terms of setting the stage for a positive singularity and just making life less shitty for humanity on the planet at this moment.\n\n**CH:** The one thing I\'ve always learned from being a cryptocurrency guy is that incentives are king, and it\'s always been an incentives problem. How many people were, in 1990, being paid to think about social networks? You\'d probably be in the sociology department at Harvard or something that, or toying around in an MIT AI group or something. But it wasn\'t a real job and nobody would understand. How many people who are experts in how to build effective social networks are floating around now? There\'s thousands of them. They\'re fabulously wealthy. So if you show that in a free market system you can achieve great wealth, or at least the prospect of great wealth by building a system of a certain design, then you\'ll end up getting a lot of it.\n\nThe cryptocurrency space was exactly the same. How many people were experts in Bitcoin-like systems in 2010? Very few. Now in 2021, now the existing chairman of the Securities Exchange Commission, Gensler, he was lecturing at MIT on cryptocurrencies. That\'s how far we\'ve gone in just such a short period of time because the incentives are right. So when I look at this problem, I say, "Well, how do we get the incentives in the right way to encourage a large clique of people to come in and actually start applying serious hardcore brainpower to these types of problems?" So it\'s a first mover situation. Now, to the minds and these other guys, to that earlier point you brought up, I look at them almost like mechanical horses. When we were first thinking, how do we build a better horse? If we all let\'s build a robot horse, or a steam powered horse or something like that. Well now there\'s this automobile idea that we\'ve been toying around with. Maybe that\'s just a fundamentally more competitive or better model.\n\nOr similarly, when people are thinking about vacuum tubes, you can certainly optimize them, and I\'m sure you could build a much better vacuum tube today than they were building back in the 1940s. But obviously that was superseded by the transistor. So similarly, when you look at social networks, we have to say what is our automobile moment to replace the horse?" And minds is not it. I think that if those things existed, they\'d actually just be worse than Facebook or Twitter. They\'d get far more siloed. The three problems I outlined, the great moderation, the incentives models being aligned so that people can actually make money and produce money and do useful things with the system, and the infrastructure funding problem.\n\nYou have to solve all three of those with one protocol design and one incentives design. And if you do that, then it\'s going to be this massive beacon that will attract tons of people to come in and start working on an augmented system and evolve it. And it doesn\'t matter if it starts very small. It\'ll go very viral and eventually get to that Tesla-style hockey stick, when Tesla figured out the entire model. Plenty of battery-powered cars before, but their particular model was the one that everything came together and then it had exponential.\n\n**BG:** In terms of tokenomics systems, it\'s quite interesting. Because having a unified scheme and dynamic for promoting the right incentives doesn\'t mean just one token. So you\'re sculpting multiple tokens in a multi-token ecosystem where they interoperate. So say we have ada, we the AGI token on ada, and for, say, a decentralized social network running on ada, leveraging SingularityNET AI, potentially could involve a different token for a certain purpose within that network. You have to think through the inter interoperation of these different networks. And I think that this is one of the things I\'m most excited about in collaboration between the two of us and between SingularityNET and Cardano. I think you guys have done very well in thinking through incentive structures and how they boil down into tokenomic structures. I look forward to some cognitive synergy among us on that.\n\n**CH:** We learned how much we don\'t know. We started this program at Oxford with Elias, and he\'s an algorithmic game theorist. He won the Gödel Prize and all these things. He\'s a really good guy, and he\'s got some... Yeah, Oxford, he\'s got some really good graduate students too, so we said, "Okay, between him and his graduate students, we\'re done. Put a fork in it. We should easily be able to tackle all these consensus incentives problems in Ouroboros." It took two years to refine the entire incentive model just for a consensus algorithm, and now we\'re talking about incentives for the curation of information. So it\'s going to be fun to collaborate. I agree there. It\'s such a hard problem.\n\n**BG:** Curation of information that\'s being created by just decentralized AI algorithms, not just of existing information.\n\n**CH:** Yeah, because you need to create demand for a token and you need to be able to use that token because it\'s demanded and it\'s valuable to incentivize a certain collection of human behavior. You also need to be able to use that to incentivize people to interact with agents in a way that they could become trained to become good cognitive crutches to reinforce the network, and then that token also has to incentivize the hosting of decentralized infrastructure that eventually can scale to petabyte scale storage and huge network capacity and massive computational capacity. It\'s a tall order. It\'s a lot of incentive engineering, and that\'s why I don\'t think these networks exist yet.\n\n**BG:** They don\'t. As you say, once it\'s gotten to a certain level, the potential to gain both personal wealth and to help promote broad benefit to a huge degree, those are both there in a very clear way, which I think can cause a rush of talent into the space of decentralized AI and decentralized AI guided social networks. We\'re at a pivotal moment now, I think, in terms of both the readiness and even eagerness of the world for these technologies and the existence of the needed tools, or at least a significant fraction of the needed tools to create them. This conversation is occurring in a quite interesting time.\n\n**CH:** But the good news is that there\'s a lot of almost right attempts, like the creation of Bitcoin, we had HashCash and bit gold and DigiCash. They were wrong, but they were wrong in the right direction, so you just had to pull them along enough and then eventually it fell through. So you have things like BATs, and I mentioned that before, and suddenly now you\'ve created demand for a token. Steem had enormous growth, but the problem was there was no demand for the token, but there was good payment for content creation and curation. So they got a lot of users, but they had too much value leakage, so they couldn\'t sustain network value and then the system fell apart.\n\nI almost felt if you could combine BATs and Steem together, then you\'ve created a feedback loop where the system will sustain and it\'ll continue to grow at a very rapid rate. However, they had to use the token to subsidize the actual running of the infrastructure. They didn\'t have a sustainable model there. So even though it was the protocol Steem and Steemit was just the company, the Steemit company had all the power and control because they were the people that could afford to run that protocol.\n\n**BG:** We\'ve got a hive now, right? I mean, that\'s the beauty of open source code and decentralized communities.\n\n**CH:** It\'s a Pareto problem where a small group runs the vast majority of everything and there\'s no economic diversity there. With Cardano, we spent five years on Ouroboros because we wanted a system that would get naturally more decentralized over time. So as the price of ADA increases, the K factor increases, and then suddenly you go from 1,000 to 10,000 stake pools and then 100,000, and then all the infrastructure is federated with those stake pools, so suddenly you have 10,000 Hydra channels and suddenly you have 10,000 oracle entry points et cetera, et cetera. So the system, when we get to Bitcoin scale, could have 100,000 stake pool operators that run that, and that scales quite nicely.\n\n**BG:** I\'m sort of thinking into the growth of SingularityNET during the next phase. I think that the platform as we\'ve built it now does something good. If you create multiple AI agents all over the place that collaborate and cooperate to solve hard problems. But we need to architect the next stages of development in a way that will incentivize massive increase of utilization of the platform using AGI ADA, but also that will ensure that increasing decentralized control of the network happens along with this massive increasing utilization. I think we can do it, and I think a lot of the thinking you guys have put into growing Cardano was actually helpful there in ways that we probably don\'t have time to explore in this podcast.\n\n**CH:** Well you get the democracy stack for free with Catalyst, and you also get the decentralized infrastructure for free. One thing we\'d love to do is see if we can get outsourceable computation. I\'ve been following that for God knows how many years. Pinocchio and Geppetto over at MSR, can you do the computation on an untrusted computer, but then provide a proof that the computation was done correctly? And then you know that whatever the result was given is right, regardless of who did it.\n\n**BG:** That\'s there on the computer science level, but it\'s not yet there on the scalable, usable software level.\n\n**CH:** We have some proof that perhaps these algorithms work, but a lot of them are exponential time.\n\n**BG:** One of the things I\'ve been doing with my non-existent spare time is going through all the core cognitive algorithms of OpenCog, which is the AI architecture I\'m working on, expressing all the core algorithms of OpenCog in terms of Galois connections over metagraphs and the chrono morphisms and stuff. So you get the right elegant formalization of your core cognitive algorithms. And then once you\'ve done that, then you can deploy the kind of math you\'re saying so that this core AGI computation could be done by outsourced computing. So the math and CS is there for a lot of these different things, but there\'s a number of stages yet to go through before that kind of thing is rolled out scalably.\n\n**CH:** That\'s an interesting mathematical expression. Do you deal with a dependent type system?\n\n**BG:** It\'s an independent pair of consistent probabilistic type systems, so yeah.\n\n**CH:** That\'s a mouthful. But can you prove anything interesting? You can show certain things that are isomorphic to each other or what you are looking for with those.\n\n**BG:** We are working on that right now, actually. But this would probably lead us too deep down some usually interesting rabbit holes for a broad audience podcast.\n\n**CH:** Okay, fair enough. All right. Well, Ben, this has been so much fun. I have another meeting I got to jump into, but I really enjoyed our time.\n\n**BG:** Yeah, this is fantastic. It\'s both broad and deep, and I think decentralized social networks, it\'s both really important on its own, and I think we can work together to solve it, but it also highlights a bunch of other more general points, both about bringing Singularity and Cardano together and about just what we need blockchain and AI together to do. So yeah, very cool. Look forward to the next one.\n\n**CH:** I guess a closing point is platforms tend to get defined by the killer apps that are on the platforms, and I\'m very glad that one of the most meaningful and significant applications on our platform is SingularityNET. I would hate to see us be defined by Crypto Kitties or something like that. It\'s great to have you guys around. I think this collaboration is going to result in an enormous amount of evolution of our own platform and an acid testing of things in a way that\'s very productive for everybody. And my hope is you guys become one of the most successful pieces of infrastructure on top of a Cardano and it leads to a lot of user growth. And we\'re not just collaborating technologically. I think we\'re going to share some office space at some point in Ethiopia.\n\n**BG:** The space has been found, actually. So our Addis team and your Addis team will co-locate.\n\n**CH:** John was very excited about it, so I imagine the office is quite nice.\n\n**BG:** It\'s in Bole, which is a great neighborhood. It was a very pleasant and surprising coincidence that we actually both had flourishing teams in Addis Ababa contributing to the development of our various platforms. Very cool that maybe the next time we meet face to face will be over some injera in Addis.\n\n**CH:** That\'d be a lot of fun. That\'d be a lot of it just to have to get rid of the civil war and the COVID, but those are just minor technical details,  All right. Thank you so much, Ben.\n\n**BG:** Great. Thanks a lot.\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Decentralizing social media: a conversation with Ben Goertzel and Charles Hoskinson',
                                subtitle: 'The minds behind SingularityNET and Cardano come together to explore a vision of the future of decentralization, AI, and social media.',
                                audio: null,
                                soundcloud: null,
                                body_content: '<!--StartFragment-->\n\n*At the end of 2020, we announced our collaboration with SingularityNET, in an exclusive [fireside chat](https://www.youtube.com/watch?v=W3O5F_CCT8c) between Charles Hoskinson and SingularityNET founder & CEO, Ben Goertzel.* \n\n*SingularityNET recently shared further information on the partnership when they announced their exciting [Phase Two initiative](https://blog.singularitynet.io/singularitynet-phase-two-massive-token-utilization-toward-decentralized-beneficial-agi-6e3ac5a5b44a),* [](https://blog.singularitynet.io/singularitynet-phase-two-massive-token-utilization-toward-decentralized-beneficial-agi-6e3ac5a5b44a) *which includes a shift from Ethereum to Cardano, to achieve new network functionalities and launching a Stream of New AGI-ADA Tokens.*\n\n*Last week, Charles and Ben sat down again together in a special [SingularityNET podcast](https://www.youtube.com/watch?v=TNWJGGc7ESI). In a wide-ranging discussion, the pair explore decentralized social media, the Cardano collaboration, and how a benevolent general AI technology might help a healthier social discourse.*\n\n*Here, in this exclusive long read, we have transcribed the whole conversation for you to enjoy and savour.*\n\n*<!--EndFragment-->*\n\n**Ben Goertzel:** Alright. Pleasure to be chatting once more Charles. And I thought it\'ll be amazing to have an on air discussion on the topic that\'s been in so many people\'s minds recently, which is the perhaps of critical importance of decentralization for social media and social networks, because this is something we both been thinking about deeply for quite a long time and have been both moving toward action on for quite a long time in our own ways, maybe the AI spin and you with Cardano and blockchain. But now things seem to be coming to a head and the world seems to suddenly be concerned that a few large corporations are programming everyone\'s brains in bizarre ways. So, yeah, maybe it is cool to start out just by hearing your overview of the topic.\n\n**Charles Hoskinson:** Yeah, it\'s an interesting situation. So I\'m kind of conflicted. So, I\'m a big libertarian and the libertarian guys say, "Hey, let the market decide. So when someone gets de-platformed, we say, "Hey, it\'s a private company. They can do whatever they want." But the issue is collusion and so the watershed moment for me wasn\'t the de-platforming of Trump. I said, yeah, okay the guy violated the end user license agreement probably 9 million times. At some point you have to throw the guy out. The issue was the de-platforming of Parler, because that was a very different animal.\n\nSo the whole argument was, well, if you don\'t like Twitter, go compete with it, build your own social network. That\'s exactly what Parler did. And they had different moderation standards. But then what occurred was that all of Silicon Valley got together and they colluded and they basically jointly decided to completely de-platform Parler. So Amazon took them down, Apple took them down, Google took them down. And if you\'re put in a market position where 100% of the mobile market and most of the web market is basically blacklisting you and you have no way to be on a cell phone for an average consumer, no way to have a website for an average consumer without going to extraordinary lengths and it\'s almost like the pirate bay. You have to host servers in Afghanistan or something to escape it. That\'s very problematic. It feels like a standard oil controlling the shipping prices of oil back in the 19th century.\n\n**BG:** The appeal to ethics seems so disingenuous, right? It\'s like you can search Qanon on garbage on Google just fine. So then why is it so unethical for there to be Qanon garbage on Parler as some of the content, right?\n\nThe idea that these big tech companies are acting out of a moral necessity to save everyone\'s lives. I mean, it rings very hollow, right? And I mean, there\'s no doubt some people in those companies really are thinking that way. But the alignment of these marginal ethical arguments with obvious corporate profit interests as being advanced by explicit collusion among these big players. It makes it hard to take the ethical aspect one hundred percent seriously.\n\n**CH:** It\'s almost become like an ethical tautology in a certain respect. They say \'Don\'t be evil, except for the times you have to be.\' It\'s a crazy, crazy statement where these companies say, well, we\'re trying to be moral. And I say, \'Okay, but no one elected you. And why are you guys in charge of the totality and curation flow of all information?\' I very firmly believe what needs to happen is we need to split the protocols that carry the information from the interfaces that curate that information. And that feels to be a much more natural thing. The problem we have right now is the stack is vertically completely controlled by a company.\n\nSo, Google doesn\'t just curate what you see in the search engine. They also control the underlying engine. And so as a consequence, they can make a decision on pretty much anything and exclude people laterally. And it\'s the same for the app stores. It\'s the same for social networks. The level of collusion is very problematic. I mean, you can\'t tell me that they didn\'t talk to each other if they all de-platformed someone the same day in the same hour. It\'d be one thing if it was a gradual process where maybe Google and two weeks later, Amazon, something like that. But if it\'s all exactly at the same time, then it means they picked up the phone and they called each other and say, well, we just decided that this is no good for you.\n\nThe problem is that decentralization doesn\'t solve the underlying problem that they\'re complaining about, which is radicalization. The issue is that the way information is being presented, it\'s manipulating our cognitive biases. We\'re creatures of cognitive biases. No matter how smart we are, we have availability bias, and selection bias and confirmation biases. There\'s hundreds of them and social scientists, psychologists and neuroscientists, they think about these things and quantify them. And if you digitize those biases and you build algorithms to exploit them, then what ends up happening is you create echo chambers. So you create these silos. Each and every one of those silos they are incapable of getting out of it. There\'s no idea flow between them. So all you do when you decentralize that, if you don\'t solve that underlying problem is you make the silos more resilient.\n\n**BG:** I mean there\'s a problem when you\'re applying AIs to learn to win in games or video games, which is both a problem and a benefit is that the AI will learn to do what you asked it to do. So if you\'re asking it to get maximum points in this game, and there\'s a way to do it by hacking around the rules of the game in some weird way no human would ever think of, the AI will explore various options. And if it\'s working well, will find some route to achieve the objective function without taking into account whatever implicit constraints you had about what\'s the artful way to do it.\n\nI think something similar exists with social media companies. They have certain metrics and objectives they\'re working toward. Often very, systemically internally, right? I mean, they want people to be looking at their site as long as possible, for example, or they want them to be spending as much as possible clicking on ads. And they\'ll put a lot of human and algorithmic effort into optimizing toward that goal. And then we can\'t be very surprised that these groups of brilliant people make cool software build systems that are optimizing toward that goal, like via whatever hacks they can find. And those hacks include exploiting human cognitive biases and exploiting dynamics of addiction in the human brain and all sorts of human, emotional patterns. Exploiting human angst and the desperation and existential confusion. I mean the algorithms and the corporate systems will exploit whatever they can to achieve the goals they\'re given.\n\nAnd as you say, it\'s organized so that these corporate organisms, which are now hybrid human and digital computing process organisms. These corporate organisms are almost like a parasite on modern society and they\'re achieving their own goal pretty effectively. If you took a bird\'s eye view of human society and where we want to be and where we want to go during the next few years, and maybe leading towards the singularity and creation of AGI and all that. A situation where these corporate human/computer networks orient toward maximizing shareholder value by getting you to buy stuff online and stare at their website as long as possible.\n\nI mean, these sorts of organizations having that much power is not the optimal dynamic for shaping the collective mind, heart and soul of humanity, right? I mean it\'s pretty far off from where we want to be. You\'d imagine that extremism and siloeing and tribalism, which we\'re seeing online and in real life, I think that\'s probably the only scratching the surface of the screwed up patterns that are being fostered. That\'s the surface layer where it\'s easy to see how screwed up it is. And there\'s so many other screwed up individual and collective dynamics that are happening. I wouldn\'t say all caused by this organization of social media in the tech industry, but certainly co-evolving with it and codependent on it.\n\n**CH:** Well, it\'s an interesting thing. So I tend to agree with Max Tegmark in this respect where you invent the car first and then you invent the safety belt. With new technology or new processes, there\'s a lack of wisdom in the safety components of it until after you\'ve suffered the consequences. So, we looked at the oil and gas industry in the 19th century, they started drilling all these wells and only after they started doing that, did we start thinking about environmentalism. And we said, well, maybe it\'s not such a good idea just to have unrestricted oil well drilling. Maybe we need to think carefully about what this is actually doing to the environment.\n\nWell, the oil of the 21st century is really the attention economy and the data economy. And we have all this surveillance capitalism and we have all these early pioneering firms and they\'re effectively mining that. And they\'re creating a social environmental damage by this process, to use an analogy where these algorithms are built and these platforms were built away to exacerbate human nature. So to your point that they didn\'t cause it, but I\'d certainly say that they\'re exacerbating it and-\n\n**BG:** I always think of everything in human society from the end game of legacy humanity. Like we\'re working on creating AGI. If we can create a benevolent AGI, I mean, this is going to make our current problems seem so archaic and silly. Of course, things won\'t be perfect. There will be new problems we can\'t imagine there. But this is certainly the biggest threshold event in the history of humanity, perhaps of life on earth. We could be a few decades from that even less. If there\'s even a decent odds that this singularitarian view is true, I mean then how the collective mind of humanity is shaped is insanely important, right?\n\nBecause the first AGI probably isn\'t going to be just a stupid human, stupid mind in a box, totally separate from human society. The way things are going it\'s more likely to come out of the interaction of multiple different AI components made by multiple parties, serving useful economic functions in the world at large. If the first AGI, which triggers this singularity is coming out of the whole mess of the tech ecosystem and people using the technology to do useful things, I mean then how messy that mess is, is an extremely important thing. And that right now, the direction does not look like the internet AI tech ecosystem is evolving in a great configuration for spotting a benevolent super AGI, 5, 10 to 20 years from now, right? Maybe some redirection if some of the sub-networks in there, like the ones we\'re involved with could affect it. Some redirection would be highly beneficial.\n\n**CH:** Well, the problem with AGI is that that\'s kind of like the Deus ex Machina situation where you\'re saying, well, we could solve this problem if we have this insanely powerful tool. And it\'s like, well, yeah, but maybe we don\'t actually need a tool that powerful to make meaningful progress towards this problem.\n\n**BG:** Decentralized social networks you don\'t need AGI. Absolutely not. You can do a lot with blockchain networks.\n\n**CH:** Hang on. So I think an AI solution does provide a lot of value, but I look at it more like a cognitive crutch. So if you injure your leg you get on crutches or you walk with a cane or something like that. I recently had a gout attack and for two weeks I was on a cane. So it\'s kind of funny. We physically think about this, but for the mental stuff, we don\'t really think we need it. We say, oh, our brains are perfectly well functions. Like no, we\'re dopamine addicts. We\'re constantly manipulated by digital devices and we\'re in a situation where we\'re not acting rationally or objectively most of the time.\n\n**BG:** With access to our hardware and software. We can\'t fix the bugs in the direct way.\n\n**CH:** So the question is, what would be the simplest possible agent, intelligent agent that could be constructed that could act as a cognitive crutch to alert us if we are being manipulated or our behavior is exhibiting patterns that have been propagandized. That feels like it would be a massive step forward.\n\n**BG:** Now we\'re getting it. Some of this stuff that I\'m hoping we will be able to build together with a SingularityNET on the Cardano network over the next few years. I mean, if you look at intelligent virtual assistants now like an Alexa or Google assistant, I mean, A: these things are very stupid in many senses, right? I mean, I have a Google Home Max. I used to play music in my house and the system still hasn\'t realized I never listen to music with vocals during the day. I mean, it doesn\'t have that metadata there. It hasn\'t recognized that very simple pattern, so repeatedly throw stuff at me. I won\'t listen to it. It\'s not even able to understand extremely simple repeated patterns in human behavior, which would help them make more money, even by showing me more stuff I want to listen to, right?\n\nSo these systems are optimized very narrowly to serve certain functions and their functions certainly are not to help us navigate the universe of the internet and media, in a way that\'s optimal for our own growth and self understanding, achieving our own goals and optimizing the collective intelligence of humanity. Very, far from it. So one could envision a personal assistant that had a bit more general intelligence. So it understood at least a little bit of what we actually want and are doing, but also was not controlled by a mega corporation with the primary goal of making them money, but was controlled by us who were being assisted by the personal assistant, right?\n\nI mean, I don\'t want the human personal assistant working for me, helping me do things whose main goal is to make some other corporation money, right? I want the human personal assistant working for me whose goal is to help me because I hired them to help me, right?\n\nAnd we should have digital assistants like that and they\'re going to be building machine learning models of everything we\'re doing like a human assistant builds their own biological model of what their employer is doing. And we should be better than the human assistant. We should be able to explicitly inspect what that model is and edit and correct it if we didn\'t like it and delete that model if we want to, right? So, I mean, we need among other things, we need intelligent virtual agents to help guide our navigation of the whole internet information sphere, which are secure and decentralized and explainable to us. The thing is we can do that without AGI. We can do that with technology we have right now, and this technology can help along the path toward AGI.\n\n**CH:** Where do we get the training data from? That was the one thing I was thinking about is how do I train an agent like that?\n\n**BG:** I mean it\'s going into smartphones that we use all day, right? So the training day that Google and Amazon and so forth are using, where does it come from? It comes from all of us. In principle, you can download most of what Google is basing its training data on you on, but very few of us are doing it. We\'re not using it, right? So, I mean, clearly you need all the data that you\'re using to interact with devices and with people all day. I mean you need that data to be in a secure data world that\'s owned and controlled by you where you\'re confident it\'s being managed and secure. Yeah, but we got to get a little deeper. I mean, it\'s not just interaction use. You\'d have to clearly show an example of confirmation bias to an extent that an ML model would be able to understand that. And so how do you do that in an unsupervised way?\n\n**BG:** We show it all the time, right? And I mean if the AI has a view of a lot of people, I mean, even those of us who are especially clever in some ways and our basic human social, emotional interactions, there\'s a lot that we do, which is the same.\n\nEmotional interactions. There\'s a lot that we do, which is the same as a lot of other people are doing, right? Like in how you interact with an employee versus a romantic partner or a friend or someone who\'s arguing with you. I think the sort of dialogue meta games and the inner dialogue meta games that people are playing, they\'re within the scope of current advanced neuro AI tech to recognize it\'s just, that\'s not what\'s being focused on. What\'s being focused on is recognizing subtle patterns and who\'s going to click on what ad. And I mean, you don\'t need to tell that to predict who\'s going to click on what ad in the most concise and effective way. I mean, you don\'t care. Right?\n\nIt\'s just a principle problem that the tech industry is not currently trying very hard to solve, but yeah, you\'re right. You focus on the AI part and I focus on the blockchain part. But in reality, I mean, you need them because I guess the other guy\'s part is harder because we understand how to solve our part. But I mean, you need both of them. I mean, you need the secure, scalable data ecosystem, respecting data sovereignty and you need that to fuel intelligent virtual assistants that really serve the person that they\'re assisting is the prime directive. Plus this massive scale data analytics that really understands what\'s going on with each of us in a way that lets it genuinely help us.\n\nBecause what is giving a person what they want? Does it mean gratifying their most intense short-term impulse at each moment? Or does it mean giving them what they want in a sort of balance along multiple timescales? Which is at multiple levels of our being, which is what we try to do with our family and our human friends. And AI\'s, they\'re laughably far from making an effort to give us what we want and in the more profound sense at the moment.\n\n**CH:** Right? Well, the reason why I was focusing on the AI part is the biggest part, the blockchain part, the incentives engineering relies very heavily upon the users and the agents inside the system. And so we say, "Okay, how do we incentivize people to supervise and curate data and agents in a way that we get more dialogue and we get a great moderation?" The ideal form would be, if you take clique\'s that are disjoint and you put them in the system, then idea flow starts occurring between them. And over time they\'ll converge into kind of a great moderated middle.\n\nSo you can take a very extremist person and either the system acts like it has an immune system and it kind of kicks them out or that node over time, moderates. The incentives in the system have to be designed that way. The reason we have so many problems in my view with Facebook and Twitter is that it actually has the opposite incentive. You get more clicks and more interaction with the more polarized people become. So the system is built in a way to polarize people as much as possible and thus divide them as much as possible. Because it\'s actually boosting revenue.\n\n**BG:** I think that\'s an easier problem to solve. Righteous indignation and the glorious feeling being approved by others in your ingroup and jointly indignant of the guys in the next group. This is a really easy emotion to manipulate with people. It\'s sort of a low hanging fruit. And to an extent these networks implicitly got stuck in manipulating this low-hanging fruit because it was the easiest way to keep people staring at their app. I mean, just as the internet settled on porn with love, it\'s been with. Because that\'s a really low algorithmic complexity way to keep people staring at something, is to show them naked bodies. So, if something would give greater benefit and even get people to start their site longer in the long run, but it isn\'t quite as simple of a problem, it sort of gets bypassed in the loop of trying to incrementally achieve these metrics more and more each month.\n\nAnd what\'s interesting is that the thought that rearranging sort of the configuration of the tech stack as you suggest in the beginning of the conversation, so like rearranging the tech stack so that the protocols are separate from the applications and then the AI models and tools used to create the AI models and inspect the AI models, they\'re also separate from the applications. I mean, reorganizing things in this way, then it sort of opens up the dynamics of the whole ecosystem in a way that I believe has decent odds of leading to the evolution of social media tools that they give people what they want in a more profound sense. And in doing so, they\'re creating communication networks among people that are not focused entirely on sort of immediate gratification of the ego and soaking of inter tribal rivalries and so forth.\n\nBecause all these good and beautiful things we\'re alluding to, exist on the internet right now. They exist on the internet right now. There\'s love, there\'s compassion, there\'s true connection between people with rival political views or from different historical tribes and so forth. It\'s not that we\'re not capable of that or that it isn\'t there. People are capable of amazing deep connections with other people and have incredible self-awareness and uplifting of their own consciousness. It\'s just, you need networks that foster this rather than trying to squash it and channel you into tribalism and immediate ego gratification. And of course neither you or I nor our teams are going to build all the systems that solve this problem. So you\'re going to create the ecosystem and tool set in which the solutions are going to emerge.\n\n**CH:** Right. Well, that\'s the point of incentives engineering is that it\'s the initial push. And because you don\'t have friction to slow you down, you tend to accelerate and eventually you get to a great place. I mean, Bitcoin obviously got their incentives engineering right. And they went from a single miner to warehouses of miners all around the world. And now this colossal system. We can argue about the power consumption, but that model was quite competitive to a point that it created a trillion dollar ecosystem. So I often think, "Well, what incentives do we need?" And we kind of have three sets of distinct things we need to accomplish at the same time if the network is going to be sustainable and useful to society.\n\nSo one thing is that you would like information to be curated, where it can clearly separate objective reality from the subjective analysis of it and give people a diverse set of viewpoints and understand that stuff is nuanced. So if they get that, then you kind of get rid of the fake news. You also get some consensus in the network of baseline facts. Because right now we live in a reality where people can\'t even agree to basic things. Some people think coronavirus is a hoax. Some people think vaccines are poisoned, et cetera, et cetera. So there\'s just disjoint realities that people are in. It used to be we would have one set of facts. We\'d agree on that. But then our interpretation of what those means-\n\n**BG:** It\'s true. A lot of people really believed Donald Trump had the most people at his inauguration ever, and the New Yorker doctored those images. And of course, sometimes the mainstream media may have distorted something about Trump, but the thing is, that\'s like an image, right? And people didn\'t believe the photograph, they believed the photograph was fake. And when you\'re at that point where people don\'t believe the photographs, then it\'s very hard. Then you have to be on the ground there, observing it in a sort of very clear state of mind to believe anything.\n\nSo, I mean, I\'m not even a realist or materialist fundamentally. I don\'t know if there is an objective reality. But what people are doing is they\'re not thinking in a clear and coordinated way about this belief they have or this thing they\'d been told. What evidence is that grounded in? What\'s the process of grounding the abstraction or the claim in the evidence? That process is broken. And it\'s partly because of AI and advanced informatics tools. Because you can make a deep fake. I mean, it\'s actually hard to tell if this video is Goertzel and Hoskinson or is this video a deep fake of Goertzel and Hoskinson put up by someone to troll all of us. It\'s not immediate seeing is believing to tell that you have to think.\n\n**CH:** Oh yeah. Like the Collider, George Lucas, deep fakes are extraordinary. And that\'s last generation technology. Where they\'re going in a few years is going to be socially very damaging because you\'ll have these perfect simulacrums of major figures and there\'ll be saying and doing terrible things. So that\'s the first part, the curation, go ahead?\n\n**BG:** You need the social network to tell bullshit from reality. So if the social network is broken, then you can\'t tell because you can\'t tell by looking, you can only tell by what you read and what others are saying, right?\n\n**CH:** Right. And I think that\'s why they\'re proactively de-platforming people and controlling flow of information because there\'s a political terror about the consequences of deep fakes and what they\'re going to do to dialogue.\n\n**BG:** Yeah, the point they\'re going to come to.\n\n**CH:** Yeah. Put a pin in that because there\'s two more points. So, as I mentioned, the first is just the curation of the information itself. And putting it in a way that it promotes instead of siloing idea flow, idea quality, separation of objective reality from subjective reality. And then when you\'re looking at the subjective to give you a spectrum of viewpoints, almost like a next-generation Nolan chart to show you different viewpoints.\n\nOkay, so then second there\'s clearly a data economy that exists. And surveillance capitalism is not just a nice term. It\'s a multi-billion perhaps trillion dollar economy. It\'s very valuable to society in certain respects. It allows you to micro target people. It allows you to have more friction-free commerce. You get the right products to the right people. So there\'s a huge advertising model and that shouldn\'t go away, but it should respect the privacy of the individual.\n\nSo there\'s been a lot of attempts to explore better ad models like with Brave and BATs, for example. I think whatever social network you create, you have to move in that particular direction where people are able to monetize their data and preserve their privacy, and actually get a share of the profit from the interactions that they have. And then the third design goal has to be the infrastructure itself is horrendously expensive to maintain. I mean, you\'re talking about petabytes of data. All these systems have N squared plus interactions. And so as your social network gets to a billion people, that quadratic complexity becomes very difficult to curate and manage. So the computational cost of that infrastructure, there\'s a reason why Google is so big and Amazon is so big and Facebook is so big.\n\nSo you somehow have to figure out how you subsidize a decentralized distributed system to curate and store all of that information. And you actually have to make data and users an economic actor, or they get pruned out if they don\'t contribute enough to the system. And we haven\'t quite figured out how to do that in a much simpler sense with just smart contracts and these big systems.\n\nI mean, you see things like IPFS and Gollum and other attempts to distribute network and data and storage. But if those protocols are imperfect, and when you talk about a social network, you talk about people posting videos, every day, 4k videos. You talk about people posting pictures every day, sometimes 100s of them, millions of meaningful interactions, even a small clique. If you take an extended family, that\'s going to be over a month\'s time, probably a million plus interactions of various things from likes and thumbs up. And then you\'re adding these intelligent agents that also have to do an enormous amount of processing on a regular basis. And those agents are only going to get more sophisticated and be interacted with a lot. So you have to have a lot of that be handled by the edges, the end user.\n\n**BG:** Yeah, yeah, yeah, absolutely. And that\'s hard. I mean, we\'ve been working on that with a project called NewNET, which is spun off of SingularityNET. And I think we understand a lot about the architecture that has to be there and about how this sort of split up machine learning algorithms for this sort of a hardware infrastructure. But there\'s a lot of work to be done there. There\'s a lot of avenues for inter-operation of NewNET, SingularityNET, and Cardano there. But I mean, it\'s hard. It\'s hard to do computer science and software engineering. And on the other hand, obviously Google and Amazon and Microsoft have solved a lot of really hard large-scale software engineering problems, different ones. But I mean, I think with a fraction of the effort that they put in, I think we can solve that problem.\n\n**CH:** Yeah, they\'re cheating because they always have a trusted third party. And so that massively simplifies your protocol. Their problem is easier. This is a harder problem. But on the other hand, computer science and hardware have both advanced a lot since they started doing what they\'re doing. But yeah, the incentive engineering aspect, incentive design aspect is quite critical and quite fascinating and exists for end users and also just within the developer community. Because I mean, what you see now is the significant majority of AI PGS, and we\'re going to work for these big tech companies. Or start a startup, which then gets acquired by one of these big tech companies. So the incentive structures of end users and of developers have sort of been channeled. They\'ve been channeled around these large tech companies, which is an amazing achievement. I would be proud if I created one of them. On the other hand, it\'s not optimal, but it\'s doing the course of society.\n\nAnd I mean, this is one thing that interests me, in our own collaboration over the next few years. I\'ve been working with my team in SingularityNET to architect a five-year tentative plan for how to roll out and grow SingularityNET on Cardano platform. I mean, part of this involves the AGI token, the new AGI on the ada token that we\'re working to launch as a new version of Singularity AGI token. Because we need the AGI token to be the right sort of incentive mechanism, largely on the backend. For AI algorithm developers and for AI application developers who are building these applications backending on the AI, you need the incentivization there to work right in order to create the systems that will be creating the right incentive structures for end users.\n\n**BG:** And I think things like the Catalyst Program within Cardano or a very interesting step there. I mean, where in Catalyst community members democratically vote with some liquid democracy mechanisms that they vote on, which Cardano projects should get some tokens. And I\'ve been watching and participating now, and then on the Catalyst discussions. And I want to do something that\'s a lot like that with some added dimensions, for SingularityNET on Cardano for fostering the community and expanding the community to build AI applications on our shared decentralized network. Because you need the right incentive structures on all these different levels and they need to coordinate together, which is hard. But I mean, there I think Tokenomics sort of gives you an advantage over what the big tech has because it\'s more scriptable and it\'s more flexible than the money and stock options and the incentive mechanisms they have.\n\n**CH:** Well, what\'s so cool about Catalyst is there\'s at the end of this year, going to be at least probably a $100 million worth of value that\'s available to the community. And the partnership with IdeaScale is just the beginning. We keep adding more and more firms to assist us with figuring out how to build a productive voting community, because it\'s not just the raw participation. So we say, "Hey, I think about two, 3% of ada holders are right now in idea scale, Because it\'s still kind of in a beta form. Our goal is to get that to 50% before the end of the year." But then we were trying to identify what meaningful participation means?\n\nBecause I would argue the American election system is not meaningful at all. You just show up and vote, but whether you spent hours thinking carefully about it, or you just voted randomly, it doesn\'t really matter. And the system doesn\'t differentiate that. So you end up with very poor outcomes and rational ignorance and a race to the bottom, effectively. So, meaningful participation is something we\'re definitely very interested in. And our hypothesis is that\'s going to lead to significantly better funding outcomes. So our return on intention is quite good for the system. \n\nIt gives you this M & M thing. It feels so empty without M & M, maintenance and moonshots. So maintenance means that you can maintain the system as it is and iterate and refine and evolve, and moonshots means that you have enough money to go pursue a high risk, high return research. And most great societies do this through some vehicle. It can be the Horizons program, the European Union, or it can be DARPA in the United States where they say, "All right, we\'re going to throw a bunch of money at some crazy stuff." And the odds are, it\'s probably not all going to work out. In fact, we seldom get exactly what we want, but then every now and then, we get fiber optic cables and satellites and the internet, and we get self-driving cars, and we get CALO and these other cool things.\n\nThe value to any DApp that comes over to Cardano is that you get to reuse the catalyst stack at some point, and then you can start entertaining, "Well, what does a treasury system look like within our ecosystem?" So, let\'s look three, five years out into the future, and let\'s say SingularityNET\'s gotten a lot of adoption. There\'s tons of transaction volume. You could put a slight tax on each transaction that can go into a treasury system for all the AGI holders. And then suddenly, you now have a mini catalyst just for AGI, and you can follow your own M & M strategy. So one part can say, "Hey, we just want to add more agents and more capabilities," and the other part can say, "Let\'s go tackle a super hard problem in the AI space." And it\'s really risky to go chase that problem. It may be the Holy Grail AGI, or it could be a subset of that or a compositional subset where you can decompose that problem to a collection of subproblems, and you\'re solving one of them. And if you fail, it\'s okay. And if you succeed, that solution lives in the open domain, and it\'s not controlled by a company. It\'s controlled by a protocol, so it\'s ubiquitously accessible.\n\n**BG:** So with what we\'re planning out now with a certain amount of AGI ADA tokens, I think we can do something catalyst based that can help get AI developers on the SingularityNET on Cardano platform and can help build toward both applied narrow AI in domains from social media to medicine, to DeFi as well as other components toward AGI. But there\'s also much bigger things. Like if you think about it, we\'re competing with these trillion-dollar companies, right, so I mean, eventually, we need custom hardware for decentralized AGI. If there is enough usage, as you say, a modest fee on usage can, can drive catalyst-based funding of research. And I mean, you could fund the design and prototyping of decentralized AGI chips, right?\n\nI mean, ultimately, we need to be seeding these exponential economic growth processes to the point where there\'s more wealth in the decentralized AI ecosystem than there is in the centralized AI ecosystem, which sounds very fanciful now. But I mean, I\'m a lot older than you. I\'m old enough to remember the computer \n\ncompanies were like Honeywell right? No one believed that PC companies were going to supply them, let alone internet companies like online ad agencies. Right? But this is how things go. And I mean, in the same way, the potential for network effects and exponential growth based on the right incentive mechanisms on multiple layers... The potential is there for a decentralized AI ecosystem to grow much bigger than the current trillion dollar companies. I mean, you just need to see the right growth processes in place. And I think, between our communities and codebases, we\'re able to see what those are right now, but of course, getting that seeding to work involves an endless number of difficult subproblems, both technological and human.\n\n**CH:** Right. Well, that\'s the value of trade. Bob makes the spear, and Alice makes the rope. So one of the things we\'re trying to focus on in Cardano is abstracting the toolsets and capabilities of the protocol so that each DApp that comes can reuse that, and they don\'t have to be a domain expert.\n\n**BG:** That\'s what got me to fall in love with Cardano in the first place. It\'s like, this is actually a reasonable software architecture, right? I mean, you\'re using functional programming. You\'re breaking things down into pieces. So if I want to take some AI algorithm and make it do homomorphic encryption or multi-party computing, so it runs in a secure and scalable way, I don\'t need to write all that code myself. There\'s actually tools within the blockchain infrastructure that are useful as code when you\'re on the AI level. I mean, Ethereum is super cool. Launching smart contracts into the world was a landmark thing, but I mean, the Ethereum codebase is not like that. There\'s nothing in there you\'re going to reference or use within your secure AI layer.\n\n**CH:** Well, the computation model is just wrong. It\'s got a global state, and so you can\'t grow beyond a certain amount.\n\n**BG:** It\'s supposed to be a world computer, but you cannot build a functional world computer that way.\n\n**CH:** No. You have to go from global to local. And then you just have so many problems in that model. In fact, we just had a lecture this morning with Manuel Chavravarty talking about the differences with the extended UTX cell model to the Ethereum style accounts model. And we\'ll publish that video probably next week, but it just becomes so obviously self-evident that while it\'s a great proof of concept, the system... First, it can\'t scale. And second, the use of other utilities comes at the same resources for everything. So whether you\'re using a voting system, or you\'re using a stablecoin or a DEX, it all comes from one pool of finite resources. So if one of those resources gets over consumed by a Crypto Kitties, it makes all the other resources in the system more expensive. And that\'s a bizarre and asinine model. If a catalyst, for example, runs as a side chain of Cardano\'s... So let\'s say we have tons of DApps bombarding that, using that for the voting systems for their DApp, that will have no impact at all on the main chain performance.\n\n**BG:** A hundred US dollars in gas for you to swap transactions.\n\n**CH:** I know.\n\n**BG:** And how can you obsolete Wall Street that way? I mean, it\'s going to be tough, right? But on the other hand, I think the foundational algorithms to get around those problems are there in Cardano. And then, in SingularityNET, we have foundational algorithms for distributing and decentralizing secure AI. So, I mean, I think ingredients are there for what needs to be done. On the downside, none of us has the war chest that Google and Amazon and Apple and Microsoft do, so we have to work around that by being cleverer than them and designing the right incentive mechanisms so that you get positive feedback effects and network effects, and things can really grow. And I think that this year is going to be pivotal actually, but we\'re going to... I mean, you\'ve got native assets coming out, and we\'ll be putting AGI token as a native asset, and then a few other SingularityNET spin offs as native assets.\n\nBut I mean, we\'re going to get to a flourishing native asset ecosystem in Cardano, and then SingularityDAO, which is a DeFi system we\'re building on SingularityNET, I mean, we can use to help coordinate getting liquidity into all these Cardano native assets. I\'m super psyched about that coming out publicly because not many people are thinking about what you can do when you have a real programming language as a smart contract framework, which security by design is built in. So, I mean, I think we\'re really providing stuff that is prepared to explode in an incredible way in 2021.\n\n**CH:** Yeah. So first about the treasury management, Tesla 2008 was a day away from bankruptcy, and now it\'s worth more than Toyota, Honda, Nissan, and Ford and GM combined. I mean, it\'s just crazy how fast they grew. So treasuries can grow exponentially if you get to a certain... It\'s almost like a standing ovation model where a few people stand up and clap, and then eventually you hit this point, and then everybody just gets up and claps. And it\'s the same thing, I think, with capital and companies. There\'s a few pivotal moments that you have where you\'re just right at this explosive growth, and then boom, the hockey stick happens, and then suddenly you have a lot there. And I think that\'s happening in the crypto industry. I remember when we hit a billion dollars with Bitcoin, and I was like, "Wow, this is incredible." We could never fathom a trillion dollars. It was a crazy concept, and that had happened within eight years of that point. It took nearly five years for it to get to a billion. So it\'s extraordinary how quickly things can grow.\n\nThen in terms of the collaboration, getting to that, Plutus is coming very soon, and we have this test net coming out. What we\'re doing is we\'re going to beat the hell out of it. So we\'d love for your guys to beat the hell out of it with the SingularityDAO.\n\n**BG:** Beat the hell out of it. That\'s right. Yeah.\n\n**CH:** We\'re a little easier because we have the Hard Fork Combinator, but your mistakes tend to sit around forever. Like we made a lot of protocol design mistakes with Byron, and we still have to support them. And so we found a really nice way of doing that. But when we released version one of Plutus and the extended UTXO model and native asset standard, that\'s probably not going to be perfect because nothing is. As an engineer, version one\'s there, but yet we have to be backwards compatible. So when you go to version two, you still have to support version one. So to me, it\'s super important that we get as many people as quickly as possible, beat the hell out of the native assets standard, beat the hell out of, especially Plutus, before we do the next hard fork to bring that in because I would rather not be backwards compatible with obviously wrong things as we are with Byron.\n\nSo it\'s great to have you guys around. I know that the code you\'re going to write is very novel, and it\'s also going to push the system to its limits. And you\'re going to create a very strong demand for performance and scale, I think. And I can already see several areas where we would like to use AI, for example, transaction fees. We have this fee parameter, and that\'s right now set with the update system, so the minimum transaction fee is a DDoS parameter. It\'d be so cool once we have Oracles and DEXs within the system, and we have some notion of the value of ada relative to the US dollar, to create an automated transaction monetary policy that can take those data points and compare them to other networks real-time, and then try to make sure that we always have a compatible-\n\n**BG:** This is actually a subtle point that we\'ve been discussing between SingularityNET platform team and Cardano platform team, right? Because I mean, the transaction framework for Cardano now, and that\'s planned for common native assets, it\'s fine from what we\'re doing with SingularityNet at this moment, but if we want to go to a swarm AI or microservices model, where you have a whole bunch of little AIs that within the second, one AI is consulting others to create others. I mean, if you really want to get AI by this dynamic microservices architecture, I want to have this using the blockchain rather than all off on the side. I mean, you need a way for some sub-networks to have substantially lower transaction fees, but then you need some system that\'s intelligent in some sense to regulate and moderate that because you still need to protect against DDoS attacks and then all sorts of other things, right. So there\'s a lot of areas like that where some machine learning, participating in the infrastructure can help a lot. And one of the things it can help with is to help make the system better able to manifest the emergence of higher levels of intelligence and learning, right, so you got a lot of positive cycles there.\n\n**CH:** Yeah, and you want it to be deterministic yet dynamic. And you would also like it to be globally aware of competition. So you\'d like the agents to be able to parse all the competing blockchains and look at their monetary policies, look at their transaction policies or transaction rates and their relative values to each other, and then be able to pull that into Cardano and form a transaction policy based on that.\n\n**BG:** It is there, right. I mean, the data is there online. You can download it into your AI, and I think that\'s quite feasible. So, yeah, going back to decentralized social networks, where we started, I mean, there\'s been, as you know, and you\'ve looked at this in more depth than me even... I mean, there\'s been loads and loads of attempts to make decentralized social networks. There\'s dozens of cool projects started by smart well-intentioned people with the right vision. Obviously, none of them has yet become the next Facebook or Twitter. I mean, some like Minds.com from Bill Ottman, I think, is really cool, but I log on there not yet as often, even as I log onto Facebook, which is not that often, right. I mean, Mines is great. It just doesn\'t have such a critical mass of people yet, although it\'s done a way, way better job than the vast majority of decentralized social networks, right?\n\nSo how do we get Minds and Everipedia and dozens of other decentralized social network platforms and the new ones that haven\'t been heard of yet... How do we get these to really take off? And I think we share the conclusion that a lot of what\'s needed there is to make the underlying stack more amenable to lower costs, larger-scale operations of the needed kinds, both in data storage and processing distribution, and then the distributed AI, also. It\'s interesting, Jack Dorsey from Twitter has seen this also, and they\'re looking at making a decentralized protocol and reorganizing the Twitter stack. The question there is, can you really make that work with incentive structures that are implicit in Twitter as the company that it is?\n\n**CH:** That\'s why I separate the base protocol from the interface, like what Steem did. They had the Steem protocol and then Steem at the interface, and their problem was that they didn\'t have a full end to end monetary policies, so they had value leakage. There was no incentive to buy the token, but they used the token to curate information. Had they solved that problem, it would be still around and much larger, but I think that Twitter can survive with a decentralized social network protocol because it would just be a very popular, curated interface to it, and they\'d still have their network effect. It\'s just the customers, and the data would be ephemeral. They could flow from one interface to another interface and get that same experience. The problem right now is you have to rebuild the network effect every time you launch a new one of these things. Every time we want to do an internet application, we have to completely rebuild the internet underneath it. It\'s a preposterous thing, right? Yeah.\n\n**BG:** It makes sense, and I think it\'s visionary of Jack Dorsey to even entertain the notion, right? I mean, not many corporations of that scale are willing to-\n\n**CH:** Well, it\'s a proactive solution to a big problem he has because if he plays censor and chief and he has to de-platform people from the protocol, then he can never win.\n\n**BG:** I wouldn\'t want that job either because, I mean, you got people that are clearly colluding to kill someone. Fine. You ban them. You have people who are saying stuff that\'s nasty but not yet criminal. And then I don\'t want them to be in the job of telling what\'s too nasty and what\'s okay. I mean, court systems aren\'t perfect at that, but I mean, they\'ve been honed for that over significant periods of time, and you don\'t want to have to do that at fast speed and large scale as part of operating your tech company. And I mean, none of these tech companies actually want that job, right. That\'s not why they got into the business, like how can I censor people\'s political speech? So, I mean, of course, if things can be reorganized so that that job is done by the community for the community, rather than having to be done by the CEO. I mean, that\'s far, far better. And the community won\'t do it perfectly, but actually, it will do a better job than these centralized authorities. And I mean, it\'s completely possible to do that. \n\nWe did a lot of simulations of Singularity \'s machine learning-moderated reputation system over the last couple of years. You can make decentralized, AI-guided rating and reputation systems and you can tune them and you can see if I tune it one way, you get information silos, if you tune it another way, you just get trolls and spammers and so forth. If you tune it in a different way, you get a system that self-policing and fosters a healthy level of interaction. And you can do this to get networks that self-regulate without anyone giving top level control. If this is operating within the current global political systems, which I have my issues with too, as I\'m sure you do, but it\'s there, then you still have top level control over things that are clear crimes, according to the nation states people\'s bodies are sitting in, but you don\'t need top level control for anything else.\n\nAnd I think that not just would avoid garbage like minds are proud of being de-platformed. It would also create something that\'s a breeding ground for positive and creative and beneficial content in which people\'s minds are being nudged toward positive growth, rather than channeled into this site and click on this ad. I think potential is there to do that. What\'s a little scary is that handful of us in the decentralized AI space, the two of us, probably understand more about how to achieve this than anyone else on the planet. It\'s actually a very big and significant problem, both in terms of setting the stage for a positive singularity and just making life less shitty for humanity on the planet at this moment.\n\n**CH:** The one thing I\'ve always learned from being a cryptocurrency guy is that incentives are king, and it\'s always been an incentives problem. How many people were, in 1990, being paid to think about social networks? You\'d probably be in the sociology department at Harvard or something that, or toying around in an MIT AI group or something. But it wasn\'t a real job and nobody would understand. How many people who are experts in how to build effective social networks are floating around now? There\'s thousands of them. They\'re fabulously wealthy. So if you show that in a free market system you can achieve great wealth, or at least the prospect of great wealth by building a system of a certain design, then you\'ll end up getting a lot of it.\n\nThe cryptocurrency space was exactly the same. How many people were experts in Bitcoin-like systems in 2010? Very few. Now in 2021, now the existing chairman of the Securities Exchange Commission, Gensler, he was lecturing at MIT on cryptocurrencies. That\'s how far we\'ve gone in just such a short period of time because the incentives are right. So when I look at this problem, I say, "Well, how do we get the incentives in the right way to encourage a large clique of people to come in and actually start applying serious hardcore brainpower to these types of problems?" So it\'s a first mover situation. Now, to the minds and these other guys, to that earlier point you brought up, I look at them almost like mechanical horses. When we were first thinking, how do we build a better horse? If we all let\'s build a robot horse, or a steam powered horse or something like that. Well now there\'s this automobile idea that we\'ve been toying around with. Maybe that\'s just a fundamentally more competitive or better model.\n\nOr similarly, when people are thinking about vacuum tubes, you can certainly optimize them, and I\'m sure you could build a much better vacuum tube today than they were building back in the 1940s. But obviously that was superseded by the transistor. So similarly, when you look at social networks, we have to say what is our automobile moment to replace the horse?" And minds is not it. I think that if those things existed, they\'d actually just be worse than Facebook or Twitter. They\'d get far more siloed. The three problems I outlined, the great moderation, the incentives models being aligned so that people can actually make money and produce money and do useful things with the system, and the infrastructure funding problem.\n\nYou have to solve all three of those with one protocol design and one incentives design. And if you do that, then it\'s going to be this massive beacon that will attract tons of people to come in and start working on an augmented system and evolve it. And it doesn\'t matter if it starts very small. It\'ll go very viral and eventually get to that Tesla-style hockey stick, when Tesla figured out the entire model. Plenty of battery-powered cars before, but their particular model was the one that everything came together and then it had exponential.\n\n**BG:** In terms of tokenomics systems, it\'s quite interesting. Because having a unified scheme and dynamic for promoting the right incentives doesn\'t mean just one token. So you\'re sculpting multiple tokens in a multi-token ecosystem where they interoperate. So say we have ada, we the AGI token on ada, and for, say, a decentralized social network running on ada, leveraging SingularityNET AI, potentially could involve a different token for a certain purpose within that network. You have to think through the inter interoperation of these different networks. And I think that this is one of the things I\'m most excited about in collaboration between the two of us and between SingularityNET and Cardano. I think you guys have done very well in thinking through incentive structures and how they boil down into tokenomic structures. I look forward to some cognitive synergy among us on that.\n\n**CH:** We learned how much we don\'t know. We started this program at Oxford with Elias, and he\'s an algorithmic game theorist. He won the Gödel Prize and all these things. He\'s a really good guy, and he\'s got some... Yeah, Oxford, he\'s got some really good graduate students too, so we said, "Okay, between him and his graduate students, we\'re done. Put a fork in it. We should easily be able to tackle all these consensus incentives problems in Ouroboros." It took two years to refine the entire incentive model just for a consensus algorithm, and now we\'re talking about incentives for the curation of information. So it\'s going to be fun to collaborate. I agree there. It\'s such a hard problem.\n\n**BG:** Curation of information that\'s being created by just decentralized AI algorithms, not just of existing information.\n\n**CH:** Yeah, because you need to create demand for a token and you need to be able to use that token because it\'s demanded and it\'s valuable to incentivize a certain collection of human behavior. You also need to be able to use that to incentivize people to interact with agents in a way that they could become trained to become good cognitive crutches to reinforce the network, and then that token also has to incentivize the hosting of decentralized infrastructure that eventually can scale to petabyte scale storage and huge network capacity and massive computational capacity. It\'s a tall order. It\'s a lot of incentive engineering, and that\'s why I don\'t think these networks exist yet.\n\n**BG:** They don\'t. As you say, once it\'s gotten to a certain level, the potential to gain both personal wealth and to help promote broad benefit to a huge degree, those are both there in a very clear way, which I think can cause a rush of talent into the space of decentralized AI and decentralized AI guided social networks. We\'re at a pivotal moment now, I think, in terms of both the readiness and even eagerness of the world for these technologies and the existence of the needed tools, or at least a significant fraction of the needed tools to create them. This conversation is occurring in a quite interesting time.\n\n**CH:** But the good news is that there\'s a lot of almost right attempts, like the creation of Bitcoin, we had HashCash and bit gold and DigiCash. They were wrong, but they were wrong in the right direction, so you just had to pull them along enough and then eventually it fell through. So you have things like BATs, and I mentioned that before, and suddenly now you\'ve created demand for a token. Steem had enormous growth, but the problem was there was no demand for the token, but there was good payment for content creation and curation. So they got a lot of users, but they had too much value leakage, so they couldn\'t sustain network value and then the system fell apart.\n\nI almost felt if you could combine BATs and Steem together, then you\'ve created a feedback loop where the system will sustain and it\'ll continue to grow at a very rapid rate. However, they had to use the token to subsidize the actual running of the infrastructure. They didn\'t have a sustainable model there. So even though it was the protocol Steem and Steemit was just the company, the Steemit company had all the power and control because they were the people that could afford to run that protocol.\n\n**BG:** We\'ve got a hive now, right? I mean, that\'s the beauty of open source code and decentralized communities.\n\n**CH:** It\'s a Pareto problem where a small group runs the vast majority of everything and there\'s no economic diversity there. With Cardano, we spent five years on Ouroboros because we wanted a system that would get naturally more decentralized over time. So as the price of ADA increases, the K factor increases, and then suddenly you go from 1,000 to 10,000 stake pools and then 100,000, and then all the infrastructure is federated with those stake pools, so suddenly you have 10,000 Hydra channels and suddenly you have 10,000 oracle entry points et cetera, et cetera. So the system, when we get to Bitcoin scale, could have 100,000 stake pool operators that run that, and that scales quite nicely.\n\n**BG:** I\'m sort of thinking into the growth of SingularityNET during the next phase. I think that the platform as we\'ve built it now does something good. If you create multiple AI agents all over the place that collaborate and cooperate to solve hard problems. But we need to architect the next stages of development in a way that will incentivize massive increase of utilization of the platform using AGI ADA, but also that will ensure that increasing decentralized control of the network happens along with this massive increasing utilization. I think we can do it, and I think a lot of the thinking you guys have put into growing Cardano was actually helpful there in ways that we probably don\'t have time to explore in this podcast.\n\n**CH:** Well you get the democracy stack for free with Catalyst, and you also get the decentralized infrastructure for free. One thing we\'d love to do is see if we can get outsourceable computation. I\'ve been following that for God knows how many years. Pinocchio and Geppetto over at MSR, can you do the computation on an untrusted computer, but then provide a proof that the computation was done correctly? And then you know that whatever the result was given is right, regardless of who did it.\n\n**BG:** That\'s there on the computer science level, but it\'s not yet there on the scalable, usable software level.\n\n**CH:** We have some proof that perhaps these algorithms work, but a lot of them are exponential time.\n\n**BG:** One of the things I\'ve been doing with my non-existent spare time is going through all the core cognitive algorithms of OpenCog, which is the AI architecture I\'m working on, expressing all the core algorithms of OpenCog in terms of Galois connections over metagraphs and the chrono morphisms and stuff. So you get the right elegant formalization of your core cognitive algorithms. And then once you\'ve done that, then you can deploy the kind of math you\'re saying so that this core AGI computation could be done by outsourced computing. So the math and CS is there for a lot of these different things, but there\'s a number of stages yet to go through before that kind of thing is rolled out scalably.\n\n**CH:** That\'s an interesting mathematical expression. Do you deal with a dependent type system?\n\n**BG:** It\'s an independent pair of consistent probabilistic type systems, so yeah.\n\n**CH:** That\'s a mouthful. But can you prove anything interesting? You can show certain things that are isomorphic to each other or what you are looking for with those.\n\n**BG:** We are working on that right now, actually. But this would probably lead us too deep down some usually interesting rabbit holes for a broad audience podcast.\n\n**CH:** Okay, fair enough. All right. Well, Ben, this has been so much fun. I have another meeting I got to jump into, but I really enjoyed our time.\n\n**BG:** Yeah, this is fantastic. It\'s both broad and deep, and I think decentralized social networks, it\'s both really important on its own, and I think we can work together to solve it, but it also highlights a bunch of other more general points, both about bringing Singularity and Cardano together and about just what we need blockchain and AI together to do. So yeah, very cool. Look forward to the next one.\n\n**CH:** I guess a closing point is platforms tend to get defined by the killer apps that are on the platforms, and I\'m very glad that one of the most meaningful and significant applications on our platform is SingularityNET. I would hate to see us be defined by Crypto Kitties or something like that. It\'s great to have you guys around. I think this collaboration is going to result in an enormous amount of evolution of our own platform and an acid testing of things in a way that\'s very productive for everybody. And my hope is you guys become one of the most successful pieces of infrastructure on top of a Cardano and it leads to a lot of user growth. And we\'re not just collaborating technologically. I think we\'re going to share some office space at some point in Ethiopia.\n\n**BG:** The space has been found, actually. So our Addis team and your Addis team will co-locate.\n\n**CH:** John was very excited about it, so I imagine the office is quite nice.\n\n**BG:** It\'s in Bole, which is a great neighborhood. It was a very pleasant and surprising coincidence that we actually both had flourishing teams in Addis Ababa contributing to the development of our various platforms. Very cool that maybe the next time we meet face to face will be over some injera in Addis.\n\n**CH:** That\'d be a lot of fun. That\'d be a lot of it just to have to get rid of the civil war and the COVID, but those are just minor technical details,  All right. Thank you so much, Ben.\n\n**BG:** Great. Thanks a lot.\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'decentralizing-social-media',
                                url: '/blog/posts/2021/02/05/decentralizing-social-media/',
                                read_time: 57
                            },
                            {
                                publish_date: '2021-01-06T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/344fa779-3928-4439-870f-7977abbfec51/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: ' Project Catalyst blasts off into 2021 ',
                                        subtitle: 'New fund will commit $500k in ada to find groundbreaking ideas which accelerate Cardano development',
                                        audio: '',
                                        soundcloud: [
                                            {
                                                trackid: 987296944
                                            }
                                        ],
                                        body_content: '<!--StartFragment-->\n\nProject Catalyst is the first stage in our Voltaire roadmap, created to bring best-in-class governance to Cardano. Effective governance is vital to Cardano because it gives the power to shape the blockchain to its users. Anyone who signs up to Catalyst will be able to propose ideas, and then registered ada holders will vote on funding proposals focused on the continued evolution of Cardano as a platform and a community. This will not only accelerate development but also sustain the Cardano ecosystem in the long term. \n\n\n\nThis journey began with two test funds, and then Catalyst swung into action for real with [Fund2 in September](https://iohk.io/en/blog/posts/2020/09/16/project-catalyst-introducing-our-first-public-fund-for-cardano-community-innovation/). With it we saw a very early – and remarkable – example of decentralized collaboration. Thousands of people came together – proposing teams, community advisers and ada-holding voters – to generate, refine and prioritize funding for proposals to drive Cardano forward.\n\n\n\nVoting on Fund2 has just concluded and tallying of the votes is under way. Soon, the winning teams will receive funding to help make their proposals a reality. [Join our dedicated Telegram channel for Catalyst](https://t.me/cardanocatalyst) and stay tuned to our social channels for updates on this.\n\n\n\n**Challenge accepted**\n\nMeanwhile, with barely a beat, we’re moving forward with even greater purpose by harnessing the community momentum integral to Catalyst. Fund3 launches today and we want to expand the Catalyst community with every fund, encouraging ever more people to get involved.\n\n\n\nIf you’re not familiar with Project Catalyst, this is how it works. Every funding round begins with a defined set of challenges. Each challenge represents an ‘intention’ by the Cardano community, a collective goal we’d like to achieve – we like to talk of return on intention as the way of measuring progress for the project! Each challenge is designed to be broad enough to inspire both technical and general ideas, while being specific enough to provide focus. As long as an idea addresses a challenge and makes a strong case for meeting the intended outcome, it will be considered. So we welcome all proposals, from marketing initiatives and infrastructure development, to content production and product enhancement. \n\n\n\nProject Catalyst relies on the ingenuity of a global network of participants so all ideas are encouraged and can always be ‘re-entered’ for future funds if they do not meet the challenge criteria at hand.\n\n\n\nFund2 contained a pool of ada worth $250,000 and Fund3 doubles that, distributing $500,000 in ada between proposers, voters, and community advisers. Fund3 has three challenges:\n\n\n\n1. **Developer ecosystem challenge:** How can we encourage developers to build on Cardano in the next six months?\n2. **DApp creation challenge:** What decentralized applications (DApps) should be funded to drive user adoption in the next six months?\n3. **‘Community choice’ challenge:** This new category is where we ask the community itself to set one or more challenges, which will have their own funding round in Fund5. An additional $500,000 pool will be available to cover any goal the community wishes to set, whether it’s about executing the community roadmap, funding content or podcasts, encouraging non-profit work or whatever else is determined to be a priority.\n\nSo how do you participate in Project Catalyst?\n\n\n\n**From sharing insights to submitting ideas** \n\n\n\nFirst of all, anyone wishing to get involved with the project, whether as a proposer, adviser or simply a voter, should sign up to our [collaboration platform](https://cardano.ideascale.com/a/index). You do not have to be an ada holder to propose an idea or take part in the discussion phase. \n\n\n\nFund3 begins with an insight-sharing phase in which people can give their perspectives on the challenge before proposals are launched. Think of this phase as a community brainstorming forum to inspire proposers.\n\n\n\nAfter the discussion of the challenge, participants with proposals will publicly submit an initial draft.\n\n\n\n**Refining ideas, finalizing proposals and review**\n\nCommunity members will be invited to provide constructive criticism, offer suggestions, give positive affirmations in the form of ‘kudos’, and even offer to form partnerships and collaborations with proposing teams. The goal is to pool community knowledge and expertise – and Catalyst members are a diverse crew with valuable life and professional experience to offer. The following graph shows the makeup of people who signed up for Fund2:\n\n\n\n![](https://lh4.googleusercontent.com/8LBEdMEm001aTnHnR8Kq0RPyjg_ggwT_8lPmGOPjcum8nnMg1phpEdbPYFUzhzsLX3pNqES1tR1YcQ0Pwh9XeD3sZzINuOJmlzMCPcUAXGhuMzAjbVhxhMqQWp5OTyqclOGaFJvW)\n\n\n\nAfter community feedback is given, proposers are afforded the opportunity to revise and finalize their plans.\n\nOnce proposals are ready, a group of expert reviewers, recruited as community advisers, will give a rating for how well each one addresses the challenge. After this, ada holders can register and then cast their vote. The votes, which are weighted according to the size of each voter’s holding, are then counted and requested funds distributed to the winning proposals.\n\n\n\n**Looking forward**\n\nFund2 generated incredible creativity and strong proposals, some of which will soon be funded into reality. We expect even greater things from Fund3 as we start building a thriving DApp ecosystem on Cardano. We call Project Catalyst an ‘experiment’ – and we intend to encourage this spirit for some time to come. But our intent is very real and very determined. Every week that goes by presents opportunities to improve and refine this groundbreaking program for, and with, the Cardano community.\n\n\n\n*Join us in developing Cardano’s on-chain governance by signing up to our [IdeaScale](https://cardano.ideascale.com/) collaboration platform and our dedicated Catalyst [Telegram](https://t.me/cardanocatalyst) channel.*\n\n\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: ' Project Catalyst blasts off into 2021 ',
                                subtitle: 'New fund will commit $500k in ada to find groundbreaking ideas which accelerate Cardano development',
                                audio: '',
                                soundcloud: [
                                    {
                                        trackid: 987296944
                                    }
                                ],
                                body_content: '<!--StartFragment-->\n\nProject Catalyst is the first stage in our Voltaire roadmap, created to bring best-in-class governance to Cardano. Effective governance is vital to Cardano because it gives the power to shape the blockchain to its users. Anyone who signs up to Catalyst will be able to propose ideas, and then registered ada holders will vote on funding proposals focused on the continued evolution of Cardano as a platform and a community. This will not only accelerate development but also sustain the Cardano ecosystem in the long term. \n\n\n\nThis journey began with two test funds, and then Catalyst swung into action for real with [Fund2 in September](https://iohk.io/en/blog/posts/2020/09/16/project-catalyst-introducing-our-first-public-fund-for-cardano-community-innovation/). With it we saw a very early – and remarkable – example of decentralized collaboration. Thousands of people came together – proposing teams, community advisers and ada-holding voters – to generate, refine and prioritize funding for proposals to drive Cardano forward.\n\n\n\nVoting on Fund2 has just concluded and tallying of the votes is under way. Soon, the winning teams will receive funding to help make their proposals a reality. [Join our dedicated Telegram channel for Catalyst](https://t.me/cardanocatalyst) and stay tuned to our social channels for updates on this.\n\n\n\n**Challenge accepted**\n\nMeanwhile, with barely a beat, we’re moving forward with even greater purpose by harnessing the community momentum integral to Catalyst. Fund3 launches today and we want to expand the Catalyst community with every fund, encouraging ever more people to get involved.\n\n\n\nIf you’re not familiar with Project Catalyst, this is how it works. Every funding round begins with a defined set of challenges. Each challenge represents an ‘intention’ by the Cardano community, a collective goal we’d like to achieve – we like to talk of return on intention as the way of measuring progress for the project! Each challenge is designed to be broad enough to inspire both technical and general ideas, while being specific enough to provide focus. As long as an idea addresses a challenge and makes a strong case for meeting the intended outcome, it will be considered. So we welcome all proposals, from marketing initiatives and infrastructure development, to content production and product enhancement. \n\n\n\nProject Catalyst relies on the ingenuity of a global network of participants so all ideas are encouraged and can always be ‘re-entered’ for future funds if they do not meet the challenge criteria at hand.\n\n\n\nFund2 contained a pool of ada worth $250,000 and Fund3 doubles that, distributing $500,000 in ada between proposers, voters, and community advisers. Fund3 has three challenges:\n\n\n\n1. **Developer ecosystem challenge:** How can we encourage developers to build on Cardano in the next six months?\n2. **DApp creation challenge:** What decentralized applications (DApps) should be funded to drive user adoption in the next six months?\n3. **‘Community choice’ challenge:** This new category is where we ask the community itself to set one or more challenges, which will have their own funding round in Fund5. An additional $500,000 pool will be available to cover any goal the community wishes to set, whether it’s about executing the community roadmap, funding content or podcasts, encouraging non-profit work or whatever else is determined to be a priority.\n\nSo how do you participate in Project Catalyst?\n\n\n\n**From sharing insights to submitting ideas** \n\n\n\nFirst of all, anyone wishing to get involved with the project, whether as a proposer, adviser or simply a voter, should sign up to our [collaboration platform](https://cardano.ideascale.com/a/index). You do not have to be an ada holder to propose an idea or take part in the discussion phase. \n\n\n\nFund3 begins with an insight-sharing phase in which people can give their perspectives on the challenge before proposals are launched. Think of this phase as a community brainstorming forum to inspire proposers.\n\n\n\nAfter the discussion of the challenge, participants with proposals will publicly submit an initial draft.\n\n\n\n**Refining ideas, finalizing proposals and review**\n\nCommunity members will be invited to provide constructive criticism, offer suggestions, give positive affirmations in the form of ‘kudos’, and even offer to form partnerships and collaborations with proposing teams. The goal is to pool community knowledge and expertise – and Catalyst members are a diverse crew with valuable life and professional experience to offer. The following graph shows the makeup of people who signed up for Fund2:\n\n\n\n![](https://lh4.googleusercontent.com/8LBEdMEm001aTnHnR8Kq0RPyjg_ggwT_8lPmGOPjcum8nnMg1phpEdbPYFUzhzsLX3pNqES1tR1YcQ0Pwh9XeD3sZzINuOJmlzMCPcUAXGhuMzAjbVhxhMqQWp5OTyqclOGaFJvW)\n\n\n\nAfter community feedback is given, proposers are afforded the opportunity to revise and finalize their plans.\n\nOnce proposals are ready, a group of expert reviewers, recruited as community advisers, will give a rating for how well each one addresses the challenge. After this, ada holders can register and then cast their vote. The votes, which are weighted according to the size of each voter’s holding, are then counted and requested funds distributed to the winning proposals.\n\n\n\n**Looking forward**\n\nFund2 generated incredible creativity and strong proposals, some of which will soon be funded into reality. We expect even greater things from Fund3 as we start building a thriving DApp ecosystem on Cardano. We call Project Catalyst an ‘experiment’ – and we intend to encourage this spirit for some time to come. But our intent is very real and very determined. Every week that goes by presents opportunities to improve and refine this groundbreaking program for, and with, the Cardano community.\n\n\n\n*Join us in developing Cardano’s on-chain governance by signing up to our [IdeaScale](https://cardano.ideascale.com/) collaboration platform and our dedicated Catalyst [Telegram](https://t.me/cardanocatalyst) channel.*\n\n\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'project-catalyst-blasts-off-into-2021',
                                url: '/blog/posts/2021/01/06/project-catalyst-blasts-off-into-2021/',
                                read_time: 5
                            },
                            {
                                publish_date: '2020-12-17T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/7f85ed71-17c6-4fdd-8d69-5b6c1d77c6d8/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: ' IOHK partners with Wolfram to power Cardano',
                                        subtitle: 'Cardano joins Bitcoin and Ethereum in integrating into Wolfram’s industry leading technology and knowledge base, Wolfram Alpha. But this is only the beginning of an exciting new partnership.',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: '\n\n<!--StartFragment-->\n\nIOHK is dedicated to making Cardano an industry leading blockchain project. This has led us to collaborating with global leaders in technology, business and finance. Now, we’re pleased to announce a new partnership with Wolfram. As a part of this relationship, Cardano data will be integrated into the Wolfram Alpha computational intelligence engine. This places Cardano alongside Ethereum and the Bitcoin as blockchain data to be included within Wolfram Alpha.\n\n\n\nWolfram and IOHK have historically enjoyed close ties, with Stephen Wolfram presenting at [\\#Cardano2020](https://www.youtube.com/watch?v=h94VrSuPFJc&t=17s) as well as at the IOHK Miami 2019 summit. The company has consistently proven itself to be a leader in pushing open source intelligence across a variety of fields including computation, mathematics, and now, blockchain technology. The inclusion of Cardano data into Wolfram Alpha is a landmark moment for IOHK, but it is just the beginning of our collaboration.\n\n\n\nWe are currently defining a scope of work which would leverage Wolfram Alpha to provide Oracle services for Cardano. Oracles are a crucial component of powering smart contracts. They allow data to be transported from a variety of sources into the blockchain. This information can be anything from election results and sports scores to currency exchange rates and statistical data. This greatly expands Cardano’s ability to offer new ways for developers to integrate advanced external information into their smart contacts.\n\n\n\nAs a part of this ongoing roll out IOHK will also work closely with Wolfram Blockchain Labs. Wolfram Blockchain Labs provides blockchain ecosystems with necessary tools to assist in DLT-based commerce and business innovation. The educational teams at IOHK and Wolfram will collaborate to provide Cardano-specific course material. This will help draw developers and users into the Cardano ecosystem by promoting understanding of the platform. \n\n\n\nIntegrating with Wolfram Alpha also boasts industry leading natural language processing capabilities. This makes Cardano’s information available to virtual assistants like Alexa and Siri. Once integrated, users will be able to query the system to find information or solve computational problems as easily as asking their virtual assistant. We anticipate the initial phases of integration with Wolfram will occur Q2/Q3 of next year.\n\n\n\nIOHK and Wolfram are currently building out a collaborative framework, so we’ll have lots more to share over the months ahead. Meanwhile, if you would like to hear more about the partnership between Wolfram and Cardano, check out our interview with Wolfram Blockchain Labs’ (WBL) Jon Woodard on December’s monthly [Cardano product update](https://www.youtube.com/watch?v=32A3878DLnk&feature=youtu.be).\n\n\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: ' IOHK partners with Wolfram to power Cardano',
                                subtitle: 'Cardano joins Bitcoin and Ethereum in integrating into Wolfram’s industry leading technology and knowledge base, Wolfram Alpha. But this is only the beginning of an exciting new partnership.',
                                audio: null,
                                soundcloud: null,
                                body_content: '\n\n<!--StartFragment-->\n\nIOHK is dedicated to making Cardano an industry leading blockchain project. This has led us to collaborating with global leaders in technology, business and finance. Now, we’re pleased to announce a new partnership with Wolfram. As a part of this relationship, Cardano data will be integrated into the Wolfram Alpha computational intelligence engine. This places Cardano alongside Ethereum and the Bitcoin as blockchain data to be included within Wolfram Alpha.\n\n\n\nWolfram and IOHK have historically enjoyed close ties, with Stephen Wolfram presenting at [\\#Cardano2020](https://www.youtube.com/watch?v=h94VrSuPFJc&t=17s) as well as at the IOHK Miami 2019 summit. The company has consistently proven itself to be a leader in pushing open source intelligence across a variety of fields including computation, mathematics, and now, blockchain technology. The inclusion of Cardano data into Wolfram Alpha is a landmark moment for IOHK, but it is just the beginning of our collaboration.\n\n\n\nWe are currently defining a scope of work which would leverage Wolfram Alpha to provide Oracle services for Cardano. Oracles are a crucial component of powering smart contracts. They allow data to be transported from a variety of sources into the blockchain. This information can be anything from election results and sports scores to currency exchange rates and statistical data. This greatly expands Cardano’s ability to offer new ways for developers to integrate advanced external information into their smart contacts.\n\n\n\nAs a part of this ongoing roll out IOHK will also work closely with Wolfram Blockchain Labs. Wolfram Blockchain Labs provides blockchain ecosystems with necessary tools to assist in DLT-based commerce and business innovation. The educational teams at IOHK and Wolfram will collaborate to provide Cardano-specific course material. This will help draw developers and users into the Cardano ecosystem by promoting understanding of the platform. \n\n\n\nIntegrating with Wolfram Alpha also boasts industry leading natural language processing capabilities. This makes Cardano’s information available to virtual assistants like Alexa and Siri. Once integrated, users will be able to query the system to find information or solve computational problems as easily as asking their virtual assistant. We anticipate the initial phases of integration with Wolfram will occur Q2/Q3 of next year.\n\n\n\nIOHK and Wolfram are currently building out a collaborative framework, so we’ll have lots more to share over the months ahead. Meanwhile, if you would like to hear more about the partnership between Wolfram and Cardano, check out our interview with Wolfram Blockchain Labs’ (WBL) Jon Woodard on December’s monthly [Cardano product update](https://www.youtube.com/watch?v=32A3878DLnk&feature=youtu.be).\n\n\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'iohk-partners-with-wolfram-to-power-cardano',
                                url: '/blog/posts/2020/12/17/iohk-partners-with-wolfram-to-power-cardano/',
                                read_time: 2
                            },
                            {
                                publish_date: '2020-10-06T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/0b407539-3d27-4de5-a711-06e1626dcbd8/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Developer challenge: using blockchain to support the UN’s sustainable development goals',
                                        subtitle: 'IOHK has set up a $10,000 fund to invest in ideas for sustainable development based on Cardano.',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: '<!--StartFragment-->\n\nCreating a decentralized financial and social operating system for the world is the core mission of Cardano. But it’s not one that we can accomplish alone. That’s why we are always on the lookout for relationships which help us build a global foundation for growth. So, we’re thrilled to announce our hackathon challenge to support the UN’s sustainable development goals (SDGs) designed to accelerate progress on fighting hunger, injustice, and climate change.\n\n## Sustainability and blockchain\n\nIn this hackathon challenge we aim to give the blockchain community an opportunity to make an impact on international development. The challenge will draw on IOHK’s expertise in community-focused funding developed with Project Catalyst. This initiative brings innovation, voting, and decentralized funding to Cardano by crowdsourcing development proposals, and financing their implementation.\n\nIOHK and United Nations personnel will use the Project Catalyst platform to find and fund initiatives that align with the UN’s Sustainable Development Goals. These goals were adopted by 193 world leaders in 2015. Each of the 17 targets focus on ending extreme poverty and hunger, fighting inequality and injustice, and tackling climate change by 2030.\n\nThis IOHK-sponsored challenge hopes to promote projects based in the digitization of finance which increase the efficacy and transparency of funding for the UN’s Decade of Action. In the run-up to the 2030 deadline for achieving the global sustainability goals, the UN is marking 75 years since its establishment. Given that the transnational organization works on global collective action problems it has engaged with blockchain technology as a solution.\n\n## Crowdsourcing the future\n\nParticipants in the program can put forward ideas focused on any of the 17 goals. To encourage participation, IOHK is sponsoring a prize fund of ada worth $10,000 as well as ongoing support to bring the projects to fruition. Proposals will be judged by a panel of IOHK and UN employees. They will determine the winners based on an idea’s technical prowess, scalability and social impact, as well as its financial and volunteer support. The winning ideas will be able to seek the advice of experts from both the UN and IOHK to ensure that they are implemented in the most impactful way.\n\nTo qualify for the scheme, entries must be open source and be created for use on the Cardano blockchain. Example code should be written in Marlowe, a domain specific language developed for financial contracts on Cardano. These do not need to be fully coded submissions. Instead they can be ideas which inspire anyone to get involved with blockchain technology and sustainable development. The proposal submission period opens on Saturday October 10th. Participants must be registered by then in order to submit. Entries must be finalized by October 18 at 11:59 MDT. Make sure to check the [official rules](https://static.iohk.io/docs/IOHK_UN_challenge.pdf) to learn more.\n\nWinners will be announced on October 24, United Nations Day, which marks the anniversary of the charter of the organization. We encourage everyone with an interest in using Cardano to achieve sustainability goals to get involved. Make your voice heard to help the UN’s [Decade of Action](https://www.un.org/sustainabledevelopment/decade-of-action/) now. If you are interested more generally in developing Cardano, join Project Catalyst on [Ideascale](https://cardano.ideascale.com/).\n\n<!--EndFragment-->\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Developer challenge: using blockchain to support the UN’s sustainable development goals',
                                subtitle: 'IOHK has set up a $10,000 fund to invest in ideas for sustainable development based on Cardano.',
                                audio: null,
                                soundcloud: null,
                                body_content: '<!--StartFragment-->\n\nCreating a decentralized financial and social operating system for the world is the core mission of Cardano. But it’s not one that we can accomplish alone. That’s why we are always on the lookout for relationships which help us build a global foundation for growth. So, we’re thrilled to announce our hackathon challenge to support the UN’s sustainable development goals (SDGs) designed to accelerate progress on fighting hunger, injustice, and climate change.\n\n## Sustainability and blockchain\n\nIn this hackathon challenge we aim to give the blockchain community an opportunity to make an impact on international development. The challenge will draw on IOHK’s expertise in community-focused funding developed with Project Catalyst. This initiative brings innovation, voting, and decentralized funding to Cardano by crowdsourcing development proposals, and financing their implementation.\n\nIOHK and United Nations personnel will use the Project Catalyst platform to find and fund initiatives that align with the UN’s Sustainable Development Goals. These goals were adopted by 193 world leaders in 2015. Each of the 17 targets focus on ending extreme poverty and hunger, fighting inequality and injustice, and tackling climate change by 2030.\n\nThis IOHK-sponsored challenge hopes to promote projects based in the digitization of finance which increase the efficacy and transparency of funding for the UN’s Decade of Action. In the run-up to the 2030 deadline for achieving the global sustainability goals, the UN is marking 75 years since its establishment. Given that the transnational organization works on global collective action problems it has engaged with blockchain technology as a solution.\n\n## Crowdsourcing the future\n\nParticipants in the program can put forward ideas focused on any of the 17 goals. To encourage participation, IOHK is sponsoring a prize fund of ada worth $10,000 as well as ongoing support to bring the projects to fruition. Proposals will be judged by a panel of IOHK and UN employees. They will determine the winners based on an idea’s technical prowess, scalability and social impact, as well as its financial and volunteer support. The winning ideas will be able to seek the advice of experts from both the UN and IOHK to ensure that they are implemented in the most impactful way.\n\nTo qualify for the scheme, entries must be open source and be created for use on the Cardano blockchain. Example code should be written in Marlowe, a domain specific language developed for financial contracts on Cardano. These do not need to be fully coded submissions. Instead they can be ideas which inspire anyone to get involved with blockchain technology and sustainable development. The proposal submission period opens on Saturday October 10th. Participants must be registered by then in order to submit. Entries must be finalized by October 18 at 11:59 MDT. Make sure to check the [official rules](https://static.iohk.io/docs/IOHK_UN_challenge.pdf) to learn more.\n\nWinners will be announced on October 24, United Nations Day, which marks the anniversary of the charter of the organization. We encourage everyone with an interest in using Cardano to achieve sustainability goals to get involved. Make your voice heard to help the UN’s [Decade of Action](https://www.un.org/sustainabledevelopment/decade-of-action/) now. If you are interested more generally in developing Cardano, join Project Catalyst on [Ideascale](https://cardano.ideascale.com/).\n\n<!--EndFragment-->\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'united-nations-and-iohk-join-forces-to-use-blockchain-for-development-goals',
                                url: '/blog/posts/2020/10/06/united-nations-and-iohk-join-forces-to-use-blockchain-for-development-goals/',
                                read_time: 3
                            },
                            {
                                publish_date: '2020-06-30T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/2f814404-79f8-4459-86d4-f0199e4ecfe1/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Bringing the community together for the Cardano Virtual Summit 2020: Shelley Edition',
                                        subtitle: 'Celebrating the journey and making way for the future with IOHK',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: '<!--StartFragment-->\n\nShelley has arrived and IOHK is gearing up to celebrate with the [Cardano Virtual Summit 2020: Shelley Edition](https://cardanosummit.iohk.io/) on July 2nd and 3rd. Every presentation, panel and guest speaker at this online event, has been chosen to represent the many faces of Cardano. From world-class foundational research to the latest advances in cryptographic development; from the passion and dedication of the wider community to some of the innovators who have created our world and are lighting the path to the future. The event is meant to honor the hard work and dedication of the Cardano community, developers and contributors, and the wider ecosystem.\n\nThe virtual summit, much like IOHK’s 2019 Miami summit will include presentations from IOHK team members, special guest appearances by thought leaders and a keynote speech by IOHK CEO, Charles Hoskinson. We were proud to announce that our guest of honor is internet co-creator and lead internet evangelist for Google, Vint Cerf. As one of the lead architects of the internet Vint is uniquely positioned to give us insight into building world changing technology.\n\nWe’ll also be joined by Caitlin Long of the Wyoming Blockchain Select Committee. The Wall Street professional turned crypto pioneer has been blazing the trail for adoption in the state of Wyoming. She will give us a look at the challenges and opportunities she has faced while pushing for wider adoption of decentralization. Our final special guest, Stephen Wolfram is the creator of the computational knowledge platform Wolfram Alpha and the CEO of Wolfram Research. Cardano shares his dedication to advancing technology through open source research and a commitment to academic excellence. Between each of these important discussions our colleagues at IOHK will take center stage.\n\n## Thought leadership\n\nIOHK’s chief scientist, Aggelos Kiayias, and director of African operations John O’Connor will talk about research and outreach in the Cardano Blockchain. Our panel entitled ‘Haskell, then, now, and the future’ will examine the impact the functional programming language has had and where it is heading. The virtual summit also serves as the launchpad for new advancements like ‘Prism’ our decentralized identity solution. More guest speakers will be announced over the week ahead and we’ll also have a number of special announcements over the 2-day summit itself; we’re keeping those under our hats until then.\n\nThe two day [agenda](https://cardanosummit.iohk.io/images/virtual-summit-agenda.pdf) includes five digital stages with programs dedicated to the ideology of blockchain technology; the science of decentralization, and building distributed ledgers for business and enterprise. We will be discussing next steps for growing the Cardano community alongside oncoming blockchain regulations, governance, and opportunities. In combination, we hope the summit tracks will offer something for anyone interested in the future of Cardano, by the science and ideas that surround it, by the great minds making it all happen and by the incredible community that has brought us here and will take us forward.\n\nSessions will encompass the philosophical as well as the technical. Brian Behlendorf, the CEO of the Hyperledger Consortium will form part of a panel focused on the importance of open source development. IOHK recently [joined](https://iohk.io/en/blog/posts/2020/06/11/why-we-are-joining-hyperledger/) the Hyperledger Consortium, to better exploit our common vision of a future made better through shared knowledge. Following on the philosophy track, artificial intelligence researcher, Ben Goertzel will speak on the intersection of AI and decentralized technology. We hope to announce more exciting sessions in the days leading up to the event. At the end of the day, building the next generation of technology means bringing the best minds of many fields into the same room, even if it’s a virtual one.\n\n## Building community\n\nThe Cardano Virtual Summit 2020: Shelley Edition, won’t be all work and no play. The Covid crisis has forced every conference online in past months. While we can’t recreate the full physical conference experience in the virtual space, we’re keen to provide some of the networking and downtime opportunities you might expect. So we’ve added a virtual ‘chill-out’ zone, with guided meditations, a DJ set, and even an online calligraphy lesson/demonstration. Our virtual platform will allow attendees to enjoy the digital expo space through avatars. We’ll even get the conversation flowing with a digital Shelley cocktail ‘happy hour’ between meetings.\n\nRecent events have made it difficult to meet in person but we see The Cardano Virtual Summit as an opportunity to invite everyone from around the world to participate. Attendance for anyone interested in the summit is absolutely free of charge. To join in, simply [reserve](https://www.ubivent.com/register/cardanovirtualsummit) your spot.\n\nShelley is the culmination of over 5 years of research and development, the creation of a multi-disciplinary team and a remarkable community. The virtual summit is just a single point of time – a time to take stock, reflect and celebrate. But it marks just the start of a groundbreaking new era of decentralization, growth and adoption.\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Bringing the community together for the Cardano Virtual Summit 2020: Shelley Edition',
                                subtitle: 'Celebrating the journey and making way for the future with IOHK',
                                audio: null,
                                soundcloud: null,
                                body_content: '<!--StartFragment-->\n\nShelley has arrived and IOHK is gearing up to celebrate with the [Cardano Virtual Summit 2020: Shelley Edition](https://cardanosummit.iohk.io/) on July 2nd and 3rd. Every presentation, panel and guest speaker at this online event, has been chosen to represent the many faces of Cardano. From world-class foundational research to the latest advances in cryptographic development; from the passion and dedication of the wider community to some of the innovators who have created our world and are lighting the path to the future. The event is meant to honor the hard work and dedication of the Cardano community, developers and contributors, and the wider ecosystem.\n\nThe virtual summit, much like IOHK’s 2019 Miami summit will include presentations from IOHK team members, special guest appearances by thought leaders and a keynote speech by IOHK CEO, Charles Hoskinson. We were proud to announce that our guest of honor is internet co-creator and lead internet evangelist for Google, Vint Cerf. As one of the lead architects of the internet Vint is uniquely positioned to give us insight into building world changing technology.\n\nWe’ll also be joined by Caitlin Long of the Wyoming Blockchain Select Committee. The Wall Street professional turned crypto pioneer has been blazing the trail for adoption in the state of Wyoming. She will give us a look at the challenges and opportunities she has faced while pushing for wider adoption of decentralization. Our final special guest, Stephen Wolfram is the creator of the computational knowledge platform Wolfram Alpha and the CEO of Wolfram Research. Cardano shares his dedication to advancing technology through open source research and a commitment to academic excellence. Between each of these important discussions our colleagues at IOHK will take center stage.\n\n## Thought leadership\n\nIOHK’s chief scientist, Aggelos Kiayias, and director of African operations John O’Connor will talk about research and outreach in the Cardano Blockchain. Our panel entitled ‘Haskell, then, now, and the future’ will examine the impact the functional programming language has had and where it is heading. The virtual summit also serves as the launchpad for new advancements like ‘Prism’ our decentralized identity solution. More guest speakers will be announced over the week ahead and we’ll also have a number of special announcements over the 2-day summit itself; we’re keeping those under our hats until then.\n\nThe two day [agenda](https://cardanosummit.iohk.io/images/virtual-summit-agenda.pdf) includes five digital stages with programs dedicated to the ideology of blockchain technology; the science of decentralization, and building distributed ledgers for business and enterprise. We will be discussing next steps for growing the Cardano community alongside oncoming blockchain regulations, governance, and opportunities. In combination, we hope the summit tracks will offer something for anyone interested in the future of Cardano, by the science and ideas that surround it, by the great minds making it all happen and by the incredible community that has brought us here and will take us forward.\n\nSessions will encompass the philosophical as well as the technical. Brian Behlendorf, the CEO of the Hyperledger Consortium will form part of a panel focused on the importance of open source development. IOHK recently [joined](https://iohk.io/en/blog/posts/2020/06/11/why-we-are-joining-hyperledger/) the Hyperledger Consortium, to better exploit our common vision of a future made better through shared knowledge. Following on the philosophy track, artificial intelligence researcher, Ben Goertzel will speak on the intersection of AI and decentralized technology. We hope to announce more exciting sessions in the days leading up to the event. At the end of the day, building the next generation of technology means bringing the best minds of many fields into the same room, even if it’s a virtual one.\n\n## Building community\n\nThe Cardano Virtual Summit 2020: Shelley Edition, won’t be all work and no play. The Covid crisis has forced every conference online in past months. While we can’t recreate the full physical conference experience in the virtual space, we’re keen to provide some of the networking and downtime opportunities you might expect. So we’ve added a virtual ‘chill-out’ zone, with guided meditations, a DJ set, and even an online calligraphy lesson/demonstration. Our virtual platform will allow attendees to enjoy the digital expo space through avatars. We’ll even get the conversation flowing with a digital Shelley cocktail ‘happy hour’ between meetings.\n\nRecent events have made it difficult to meet in person but we see The Cardano Virtual Summit as an opportunity to invite everyone from around the world to participate. Attendance for anyone interested in the summit is absolutely free of charge. To join in, simply [reserve](https://www.ubivent.com/register/cardanovirtualsummit) your spot.\n\nShelley is the culmination of over 5 years of research and development, the creation of a multi-disciplinary team and a remarkable community. The virtual summit is just a single point of time – a time to take stock, reflect and celebrate. But it marks just the start of a groundbreaking new era of decentralization, growth and adoption.\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'bringing-the-community-together-for-the-cardano-virtual-summit-2020-shelley-edition',
                                url: '/blog/posts/2020/06/30/bringing-the-community-together-for-the-cardano-virtual-summit-2020-shelley-edition/',
                                read_time: 4
                            },
                            {
                                publish_date: '2020-06-15T00:00:00.000Z',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/d7ff7981-5871-4a03-b7e9-2cc8765843a5/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Integrating and advancing with Adrestia',
                                        subtitle: 'Taking the challenge out of fast-paced blockchain development',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: '<!--StartFragment-->\n\nFor exchanges and developer partners, integrating with any blockchain can be challenging. The technology often moves so quickly that keeping up with the pace of change can be unrealistic. Cardano’s development and release process are now driving things forward apace. Managing parallel software development workstreams moving at different speeds can feel a bit like changing the tires on a truck while it’s driving at 60 miles per hour. \n\nCardano’s vision is to provide unparalleled security and sustainability to decentralized applications, systems, and societies. It has been created to be the most technologically advanced and environmentally sustainable blockchain platform, offering a secure, transparent, and scalable template for how we work, interact, and create, as individuals, businesses, and societies.\n\nIn line with these ambitions, we needed to devise a way that our partners could swiftly, easily and reliably integrate with Cardano, regardless of what was going on under the hood. Whatever the pace and cadence of future rollouts, we wanted to develop a consistent method by which all updates to the core node could be easily adopted by everyone.\n\nIn order to make that integration and interaction with Cardano easier and faster, IOHK engineers formed the Adrestia team, to take responsibility for building all the web APIs and libraries that make Cardano accessible to developers and application builders. Developments to the node can then focus on performance and scalability, while users will always be able to interact with it effortlessly. The name Adrestia was chosen after the goddess of revolt because with these new interfaces we expect everyone to be able to integrate with Cardano, creating a ‘revolution’ in accessibility.\n\n## Enabling developers to keep pace with change\n\nThe goal of the Adrestia team is to provide – via Web APIs – a consistent integration experience so that developers can know what to expect between Cardano roadmap releases. Whether they are a wallet developer or an exchange, users can flexibly explore the chain, make transactions and more.\n\nThe APIs are as follows:\n\n* cardano-wallet: HTTP ReST API for managing UTXOs, and much more.\n* cardano-submit-api: HTTP API for submitting signed transactions.\n* cardano-graphql: HTTP GraphQL API for exploring the blockchain.\n\nThe SDK consists of several low-level libraries:\n\n* cardano-addresses: Address generation, derivation & mnemonic manipulation.\n* cardano-coin-selection: Algorithms for coin selection and fee balancing.\n* cardano-transactions: Utilities for constructing and signing transactions.\n* bech32: Haskell implementation of the Bech32 address format (BIP 0173).\n\nIn addition to providing a flexible and productive way to integrate with Cardano, maintenance is also made easier. With consistency, it can often require less time to update integrations between releases. This familiarity reduces maintenance costs. New software can then deploy in days rather than weeks. Ultimately, anyone can keep pace with change.\n\n## Get Started\n\nThe results are now live in the Byron era of Cardano. Exchanges or third-party wallets using Cardano-SL, should now be integrating to prepare for the new Byron and upgrading to Shelley wallet. These need to happen consecutively to avoid any outages. Full details have been added to the Adrestia team repo and we continue to work with our partners to ensure there is no interruption in service for ada holders keeping their funds on exchanges or in third-party wallets. The chart below shows the difference between the Cardano-SL node and the upcoming Shelley node. The components in red are non-Shelley compatible and will break after the hard fork, while the other components are Shelley compatible and will be supported during and after the hard fork.\n\n![](https://lh5.googleusercontent.com/j_lrO83Ixg29ne93vH3dhw3qnHBGhuPcZcUG36ZCCqK9sV5V5WCPf1VoUh2XH9khEeVxFJGpZb3eBlEgw4aQX6Ejyk3tMta4ARVXrQOE9bQQcsBbWM40xPDbSvEkUrvd2vE2EFUv)\n\nConsistency is key in creating a blockchain network that works for everyone. Cardano is not being built for the next five or ten years, but for the next fifty. Change to the system is inevitable in that time but Adrestia was made to ensure that everyone can connect with the Cardano node. To get started, check out the Adrestia project [repo](https://github.com/input-output-hk/adrestia) and read the[ user guide](https://input-output-hk.github.io/adrestia/).\n\n<!--EndFragment-->',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Integrating and advancing with Adrestia',
                                subtitle: 'Taking the challenge out of fast-paced blockchain development',
                                audio: null,
                                soundcloud: null,
                                body_content: '<!--StartFragment-->\n\nFor exchanges and developer partners, integrating with any blockchain can be challenging. The technology often moves so quickly that keeping up with the pace of change can be unrealistic. Cardano’s development and release process are now driving things forward apace. Managing parallel software development workstreams moving at different speeds can feel a bit like changing the tires on a truck while it’s driving at 60 miles per hour. \n\nCardano’s vision is to provide unparalleled security and sustainability to decentralized applications, systems, and societies. It has been created to be the most technologically advanced and environmentally sustainable blockchain platform, offering a secure, transparent, and scalable template for how we work, interact, and create, as individuals, businesses, and societies.\n\nIn line with these ambitions, we needed to devise a way that our partners could swiftly, easily and reliably integrate with Cardano, regardless of what was going on under the hood. Whatever the pace and cadence of future rollouts, we wanted to develop a consistent method by which all updates to the core node could be easily adopted by everyone.\n\nIn order to make that integration and interaction with Cardano easier and faster, IOHK engineers formed the Adrestia team, to take responsibility for building all the web APIs and libraries that make Cardano accessible to developers and application builders. Developments to the node can then focus on performance and scalability, while users will always be able to interact with it effortlessly. The name Adrestia was chosen after the goddess of revolt because with these new interfaces we expect everyone to be able to integrate with Cardano, creating a ‘revolution’ in accessibility.\n\n## Enabling developers to keep pace with change\n\nThe goal of the Adrestia team is to provide – via Web APIs – a consistent integration experience so that developers can know what to expect between Cardano roadmap releases. Whether they are a wallet developer or an exchange, users can flexibly explore the chain, make transactions and more.\n\nThe APIs are as follows:\n\n* cardano-wallet: HTTP ReST API for managing UTXOs, and much more.\n* cardano-submit-api: HTTP API for submitting signed transactions.\n* cardano-graphql: HTTP GraphQL API for exploring the blockchain.\n\nThe SDK consists of several low-level libraries:\n\n* cardano-addresses: Address generation, derivation & mnemonic manipulation.\n* cardano-coin-selection: Algorithms for coin selection and fee balancing.\n* cardano-transactions: Utilities for constructing and signing transactions.\n* bech32: Haskell implementation of the Bech32 address format (BIP 0173).\n\nIn addition to providing a flexible and productive way to integrate with Cardano, maintenance is also made easier. With consistency, it can often require less time to update integrations between releases. This familiarity reduces maintenance costs. New software can then deploy in days rather than weeks. Ultimately, anyone can keep pace with change.\n\n## Get Started\n\nThe results are now live in the Byron era of Cardano. Exchanges or third-party wallets using Cardano-SL, should now be integrating to prepare for the new Byron and upgrading to Shelley wallet. These need to happen consecutively to avoid any outages. Full details have been added to the Adrestia team repo and we continue to work with our partners to ensure there is no interruption in service for ada holders keeping their funds on exchanges or in third-party wallets. The chart below shows the difference between the Cardano-SL node and the upcoming Shelley node. The components in red are non-Shelley compatible and will break after the hard fork, while the other components are Shelley compatible and will be supported during and after the hard fork.\n\n![](https://lh5.googleusercontent.com/j_lrO83Ixg29ne93vH3dhw3qnHBGhuPcZcUG36ZCCqK9sV5V5WCPf1VoUh2XH9khEeVxFJGpZb3eBlEgw4aQX6Ejyk3tMta4ARVXrQOE9bQQcsBbWM40xPDbSvEkUrvd2vE2EFUv)\n\nConsistency is key in creating a blockchain network that works for everyone. Cardano is not being built for the next five or ten years, but for the next fifty. Change to the system is inevitable in that time but Adrestia was made to ensure that everyone can connect with the Cardano node. To get started, check out the Adrestia project [repo](https://github.com/input-output-hk/adrestia) and read the[ user guide](https://input-output-hk.github.io/adrestia/).\n\n<!--EndFragment-->',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'integrating-and-advancing-with-adrestia',
                                url: '/blog/posts/2020/06/15/integrating-and-advancing-with-adrestia/',
                                read_time: 4
                            },
                            {
                                publish_date: '2020-04-07',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/7ff3d68c-a443-44ae-b104-a74a1a686d78/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Architecting Shelley: an interview with Duncan Coutts',
                                        subtitle: 'A fireside chat with Duncan Coutts, Cardano\'s chief technical architect, about Haskell and delivering Shelley',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'Duncan Coutts has been an important guide on the road to the Cardano Shelley mainnet. Long time supporters of IOHK are likely familiar with his signature long hair, beard, and penchant for drinking tea while discussing decentralization in front of a [white board](https://www.youtube.com/watch?v=TZGVgNsJSnA&t=572s). He recently sat down for an interview to discuss the upcoming Byron reboot, the Haskell Shelley testnet, and the conclusion of the pre-Shelley development cycle. Coutts, who has been working with IOHK since 2016, brings a wealth of knowledge from working with the Haskell programming language for nearly 20 years and helping found the Well-Typed consultancy.\n\n**What’s your role at IOHK?**\n\nI’m the chief technical architect for the Cardano project and I’m primarily responsible for the design and implementation of the node. This means that I collaborate with the teams that work on consensus, ledger, networking, and other things. Ultimately, I work to bring everyone together around the same design after a discussion with the team leaders. The design of Cardano is the product of joint work by many individuals working together.\n\n**What does the Haskell programming language bring to Cardano?**\n\nHaskell is an enabler. It makes it easier for us to follow the approach that we believe is right, which is driven by computer science. We know how to do things properly; computer science tells us how. We just need to pick the appropriate techniques to do that. Haskell makes that easier.\n\nIt’s a good fit for Cardano because it suits the high-assurance, specification-driven software that is vital for a blockchain. Haskell helps us find systematic ways of avoiding mistakes. In essence, it’s a better mousetrap.\n\n**You’ve been working with Haskell for a long time. How have you seen the landscape of functional programming change?**\n\nPeople take it seriously now. When I started as an undergraduate in 1999, I thought that Haskell was amazing. Other students thought, ‘Wow that’s totally impractical. How will you ever get a job?’\n\nAt the time, functional programming was an academic curiosity. There wasn’t any prebuilt code and it wasn’t machine readable, which meant that Haskell wasn’t usable for a wide range of people. There wasn’t the tooling, range of libraries, or experience. That has changed over the years: the tooling got better, the libraries got better. IOHK has helped develop the infrastructure for building and distributing open-source Haskell code and the number of libraries exploded. That, combined with more teaching and a gradual change of attitude in the industry, means that people take it more seriously now. Haskell hasn’t changed as much as the industry around us has.\n\n**What’s the biggest change from an industry point of view?**\n\nThere are two things. The first is that attitudes are changing, albeit slowly. People are changing their opinions about what they consider a sensible language choice. Previously, everything had to be in C or Java or maybe Python, but eventually good ideas make progress, even if it takes a long time. You can make a lot of progress by just recognizing that a good idea is a good idea. The mainstream does pick up on important developments, even if it does take 10 or 15 years. The industry has not embraced functional programming wholesale yet, but individual programmers have taken up various ideas. That makes Haskell look less radical.\n\nIf you look at a language like Rust, it has some of the clever type systems of Haskell, although it doesn’t have any functional programming ideas. Even Java and C++ have some functional programming ideas in them these days, so Haskell is not quite so far from the mainstream as it used to be.\n\nThe second major change has been performance, which is getting much better. We’ve recently become competitive with Java in terms of performance. It makes people say, ‘Wow, Haskell is so fast,’ but that’s because they’re comparing it to Python and PHP rather than C. So that’s another way of saying that Haskell has improved slightly, but the industry environment around it has changed as well.\n\n**You have been heavily involved in the Byron reboot which was kicked off last week. Why was this work important?**\n\nThe [Byron reboot](https://iohk.io/en/blog/posts/2020/03/30/what-the-byron-reboot-means-for-cardano/) is the culmination of over 18 months of hard work across multiple IOHK development teams, and constitutes a complete overhaul of the node infrastructure with 100% fresh code. The reboot introduces an extensible, modular design within the node itself, separating out the ledger, consensus, and networking components, as well as improvements and new functionality in the wallet backend and the Cardano explorer.\n\nFor Daedalus users, the Byron reboot will see us moving to a regular update cadence [see our recent piece on [Daedalus Flight](https://iohk.io/en/blog/posts/2020/04/01/we-need-you-for-the-daedalus-flight-testing-program/) for more on that], after which they should find that Daedalus is faster, more reliable, and uses less memory. A lot of the issues users have experienced with Daedalus in the past were due to the underlying node, rather than Daedalus itself. The Byron reboot will go a long way to improving things, and users should see Daedalus syncing and restoring wallets within minutes, even when downloading the entire Cardano blockchain.\n\n**As the chief architect, your job is to lay the foundation for Cardano’s future. What have you focused on to achieve this?**\n\nThe most important aspect in terms of flexibility for the future is keeping different functions separate. One of the big improvements of the Byron reboot is that the ledger rules will be totally independent of the consensus implementation; this modularity means that the ledger rules are perfectly clean mathematical functions, which is a core aspect of functional programming.\n\nAs a result, everything is easier to test, tweak, and change, both now and in the future. The consensus algorithm isn’t entangled with the details of the ledger rules, so we can alter the ledger rules without changing the consensus implementation. This makes integrating Plutus and smart contracts functionality much easier and will also help in the future when we are adding treasury and governance features.\n\nThe consensus implementation itself has also been parameterized so that we can transition from the Ouroboros Classic consensus protocol to BFT and then Praos, which also provides flexibility for future versions of the protocol that haven\'t been developed yet.\n\n**Shelley is a big step towards the future of Cardano, but what is the significance of compiling Haskell into JavaScript and WebAssembly?**\n\nWe’re interested in compiling to JavaScript or WebAssembly because of Plutus. We want to have Plutus contracts or Plutus applications that can be distributed to users, which would include custom interfaces and custom logic with the user rather than in a server. Compiling to JavaScript allows us to do that; you can compile the Plutus code once and distribute it to users on different platforms.\n\n- - -\n\nThanks to Duncan Coutts for his time. As chief technical architect, he’s a cornerstone of the Cardano project and has been fundamental to the ongoing success of the platform. For more interviews with the team, stay tuned to our social channels and the IOHK blog.',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Architecting Shelley: an interview with Duncan Coutts',
                                subtitle: 'A fireside chat with Duncan Coutts, Cardano\'s chief technical architect, about Haskell and delivering Shelley',
                                audio: null,
                                soundcloud: null,
                                body_content: 'Duncan Coutts has been an important guide on the road to the Cardano Shelley mainnet. Long time supporters of IOHK are likely familiar with his signature long hair, beard, and penchant for drinking tea while discussing decentralization in front of a [white board](https://www.youtube.com/watch?v=TZGVgNsJSnA&t=572s). He recently sat down for an interview to discuss the upcoming Byron reboot, the Haskell Shelley testnet, and the conclusion of the pre-Shelley development cycle. Coutts, who has been working with IOHK since 2016, brings a wealth of knowledge from working with the Haskell programming language for nearly 20 years and helping found the Well-Typed consultancy.\n\n**What’s your role at IOHK?**\n\nI’m the chief technical architect for the Cardano project and I’m primarily responsible for the design and implementation of the node. This means that I collaborate with the teams that work on consensus, ledger, networking, and other things. Ultimately, I work to bring everyone together around the same design after a discussion with the team leaders. The design of Cardano is the product of joint work by many individuals working together.\n\n**What does the Haskell programming language bring to Cardano?**\n\nHaskell is an enabler. It makes it easier for us to follow the approach that we believe is right, which is driven by computer science. We know how to do things properly; computer science tells us how. We just need to pick the appropriate techniques to do that. Haskell makes that easier.\n\nIt’s a good fit for Cardano because it suits the high-assurance, specification-driven software that is vital for a blockchain. Haskell helps us find systematic ways of avoiding mistakes. In essence, it’s a better mousetrap.\n\n**You’ve been working with Haskell for a long time. How have you seen the landscape of functional programming change?**\n\nPeople take it seriously now. When I started as an undergraduate in 1999, I thought that Haskell was amazing. Other students thought, ‘Wow that’s totally impractical. How will you ever get a job?’\n\nAt the time, functional programming was an academic curiosity. There wasn’t any prebuilt code and it wasn’t machine readable, which meant that Haskell wasn’t usable for a wide range of people. There wasn’t the tooling, range of libraries, or experience. That has changed over the years: the tooling got better, the libraries got better. IOHK has helped develop the infrastructure for building and distributing open-source Haskell code and the number of libraries exploded. That, combined with more teaching and a gradual change of attitude in the industry, means that people take it more seriously now. Haskell hasn’t changed as much as the industry around us has.\n\n**What’s the biggest change from an industry point of view?**\n\nThere are two things. The first is that attitudes are changing, albeit slowly. People are changing their opinions about what they consider a sensible language choice. Previously, everything had to be in C or Java or maybe Python, but eventually good ideas make progress, even if it takes a long time. You can make a lot of progress by just recognizing that a good idea is a good idea. The mainstream does pick up on important developments, even if it does take 10 or 15 years. The industry has not embraced functional programming wholesale yet, but individual programmers have taken up various ideas. That makes Haskell look less radical.\n\nIf you look at a language like Rust, it has some of the clever type systems of Haskell, although it doesn’t have any functional programming ideas. Even Java and C++ have some functional programming ideas in them these days, so Haskell is not quite so far from the mainstream as it used to be.\n\nThe second major change has been performance, which is getting much better. We’ve recently become competitive with Java in terms of performance. It makes people say, ‘Wow, Haskell is so fast,’ but that’s because they’re comparing it to Python and PHP rather than C. So that’s another way of saying that Haskell has improved slightly, but the industry environment around it has changed as well.\n\n**You have been heavily involved in the Byron reboot which was kicked off last week. Why was this work important?**\n\nThe [Byron reboot](https://iohk.io/en/blog/posts/2020/03/30/what-the-byron-reboot-means-for-cardano/) is the culmination of over 18 months of hard work across multiple IOHK development teams, and constitutes a complete overhaul of the node infrastructure with 100% fresh code. The reboot introduces an extensible, modular design within the node itself, separating out the ledger, consensus, and networking components, as well as improvements and new functionality in the wallet backend and the Cardano explorer.\n\nFor Daedalus users, the Byron reboot will see us moving to a regular update cadence [see our recent piece on [Daedalus Flight](https://iohk.io/en/blog/posts/2020/04/01/we-need-you-for-the-daedalus-flight-testing-program/) for more on that], after which they should find that Daedalus is faster, more reliable, and uses less memory. A lot of the issues users have experienced with Daedalus in the past were due to the underlying node, rather than Daedalus itself. The Byron reboot will go a long way to improving things, and users should see Daedalus syncing and restoring wallets within minutes, even when downloading the entire Cardano blockchain.\n\n**As the chief architect, your job is to lay the foundation for Cardano’s future. What have you focused on to achieve this?**\n\nThe most important aspect in terms of flexibility for the future is keeping different functions separate. One of the big improvements of the Byron reboot is that the ledger rules will be totally independent of the consensus implementation; this modularity means that the ledger rules are perfectly clean mathematical functions, which is a core aspect of functional programming.\n\nAs a result, everything is easier to test, tweak, and change, both now and in the future. The consensus algorithm isn’t entangled with the details of the ledger rules, so we can alter the ledger rules without changing the consensus implementation. This makes integrating Plutus and smart contracts functionality much easier and will also help in the future when we are adding treasury and governance features.\n\nThe consensus implementation itself has also been parameterized so that we can transition from the Ouroboros Classic consensus protocol to BFT and then Praos, which also provides flexibility for future versions of the protocol that haven\'t been developed yet.\n\n**Shelley is a big step towards the future of Cardano, but what is the significance of compiling Haskell into JavaScript and WebAssembly?**\n\nWe’re interested in compiling to JavaScript or WebAssembly because of Plutus. We want to have Plutus contracts or Plutus applications that can be distributed to users, which would include custom interfaces and custom logic with the user rather than in a server. Compiling to JavaScript allows us to do that; you can compile the Plutus code once and distribute it to users on different platforms.\n\n- - -\n\nThanks to Duncan Coutts for his time. As chief technical architect, he’s a cornerstone of the Cardano project and has been fundamental to the ongoing success of the platform. For more interviews with the team, stay tuned to our social channels and the IOHK blog.',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'architecting-shelley-an-interview-with-duncan-coutts-1',
                                url: '/blog/posts/2020/04/07/architecting-shelley-an-interview-with-duncan-coutts-1/',
                                read_time: 6
                            },
                            {
                                publish_date: '2019-09-20',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/fc951213-a949-471f-95a8-b10bd350d2e7/',
                                custom_meta_img: null,
                                old_url: '/blog/plutus-and-marlowe-in-spotlight-at-wyohackathon-2019/',
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'Plutus and Marlowe in the spotlight at WyoHackathon 2019',
                                        subtitle: 'Plutus and Marlowe, IOHK\'s smart contract programming languages, will have their next generations released at the 2019 WyoHackathon',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'The Cardano network was engineered to be the best possible foundation for the future of decentralized technology – but a foundation is only as good as what can be built upon it. Smart contracts are one of the most powerful ways a distributed network can generate value, allowing individuals and organizations to agree to conditions and automatically execute exchanges of information and wealth, all in a trustless way without relying on third parties. But smart contracts are still code, which means that the languages and tools they’re written with make a difference to their final level of security, efficiency, and reliability.\n\nThat said, understanding the potential of smart contracts is different from realizing their integration and adoption. Existing smart contract languages provide the basis for a solution, but are not the final answer. Current smart contracts are complex and difficult to program, partly because they’re built with languages created at the emergence of distributed technologies, and are vulnerable to malicious actors. Blockchain technology has changed drastically since it first emerged, and the conditions that underpinned the first languages are no longer true. The first answer to a problem is rarely the best, and any enterprise-focused solution cannot be gated by complexity or threaten network security.\n\n## Bringing functional programming to smart contracts with Plutus\n\nWe’re big fans of functional programming here at IOHK and are proud to be able to say that the code underpinning the Cardano network is written in Haskell, the world’s foremost functional programming language. Plutus is no different. Compared to their object-oriented counterparts, functional programming languages are less prone to ambiguity and human error – always a good thing – as well as being easier to verify and test. By using Plutus to write smart contracts on the Cardano network, developers benefit from all of the above, as well as the ability to use the same language for both on and off-chain code.\n\nWhile developers will have to wait for the Goguen era to launch smart contracts on the Cardano network, they can begin testing their smart contract skills in the [Plutus Playground](https://testnet.iohkdev.io/plutus/tools/playground/ "Plutus Playground, testnet.iohkdev.io"). IOHK has also created a [Plutus ebook](https://www.amazon.co.uk/Plutus-Writing-reliable-smart-contracts-ebook/dp/B07V46LWTW "Plutus ebook, amazon.com") and [Udemy course](https://www.udemy.com/course/plutus-reliable-smart-contracts/ "Plutus Udemy course, udemy.com") to help developers hit the ground running once Plutus is available on the Cardano mainnet.\n\n## And bringing Plutus to everyone with Marlowe\n\nThe problem with smart contracts, however, is that sometimes the people who know how to write the code don’t have the industry expertise to know how to structure the contracts themselves. Enter Marlowe, IOHK’s domain-specific language (DSL). Marlowe is designed for use by anyone that wants to write a financial smart contract without the programming skills to implement it. Users can try out Marlowe via the [Marlowe Playground](https://testnet.iohkdev.io/marlowe/get-started/sample-marlowe-smart-contracts/ "Marlowe Playground, testnet.iohkdev.io"), a web utility with a user-friendly GUI and drag and drop components, where they can create financial smart contracts which, when complete, will generate fully-functional, implementation-ready Plutus code.\n\nMarlowe gives anyone the ability to gain familiarity with smart contracts while protecting them from unexpected outcomes. It also protects the developer and the system by ensuring that ill-formed smart contracts cannot be run. Finally, Marlowe focuses on commitment-of-funds and time-outs. These make certain that both parties have dedicated funds in the agreement while ensuring that money will not be left in the system after a contract has concluded.\n\n## Laying solid foundations\n\nPlutus, Marlowe, and the Cardano ecosystem continue to evolve to provide the safest and most efficient conditions to build decentralized applications. The next generations of Plutus and Marlowe will be announced at the WyoHackathon at the University of Wyoming on September 20, ahead of their release on mainnet at the start of the Goguen era. Marlowe advances include a high-fidelity development system that aids the writing of executable contracts and the new iteration of Plutus will allow users to access their contracts from web or mobile applications. To get the latest news from the event, you can follow the [WyoHackathon’s Twitter feed](https://twitter.com/hashtag/wyohackathon?lang=en "#wyohackathon, twitter.com").\n\nAt IOHK, we\'re focused on creating the safest, most efficient platform for the building of decentralized applications. Plutus and Marlowe will be the first building blocks to be placed on the foundation which is the Cardano network – and they won\'t be the last. With this new suite of accessible, inclusive tools, Cardano becomes more capable of serving the diverse audiences that stand to benefit from a secure, decentralized network platform.\n\n<small>Artwork, [<i class="fa fa-creative-commons" aria-hidden="true"></i>](https://creativecommons.org/licenses/by/4.0/ "Creative Commons") [Stephen Walker](https://unsplash.com/photos/297SaBStwnQ)</small>\n',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'Plutus and Marlowe in the spotlight at WyoHackathon 2019',
                                subtitle: 'Plutus and Marlowe, IOHK\'s smart contract programming languages, will have their next generations released at the 2019 WyoHackathon',
                                audio: null,
                                soundcloud: null,
                                body_content: 'The Cardano network was engineered to be the best possible foundation for the future of decentralized technology – but a foundation is only as good as what can be built upon it. Smart contracts are one of the most powerful ways a distributed network can generate value, allowing individuals and organizations to agree to conditions and automatically execute exchanges of information and wealth, all in a trustless way without relying on third parties. But smart contracts are still code, which means that the languages and tools they’re written with make a difference to their final level of security, efficiency, and reliability.\n\nThat said, understanding the potential of smart contracts is different from realizing their integration and adoption. Existing smart contract languages provide the basis for a solution, but are not the final answer. Current smart contracts are complex and difficult to program, partly because they’re built with languages created at the emergence of distributed technologies, and are vulnerable to malicious actors. Blockchain technology has changed drastically since it first emerged, and the conditions that underpinned the first languages are no longer true. The first answer to a problem is rarely the best, and any enterprise-focused solution cannot be gated by complexity or threaten network security.\n\n## Bringing functional programming to smart contracts with Plutus\n\nWe’re big fans of functional programming here at IOHK and are proud to be able to say that the code underpinning the Cardano network is written in Haskell, the world’s foremost functional programming language. Plutus is no different. Compared to their object-oriented counterparts, functional programming languages are less prone to ambiguity and human error – always a good thing – as well as being easier to verify and test. By using Plutus to write smart contracts on the Cardano network, developers benefit from all of the above, as well as the ability to use the same language for both on and off-chain code.\n\nWhile developers will have to wait for the Goguen era to launch smart contracts on the Cardano network, they can begin testing their smart contract skills in the [Plutus Playground](https://testnet.iohkdev.io/plutus/tools/playground/ "Plutus Playground, testnet.iohkdev.io"). IOHK has also created a [Plutus ebook](https://www.amazon.co.uk/Plutus-Writing-reliable-smart-contracts-ebook/dp/B07V46LWTW "Plutus ebook, amazon.com") and [Udemy course](https://www.udemy.com/course/plutus-reliable-smart-contracts/ "Plutus Udemy course, udemy.com") to help developers hit the ground running once Plutus is available on the Cardano mainnet.\n\n## And bringing Plutus to everyone with Marlowe\n\nThe problem with smart contracts, however, is that sometimes the people who know how to write the code don’t have the industry expertise to know how to structure the contracts themselves. Enter Marlowe, IOHK’s domain-specific language (DSL). Marlowe is designed for use by anyone that wants to write a financial smart contract without the programming skills to implement it. Users can try out Marlowe via the [Marlowe Playground](https://testnet.iohkdev.io/marlowe/get-started/sample-marlowe-smart-contracts/ "Marlowe Playground, testnet.iohkdev.io"), a web utility with a user-friendly GUI and drag and drop components, where they can create financial smart contracts which, when complete, will generate fully-functional, implementation-ready Plutus code.\n\nMarlowe gives anyone the ability to gain familiarity with smart contracts while protecting them from unexpected outcomes. It also protects the developer and the system by ensuring that ill-formed smart contracts cannot be run. Finally, Marlowe focuses on commitment-of-funds and time-outs. These make certain that both parties have dedicated funds in the agreement while ensuring that money will not be left in the system after a contract has concluded.\n\n## Laying solid foundations\n\nPlutus, Marlowe, and the Cardano ecosystem continue to evolve to provide the safest and most efficient conditions to build decentralized applications. The next generations of Plutus and Marlowe will be announced at the WyoHackathon at the University of Wyoming on September 20, ahead of their release on mainnet at the start of the Goguen era. Marlowe advances include a high-fidelity development system that aids the writing of executable contracts and the new iteration of Plutus will allow users to access their contracts from web or mobile applications. To get the latest news from the event, you can follow the [WyoHackathon’s Twitter feed](https://twitter.com/hashtag/wyohackathon?lang=en "#wyohackathon, twitter.com").\n\nAt IOHK, we\'re focused on creating the safest, most efficient platform for the building of decentralized applications. Plutus and Marlowe will be the first building blocks to be placed on the foundation which is the Cardano network – and they won\'t be the last. With this new suite of accessible, inclusive tools, Cardano becomes more capable of serving the diverse audiences that stand to benefit from a secure, decentralized network platform.\n\n<small>Artwork, [<i class="fa fa-creative-commons" aria-hidden="true"></i>](https://creativecommons.org/licenses/by/4.0/ "Creative Commons") [Stephen Walker](https://unsplash.com/photos/297SaBStwnQ)</small>\n',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'plutus-and-marlowe-in-the-spotlight-at-wyohackathon-2019-1',
                                url: '/blog/posts/2019/09/20/plutus-and-marlowe-in-the-spotlight-at-wyohackathon-2019-1/',
                                read_time: 4
                            },
                            {
                                publish_date: '2019-09-12',
                                author: null,
                                video_id: null,
                                main_image: 'https://ucarecdn.com/a49c56d4-ed92-4b92-88f3-4e3a23c08186/',
                                custom_meta_img: null,
                                old_url: null,
                                haskell: null,
                                localized: [
                                    {
                                        lang: 'en',
                                        title: 'IOHK brings Plutus to Wyoming\'s hackathon',
                                        subtitle: 'Cardano engineers introduce next phase of the smart contract platform to the Cowboy State',
                                        audio: null,
                                        soundcloud: null,
                                        body_content: 'The state of Wyoming is famous for being part of the American frontier, but it has also established a new reputation, with blockchain pioneers blazing trails in the Cowboy State. But why Wyoming?\n\n\n\nThe blockchain revolution in Wyoming is the result of a series of laws and regulations passed within its borders. These key pieces of legislation include exemptions from money transmitting laws for virtual assets, as well as a blockchain ‘sandbox’ bill that would allow decentralized businesses to operate free from the red tape encountered elsewhere in the US. The state is also home to the Wyoming Blockchain Coalition, headed by former Wall Street corporate financier Caitlin Long, which has worked to make Wyoming the standard-bearer of blockchain in the country.\n\n\n\nIn 2018, IOHK relocated its headquarters to Wyoming to take advantage of the state’s legislative embracing of distributed ledger technology, making it the biggest decentralized company in the state. As a result, IOHK has become a nexus for developers, crypto enthusiasts, businesses, and government officials in the area. Events like the 2019 WyoHackathon bring these groups together to advance the cutting edge of blockchain innovation.\n\n‘We’re thrilled to welcome the Cardano community to this special event in IOHK’s home state,’ says Caitlin Long. The event has also inspired a group of high school students from a remote part of Wyoming to make the journey to participate in the hackathon and meet IOHK CEO, Charles Hoskinson. ‘There is something special building between the University of Wyoming computer science department and Cardano!’ she adds.\n\n\n\nThe hackathon will see hundreds of developers participating in workshops, presenting papers, and acquainting themselves with new technology. Charles Hoskinson and Cardano’s senior product manager David Esser will be among the speakers at the event, alongside prominent leaders in the blockchain industry such as Jesse Powell of Kraken and Anthony Pompliano of Morgan Creek Digital. September marks the second anniversary of the Cardano project and is a milestone for IOHK, with several major advances to Cardano being delivered. Plutus engineers Jann Müller and Michael Peyton Jones will be at the event to explain how work on Cardano is progressing to create the ideal environment for smart contract development and execution.\n\n\n\nLast but certainly not least, the next iteration of the Plutus framework will be released during the hackathon. Plutus is a functional programming language and smart contract platform that allows developers of all kinds to launch smart contracts on the Cardano network. While Ethereum paved the way for programmable blockchains, it also has some significant barriers to entry. IOHK aims to bring greater scalability, sustainability, and interoperability to the crypto sphere by allowing anyone to build on a distributed ledger. Ultimately, it is developers that will build the businesses which will solve local and international problems. Plutus was created to enable those developers, and is supported by an IOHK-created \\[programming book](https://www.amazon.com/Plutus-Writing-reliable-smart-contracts-ebook/dp/B07V46LWTW "Plutus ebook on Amazon, amazon.com").\n\n\n\nBoth Wyoming and IOHK have aligned their interests in supporting the next generation of thinkers in distributed ledger technology. Events like the hackathon help to inspire and elevate those who will build the decentralized infrastructure of the future. We hope that the 2019 WyoHackathon will be another pioneering step on the road towards better, more comprehensive adoption and use of both blockchain and crypto technology.\n\n\n\n_To find out more, check out the \\[WyoHackathon 2019 website](https://wyohackathon.io/ "WyoHackathon 2019 website, wyohackathon.io")._',
                                        uses_mathjax: false,
                                        attachments: []
                                    }
                                ],
                                lang: 'en',
                                title: 'IOHK brings Plutus to Wyoming\'s hackathon',
                                subtitle: 'Cardano engineers introduce next phase of the smart contract platform to the Cowboy State',
                                audio: null,
                                soundcloud: null,
                                body_content: 'The state of Wyoming is famous for being part of the American frontier, but it has also established a new reputation, with blockchain pioneers blazing trails in the Cowboy State. But why Wyoming?\n\n\n\nThe blockchain revolution in Wyoming is the result of a series of laws and regulations passed within its borders. These key pieces of legislation include exemptions from money transmitting laws for virtual assets, as well as a blockchain ‘sandbox’ bill that would allow decentralized businesses to operate free from the red tape encountered elsewhere in the US. The state is also home to the Wyoming Blockchain Coalition, headed by former Wall Street corporate financier Caitlin Long, which has worked to make Wyoming the standard-bearer of blockchain in the country.\n\n\n\nIn 2018, IOHK relocated its headquarters to Wyoming to take advantage of the state’s legislative embracing of distributed ledger technology, making it the biggest decentralized company in the state. As a result, IOHK has become a nexus for developers, crypto enthusiasts, businesses, and government officials in the area. Events like the 2019 WyoHackathon bring these groups together to advance the cutting edge of blockchain innovation.\n\n‘We’re thrilled to welcome the Cardano community to this special event in IOHK’s home state,’ says Caitlin Long. The event has also inspired a group of high school students from a remote part of Wyoming to make the journey to participate in the hackathon and meet IOHK CEO, Charles Hoskinson. ‘There is something special building between the University of Wyoming computer science department and Cardano!’ she adds.\n\n\n\nThe hackathon will see hundreds of developers participating in workshops, presenting papers, and acquainting themselves with new technology. Charles Hoskinson and Cardano’s senior product manager David Esser will be among the speakers at the event, alongside prominent leaders in the blockchain industry such as Jesse Powell of Kraken and Anthony Pompliano of Morgan Creek Digital. September marks the second anniversary of the Cardano project and is a milestone for IOHK, with several major advances to Cardano being delivered. Plutus engineers Jann Müller and Michael Peyton Jones will be at the event to explain how work on Cardano is progressing to create the ideal environment for smart contract development and execution.\n\n\n\nLast but certainly not least, the next iteration of the Plutus framework will be released during the hackathon. Plutus is a functional programming language and smart contract platform that allows developers of all kinds to launch smart contracts on the Cardano network. While Ethereum paved the way for programmable blockchains, it also has some significant barriers to entry. IOHK aims to bring greater scalability, sustainability, and interoperability to the crypto sphere by allowing anyone to build on a distributed ledger. Ultimately, it is developers that will build the businesses which will solve local and international problems. Plutus was created to enable those developers, and is supported by an IOHK-created \\[programming book](https://www.amazon.com/Plutus-Writing-reliable-smart-contracts-ebook/dp/B07V46LWTW "Plutus ebook on Amazon, amazon.com").\n\n\n\nBoth Wyoming and IOHK have aligned their interests in supporting the next generation of thinkers in distributed ledger technology. Events like the hackathon help to inspire and elevate those who will build the decentralized infrastructure of the future. We hope that the 2019 WyoHackathon will be another pioneering step on the road towards better, more comprehensive adoption and use of both blockchain and crypto technology.\n\n\n\n_To find out more, check out the \\[WyoHackathon 2019 website](https://wyohackathon.io/ "WyoHackathon 2019 website, wyohackathon.io")._',
                                uses_mathjax: false,
                                attachments: [],
                                slug: 'iohk-brings-plutus-to-wyomings-hackathon',
                                url: '/blog/posts/2019/09/12/iohk-brings-plutus-to-wyomings-hackathon/',
                                read_time: 3
                            }
                        ]
                    },
                    video_id: null,
                    main_image: 'https://ucarecdn.com/a654b860-da1e-415c-8eb9-0b6188229740/',
                    custom_meta_img: null,
                    old_url: null,
                    haskell: null,
                    localized: [
                        {
                            lang: 'en',
                            title: 'Nervos partnership to build the first cross-chain bridge with Cardano',
                            subtitle: ' Our new collab lets Cardano and Nervos token holders transmit their value across both platforms while building interoperability across the crypto space',
                            audio: null,
                            soundcloud: [
                                {
                                    trackid: 1060596082
                                }
                            ],
                            body_content: '<!--StartFragment-->\n\nIOHK and Nervos are teaming up to build a bridge of interoperability between Cardano and the Nervos Network. Once completed, this pioneering cross-chain bridge will enable users to transact assets between the two blockchains. The end goal is to foster greater interoperability while expanding the global reach and utility of both Nervos and Cardano.\n\n\n\nThe Nervos ‘Common Knowledge Base’ ([CKB](https://coinmarketcap.com/currencies/nervos-network/historical-data/)) is a permissionless, layer 1, open-source, proof-of-work blockchain protocol focused on creating the foundations for an interoperable universal public network. It allows any crypto asset to be kept in a secure, immutable, and permissionless environment with the added benefit of smart contracts and layer 2 scaling. \n\n\n\nNervos is developing this robust network through three key components. Together, these make up the Universal Passport, Nervos’ approach to next generation interoperability. \n\n\n\n* **PW Core** – enables developers to build applications on all chains\n* **Nervos’ Polyjuice** – an Ethereum-compatible layer that allows developers to port a smart contract from Ethereum to Nervos\n* **Force Bridge** – a trustless bridge that enables cross-chain transactions between Nervos and a spectrum of blockchains. Nervos will use Force Bridge to connect directly to Cardano, which means that users will be able to transact using their existing Cardano wallets.\n\n\n\n## Bridging blockchains with transportable tokens\n\n\n\nSo what does this mean in practice? Holders of Nervos CKByte (CKB) and ada will be able to transact both currencies interchangeably. Nervos users will also be able to take advantage of Cardano\'s native asset standard to create tokens that can be ported and used across both networks. On top of this, the bridge enables developers on both chains gain access to services and features to expand their DApp ecosystem and user bases. \n\n\n\n[Mousebelt](https://www.mousebelt.com/), a full-service blockchain accelerator, will build the bridge with financial support from Nervos. The Cardano team will contribute expertise and resources to connect Cardano to the bridge. Development work is already underway and it is expected to be completed in the next six weeks. \n\n\n\n\'Using the Force Bridge to link the Nervos Network and Cardano is especially exciting given the relationship we have already built with IOHK,\' said Kevin Wang, co-founder of Nervos. \'We have been growing our research and development partnership, but we will soon have a tangible bridge that will also showcase the power of the Force Bridge and push us further along the road to a functional and interoperable network.\'\n\n\n\nThis bridge is just part of our collaboration with Nervos. \'We share a vision of a world that works on a ‘constellation’ of interoperating blockchains,\' says Romain Pellerin, CTO at Input Output. \'We believe that academic research is also fundamental to advancing the entire crypto space. Together we will also be co-authoring academic papers to pioneer improvements to the UTXO model, explore universal accounting standards, and contribute to the future development of decentralized technology through open-source research.\'\n\n\n\nBlockchain technology will only achieve mainstream acceptance when end users are not locked into one blockchain or standard, but can seamlessly access value and utility, regardless of which blockchain they are using. \'Bridges like this are an absolute necessity in order to ensure that users have a seamless experience,\' continued Pellerin. ‘By connecting our communities and finding innovative new ways to work together, as we have been doing with Nervos, we can ensure that blockchain lives up to its promises of creating a fairer and more efficient global financial operating system.\'\n\n\n\n*Check out the [Nervos website](https://www.nervos.org/) for more information on upcoming partnerships and research initiatives.*\n\n\n\n<!--EndFragment-->',
                            uses_mathjax: false,
                            attachments: []
                        },
                        {
                            lang: 'jp',
                            title: 'NervosとのパートナーシップでCardanoと初のクロスチェーンブリッジを構築',
                            subtitle: '新たなコラボレーションにより、暗号資産界全体に相互運用性を構築。CardanoとNervosのトークン所有者は、両プラットフォーム間で資産取引が可能に',
                            audio: null,
                            soundcloud: [
                                {
                                    trackid: 1060596082
                                }
                            ],
                            body_content: '<!--StartFragment-->\n\nIOHKとNervosは協力してCardanoとNervosネットワーク間に相互運用性を構築します。完成すれば、この先駆的なクロスチェーンのブリッジにより、ユーザーは2つのブロックチェーン間で資産取引が可能になります。最終目標はより優れた相互運用性を促進すること。その間、NervosとCardano両者のグローバルリーチとユーティリティを拡張していきます。\n\n\nNervosの「Common Knowledge Base」（共通知識ベース：CKB）は、パーミッションレス、レイヤー1、オープンソースのプルーフオブワークブロックチェーンプロトコルで、相互運用可能なユニバーサルパブリックネットワークの基礎を築くことに主眼を置いています。これにより、あらゆる暗号資産は、スマートコントラクトとレイヤー2スケーリングのメリットが追加された、安全、不変、そしてパーミッションレスな環境に保管されます。 \n\n\nNervosはこの頑丈なネットワークを3つの主要コンポーネントを軸として開発しています。これらはともに、Nervosの次世代相互運用性へのアプローチであるユニバーサスパスポートを構成するものです。 \n\n\n\n* **PW Core**（PWコア）- 開発者がすべてのチェーンでアプリケーションを構築することを可能にします。\n* **Nervos’ Polyjuice**（Nervosポリジュース）- 開発者がイーサリアムからNervosへスマートコントラクトを移植できるようにするイーサリアム対応レイヤーです。\n\n* **Force Bridge** (フォースブリッジ - Nervosとさまざまなブロックチェーンとのクロスチェーントランザクションを可能にするトラストレスなブリッジです。NervosはForce Bridgeを使用してCardanoと直接接続し、ユーザーは既存のCardanoウォレットを使用してトランザクションを行うことができます。\n\n\n\n## 可搬トークンでブロックチェーンを橋渡しする\n\n\n\nこれは実際何を意味するのでしょうか。NervosのCKByte（CKB）とADA保有者は、両通貨を交換して取引することができます。NervosユーザーはCardanoのネイティブアセット規格を利用してトークンを作成し、両ネットワークを行き来させて、使用することができます。加えて、ブリッジにより開発者は両チェーン上でサービスや機能へアクセスし、自分たちのDAppエコシステムやユーザーベースを拡張することができます。 \n\n\nフルサービスのブロックチェーンアクセラレーター、[Mousebelt](https://www.mousebelt.com/)は、Nervosから財政支援を得てブリッジを構築します。Cardanoチームは、Cardanoとブリッジを接続するために、専門知識とリソースを提供します。開発作業は既に進行中で、今後6週間で完了する見込みです。 \n\n\n\n「Force Bridgeを使用してNervos NetworkとCardanoをリンクすることは、IOHKとの間に既に築き上げられている関係を考えても特にエキサイティングです」と、Nervosの共同創業者Kevin Wang氏は語ります。「私たちは研究開発パートナーシップを育ててきましたが、まもなく実際のブリッジを手にすることができます。これはForce Bridgeのパワーを示すショーケースでもあり、機能的かつ相互運用可能なネットワークへとつながる道にいる私たちをさらに前進させるものです」\n\n\n\nこのブリッジは、Nervosとのコラボレーションの一部に過ぎません。「私たちは、相互運用可能なブロックチェーンの「星座」で機能する世界というビジョンを共有しています」とInput OutputのCTO、Romain Pellerinは述べます。「学術研究も暗号界全体を前進させる基盤となっていると信じています。私たちはまた、UTXOモデルの画期的な改良に関する論文の共同執筆、ユニバーサル会計規格の検討、オープンソースの研究を介した分散型技術の今後の開発への協力を予定しています」\n\n\n\nブロックチェーン技術は、エンドユーザーが1つのブロックチェーンや規格に縛られることなく、どのブロックチェーンを使用していようとも、価値やユーティリティにシームレスにアクセスできて初めて、主流に受け入れられるようになります。「このようなブリッジは、ユーザーにシームレスなエクスペリエンスを提供するうえで絶対に欠かせません」とPellerinは続けます。「私たちとNervosが実行しているように、コミュニティを繋げ、協力するための革新的な方法を見つけることにより、より公正で効率的なグローバル金融オペレーティングシステムを創造するという約束を確実に果たすことができるのです」\n\n\n*予定されているパートナーシップと研究イニシアチブについての詳細は、[Nervos website](https://www.nervos.org/)をご覧ください。*\n\n\n\n\n<!--EndFragment-->',
                            uses_mathjax: false,
                            attachments: []
                        }
                    ],
                    lang: 'en',
                    title: 'Nervos partnership to build the first cross-chain bridge with Cardano',
                    subtitle: ' Our new collab lets Cardano and Nervos token holders transmit their value across both platforms while building interoperability across the crypto space',
                    audio: null,
                    soundcloud: [
                        {
                            trackid: 1060596082
                        }
                    ],
                    body_content: '<!--StartFragment-->\n\nIOHK and Nervos are teaming up to build a bridge of interoperability between Cardano and the Nervos Network. Once completed, this pioneering cross-chain bridge will enable users to transact assets between the two blockchains. The end goal is to foster greater interoperability while expanding the global reach and utility of both Nervos and Cardano.\n\n\n\nThe Nervos ‘Common Knowledge Base’ ([CKB](https://coinmarketcap.com/currencies/nervos-network/historical-data/)) is a permissionless, layer 1, open-source, proof-of-work blockchain protocol focused on creating the foundations for an interoperable universal public network. It allows any crypto asset to be kept in a secure, immutable, and permissionless environment with the added benefit of smart contracts and layer 2 scaling. \n\n\n\nNervos is developing this robust network through three key components. Together, these make up the Universal Passport, Nervos’ approach to next generation interoperability. \n\n\n\n* **PW Core** – enables developers to build applications on all chains\n* **Nervos’ Polyjuice** – an Ethereum-compatible layer that allows developers to port a smart contract from Ethereum to Nervos\n* **Force Bridge** – a trustless bridge that enables cross-chain transactions between Nervos and a spectrum of blockchains. Nervos will use Force Bridge to connect directly to Cardano, which means that users will be able to transact using their existing Cardano wallets.\n\n\n\n## Bridging blockchains with transportable tokens\n\n\n\nSo what does this mean in practice? Holders of Nervos CKByte (CKB) and ada will be able to transact both currencies interchangeably. Nervos users will also be able to take advantage of Cardano\'s native asset standard to create tokens that can be ported and used across both networks. On top of this, the bridge enables developers on both chains gain access to services and features to expand their DApp ecosystem and user bases. \n\n\n\n[Mousebelt](https://www.mousebelt.com/), a full-service blockchain accelerator, will build the bridge with financial support from Nervos. The Cardano team will contribute expertise and resources to connect Cardano to the bridge. Development work is already underway and it is expected to be completed in the next six weeks. \n\n\n\n\'Using the Force Bridge to link the Nervos Network and Cardano is especially exciting given the relationship we have already built with IOHK,\' said Kevin Wang, co-founder of Nervos. \'We have been growing our research and development partnership, but we will soon have a tangible bridge that will also showcase the power of the Force Bridge and push us further along the road to a functional and interoperable network.\'\n\n\n\nThis bridge is just part of our collaboration with Nervos. \'We share a vision of a world that works on a ‘constellation’ of interoperating blockchains,\' says Romain Pellerin, CTO at Input Output. \'We believe that academic research is also fundamental to advancing the entire crypto space. Together we will also be co-authoring academic papers to pioneer improvements to the UTXO model, explore universal accounting standards, and contribute to the future development of decentralized technology through open-source research.\'\n\n\n\nBlockchain technology will only achieve mainstream acceptance when end users are not locked into one blockchain or standard, but can seamlessly access value and utility, regardless of which blockchain they are using. \'Bridges like this are an absolute necessity in order to ensure that users have a seamless experience,\' continued Pellerin. ‘By connecting our communities and finding innovative new ways to work together, as we have been doing with Nervos, we can ensure that blockchain lives up to its promises of creating a fairer and more efficient global financial operating system.\'\n\n\n\n*Check out the [Nervos website](https://www.nervos.org/) for more information on upcoming partnerships and research initiatives.*\n\n\n\n<!--EndFragment-->',
                    uses_mathjax: false,
                    attachments: [],
                    slug: 'nervos-partnership-to-build-the-first-cross-chain-bridge-with-cardano',
                    url: '/blog/posts/2021/06/02/nervos-partnership-to-build-the-first-cross-chain-bridge-with-cardano/',
                    read_time: 3
                }
            ],
            total_pages: 44,
            current_page: 1,
            filters: {
                '2016': {
                    '10': 4,
                    '12': 1,
                    __total: 23,
                    '09': 5,
                    '08': 3,
                    '07': 5,
                    '05': 2,
                    '01': 3
                },
                '2017': {
                    '10': 7,
                    '11': 2,
                    '12': 5,
                    __total: 43,
                    '09': 3,
                    '08': 4,
                    '07': 3,
                    '06': 2,
                    '05': 2,
                    '04': 2,
                    '03': 6,
                    '02': 6,
                    '01': 1
                },
                '2018': {
                    '10': 4,
                    '12': 5,
                    __total: 37,
                    '09': 1,
                    '08': 3,
                    '07': 3,
                    '06': 3,
                    '05': 4,
                    '04': 3,
                    '03': 3,
                    '02': 4,
                    '01': 4
                },
                '2019': {
                    '10': 1,
                    '11': 1,
                    '12': 1,
                    __total: 24,
                    '09': 4,
                    '07': 4,
                    '06': 2,
                    '05': 2,
                    '04': 4,
                    '03': 1,
                    '02': 2,
                    '01': 2
                },
                '2020': {
                    '10': 6,
                    '11': 7,
                    '12': 11,
                    __total: 56,
                    '09': 3,
                    '08': 2,
                    '07': 4,
                    '06': 6,
                    '05': 5,
                    '04': 4,
                    '03': 3,
                    '02': 4,
                    '01': 1
                },
                '2021': {
                    __total: 36,
                    '06': 3,
                    '05': 6,
                    '04': 8,
                    '03': 7,
                    '02': 7,
                    '01': 5
                }
            },
            crumbs: [
                {
                    path: '/blog/posts/page-1/',
                    name: 'blog_posts',
                    active: true
                }
            ]
        }
    }
}
